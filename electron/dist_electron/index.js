/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 0);
/******/ })
/************************************************************************/
/******/ ({

/***/ "./node_modules/asn1/lib/ber/errors.js":
/*!*********************************************!*\
  !*** ./node_modules/asn1/lib/ber/errors.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n\nmodule.exports = {\n\n  newInvalidAsn1Error: function (msg) {\n    var e = new Error();\n    e.name = 'InvalidAsn1Error';\n    e.message = msg || '';\n    return e;\n  }\n\n};\n\n\n//# sourceURL=webpack:///./node_modules/asn1/lib/ber/errors.js?");

/***/ }),

/***/ "./node_modules/asn1/lib/ber/index.js":
/*!********************************************!*\
  !*** ./node_modules/asn1/lib/ber/index.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar errors = __webpack_require__(/*! ./errors */ \"./node_modules/asn1/lib/ber/errors.js\");\nvar types = __webpack_require__(/*! ./types */ \"./node_modules/asn1/lib/ber/types.js\");\n\nvar Reader = __webpack_require__(/*! ./reader */ \"./node_modules/asn1/lib/ber/reader.js\");\nvar Writer = __webpack_require__(/*! ./writer */ \"./node_modules/asn1/lib/ber/writer.js\");\n\n\n// --- Exports\n\nmodule.exports = {\n\n  Reader: Reader,\n\n  Writer: Writer\n\n};\n\nfor (var t in types) {\n  if (types.hasOwnProperty(t))\n    module.exports[t] = types[t];\n}\nfor (var e in errors) {\n  if (errors.hasOwnProperty(e))\n    module.exports[e] = errors[e];\n}\n\n\n//# sourceURL=webpack:///./node_modules/asn1/lib/ber/index.js?");

/***/ }),

/***/ "./node_modules/asn1/lib/ber/reader.js":
/*!*********************************************!*\
  !*** ./node_modules/asn1/lib/ber/reader.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar assert = __webpack_require__(/*! assert */ \"assert\");\nvar Buffer = __webpack_require__(/*! safer-buffer */ \"./node_modules/safer-buffer/safer.js\").Buffer;\n\nvar ASN1 = __webpack_require__(/*! ./types */ \"./node_modules/asn1/lib/ber/types.js\");\nvar errors = __webpack_require__(/*! ./errors */ \"./node_modules/asn1/lib/ber/errors.js\");\n\n\n// --- Globals\n\nvar newInvalidAsn1Error = errors.newInvalidAsn1Error;\n\n\n\n// --- API\n\nfunction Reader(data) {\n  if (!data || !Buffer.isBuffer(data))\n    throw new TypeError('data must be a node Buffer');\n\n  this._buf = data;\n  this._size = data.length;\n\n  // These hold the \"current\" state\n  this._len = 0;\n  this._offset = 0;\n}\n\nObject.defineProperty(Reader.prototype, 'length', {\n  enumerable: true,\n  get: function () { return (this._len); }\n});\n\nObject.defineProperty(Reader.prototype, 'offset', {\n  enumerable: true,\n  get: function () { return (this._offset); }\n});\n\nObject.defineProperty(Reader.prototype, 'remain', {\n  get: function () { return (this._size - this._offset); }\n});\n\nObject.defineProperty(Reader.prototype, 'buffer', {\n  get: function () { return (this._buf.slice(this._offset)); }\n});\n\n\n/**\n * Reads a single byte and advances offset; you can pass in `true` to make this\n * a \"peek\" operation (i.e., get the byte, but don't advance the offset).\n *\n * @param {Boolean} peek true means don't move offset.\n * @return {Number} the next byte, null if not enough data.\n */\nReader.prototype.readByte = function (peek) {\n  if (this._size - this._offset < 1)\n    return null;\n\n  var b = this._buf[this._offset] & 0xff;\n\n  if (!peek)\n    this._offset += 1;\n\n  return b;\n};\n\n\nReader.prototype.peek = function () {\n  return this.readByte(true);\n};\n\n\n/**\n * Reads a (potentially) variable length off the BER buffer.  This call is\n * not really meant to be called directly, as callers have to manipulate\n * the internal buffer afterwards.\n *\n * As a result of this call, you can call `Reader.length`, until the\n * next thing called that does a readLength.\n *\n * @return {Number} the amount of offset to advance the buffer.\n * @throws {InvalidAsn1Error} on bad ASN.1\n */\nReader.prototype.readLength = function (offset) {\n  if (offset === undefined)\n    offset = this._offset;\n\n  if (offset >= this._size)\n    return null;\n\n  var lenB = this._buf[offset++] & 0xff;\n  if (lenB === null)\n    return null;\n\n  if ((lenB & 0x80) === 0x80) {\n    lenB &= 0x7f;\n\n    if (lenB === 0)\n      throw newInvalidAsn1Error('Indefinite length not supported');\n\n    if (lenB > 4)\n      throw newInvalidAsn1Error('encoding too long');\n\n    if (this._size - offset < lenB)\n      return null;\n\n    this._len = 0;\n    for (var i = 0; i < lenB; i++)\n      this._len = (this._len << 8) + (this._buf[offset++] & 0xff);\n\n  } else {\n    // Wasn't a variable length\n    this._len = lenB;\n  }\n\n  return offset;\n};\n\n\n/**\n * Parses the next sequence in this BER buffer.\n *\n * To get the length of the sequence, call `Reader.length`.\n *\n * @return {Number} the sequence's tag.\n */\nReader.prototype.readSequence = function (tag) {\n  var seq = this.peek();\n  if (seq === null)\n    return null;\n  if (tag !== undefined && tag !== seq)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + seq.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  this._offset = o;\n  return seq;\n};\n\n\nReader.prototype.readInt = function () {\n  return this._readTag(ASN1.Integer);\n};\n\n\nReader.prototype.readBoolean = function () {\n  return (this._readTag(ASN1.Boolean) === 0 ? false : true);\n};\n\n\nReader.prototype.readEnumeration = function () {\n  return this._readTag(ASN1.Enumeration);\n};\n\n\nReader.prototype.readString = function (tag, retbuf) {\n  if (!tag)\n    tag = ASN1.OctetString;\n\n  var b = this.peek();\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n\n  if (o === null)\n    return null;\n\n  if (this.length > this._size - o)\n    return null;\n\n  this._offset = o;\n\n  if (this.length === 0)\n    return retbuf ? Buffer.alloc(0) : '';\n\n  var str = this._buf.slice(this._offset, this._offset + this.length);\n  this._offset += this.length;\n\n  return retbuf ? str : str.toString('utf8');\n};\n\nReader.prototype.readOID = function (tag) {\n  if (!tag)\n    tag = ASN1.OID;\n\n  var b = this.readString(tag, true);\n  if (b === null)\n    return null;\n\n  var values = [];\n  var value = 0;\n\n  for (var i = 0; i < b.length; i++) {\n    var byte = b[i] & 0xff;\n\n    value <<= 7;\n    value += byte & 0x7f;\n    if ((byte & 0x80) === 0) {\n      values.push(value);\n      value = 0;\n    }\n  }\n\n  value = values.shift();\n  values.unshift(value % 40);\n  values.unshift((value / 40) >> 0);\n\n  return values.join('.');\n};\n\n\nReader.prototype._readTag = function (tag) {\n  assert.ok(tag !== undefined);\n\n  var b = this.peek();\n\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  if (this.length > 4)\n    throw newInvalidAsn1Error('Integer too long: ' + this.length);\n\n  if (this.length > this._size - o)\n    return null;\n  this._offset = o;\n\n  var fb = this._buf[this._offset];\n  var value = 0;\n\n  for (var i = 0; i < this.length; i++) {\n    value <<= 8;\n    value |= (this._buf[this._offset++] & 0xff);\n  }\n\n  if ((fb & 0x80) === 0x80 && i !== 4)\n    value -= (1 << (i * 8));\n\n  return value >> 0;\n};\n\n\n\n// --- Exported API\n\nmodule.exports = Reader;\n\n\n//# sourceURL=webpack:///./node_modules/asn1/lib/ber/reader.js?");

/***/ }),

/***/ "./node_modules/asn1/lib/ber/types.js":
/*!********************************************!*\
  !*** ./node_modules/asn1/lib/ber/types.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n\nmodule.exports = {\n  EOC: 0,\n  Boolean: 1,\n  Integer: 2,\n  BitString: 3,\n  OctetString: 4,\n  Null: 5,\n  OID: 6,\n  ObjectDescriptor: 7,\n  External: 8,\n  Real: 9, // float\n  Enumeration: 10,\n  PDV: 11,\n  Utf8String: 12,\n  RelativeOID: 13,\n  Sequence: 16,\n  Set: 17,\n  NumericString: 18,\n  PrintableString: 19,\n  T61String: 20,\n  VideotexString: 21,\n  IA5String: 22,\n  UTCTime: 23,\n  GeneralizedTime: 24,\n  GraphicString: 25,\n  VisibleString: 26,\n  GeneralString: 28,\n  UniversalString: 29,\n  CharacterString: 30,\n  BMPString: 31,\n  Constructor: 32,\n  Context: 128\n};\n\n\n//# sourceURL=webpack:///./node_modules/asn1/lib/ber/types.js?");

/***/ }),

/***/ "./node_modules/asn1/lib/ber/writer.js":
/*!*********************************************!*\
  !*** ./node_modules/asn1/lib/ber/writer.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar assert = __webpack_require__(/*! assert */ \"assert\");\nvar Buffer = __webpack_require__(/*! safer-buffer */ \"./node_modules/safer-buffer/safer.js\").Buffer;\nvar ASN1 = __webpack_require__(/*! ./types */ \"./node_modules/asn1/lib/ber/types.js\");\nvar errors = __webpack_require__(/*! ./errors */ \"./node_modules/asn1/lib/ber/errors.js\");\n\n\n// --- Globals\n\nvar newInvalidAsn1Error = errors.newInvalidAsn1Error;\n\nvar DEFAULT_OPTS = {\n  size: 1024,\n  growthFactor: 8\n};\n\n\n// --- Helpers\n\nfunction merge(from, to) {\n  assert.ok(from);\n  assert.equal(typeof (from), 'object');\n  assert.ok(to);\n  assert.equal(typeof (to), 'object');\n\n  var keys = Object.getOwnPropertyNames(from);\n  keys.forEach(function (key) {\n    if (to[key])\n      return;\n\n    var value = Object.getOwnPropertyDescriptor(from, key);\n    Object.defineProperty(to, key, value);\n  });\n\n  return to;\n}\n\n\n\n// --- API\n\nfunction Writer(options) {\n  options = merge(DEFAULT_OPTS, options || {});\n\n  this._buf = Buffer.alloc(options.size || 1024);\n  this._size = this._buf.length;\n  this._offset = 0;\n  this._options = options;\n\n  // A list of offsets in the buffer where we need to insert\n  // sequence tag/len pairs.\n  this._seq = [];\n}\n\nObject.defineProperty(Writer.prototype, 'buffer', {\n  get: function () {\n    if (this._seq.length)\n      throw newInvalidAsn1Error(this._seq.length + ' unended sequence(s)');\n\n    return (this._buf.slice(0, this._offset));\n  }\n});\n\nWriter.prototype.writeByte = function (b) {\n  if (typeof (b) !== 'number')\n    throw new TypeError('argument must be a Number');\n\n  this._ensure(1);\n  this._buf[this._offset++] = b;\n};\n\n\nWriter.prototype.writeInt = function (i, tag) {\n  if (typeof (i) !== 'number')\n    throw new TypeError('argument must be a Number');\n  if (typeof (tag) !== 'number')\n    tag = ASN1.Integer;\n\n  var sz = 4;\n\n  while ((((i & 0xff800000) === 0) || ((i & 0xff800000) === 0xff800000 >> 0)) &&\n        (sz > 1)) {\n    sz--;\n    i <<= 8;\n  }\n\n  if (sz > 4)\n    throw newInvalidAsn1Error('BER ints cannot be > 0xffffffff');\n\n  this._ensure(2 + sz);\n  this._buf[this._offset++] = tag;\n  this._buf[this._offset++] = sz;\n\n  while (sz-- > 0) {\n    this._buf[this._offset++] = ((i & 0xff000000) >>> 24);\n    i <<= 8;\n  }\n\n};\n\n\nWriter.prototype.writeNull = function () {\n  this.writeByte(ASN1.Null);\n  this.writeByte(0x00);\n};\n\n\nWriter.prototype.writeEnumeration = function (i, tag) {\n  if (typeof (i) !== 'number')\n    throw new TypeError('argument must be a Number');\n  if (typeof (tag) !== 'number')\n    tag = ASN1.Enumeration;\n\n  return this.writeInt(i, tag);\n};\n\n\nWriter.prototype.writeBoolean = function (b, tag) {\n  if (typeof (b) !== 'boolean')\n    throw new TypeError('argument must be a Boolean');\n  if (typeof (tag) !== 'number')\n    tag = ASN1.Boolean;\n\n  this._ensure(3);\n  this._buf[this._offset++] = tag;\n  this._buf[this._offset++] = 0x01;\n  this._buf[this._offset++] = b ? 0xff : 0x00;\n};\n\n\nWriter.prototype.writeString = function (s, tag) {\n  if (typeof (s) !== 'string')\n    throw new TypeError('argument must be a string (was: ' + typeof (s) + ')');\n  if (typeof (tag) !== 'number')\n    tag = ASN1.OctetString;\n\n  var len = Buffer.byteLength(s);\n  this.writeByte(tag);\n  this.writeLength(len);\n  if (len) {\n    this._ensure(len);\n    this._buf.write(s, this._offset);\n    this._offset += len;\n  }\n};\n\n\nWriter.prototype.writeBuffer = function (buf, tag) {\n  if (typeof (tag) !== 'number')\n    throw new TypeError('tag must be a number');\n  if (!Buffer.isBuffer(buf))\n    throw new TypeError('argument must be a buffer');\n\n  this.writeByte(tag);\n  this.writeLength(buf.length);\n  this._ensure(buf.length);\n  buf.copy(this._buf, this._offset, 0, buf.length);\n  this._offset += buf.length;\n};\n\n\nWriter.prototype.writeStringArray = function (strings) {\n  if ((!strings instanceof Array))\n    throw new TypeError('argument must be an Array[String]');\n\n  var self = this;\n  strings.forEach(function (s) {\n    self.writeString(s);\n  });\n};\n\n// This is really to solve DER cases, but whatever for now\nWriter.prototype.writeOID = function (s, tag) {\n  if (typeof (s) !== 'string')\n    throw new TypeError('argument must be a string');\n  if (typeof (tag) !== 'number')\n    tag = ASN1.OID;\n\n  if (!/^([0-9]+\\.){3,}[0-9]+$/.test(s))\n    throw new Error('argument is not a valid OID string');\n\n  function encodeOctet(bytes, octet) {\n    if (octet < 128) {\n        bytes.push(octet);\n    } else if (octet < 16384) {\n        bytes.push((octet >>> 7) | 0x80);\n        bytes.push(octet & 0x7F);\n    } else if (octet < 2097152) {\n      bytes.push((octet >>> 14) | 0x80);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    } else if (octet < 268435456) {\n      bytes.push((octet >>> 21) | 0x80);\n      bytes.push(((octet >>> 14) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    } else {\n      bytes.push(((octet >>> 28) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 21) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 14) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    }\n  }\n\n  var tmp = s.split('.');\n  var bytes = [];\n  bytes.push(parseInt(tmp[0], 10) * 40 + parseInt(tmp[1], 10));\n  tmp.slice(2).forEach(function (b) {\n    encodeOctet(bytes, parseInt(b, 10));\n  });\n\n  var self = this;\n  this._ensure(2 + bytes.length);\n  this.writeByte(tag);\n  this.writeLength(bytes.length);\n  bytes.forEach(function (b) {\n    self.writeByte(b);\n  });\n};\n\n\nWriter.prototype.writeLength = function (len) {\n  if (typeof (len) !== 'number')\n    throw new TypeError('argument must be a Number');\n\n  this._ensure(4);\n\n  if (len <= 0x7f) {\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xff) {\n    this._buf[this._offset++] = 0x81;\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xffff) {\n    this._buf[this._offset++] = 0x82;\n    this._buf[this._offset++] = len >> 8;\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xffffff) {\n    this._buf[this._offset++] = 0x83;\n    this._buf[this._offset++] = len >> 16;\n    this._buf[this._offset++] = len >> 8;\n    this._buf[this._offset++] = len;\n  } else {\n    throw newInvalidAsn1Error('Length too long (> 4 bytes)');\n  }\n};\n\nWriter.prototype.startSequence = function (tag) {\n  if (typeof (tag) !== 'number')\n    tag = ASN1.Sequence | ASN1.Constructor;\n\n  this.writeByte(tag);\n  this._seq.push(this._offset);\n  this._ensure(3);\n  this._offset += 3;\n};\n\n\nWriter.prototype.endSequence = function () {\n  var seq = this._seq.pop();\n  var start = seq + 3;\n  var len = this._offset - start;\n\n  if (len <= 0x7f) {\n    this._shift(start, len, -2);\n    this._buf[seq] = len;\n  } else if (len <= 0xff) {\n    this._shift(start, len, -1);\n    this._buf[seq] = 0x81;\n    this._buf[seq + 1] = len;\n  } else if (len <= 0xffff) {\n    this._buf[seq] = 0x82;\n    this._buf[seq + 1] = len >> 8;\n    this._buf[seq + 2] = len;\n  } else if (len <= 0xffffff) {\n    this._shift(start, len, 1);\n    this._buf[seq] = 0x83;\n    this._buf[seq + 1] = len >> 16;\n    this._buf[seq + 2] = len >> 8;\n    this._buf[seq + 3] = len;\n  } else {\n    throw newInvalidAsn1Error('Sequence too long');\n  }\n};\n\n\nWriter.prototype._shift = function (start, len, shift) {\n  assert.ok(start !== undefined);\n  assert.ok(len !== undefined);\n  assert.ok(shift);\n\n  this._buf.copy(this._buf, start + shift, start, start + len);\n  this._offset += shift;\n};\n\nWriter.prototype._ensure = function (len) {\n  assert.ok(len);\n\n  if (this._size - this._offset < len) {\n    var sz = this._size * this._options.growthFactor;\n    if (sz - this._offset < len)\n      sz += len;\n\n    var buf = Buffer.alloc(sz);\n\n    this._buf.copy(buf, 0, 0, this._offset);\n    this._buf = buf;\n    this._size = sz;\n  }\n};\n\n\n\n// --- Exported API\n\nmodule.exports = Writer;\n\n\n//# sourceURL=webpack:///./node_modules/asn1/lib/ber/writer.js?");

/***/ }),

/***/ "./node_modules/asn1/lib/index.js":
/*!****************************************!*\
  !*** ./node_modules/asn1/lib/index.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n// If you have no idea what ASN.1 or BER is, see this:\n// ftp://ftp.rsa.com/pub/pkcs/ascii/layman.asc\n\nvar Ber = __webpack_require__(/*! ./ber/index */ \"./node_modules/asn1/lib/ber/index.js\");\n\n\n\n// --- Exported API\n\nmodule.exports = {\n\n  Ber: Ber,\n\n  BerReader: Ber.Reader,\n\n  BerWriter: Ber.Writer\n\n};\n\n\n//# sourceURL=webpack:///./node_modules/asn1/lib/index.js?");

/***/ }),

/***/ "./node_modules/async/lib/async.js":
/*!*****************************************!*\
  !*** ./node_modules/async/lib/async.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/*!\n * async\n * https://github.com/caolan/async\n *\n * Copyright 2010-2014 Caolan McMahon\n * Released under the MIT license\n */\n(function () {\n\n    var async = {};\n    function noop() {}\n    function identity(v) {\n        return v;\n    }\n    function toBool(v) {\n        return !!v;\n    }\n    function notId(v) {\n        return !v;\n    }\n\n    // global on the server, window in the browser\n    var previous_async;\n\n    // Establish the root object, `window` (`self`) in the browser, `global`\n    // on the server, or `this` in some virtual machines. We use `self`\n    // instead of `window` for `WebWorker` support.\n    var root = typeof self === 'object' && self.self === self && self ||\n            typeof global === 'object' && global.global === global && global ||\n            this;\n\n    if (root != null) {\n        previous_async = root.async;\n    }\n\n    async.noConflict = function () {\n        root.async = previous_async;\n        return async;\n    };\n\n    function only_once(fn) {\n        return function() {\n            if (fn === null) throw new Error(\"Callback was already called.\");\n            fn.apply(this, arguments);\n            fn = null;\n        };\n    }\n\n    function _once(fn) {\n        return function() {\n            if (fn === null) return;\n            fn.apply(this, arguments);\n            fn = null;\n        };\n    }\n\n    //// cross-browser compatiblity functions ////\n\n    var _toString = Object.prototype.toString;\n\n    var _isArray = Array.isArray || function (obj) {\n        return _toString.call(obj) === '[object Array]';\n    };\n\n    // Ported from underscore.js isObject\n    var _isObject = function(obj) {\n        var type = typeof obj;\n        return type === 'function' || type === 'object' && !!obj;\n    };\n\n    function _isArrayLike(arr) {\n        return _isArray(arr) || (\n            // has a positive integer length property\n            typeof arr.length === \"number\" &&\n            arr.length >= 0 &&\n            arr.length % 1 === 0\n        );\n    }\n\n    function _arrayEach(arr, iterator) {\n        var index = -1,\n            length = arr.length;\n\n        while (++index < length) {\n            iterator(arr[index], index, arr);\n        }\n    }\n\n    function _map(arr, iterator) {\n        var index = -1,\n            length = arr.length,\n            result = Array(length);\n\n        while (++index < length) {\n            result[index] = iterator(arr[index], index, arr);\n        }\n        return result;\n    }\n\n    function _range(count) {\n        return _map(Array(count), function (v, i) { return i; });\n    }\n\n    function _reduce(arr, iterator, memo) {\n        _arrayEach(arr, function (x, i, a) {\n            memo = iterator(memo, x, i, a);\n        });\n        return memo;\n    }\n\n    function _forEachOf(object, iterator) {\n        _arrayEach(_keys(object), function (key) {\n            iterator(object[key], key);\n        });\n    }\n\n    function _indexOf(arr, item) {\n        for (var i = 0; i < arr.length; i++) {\n            if (arr[i] === item) return i;\n        }\n        return -1;\n    }\n\n    var _keys = Object.keys || function (obj) {\n        var keys = [];\n        for (var k in obj) {\n            if (obj.hasOwnProperty(k)) {\n                keys.push(k);\n            }\n        }\n        return keys;\n    };\n\n    function _keyIterator(coll) {\n        var i = -1;\n        var len;\n        var keys;\n        if (_isArrayLike(coll)) {\n            len = coll.length;\n            return function next() {\n                i++;\n                return i < len ? i : null;\n            };\n        } else {\n            keys = _keys(coll);\n            len = keys.length;\n            return function next() {\n                i++;\n                return i < len ? keys[i] : null;\n            };\n        }\n    }\n\n    // Similar to ES6's rest param (http://ariya.ofilabs.com/2013/03/es6-and-rest-parameter.html)\n    // This accumulates the arguments passed into an array, after a given index.\n    // From underscore.js (https://github.com/jashkenas/underscore/pull/2140).\n    function _restParam(func, startIndex) {\n        startIndex = startIndex == null ? func.length - 1 : +startIndex;\n        return function() {\n            var length = Math.max(arguments.length - startIndex, 0);\n            var rest = Array(length);\n            for (var index = 0; index < length; index++) {\n                rest[index] = arguments[index + startIndex];\n            }\n            switch (startIndex) {\n                case 0: return func.call(this, rest);\n                case 1: return func.call(this, arguments[0], rest);\n            }\n            // Currently unused but handle cases outside of the switch statement:\n            // var args = Array(startIndex + 1);\n            // for (index = 0; index < startIndex; index++) {\n            //     args[index] = arguments[index];\n            // }\n            // args[startIndex] = rest;\n            // return func.apply(this, args);\n        };\n    }\n\n    function _withoutIndex(iterator) {\n        return function (value, index, callback) {\n            return iterator(value, callback);\n        };\n    }\n\n    //// exported async module functions ////\n\n    //// nextTick implementation with browser-compatible fallback ////\n\n    // capture the global reference to guard against fakeTimer mocks\n    var _setImmediate = typeof setImmediate === 'function' && setImmediate;\n\n    var _delay = _setImmediate ? function(fn) {\n        // not a direct alias for IE10 compatibility\n        _setImmediate(fn);\n    } : function(fn) {\n        setTimeout(fn, 0);\n    };\n\n    if (typeof process === 'object' && typeof process.nextTick === 'function') {\n        async.nextTick = process.nextTick;\n    } else {\n        async.nextTick = _delay;\n    }\n    async.setImmediate = _setImmediate ? _delay : async.nextTick;\n\n\n    async.forEach =\n    async.each = function (arr, iterator, callback) {\n        return async.eachOf(arr, _withoutIndex(iterator), callback);\n    };\n\n    async.forEachSeries =\n    async.eachSeries = function (arr, iterator, callback) {\n        return async.eachOfSeries(arr, _withoutIndex(iterator), callback);\n    };\n\n\n    async.forEachLimit =\n    async.eachLimit = function (arr, limit, iterator, callback) {\n        return _eachOfLimit(limit)(arr, _withoutIndex(iterator), callback);\n    };\n\n    async.forEachOf =\n    async.eachOf = function (object, iterator, callback) {\n        callback = _once(callback || noop);\n        object = object || [];\n\n        var iter = _keyIterator(object);\n        var key, completed = 0;\n\n        while ((key = iter()) != null) {\n            completed += 1;\n            iterator(object[key], key, only_once(done));\n        }\n\n        if (completed === 0) callback(null);\n\n        function done(err) {\n            completed--;\n            if (err) {\n                callback(err);\n            }\n            // Check key is null in case iterator isn't exhausted\n            // and done resolved synchronously.\n            else if (key === null && completed <= 0) {\n                callback(null);\n            }\n        }\n    };\n\n    async.forEachOfSeries =\n    async.eachOfSeries = function (obj, iterator, callback) {\n        callback = _once(callback || noop);\n        obj = obj || [];\n        var nextKey = _keyIterator(obj);\n        var key = nextKey();\n        function iterate() {\n            var sync = true;\n            if (key === null) {\n                return callback(null);\n            }\n            iterator(obj[key], key, only_once(function (err) {\n                if (err) {\n                    callback(err);\n                }\n                else {\n                    key = nextKey();\n                    if (key === null) {\n                        return callback(null);\n                    } else {\n                        if (sync) {\n                            async.setImmediate(iterate);\n                        } else {\n                            iterate();\n                        }\n                    }\n                }\n            }));\n            sync = false;\n        }\n        iterate();\n    };\n\n\n\n    async.forEachOfLimit =\n    async.eachOfLimit = function (obj, limit, iterator, callback) {\n        _eachOfLimit(limit)(obj, iterator, callback);\n    };\n\n    function _eachOfLimit(limit) {\n\n        return function (obj, iterator, callback) {\n            callback = _once(callback || noop);\n            obj = obj || [];\n            var nextKey = _keyIterator(obj);\n            if (limit <= 0) {\n                return callback(null);\n            }\n            var done = false;\n            var running = 0;\n            var errored = false;\n\n            (function replenish () {\n                if (done && running <= 0) {\n                    return callback(null);\n                }\n\n                while (running < limit && !errored) {\n                    var key = nextKey();\n                    if (key === null) {\n                        done = true;\n                        if (running <= 0) {\n                            callback(null);\n                        }\n                        return;\n                    }\n                    running += 1;\n                    iterator(obj[key], key, only_once(function (err) {\n                        running -= 1;\n                        if (err) {\n                            callback(err);\n                            errored = true;\n                        }\n                        else {\n                            replenish();\n                        }\n                    }));\n                }\n            })();\n        };\n    }\n\n\n    function doParallel(fn) {\n        return function (obj, iterator, callback) {\n            return fn(async.eachOf, obj, iterator, callback);\n        };\n    }\n    function doParallelLimit(fn) {\n        return function (obj, limit, iterator, callback) {\n            return fn(_eachOfLimit(limit), obj, iterator, callback);\n        };\n    }\n    function doSeries(fn) {\n        return function (obj, iterator, callback) {\n            return fn(async.eachOfSeries, obj, iterator, callback);\n        };\n    }\n\n    function _asyncMap(eachfn, arr, iterator, callback) {\n        callback = _once(callback || noop);\n        arr = arr || [];\n        var results = _isArrayLike(arr) ? [] : {};\n        eachfn(arr, function (value, index, callback) {\n            iterator(value, function (err, v) {\n                results[index] = v;\n                callback(err);\n            });\n        }, function (err) {\n            callback(err, results);\n        });\n    }\n\n    async.map = doParallel(_asyncMap);\n    async.mapSeries = doSeries(_asyncMap);\n    async.mapLimit = doParallelLimit(_asyncMap);\n\n    // reduce only has a series version, as doing reduce in parallel won't\n    // work in many situations.\n    async.inject =\n    async.foldl =\n    async.reduce = function (arr, memo, iterator, callback) {\n        async.eachOfSeries(arr, function (x, i, callback) {\n            iterator(memo, x, function (err, v) {\n                memo = v;\n                callback(err);\n            });\n        }, function (err) {\n            callback(err, memo);\n        });\n    };\n\n    async.foldr =\n    async.reduceRight = function (arr, memo, iterator, callback) {\n        var reversed = _map(arr, identity).reverse();\n        async.reduce(reversed, memo, iterator, callback);\n    };\n\n    async.transform = function (arr, memo, iterator, callback) {\n        if (arguments.length === 3) {\n            callback = iterator;\n            iterator = memo;\n            memo = _isArray(arr) ? [] : {};\n        }\n\n        async.eachOf(arr, function(v, k, cb) {\n            iterator(memo, v, k, cb);\n        }, function(err) {\n            callback(err, memo);\n        });\n    };\n\n    function _filter(eachfn, arr, iterator, callback) {\n        var results = [];\n        eachfn(arr, function (x, index, callback) {\n            iterator(x, function (v) {\n                if (v) {\n                    results.push({index: index, value: x});\n                }\n                callback();\n            });\n        }, function () {\n            callback(_map(results.sort(function (a, b) {\n                return a.index - b.index;\n            }), function (x) {\n                return x.value;\n            }));\n        });\n    }\n\n    async.select =\n    async.filter = doParallel(_filter);\n\n    async.selectLimit =\n    async.filterLimit = doParallelLimit(_filter);\n\n    async.selectSeries =\n    async.filterSeries = doSeries(_filter);\n\n    function _reject(eachfn, arr, iterator, callback) {\n        _filter(eachfn, arr, function(value, cb) {\n            iterator(value, function(v) {\n                cb(!v);\n            });\n        }, callback);\n    }\n    async.reject = doParallel(_reject);\n    async.rejectLimit = doParallelLimit(_reject);\n    async.rejectSeries = doSeries(_reject);\n\n    function _createTester(eachfn, check, getResult) {\n        return function(arr, limit, iterator, cb) {\n            function done() {\n                if (cb) cb(getResult(false, void 0));\n            }\n            function iteratee(x, _, callback) {\n                if (!cb) return callback();\n                iterator(x, function (v) {\n                    if (cb && check(v)) {\n                        cb(getResult(true, x));\n                        cb = iterator = false;\n                    }\n                    callback();\n                });\n            }\n            if (arguments.length > 3) {\n                eachfn(arr, limit, iteratee, done);\n            } else {\n                cb = iterator;\n                iterator = limit;\n                eachfn(arr, iteratee, done);\n            }\n        };\n    }\n\n    async.any =\n    async.some = _createTester(async.eachOf, toBool, identity);\n\n    async.someLimit = _createTester(async.eachOfLimit, toBool, identity);\n\n    async.all =\n    async.every = _createTester(async.eachOf, notId, notId);\n\n    async.everyLimit = _createTester(async.eachOfLimit, notId, notId);\n\n    function _findGetResult(v, x) {\n        return x;\n    }\n    async.detect = _createTester(async.eachOf, identity, _findGetResult);\n    async.detectSeries = _createTester(async.eachOfSeries, identity, _findGetResult);\n    async.detectLimit = _createTester(async.eachOfLimit, identity, _findGetResult);\n\n    async.sortBy = function (arr, iterator, callback) {\n        async.map(arr, function (x, callback) {\n            iterator(x, function (err, criteria) {\n                if (err) {\n                    callback(err);\n                }\n                else {\n                    callback(null, {value: x, criteria: criteria});\n                }\n            });\n        }, function (err, results) {\n            if (err) {\n                return callback(err);\n            }\n            else {\n                callback(null, _map(results.sort(comparator), function (x) {\n                    return x.value;\n                }));\n            }\n\n        });\n\n        function comparator(left, right) {\n            var a = left.criteria, b = right.criteria;\n            return a < b ? -1 : a > b ? 1 : 0;\n        }\n    };\n\n    async.auto = function (tasks, concurrency, callback) {\n        if (typeof arguments[1] === 'function') {\n            // concurrency is optional, shift the args.\n            callback = concurrency;\n            concurrency = null;\n        }\n        callback = _once(callback || noop);\n        var keys = _keys(tasks);\n        var remainingTasks = keys.length;\n        if (!remainingTasks) {\n            return callback(null);\n        }\n        if (!concurrency) {\n            concurrency = remainingTasks;\n        }\n\n        var results = {};\n        var runningTasks = 0;\n\n        var hasError = false;\n\n        var listeners = [];\n        function addListener(fn) {\n            listeners.unshift(fn);\n        }\n        function removeListener(fn) {\n            var idx = _indexOf(listeners, fn);\n            if (idx >= 0) listeners.splice(idx, 1);\n        }\n        function taskComplete() {\n            remainingTasks--;\n            _arrayEach(listeners.slice(0), function (fn) {\n                fn();\n            });\n        }\n\n        addListener(function () {\n            if (!remainingTasks) {\n                callback(null, results);\n            }\n        });\n\n        _arrayEach(keys, function (k) {\n            if (hasError) return;\n            var task = _isArray(tasks[k]) ? tasks[k]: [tasks[k]];\n            var taskCallback = _restParam(function(err, args) {\n                runningTasks--;\n                if (args.length <= 1) {\n                    args = args[0];\n                }\n                if (err) {\n                    var safeResults = {};\n                    _forEachOf(results, function(val, rkey) {\n                        safeResults[rkey] = val;\n                    });\n                    safeResults[k] = args;\n                    hasError = true;\n\n                    callback(err, safeResults);\n                }\n                else {\n                    results[k] = args;\n                    async.setImmediate(taskComplete);\n                }\n            });\n            var requires = task.slice(0, task.length - 1);\n            // prevent dead-locks\n            var len = requires.length;\n            var dep;\n            while (len--) {\n                if (!(dep = tasks[requires[len]])) {\n                    throw new Error('Has nonexistent dependency in ' + requires.join(', '));\n                }\n                if (_isArray(dep) && _indexOf(dep, k) >= 0) {\n                    throw new Error('Has cyclic dependencies');\n                }\n            }\n            function ready() {\n                return runningTasks < concurrency && _reduce(requires, function (a, x) {\n                    return (a && results.hasOwnProperty(x));\n                }, true) && !results.hasOwnProperty(k);\n            }\n            if (ready()) {\n                runningTasks++;\n                task[task.length - 1](taskCallback, results);\n            }\n            else {\n                addListener(listener);\n            }\n            function listener() {\n                if (ready()) {\n                    runningTasks++;\n                    removeListener(listener);\n                    task[task.length - 1](taskCallback, results);\n                }\n            }\n        });\n    };\n\n\n\n    async.retry = function(times, task, callback) {\n        var DEFAULT_TIMES = 5;\n        var DEFAULT_INTERVAL = 0;\n\n        var attempts = [];\n\n        var opts = {\n            times: DEFAULT_TIMES,\n            interval: DEFAULT_INTERVAL\n        };\n\n        function parseTimes(acc, t){\n            if(typeof t === 'number'){\n                acc.times = parseInt(t, 10) || DEFAULT_TIMES;\n            } else if(typeof t === 'object'){\n                acc.times = parseInt(t.times, 10) || DEFAULT_TIMES;\n                acc.interval = parseInt(t.interval, 10) || DEFAULT_INTERVAL;\n            } else {\n                throw new Error('Unsupported argument type for \\'times\\': ' + typeof t);\n            }\n        }\n\n        var length = arguments.length;\n        if (length < 1 || length > 3) {\n            throw new Error('Invalid arguments - must be either (task), (task, callback), (times, task) or (times, task, callback)');\n        } else if (length <= 2 && typeof times === 'function') {\n            callback = task;\n            task = times;\n        }\n        if (typeof times !== 'function') {\n            parseTimes(opts, times);\n        }\n        opts.callback = callback;\n        opts.task = task;\n\n        function wrappedTask(wrappedCallback, wrappedResults) {\n            function retryAttempt(task, finalAttempt) {\n                return function(seriesCallback) {\n                    task(function(err, result){\n                        seriesCallback(!err || finalAttempt, {err: err, result: result});\n                    }, wrappedResults);\n                };\n            }\n\n            function retryInterval(interval){\n                return function(seriesCallback){\n                    setTimeout(function(){\n                        seriesCallback(null);\n                    }, interval);\n                };\n            }\n\n            while (opts.times) {\n\n                var finalAttempt = !(opts.times-=1);\n                attempts.push(retryAttempt(opts.task, finalAttempt));\n                if(!finalAttempt && opts.interval > 0){\n                    attempts.push(retryInterval(opts.interval));\n                }\n            }\n\n            async.series(attempts, function(done, data){\n                data = data[data.length - 1];\n                (wrappedCallback || opts.callback)(data.err, data.result);\n            });\n        }\n\n        // If a callback is passed, run this as a controll flow\n        return opts.callback ? wrappedTask() : wrappedTask;\n    };\n\n    async.waterfall = function (tasks, callback) {\n        callback = _once(callback || noop);\n        if (!_isArray(tasks)) {\n            var err = new Error('First argument to waterfall must be an array of functions');\n            return callback(err);\n        }\n        if (!tasks.length) {\n            return callback();\n        }\n        function wrapIterator(iterator) {\n            return _restParam(function (err, args) {\n                if (err) {\n                    callback.apply(null, [err].concat(args));\n                }\n                else {\n                    var next = iterator.next();\n                    if (next) {\n                        args.push(wrapIterator(next));\n                    }\n                    else {\n                        args.push(callback);\n                    }\n                    ensureAsync(iterator).apply(null, args);\n                }\n            });\n        }\n        wrapIterator(async.iterator(tasks))();\n    };\n\n    function _parallel(eachfn, tasks, callback) {\n        callback = callback || noop;\n        var results = _isArrayLike(tasks) ? [] : {};\n\n        eachfn(tasks, function (task, key, callback) {\n            task(_restParam(function (err, args) {\n                if (args.length <= 1) {\n                    args = args[0];\n                }\n                results[key] = args;\n                callback(err);\n            }));\n        }, function (err) {\n            callback(err, results);\n        });\n    }\n\n    async.parallel = function (tasks, callback) {\n        _parallel(async.eachOf, tasks, callback);\n    };\n\n    async.parallelLimit = function(tasks, limit, callback) {\n        _parallel(_eachOfLimit(limit), tasks, callback);\n    };\n\n    async.series = function(tasks, callback) {\n        _parallel(async.eachOfSeries, tasks, callback);\n    };\n\n    async.iterator = function (tasks) {\n        function makeCallback(index) {\n            function fn() {\n                if (tasks.length) {\n                    tasks[index].apply(null, arguments);\n                }\n                return fn.next();\n            }\n            fn.next = function () {\n                return (index < tasks.length - 1) ? makeCallback(index + 1): null;\n            };\n            return fn;\n        }\n        return makeCallback(0);\n    };\n\n    async.apply = _restParam(function (fn, args) {\n        return _restParam(function (callArgs) {\n            return fn.apply(\n                null, args.concat(callArgs)\n            );\n        });\n    });\n\n    function _concat(eachfn, arr, fn, callback) {\n        var result = [];\n        eachfn(arr, function (x, index, cb) {\n            fn(x, function (err, y) {\n                result = result.concat(y || []);\n                cb(err);\n            });\n        }, function (err) {\n            callback(err, result);\n        });\n    }\n    async.concat = doParallel(_concat);\n    async.concatSeries = doSeries(_concat);\n\n    async.whilst = function (test, iterator, callback) {\n        callback = callback || noop;\n        if (test()) {\n            var next = _restParam(function(err, args) {\n                if (err) {\n                    callback(err);\n                } else if (test.apply(this, args)) {\n                    iterator(next);\n                } else {\n                    callback.apply(null, [null].concat(args));\n                }\n            });\n            iterator(next);\n        } else {\n            callback(null);\n        }\n    };\n\n    async.doWhilst = function (iterator, test, callback) {\n        var calls = 0;\n        return async.whilst(function() {\n            return ++calls <= 1 || test.apply(this, arguments);\n        }, iterator, callback);\n    };\n\n    async.until = function (test, iterator, callback) {\n        return async.whilst(function() {\n            return !test.apply(this, arguments);\n        }, iterator, callback);\n    };\n\n    async.doUntil = function (iterator, test, callback) {\n        return async.doWhilst(iterator, function() {\n            return !test.apply(this, arguments);\n        }, callback);\n    };\n\n    async.during = function (test, iterator, callback) {\n        callback = callback || noop;\n\n        var next = _restParam(function(err, args) {\n            if (err) {\n                callback(err);\n            } else {\n                args.push(check);\n                test.apply(this, args);\n            }\n        });\n\n        var check = function(err, truth) {\n            if (err) {\n                callback(err);\n            } else if (truth) {\n                iterator(next);\n            } else {\n                callback(null);\n            }\n        };\n\n        test(check);\n    };\n\n    async.doDuring = function (iterator, test, callback) {\n        var calls = 0;\n        async.during(function(next) {\n            if (calls++ < 1) {\n                next(null, true);\n            } else {\n                test.apply(this, arguments);\n            }\n        }, iterator, callback);\n    };\n\n    function _queue(worker, concurrency, payload) {\n        if (concurrency == null) {\n            concurrency = 1;\n        }\n        else if(concurrency === 0) {\n            throw new Error('Concurrency must not be zero');\n        }\n        function _insert(q, data, pos, callback) {\n            if (callback != null && typeof callback !== \"function\") {\n                throw new Error(\"task callback must be a function\");\n            }\n            q.started = true;\n            if (!_isArray(data)) {\n                data = [data];\n            }\n            if(data.length === 0 && q.idle()) {\n                // call drain immediately if there are no tasks\n                return async.setImmediate(function() {\n                    q.drain();\n                });\n            }\n            _arrayEach(data, function(task) {\n                var item = {\n                    data: task,\n                    callback: callback || noop\n                };\n\n                if (pos) {\n                    q.tasks.unshift(item);\n                } else {\n                    q.tasks.push(item);\n                }\n\n                if (q.tasks.length === q.concurrency) {\n                    q.saturated();\n                }\n            });\n            async.setImmediate(q.process);\n        }\n        function _next(q, tasks) {\n            return function(){\n                workers -= 1;\n\n                var removed = false;\n                var args = arguments;\n                _arrayEach(tasks, function (task) {\n                    _arrayEach(workersList, function (worker, index) {\n                        if (worker === task && !removed) {\n                            workersList.splice(index, 1);\n                            removed = true;\n                        }\n                    });\n\n                    task.callback.apply(task, args);\n                });\n                if (q.tasks.length + workers === 0) {\n                    q.drain();\n                }\n                q.process();\n            };\n        }\n\n        var workers = 0;\n        var workersList = [];\n        var q = {\n            tasks: [],\n            concurrency: concurrency,\n            payload: payload,\n            saturated: noop,\n            empty: noop,\n            drain: noop,\n            started: false,\n            paused: false,\n            push: function (data, callback) {\n                _insert(q, data, false, callback);\n            },\n            kill: function () {\n                q.drain = noop;\n                q.tasks = [];\n            },\n            unshift: function (data, callback) {\n                _insert(q, data, true, callback);\n            },\n            process: function () {\n                while(!q.paused && workers < q.concurrency && q.tasks.length){\n\n                    var tasks = q.payload ?\n                        q.tasks.splice(0, q.payload) :\n                        q.tasks.splice(0, q.tasks.length);\n\n                    var data = _map(tasks, function (task) {\n                        return task.data;\n                    });\n\n                    if (q.tasks.length === 0) {\n                        q.empty();\n                    }\n                    workers += 1;\n                    workersList.push(tasks[0]);\n                    var cb = only_once(_next(q, tasks));\n                    worker(data, cb);\n                }\n            },\n            length: function () {\n                return q.tasks.length;\n            },\n            running: function () {\n                return workers;\n            },\n            workersList: function () {\n                return workersList;\n            },\n            idle: function() {\n                return q.tasks.length + workers === 0;\n            },\n            pause: function () {\n                q.paused = true;\n            },\n            resume: function () {\n                if (q.paused === false) { return; }\n                q.paused = false;\n                var resumeCount = Math.min(q.concurrency, q.tasks.length);\n                // Need to call q.process once per concurrent\n                // worker to preserve full concurrency after pause\n                for (var w = 1; w <= resumeCount; w++) {\n                    async.setImmediate(q.process);\n                }\n            }\n        };\n        return q;\n    }\n\n    async.queue = function (worker, concurrency) {\n        var q = _queue(function (items, cb) {\n            worker(items[0], cb);\n        }, concurrency, 1);\n\n        return q;\n    };\n\n    async.priorityQueue = function (worker, concurrency) {\n\n        function _compareTasks(a, b){\n            return a.priority - b.priority;\n        }\n\n        function _binarySearch(sequence, item, compare) {\n            var beg = -1,\n                end = sequence.length - 1;\n            while (beg < end) {\n                var mid = beg + ((end - beg + 1) >>> 1);\n                if (compare(item, sequence[mid]) >= 0) {\n                    beg = mid;\n                } else {\n                    end = mid - 1;\n                }\n            }\n            return beg;\n        }\n\n        function _insert(q, data, priority, callback) {\n            if (callback != null && typeof callback !== \"function\") {\n                throw new Error(\"task callback must be a function\");\n            }\n            q.started = true;\n            if (!_isArray(data)) {\n                data = [data];\n            }\n            if(data.length === 0) {\n                // call drain immediately if there are no tasks\n                return async.setImmediate(function() {\n                    q.drain();\n                });\n            }\n            _arrayEach(data, function(task) {\n                var item = {\n                    data: task,\n                    priority: priority,\n                    callback: typeof callback === 'function' ? callback : noop\n                };\n\n                q.tasks.splice(_binarySearch(q.tasks, item, _compareTasks) + 1, 0, item);\n\n                if (q.tasks.length === q.concurrency) {\n                    q.saturated();\n                }\n                async.setImmediate(q.process);\n            });\n        }\n\n        // Start with a normal queue\n        var q = async.queue(worker, concurrency);\n\n        // Override push to accept second parameter representing priority\n        q.push = function (data, priority, callback) {\n            _insert(q, data, priority, callback);\n        };\n\n        // Remove unshift function\n        delete q.unshift;\n\n        return q;\n    };\n\n    async.cargo = function (worker, payload) {\n        return _queue(worker, 1, payload);\n    };\n\n    function _console_fn(name) {\n        return _restParam(function (fn, args) {\n            fn.apply(null, args.concat([_restParam(function (err, args) {\n                if (typeof console === 'object') {\n                    if (err) {\n                        if (console.error) {\n                            console.error(err);\n                        }\n                    }\n                    else if (console[name]) {\n                        _arrayEach(args, function (x) {\n                            console[name](x);\n                        });\n                    }\n                }\n            })]));\n        });\n    }\n    async.log = _console_fn('log');\n    async.dir = _console_fn('dir');\n    /*async.info = _console_fn('info');\n    async.warn = _console_fn('warn');\n    async.error = _console_fn('error');*/\n\n    async.memoize = function (fn, hasher) {\n        var memo = {};\n        var queues = {};\n        var has = Object.prototype.hasOwnProperty;\n        hasher = hasher || identity;\n        var memoized = _restParam(function memoized(args) {\n            var callback = args.pop();\n            var key = hasher.apply(null, args);\n            if (has.call(memo, key)) {   \n                async.setImmediate(function () {\n                    callback.apply(null, memo[key]);\n                });\n            }\n            else if (has.call(queues, key)) {\n                queues[key].push(callback);\n            }\n            else {\n                queues[key] = [callback];\n                fn.apply(null, args.concat([_restParam(function (args) {\n                    memo[key] = args;\n                    var q = queues[key];\n                    delete queues[key];\n                    for (var i = 0, l = q.length; i < l; i++) {\n                        q[i].apply(null, args);\n                    }\n                })]));\n            }\n        });\n        memoized.memo = memo;\n        memoized.unmemoized = fn;\n        return memoized;\n    };\n\n    async.unmemoize = function (fn) {\n        return function () {\n            return (fn.unmemoized || fn).apply(null, arguments);\n        };\n    };\n\n    function _times(mapper) {\n        return function (count, iterator, callback) {\n            mapper(_range(count), iterator, callback);\n        };\n    }\n\n    async.times = _times(async.map);\n    async.timesSeries = _times(async.mapSeries);\n    async.timesLimit = function (count, limit, iterator, callback) {\n        return async.mapLimit(_range(count), limit, iterator, callback);\n    };\n\n    async.seq = function (/* functions... */) {\n        var fns = arguments;\n        return _restParam(function (args) {\n            var that = this;\n\n            var callback = args[args.length - 1];\n            if (typeof callback == 'function') {\n                args.pop();\n            } else {\n                callback = noop;\n            }\n\n            async.reduce(fns, args, function (newargs, fn, cb) {\n                fn.apply(that, newargs.concat([_restParam(function (err, nextargs) {\n                    cb(err, nextargs);\n                })]));\n            },\n            function (err, results) {\n                callback.apply(that, [err].concat(results));\n            });\n        });\n    };\n\n    async.compose = function (/* functions... */) {\n        return async.seq.apply(null, Array.prototype.reverse.call(arguments));\n    };\n\n\n    function _applyEach(eachfn) {\n        return _restParam(function(fns, args) {\n            var go = _restParam(function(args) {\n                var that = this;\n                var callback = args.pop();\n                return eachfn(fns, function (fn, _, cb) {\n                    fn.apply(that, args.concat([cb]));\n                },\n                callback);\n            });\n            if (args.length) {\n                return go.apply(this, args);\n            }\n            else {\n                return go;\n            }\n        });\n    }\n\n    async.applyEach = _applyEach(async.eachOf);\n    async.applyEachSeries = _applyEach(async.eachOfSeries);\n\n\n    async.forever = function (fn, callback) {\n        var done = only_once(callback || noop);\n        var task = ensureAsync(fn);\n        function next(err) {\n            if (err) {\n                return done(err);\n            }\n            task(next);\n        }\n        next();\n    };\n\n    function ensureAsync(fn) {\n        return _restParam(function (args) {\n            var callback = args.pop();\n            args.push(function () {\n                var innerArgs = arguments;\n                if (sync) {\n                    async.setImmediate(function () {\n                        callback.apply(null, innerArgs);\n                    });\n                } else {\n                    callback.apply(null, innerArgs);\n                }\n            });\n            var sync = true;\n            fn.apply(this, args);\n            sync = false;\n        });\n    }\n\n    async.ensureAsync = ensureAsync;\n\n    async.constant = _restParam(function(values) {\n        var args = [null].concat(values);\n        return function (callback) {\n            return callback.apply(this, args);\n        };\n    });\n\n    async.wrapSync =\n    async.asyncify = function asyncify(func) {\n        return _restParam(function (args) {\n            var callback = args.pop();\n            var result;\n            try {\n                result = func.apply(this, args);\n            } catch (e) {\n                return callback(e);\n            }\n            // if result is Promise object\n            if (_isObject(result) && typeof result.then === \"function\") {\n                result.then(function(value) {\n                    callback(null, value);\n                })[\"catch\"](function(err) {\n                    callback(err.message ? err : new Error(err));\n                });\n            } else {\n                callback(null, result);\n            }\n        });\n    };\n\n    // Node.js\n    if ( true && module.exports) {\n        module.exports = async;\n    }\n    // AMD / RequireJS\n    else if (true) {\n        !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function () {\n            return async;\n        }).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n    }\n    // included directly via <script> tag\n    else {}\n\n}());\n\n\n//# sourceURL=webpack:///./node_modules/async/lib/async.js?");

/***/ }),

/***/ "./node_modules/balanced-match/index.js":
/*!**********************************************!*\
  !*** ./node_modules/balanced-match/index.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nmodule.exports = balanced;\nfunction balanced(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n\n  var r = range(a, b, str);\n\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced.range = range;\nfunction range(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [ begs.pop(), bi ];\n      } else {\n        beg = begs.pop();\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [ left, right ];\n    }\n  }\n\n  return result;\n}\n\n\n//# sourceURL=webpack:///./node_modules/balanced-match/index.js?");

/***/ }),

/***/ "./node_modules/bcrypt-pbkdf/index.js":
/*!********************************************!*\
  !*** ./node_modules/bcrypt-pbkdf/index.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar crypto_hash_sha512 = __webpack_require__(/*! tweetnacl */ \"./node_modules/tweetnacl/nacl-fast.js\").lowlevel.crypto_hash;\n\n/*\n * This file is a 1:1 port from the OpenBSD blowfish.c and bcrypt_pbkdf.c. As a\n * result, it retains the original copyright and license. The two files are\n * under slightly different (but compatible) licenses, and are here combined in\n * one file.\n *\n * Credit for the actual porting work goes to:\n *  Devi Mandiri <me@devi.web.id>\n */\n\n/*\n * The Blowfish portions are under the following license:\n *\n * Blowfish block cipher for OpenBSD\n * Copyright 1997 Niels Provos <provos@physnet.uni-hamburg.de>\n * All rights reserved.\n *\n * Implementation advice by David Mazieres <dm@lcs.mit.edu>.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. The name of the author may not be used to endorse or promote products\n *    derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/*\n * The bcrypt_pbkdf portions are under the following license:\n *\n * Copyright (c) 2013 Ted Unangst <tedu@openbsd.org>\n *\n * Permission to use, copy, modify, and distribute this software for any\n * purpose with or without fee is hereby granted, provided that the above\n * copyright notice and this permission notice appear in all copies.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n */\n\n/*\n * Performance improvements (Javascript-specific):\n *\n * Copyright 2016, Joyent Inc\n * Author: Alex Wilson <alex.wilson@joyent.com>\n *\n * Permission to use, copy, modify, and distribute this software for any\n * purpose with or without fee is hereby granted, provided that the above\n * copyright notice and this permission notice appear in all copies.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n */\n\n// Ported from OpenBSD bcrypt_pbkdf.c v1.9\n\nvar BLF_J = 0;\n\nvar Blowfish = function() {\n  this.S = [\n    new Uint32Array([\n      0xd1310ba6, 0x98dfb5ac, 0x2ffd72db, 0xd01adfb7,\n      0xb8e1afed, 0x6a267e96, 0xba7c9045, 0xf12c7f99,\n      0x24a19947, 0xb3916cf7, 0x0801f2e2, 0x858efc16,\n      0x636920d8, 0x71574e69, 0xa458fea3, 0xf4933d7e,\n      0x0d95748f, 0x728eb658, 0x718bcd58, 0x82154aee,\n      0x7b54a41d, 0xc25a59b5, 0x9c30d539, 0x2af26013,\n      0xc5d1b023, 0x286085f0, 0xca417918, 0xb8db38ef,\n      0x8e79dcb0, 0x603a180e, 0x6c9e0e8b, 0xb01e8a3e,\n      0xd71577c1, 0xbd314b27, 0x78af2fda, 0x55605c60,\n      0xe65525f3, 0xaa55ab94, 0x57489862, 0x63e81440,\n      0x55ca396a, 0x2aab10b6, 0xb4cc5c34, 0x1141e8ce,\n      0xa15486af, 0x7c72e993, 0xb3ee1411, 0x636fbc2a,\n      0x2ba9c55d, 0x741831f6, 0xce5c3e16, 0x9b87931e,\n      0xafd6ba33, 0x6c24cf5c, 0x7a325381, 0x28958677,\n      0x3b8f4898, 0x6b4bb9af, 0xc4bfe81b, 0x66282193,\n      0x61d809cc, 0xfb21a991, 0x487cac60, 0x5dec8032,\n      0xef845d5d, 0xe98575b1, 0xdc262302, 0xeb651b88,\n      0x23893e81, 0xd396acc5, 0x0f6d6ff3, 0x83f44239,\n      0x2e0b4482, 0xa4842004, 0x69c8f04a, 0x9e1f9b5e,\n      0x21c66842, 0xf6e96c9a, 0x670c9c61, 0xabd388f0,\n      0x6a51a0d2, 0xd8542f68, 0x960fa728, 0xab5133a3,\n      0x6eef0b6c, 0x137a3be4, 0xba3bf050, 0x7efb2a98,\n      0xa1f1651d, 0x39af0176, 0x66ca593e, 0x82430e88,\n      0x8cee8619, 0x456f9fb4, 0x7d84a5c3, 0x3b8b5ebe,\n      0xe06f75d8, 0x85c12073, 0x401a449f, 0x56c16aa6,\n      0x4ed3aa62, 0x363f7706, 0x1bfedf72, 0x429b023d,\n      0x37d0d724, 0xd00a1248, 0xdb0fead3, 0x49f1c09b,\n      0x075372c9, 0x80991b7b, 0x25d479d8, 0xf6e8def7,\n      0xe3fe501a, 0xb6794c3b, 0x976ce0bd, 0x04c006ba,\n      0xc1a94fb6, 0x409f60c4, 0x5e5c9ec2, 0x196a2463,\n      0x68fb6faf, 0x3e6c53b5, 0x1339b2eb, 0x3b52ec6f,\n      0x6dfc511f, 0x9b30952c, 0xcc814544, 0xaf5ebd09,\n      0xbee3d004, 0xde334afd, 0x660f2807, 0x192e4bb3,\n      0xc0cba857, 0x45c8740f, 0xd20b5f39, 0xb9d3fbdb,\n      0x5579c0bd, 0x1a60320a, 0xd6a100c6, 0x402c7279,\n      0x679f25fe, 0xfb1fa3cc, 0x8ea5e9f8, 0xdb3222f8,\n      0x3c7516df, 0xfd616b15, 0x2f501ec8, 0xad0552ab,\n      0x323db5fa, 0xfd238760, 0x53317b48, 0x3e00df82,\n      0x9e5c57bb, 0xca6f8ca0, 0x1a87562e, 0xdf1769db,\n      0xd542a8f6, 0x287effc3, 0xac6732c6, 0x8c4f5573,\n      0x695b27b0, 0xbbca58c8, 0xe1ffa35d, 0xb8f011a0,\n      0x10fa3d98, 0xfd2183b8, 0x4afcb56c, 0x2dd1d35b,\n      0x9a53e479, 0xb6f84565, 0xd28e49bc, 0x4bfb9790,\n      0xe1ddf2da, 0xa4cb7e33, 0x62fb1341, 0xcee4c6e8,\n      0xef20cada, 0x36774c01, 0xd07e9efe, 0x2bf11fb4,\n      0x95dbda4d, 0xae909198, 0xeaad8e71, 0x6b93d5a0,\n      0xd08ed1d0, 0xafc725e0, 0x8e3c5b2f, 0x8e7594b7,\n      0x8ff6e2fb, 0xf2122b64, 0x8888b812, 0x900df01c,\n      0x4fad5ea0, 0x688fc31c, 0xd1cff191, 0xb3a8c1ad,\n      0x2f2f2218, 0xbe0e1777, 0xea752dfe, 0x8b021fa1,\n      0xe5a0cc0f, 0xb56f74e8, 0x18acf3d6, 0xce89e299,\n      0xb4a84fe0, 0xfd13e0b7, 0x7cc43b81, 0xd2ada8d9,\n      0x165fa266, 0x80957705, 0x93cc7314, 0x211a1477,\n      0xe6ad2065, 0x77b5fa86, 0xc75442f5, 0xfb9d35cf,\n      0xebcdaf0c, 0x7b3e89a0, 0xd6411bd3, 0xae1e7e49,\n      0x00250e2d, 0x2071b35e, 0x226800bb, 0x57b8e0af,\n      0x2464369b, 0xf009b91e, 0x5563911d, 0x59dfa6aa,\n      0x78c14389, 0xd95a537f, 0x207d5ba2, 0x02e5b9c5,\n      0x83260376, 0x6295cfa9, 0x11c81968, 0x4e734a41,\n      0xb3472dca, 0x7b14a94a, 0x1b510052, 0x9a532915,\n      0xd60f573f, 0xbc9bc6e4, 0x2b60a476, 0x81e67400,\n      0x08ba6fb5, 0x571be91f, 0xf296ec6b, 0x2a0dd915,\n      0xb6636521, 0xe7b9f9b6, 0xff34052e, 0xc5855664,\n      0x53b02d5d, 0xa99f8fa1, 0x08ba4799, 0x6e85076a]),\n    new Uint32Array([\n      0x4b7a70e9, 0xb5b32944, 0xdb75092e, 0xc4192623,\n      0xad6ea6b0, 0x49a7df7d, 0x9cee60b8, 0x8fedb266,\n      0xecaa8c71, 0x699a17ff, 0x5664526c, 0xc2b19ee1,\n      0x193602a5, 0x75094c29, 0xa0591340, 0xe4183a3e,\n      0x3f54989a, 0x5b429d65, 0x6b8fe4d6, 0x99f73fd6,\n      0xa1d29c07, 0xefe830f5, 0x4d2d38e6, 0xf0255dc1,\n      0x4cdd2086, 0x8470eb26, 0x6382e9c6, 0x021ecc5e,\n      0x09686b3f, 0x3ebaefc9, 0x3c971814, 0x6b6a70a1,\n      0x687f3584, 0x52a0e286, 0xb79c5305, 0xaa500737,\n      0x3e07841c, 0x7fdeae5c, 0x8e7d44ec, 0x5716f2b8,\n      0xb03ada37, 0xf0500c0d, 0xf01c1f04, 0x0200b3ff,\n      0xae0cf51a, 0x3cb574b2, 0x25837a58, 0xdc0921bd,\n      0xd19113f9, 0x7ca92ff6, 0x94324773, 0x22f54701,\n      0x3ae5e581, 0x37c2dadc, 0xc8b57634, 0x9af3dda7,\n      0xa9446146, 0x0fd0030e, 0xecc8c73e, 0xa4751e41,\n      0xe238cd99, 0x3bea0e2f, 0x3280bba1, 0x183eb331,\n      0x4e548b38, 0x4f6db908, 0x6f420d03, 0xf60a04bf,\n      0x2cb81290, 0x24977c79, 0x5679b072, 0xbcaf89af,\n      0xde9a771f, 0xd9930810, 0xb38bae12, 0xdccf3f2e,\n      0x5512721f, 0x2e6b7124, 0x501adde6, 0x9f84cd87,\n      0x7a584718, 0x7408da17, 0xbc9f9abc, 0xe94b7d8c,\n      0xec7aec3a, 0xdb851dfa, 0x63094366, 0xc464c3d2,\n      0xef1c1847, 0x3215d908, 0xdd433b37, 0x24c2ba16,\n      0x12a14d43, 0x2a65c451, 0x50940002, 0x133ae4dd,\n      0x71dff89e, 0x10314e55, 0x81ac77d6, 0x5f11199b,\n      0x043556f1, 0xd7a3c76b, 0x3c11183b, 0x5924a509,\n      0xf28fe6ed, 0x97f1fbfa, 0x9ebabf2c, 0x1e153c6e,\n      0x86e34570, 0xeae96fb1, 0x860e5e0a, 0x5a3e2ab3,\n      0x771fe71c, 0x4e3d06fa, 0x2965dcb9, 0x99e71d0f,\n      0x803e89d6, 0x5266c825, 0x2e4cc978, 0x9c10b36a,\n      0xc6150eba, 0x94e2ea78, 0xa5fc3c53, 0x1e0a2df4,\n      0xf2f74ea7, 0x361d2b3d, 0x1939260f, 0x19c27960,\n      0x5223a708, 0xf71312b6, 0xebadfe6e, 0xeac31f66,\n      0xe3bc4595, 0xa67bc883, 0xb17f37d1, 0x018cff28,\n      0xc332ddef, 0xbe6c5aa5, 0x65582185, 0x68ab9802,\n      0xeecea50f, 0xdb2f953b, 0x2aef7dad, 0x5b6e2f84,\n      0x1521b628, 0x29076170, 0xecdd4775, 0x619f1510,\n      0x13cca830, 0xeb61bd96, 0x0334fe1e, 0xaa0363cf,\n      0xb5735c90, 0x4c70a239, 0xd59e9e0b, 0xcbaade14,\n      0xeecc86bc, 0x60622ca7, 0x9cab5cab, 0xb2f3846e,\n      0x648b1eaf, 0x19bdf0ca, 0xa02369b9, 0x655abb50,\n      0x40685a32, 0x3c2ab4b3, 0x319ee9d5, 0xc021b8f7,\n      0x9b540b19, 0x875fa099, 0x95f7997e, 0x623d7da8,\n      0xf837889a, 0x97e32d77, 0x11ed935f, 0x16681281,\n      0x0e358829, 0xc7e61fd6, 0x96dedfa1, 0x7858ba99,\n      0x57f584a5, 0x1b227263, 0x9b83c3ff, 0x1ac24696,\n      0xcdb30aeb, 0x532e3054, 0x8fd948e4, 0x6dbc3128,\n      0x58ebf2ef, 0x34c6ffea, 0xfe28ed61, 0xee7c3c73,\n      0x5d4a14d9, 0xe864b7e3, 0x42105d14, 0x203e13e0,\n      0x45eee2b6, 0xa3aaabea, 0xdb6c4f15, 0xfacb4fd0,\n      0xc742f442, 0xef6abbb5, 0x654f3b1d, 0x41cd2105,\n      0xd81e799e, 0x86854dc7, 0xe44b476a, 0x3d816250,\n      0xcf62a1f2, 0x5b8d2646, 0xfc8883a0, 0xc1c7b6a3,\n      0x7f1524c3, 0x69cb7492, 0x47848a0b, 0x5692b285,\n      0x095bbf00, 0xad19489d, 0x1462b174, 0x23820e00,\n      0x58428d2a, 0x0c55f5ea, 0x1dadf43e, 0x233f7061,\n      0x3372f092, 0x8d937e41, 0xd65fecf1, 0x6c223bdb,\n      0x7cde3759, 0xcbee7460, 0x4085f2a7, 0xce77326e,\n      0xa6078084, 0x19f8509e, 0xe8efd855, 0x61d99735,\n      0xa969a7aa, 0xc50c06c2, 0x5a04abfc, 0x800bcadc,\n      0x9e447a2e, 0xc3453484, 0xfdd56705, 0x0e1e9ec9,\n      0xdb73dbd3, 0x105588cd, 0x675fda79, 0xe3674340,\n      0xc5c43465, 0x713e38d8, 0x3d28f89e, 0xf16dff20,\n      0x153e21e7, 0x8fb03d4a, 0xe6e39f2b, 0xdb83adf7]),\n    new Uint32Array([\n      0xe93d5a68, 0x948140f7, 0xf64c261c, 0x94692934,\n      0x411520f7, 0x7602d4f7, 0xbcf46b2e, 0xd4a20068,\n      0xd4082471, 0x3320f46a, 0x43b7d4b7, 0x500061af,\n      0x1e39f62e, 0x97244546, 0x14214f74, 0xbf8b8840,\n      0x4d95fc1d, 0x96b591af, 0x70f4ddd3, 0x66a02f45,\n      0xbfbc09ec, 0x03bd9785, 0x7fac6dd0, 0x31cb8504,\n      0x96eb27b3, 0x55fd3941, 0xda2547e6, 0xabca0a9a,\n      0x28507825, 0x530429f4, 0x0a2c86da, 0xe9b66dfb,\n      0x68dc1462, 0xd7486900, 0x680ec0a4, 0x27a18dee,\n      0x4f3ffea2, 0xe887ad8c, 0xb58ce006, 0x7af4d6b6,\n      0xaace1e7c, 0xd3375fec, 0xce78a399, 0x406b2a42,\n      0x20fe9e35, 0xd9f385b9, 0xee39d7ab, 0x3b124e8b,\n      0x1dc9faf7, 0x4b6d1856, 0x26a36631, 0xeae397b2,\n      0x3a6efa74, 0xdd5b4332, 0x6841e7f7, 0xca7820fb,\n      0xfb0af54e, 0xd8feb397, 0x454056ac, 0xba489527,\n      0x55533a3a, 0x20838d87, 0xfe6ba9b7, 0xd096954b,\n      0x55a867bc, 0xa1159a58, 0xcca92963, 0x99e1db33,\n      0xa62a4a56, 0x3f3125f9, 0x5ef47e1c, 0x9029317c,\n      0xfdf8e802, 0x04272f70, 0x80bb155c, 0x05282ce3,\n      0x95c11548, 0xe4c66d22, 0x48c1133f, 0xc70f86dc,\n      0x07f9c9ee, 0x41041f0f, 0x404779a4, 0x5d886e17,\n      0x325f51eb, 0xd59bc0d1, 0xf2bcc18f, 0x41113564,\n      0x257b7834, 0x602a9c60, 0xdff8e8a3, 0x1f636c1b,\n      0x0e12b4c2, 0x02e1329e, 0xaf664fd1, 0xcad18115,\n      0x6b2395e0, 0x333e92e1, 0x3b240b62, 0xeebeb922,\n      0x85b2a20e, 0xe6ba0d99, 0xde720c8c, 0x2da2f728,\n      0xd0127845, 0x95b794fd, 0x647d0862, 0xe7ccf5f0,\n      0x5449a36f, 0x877d48fa, 0xc39dfd27, 0xf33e8d1e,\n      0x0a476341, 0x992eff74, 0x3a6f6eab, 0xf4f8fd37,\n      0xa812dc60, 0xa1ebddf8, 0x991be14c, 0xdb6e6b0d,\n      0xc67b5510, 0x6d672c37, 0x2765d43b, 0xdcd0e804,\n      0xf1290dc7, 0xcc00ffa3, 0xb5390f92, 0x690fed0b,\n      0x667b9ffb, 0xcedb7d9c, 0xa091cf0b, 0xd9155ea3,\n      0xbb132f88, 0x515bad24, 0x7b9479bf, 0x763bd6eb,\n      0x37392eb3, 0xcc115979, 0x8026e297, 0xf42e312d,\n      0x6842ada7, 0xc66a2b3b, 0x12754ccc, 0x782ef11c,\n      0x6a124237, 0xb79251e7, 0x06a1bbe6, 0x4bfb6350,\n      0x1a6b1018, 0x11caedfa, 0x3d25bdd8, 0xe2e1c3c9,\n      0x44421659, 0x0a121386, 0xd90cec6e, 0xd5abea2a,\n      0x64af674e, 0xda86a85f, 0xbebfe988, 0x64e4c3fe,\n      0x9dbc8057, 0xf0f7c086, 0x60787bf8, 0x6003604d,\n      0xd1fd8346, 0xf6381fb0, 0x7745ae04, 0xd736fccc,\n      0x83426b33, 0xf01eab71, 0xb0804187, 0x3c005e5f,\n      0x77a057be, 0xbde8ae24, 0x55464299, 0xbf582e61,\n      0x4e58f48f, 0xf2ddfda2, 0xf474ef38, 0x8789bdc2,\n      0x5366f9c3, 0xc8b38e74, 0xb475f255, 0x46fcd9b9,\n      0x7aeb2661, 0x8b1ddf84, 0x846a0e79, 0x915f95e2,\n      0x466e598e, 0x20b45770, 0x8cd55591, 0xc902de4c,\n      0xb90bace1, 0xbb8205d0, 0x11a86248, 0x7574a99e,\n      0xb77f19b6, 0xe0a9dc09, 0x662d09a1, 0xc4324633,\n      0xe85a1f02, 0x09f0be8c, 0x4a99a025, 0x1d6efe10,\n      0x1ab93d1d, 0x0ba5a4df, 0xa186f20f, 0x2868f169,\n      0xdcb7da83, 0x573906fe, 0xa1e2ce9b, 0x4fcd7f52,\n      0x50115e01, 0xa70683fa, 0xa002b5c4, 0x0de6d027,\n      0x9af88c27, 0x773f8641, 0xc3604c06, 0x61a806b5,\n      0xf0177a28, 0xc0f586e0, 0x006058aa, 0x30dc7d62,\n      0x11e69ed7, 0x2338ea63, 0x53c2dd94, 0xc2c21634,\n      0xbbcbee56, 0x90bcb6de, 0xebfc7da1, 0xce591d76,\n      0x6f05e409, 0x4b7c0188, 0x39720a3d, 0x7c927c24,\n      0x86e3725f, 0x724d9db9, 0x1ac15bb4, 0xd39eb8fc,\n      0xed545578, 0x08fca5b5, 0xd83d7cd3, 0x4dad0fc4,\n      0x1e50ef5e, 0xb161e6f8, 0xa28514d9, 0x6c51133c,\n      0x6fd5c7e7, 0x56e14ec4, 0x362abfce, 0xddc6c837,\n      0xd79a3234, 0x92638212, 0x670efa8e, 0x406000e0]),\n    new Uint32Array([\n      0x3a39ce37, 0xd3faf5cf, 0xabc27737, 0x5ac52d1b,\n      0x5cb0679e, 0x4fa33742, 0xd3822740, 0x99bc9bbe,\n      0xd5118e9d, 0xbf0f7315, 0xd62d1c7e, 0xc700c47b,\n      0xb78c1b6b, 0x21a19045, 0xb26eb1be, 0x6a366eb4,\n      0x5748ab2f, 0xbc946e79, 0xc6a376d2, 0x6549c2c8,\n      0x530ff8ee, 0x468dde7d, 0xd5730a1d, 0x4cd04dc6,\n      0x2939bbdb, 0xa9ba4650, 0xac9526e8, 0xbe5ee304,\n      0xa1fad5f0, 0x6a2d519a, 0x63ef8ce2, 0x9a86ee22,\n      0xc089c2b8, 0x43242ef6, 0xa51e03aa, 0x9cf2d0a4,\n      0x83c061ba, 0x9be96a4d, 0x8fe51550, 0xba645bd6,\n      0x2826a2f9, 0xa73a3ae1, 0x4ba99586, 0xef5562e9,\n      0xc72fefd3, 0xf752f7da, 0x3f046f69, 0x77fa0a59,\n      0x80e4a915, 0x87b08601, 0x9b09e6ad, 0x3b3ee593,\n      0xe990fd5a, 0x9e34d797, 0x2cf0b7d9, 0x022b8b51,\n      0x96d5ac3a, 0x017da67d, 0xd1cf3ed6, 0x7c7d2d28,\n      0x1f9f25cf, 0xadf2b89b, 0x5ad6b472, 0x5a88f54c,\n      0xe029ac71, 0xe019a5e6, 0x47b0acfd, 0xed93fa9b,\n      0xe8d3c48d, 0x283b57cc, 0xf8d56629, 0x79132e28,\n      0x785f0191, 0xed756055, 0xf7960e44, 0xe3d35e8c,\n      0x15056dd4, 0x88f46dba, 0x03a16125, 0x0564f0bd,\n      0xc3eb9e15, 0x3c9057a2, 0x97271aec, 0xa93a072a,\n      0x1b3f6d9b, 0x1e6321f5, 0xf59c66fb, 0x26dcf319,\n      0x7533d928, 0xb155fdf5, 0x03563482, 0x8aba3cbb,\n      0x28517711, 0xc20ad9f8, 0xabcc5167, 0xccad925f,\n      0x4de81751, 0x3830dc8e, 0x379d5862, 0x9320f991,\n      0xea7a90c2, 0xfb3e7bce, 0x5121ce64, 0x774fbe32,\n      0xa8b6e37e, 0xc3293d46, 0x48de5369, 0x6413e680,\n      0xa2ae0810, 0xdd6db224, 0x69852dfd, 0x09072166,\n      0xb39a460a, 0x6445c0dd, 0x586cdecf, 0x1c20c8ae,\n      0x5bbef7dd, 0x1b588d40, 0xccd2017f, 0x6bb4e3bb,\n      0xdda26a7e, 0x3a59ff45, 0x3e350a44, 0xbcb4cdd5,\n      0x72eacea8, 0xfa6484bb, 0x8d6612ae, 0xbf3c6f47,\n      0xd29be463, 0x542f5d9e, 0xaec2771b, 0xf64e6370,\n      0x740e0d8d, 0xe75b1357, 0xf8721671, 0xaf537d5d,\n      0x4040cb08, 0x4eb4e2cc, 0x34d2466a, 0x0115af84,\n      0xe1b00428, 0x95983a1d, 0x06b89fb4, 0xce6ea048,\n      0x6f3f3b82, 0x3520ab82, 0x011a1d4b, 0x277227f8,\n      0x611560b1, 0xe7933fdc, 0xbb3a792b, 0x344525bd,\n      0xa08839e1, 0x51ce794b, 0x2f32c9b7, 0xa01fbac9,\n      0xe01cc87e, 0xbcc7d1f6, 0xcf0111c3, 0xa1e8aac7,\n      0x1a908749, 0xd44fbd9a, 0xd0dadecb, 0xd50ada38,\n      0x0339c32a, 0xc6913667, 0x8df9317c, 0xe0b12b4f,\n      0xf79e59b7, 0x43f5bb3a, 0xf2d519ff, 0x27d9459c,\n      0xbf97222c, 0x15e6fc2a, 0x0f91fc71, 0x9b941525,\n      0xfae59361, 0xceb69ceb, 0xc2a86459, 0x12baa8d1,\n      0xb6c1075e, 0xe3056a0c, 0x10d25065, 0xcb03a442,\n      0xe0ec6e0e, 0x1698db3b, 0x4c98a0be, 0x3278e964,\n      0x9f1f9532, 0xe0d392df, 0xd3a0342b, 0x8971f21e,\n      0x1b0a7441, 0x4ba3348c, 0xc5be7120, 0xc37632d8,\n      0xdf359f8d, 0x9b992f2e, 0xe60b6f47, 0x0fe3f11d,\n      0xe54cda54, 0x1edad891, 0xce6279cf, 0xcd3e7e6f,\n      0x1618b166, 0xfd2c1d05, 0x848fd2c5, 0xf6fb2299,\n      0xf523f357, 0xa6327623, 0x93a83531, 0x56cccd02,\n      0xacf08162, 0x5a75ebb5, 0x6e163697, 0x88d273cc,\n      0xde966292, 0x81b949d0, 0x4c50901b, 0x71c65614,\n      0xe6c6c7bd, 0x327a140a, 0x45e1d006, 0xc3f27b9a,\n      0xc9aa53fd, 0x62a80f00, 0xbb25bfe2, 0x35bdd2f6,\n      0x71126905, 0xb2040222, 0xb6cbcf7c, 0xcd769c2b,\n      0x53113ec0, 0x1640e3d3, 0x38abbd60, 0x2547adf0,\n      0xba38209c, 0xf746ce76, 0x77afa1c5, 0x20756060,\n      0x85cbfe4e, 0x8ae88dd8, 0x7aaaf9b0, 0x4cf9aa7e,\n      0x1948c25c, 0x02fb8a8c, 0x01c36ae4, 0xd6ebe1f9,\n      0x90d4f869, 0xa65cdea0, 0x3f09252d, 0xc208e69f,\n      0xb74e6132, 0xce77e25b, 0x578fdfe3, 0x3ac372e6])\n    ];\n  this.P = new Uint32Array([\n    0x243f6a88, 0x85a308d3, 0x13198a2e, 0x03707344,\n    0xa4093822, 0x299f31d0, 0x082efa98, 0xec4e6c89,\n    0x452821e6, 0x38d01377, 0xbe5466cf, 0x34e90c6c,\n    0xc0ac29b7, 0xc97c50dd, 0x3f84d5b5, 0xb5470917,\n    0x9216d5d9, 0x8979fb1b]);\n};\n\nfunction F(S, x8, i) {\n  return (((S[0][x8[i+3]] +\n            S[1][x8[i+2]]) ^\n            S[2][x8[i+1]]) +\n            S[3][x8[i]]);\n};\n\nBlowfish.prototype.encipher = function(x, x8) {\n  if (x8 === undefined) {\n    x8 = new Uint8Array(x.buffer);\n    if (x.byteOffset !== 0)\n      x8 = x8.subarray(x.byteOffset);\n  }\n  x[0] ^= this.P[0];\n  for (var i = 1; i < 16; i += 2) {\n    x[1] ^= F(this.S, x8, 0) ^ this.P[i];\n    x[0] ^= F(this.S, x8, 4) ^ this.P[i+1];\n  }\n  var t = x[0];\n  x[0] = x[1] ^ this.P[17];\n  x[1] = t;\n};\n\nBlowfish.prototype.decipher = function(x) {\n  var x8 = new Uint8Array(x.buffer);\n  if (x.byteOffset !== 0)\n    x8 = x8.subarray(x.byteOffset);\n  x[0] ^= this.P[17];\n  for (var i = 16; i > 0; i -= 2) {\n    x[1] ^= F(this.S, x8, 0) ^ this.P[i];\n    x[0] ^= F(this.S, x8, 4) ^ this.P[i-1];\n  }\n  var t = x[0];\n  x[0] = x[1] ^ this.P[0];\n  x[1] = t;\n};\n\nfunction stream2word(data, databytes){\n  var i, temp = 0;\n  for (i = 0; i < 4; i++, BLF_J++) {\n    if (BLF_J >= databytes) BLF_J = 0;\n    temp = (temp << 8) | data[BLF_J];\n  }\n  return temp;\n};\n\nBlowfish.prototype.expand0state = function(key, keybytes) {\n  var d = new Uint32Array(2), i, k;\n  var d8 = new Uint8Array(d.buffer);\n\n  for (i = 0, BLF_J = 0; i < 18; i++) {\n    this.P[i] ^= stream2word(key, keybytes);\n  }\n  BLF_J = 0;\n\n  for (i = 0; i < 18; i += 2) {\n    this.encipher(d, d8);\n    this.P[i]   = d[0];\n    this.P[i+1] = d[1];\n  }\n\n  for (i = 0; i < 4; i++) {\n    for (k = 0; k < 256; k += 2) {\n      this.encipher(d, d8);\n      this.S[i][k]   = d[0];\n      this.S[i][k+1] = d[1];\n    }\n  }\n};\n\nBlowfish.prototype.expandstate = function(data, databytes, key, keybytes) {\n  var d = new Uint32Array(2), i, k;\n\n  for (i = 0, BLF_J = 0; i < 18; i++) {\n    this.P[i] ^= stream2word(key, keybytes);\n  }\n\n  for (i = 0, BLF_J = 0; i < 18; i += 2) {\n    d[0] ^= stream2word(data, databytes);\n    d[1] ^= stream2word(data, databytes);\n    this.encipher(d);\n    this.P[i]   = d[0];\n    this.P[i+1] = d[1];\n  }\n\n  for (i = 0; i < 4; i++) {\n    for (k = 0; k < 256; k += 2) {\n      d[0] ^= stream2word(data, databytes);\n      d[1] ^= stream2word(data, databytes);\n      this.encipher(d);\n      this.S[i][k]   = d[0];\n      this.S[i][k+1] = d[1];\n    }\n  }\n  BLF_J = 0;\n};\n\nBlowfish.prototype.enc = function(data, blocks) {\n  for (var i = 0; i < blocks; i++) {\n    this.encipher(data.subarray(i*2));\n  }\n};\n\nBlowfish.prototype.dec = function(data, blocks) {\n  for (var i = 0; i < blocks; i++) {\n    this.decipher(data.subarray(i*2));\n  }\n};\n\nvar BCRYPT_BLOCKS = 8,\n    BCRYPT_HASHSIZE = 32;\n\nfunction bcrypt_hash(sha2pass, sha2salt, out) {\n  var state = new Blowfish(),\n      cdata = new Uint32Array(BCRYPT_BLOCKS), i,\n      ciphertext = new Uint8Array([79,120,121,99,104,114,111,109,97,116,105,\n            99,66,108,111,119,102,105,115,104,83,119,97,116,68,121,110,97,109,\n            105,116,101]); //\"OxychromaticBlowfishSwatDynamite\"\n\n  state.expandstate(sha2salt, 64, sha2pass, 64);\n  for (i = 0; i < 64; i++) {\n    state.expand0state(sha2salt, 64);\n    state.expand0state(sha2pass, 64);\n  }\n\n  for (i = 0; i < BCRYPT_BLOCKS; i++)\n    cdata[i] = stream2word(ciphertext, ciphertext.byteLength);\n  for (i = 0; i < 64; i++)\n    state.enc(cdata, cdata.byteLength / 8);\n\n  for (i = 0; i < BCRYPT_BLOCKS; i++) {\n    out[4*i+3] = cdata[i] >>> 24;\n    out[4*i+2] = cdata[i] >>> 16;\n    out[4*i+1] = cdata[i] >>> 8;\n    out[4*i+0] = cdata[i];\n  }\n};\n\nfunction bcrypt_pbkdf(pass, passlen, salt, saltlen, key, keylen, rounds) {\n  var sha2pass = new Uint8Array(64),\n      sha2salt = new Uint8Array(64),\n      out = new Uint8Array(BCRYPT_HASHSIZE),\n      tmpout = new Uint8Array(BCRYPT_HASHSIZE),\n      countsalt = new Uint8Array(saltlen+4),\n      i, j, amt, stride, dest, count,\n      origkeylen = keylen;\n\n  if (rounds < 1)\n    return -1;\n  if (passlen === 0 || saltlen === 0 || keylen === 0 ||\n      keylen > (out.byteLength * out.byteLength) || saltlen > (1<<20))\n    return -1;\n\n  stride = Math.floor((keylen + out.byteLength - 1) / out.byteLength);\n  amt = Math.floor((keylen + stride - 1) / stride);\n\n  for (i = 0; i < saltlen; i++)\n    countsalt[i] = salt[i];\n\n  crypto_hash_sha512(sha2pass, pass, passlen);\n\n  for (count = 1; keylen > 0; count++) {\n    countsalt[saltlen+0] = count >>> 24;\n    countsalt[saltlen+1] = count >>> 16;\n    countsalt[saltlen+2] = count >>>  8;\n    countsalt[saltlen+3] = count;\n\n    crypto_hash_sha512(sha2salt, countsalt, saltlen + 4);\n    bcrypt_hash(sha2pass, sha2salt, tmpout);\n    for (i = out.byteLength; i--;)\n      out[i] = tmpout[i];\n\n    for (i = 1; i < rounds; i++) {\n      crypto_hash_sha512(sha2salt, tmpout, tmpout.byteLength);\n      bcrypt_hash(sha2pass, sha2salt, tmpout);\n      for (j = 0; j < out.byteLength; j++)\n        out[j] ^= tmpout[j];\n    }\n\n    amt = Math.min(amt, keylen);\n    for (i = 0; i < amt; i++) {\n      dest = i * stride + (count - 1);\n      if (dest >= origkeylen)\n        break;\n      key[dest] = out[i];\n    }\n    keylen -= i;\n  }\n\n  return 0;\n};\n\nmodule.exports = {\n      BLOCKS: BCRYPT_BLOCKS,\n      HASHSIZE: BCRYPT_HASHSIZE,\n      hash: bcrypt_hash,\n      pbkdf: bcrypt_pbkdf\n};\n\n\n//# sourceURL=webpack:///./node_modules/bcrypt-pbkdf/index.js?");

/***/ }),

/***/ "./node_modules/brace-expansion/index.js":
/*!***********************************************!*\
  !*** ./node_modules/brace-expansion/index.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var concatMap = __webpack_require__(/*! concat-map */ \"./node_modules/concat-map/index.js\");\nvar balanced = __webpack_require__(/*! balanced-match */ \"./node_modules/balanced-match/index.js\");\n\nmodule.exports = expandTop;\n\nvar escSlash = '\\0SLASH'+Math.random()+'\\0';\nvar escOpen = '\\0OPEN'+Math.random()+'\\0';\nvar escClose = '\\0CLOSE'+Math.random()+'\\0';\nvar escComma = '\\0COMMA'+Math.random()+'\\0';\nvar escPeriod = '\\0PERIOD'+Math.random()+'\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str\n    ? parseInt(str, 10)\n    : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash)\n            .split('\\\\{').join(escOpen)\n            .split('\\\\}').join(escClose)\n            .split('\\\\,').join(escComma)\n            .split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\')\n            .split(escOpen).join('{')\n            .split(escClose).join('}')\n            .split(escComma).join(',')\n            .split(escPeriod).join('.');\n}\n\n\n// Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\nfunction parseCommaParts(str) {\n  if (!str)\n    return [''];\n\n  var parts = [];\n  var m = balanced('{', '}', str);\n\n  if (!m)\n    return str.split(',');\n\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n\n  p[p.length-1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n  if (post.length) {\n    p[p.length-1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str)\n    return [];\n\n  // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction identity(e) {\n  return e;\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand(str, isTop) {\n  var expansions = [];\n\n  var m = balanced('{', '}', str);\n  if (!m || /\\$$/.test(m.pre)) return [str];\n\n  var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isSequence = isNumericSequence || isAlphaSequence;\n  var isOptions = m.body.indexOf(',') >= 0;\n  if (!isSequence && !isOptions) {\n    // {a},b}\n    if (m.post.match(/,.*\\}/)) {\n      str = m.pre + '{' + m.body + escClose + m.post;\n      return expand(str);\n    }\n    return [str];\n  }\n\n  var n;\n  if (isSequence) {\n    n = m.body.split(/\\.\\./);\n  } else {\n    n = parseCommaParts(m.body);\n    if (n.length === 1) {\n      // x{{a,b}}y ==> x{a}y x{b}y\n      n = expand(n[0], false).map(embrace);\n      if (n.length === 1) {\n        var post = m.post.length\n          ? expand(m.post, false)\n          : [''];\n        return post.map(function(p) {\n          return m.pre + n[0] + p;\n        });\n      }\n    }\n  }\n\n  // at this point, n is the parts, and we know it's not a comma set\n  // with a single entry.\n\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n  var pre = m.pre;\n  var post = m.post.length\n    ? expand(m.post, false)\n    : [''];\n\n  var N;\n\n  if (isSequence) {\n    var x = numeric(n[0]);\n    var y = numeric(n[1]);\n    var width = Math.max(n[0].length, n[1].length)\n    var incr = n.length == 3\n      ? Math.abs(numeric(n[2]))\n      : 1;\n    var test = lte;\n    var reverse = y < x;\n    if (reverse) {\n      incr *= -1;\n      test = gte;\n    }\n    var pad = n.some(isPadded);\n\n    N = [];\n\n    for (var i = x; test(i, y); i += incr) {\n      var c;\n      if (isAlphaSequence) {\n        c = String.fromCharCode(i);\n        if (c === '\\\\')\n          c = '';\n      } else {\n        c = String(i);\n        if (pad) {\n          var need = width - c.length;\n          if (need > 0) {\n            var z = new Array(need + 1).join('0');\n            if (i < 0)\n              c = '-' + z + c.slice(1);\n            else\n              c = z + c;\n          }\n        }\n      }\n      N.push(c);\n    }\n  } else {\n    N = concatMap(n, function(el) { return expand(el, false) });\n  }\n\n  for (var j = 0; j < N.length; j++) {\n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre + N[j] + post[k];\n      if (!isTop || isSequence || expansion)\n        expansions.push(expansion);\n    }\n  }\n\n  return expansions;\n}\n\n\n\n//# sourceURL=webpack:///./node_modules/brace-expansion/index.js?");

/***/ }),

/***/ "./node_modules/concat-map/index.js":
/*!******************************************!*\
  !*** ./node_modules/concat-map/index.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = function (xs, fn) {\n    var res = [];\n    for (var i = 0; i < xs.length; i++) {\n        var x = fn(xs[i], i);\n        if (isArray(x)) res.push.apply(res, x);\n        else res.push(x);\n    }\n    return res;\n};\n\nvar isArray = Array.isArray || function (xs) {\n    return Object.prototype.toString.call(xs) === '[object Array]';\n};\n\n\n//# sourceURL=webpack:///./node_modules/concat-map/index.js?");

/***/ }),

/***/ "./node_modules/core-util-is/lib/util.js":
/*!***********************************************!*\
  !*** ./node_modules/core-util-is/lib/util.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n\n\n//# sourceURL=webpack:///./node_modules/core-util-is/lib/util.js?");

/***/ }),

/***/ "./node_modules/fs.realpath/index.js":
/*!*******************************************!*\
  !*** ./node_modules/fs.realpath/index.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = realpath\nrealpath.realpath = realpath\nrealpath.sync = realpathSync\nrealpath.realpathSync = realpathSync\nrealpath.monkeypatch = monkeypatch\nrealpath.unmonkeypatch = unmonkeypatch\n\nvar fs = __webpack_require__(/*! fs */ \"fs\")\nvar origRealpath = fs.realpath\nvar origRealpathSync = fs.realpathSync\n\nvar version = process.version\nvar ok = /^v[0-5]\\./.test(version)\nvar old = __webpack_require__(/*! ./old.js */ \"./node_modules/fs.realpath/old.js\")\n\nfunction newError (er) {\n  return er && er.syscall === 'realpath' && (\n    er.code === 'ELOOP' ||\n    er.code === 'ENOMEM' ||\n    er.code === 'ENAMETOOLONG'\n  )\n}\n\nfunction realpath (p, cache, cb) {\n  if (ok) {\n    return origRealpath(p, cache, cb)\n  }\n\n  if (typeof cache === 'function') {\n    cb = cache\n    cache = null\n  }\n  origRealpath(p, cache, function (er, result) {\n    if (newError(er)) {\n      old.realpath(p, cache, cb)\n    } else {\n      cb(er, result)\n    }\n  })\n}\n\nfunction realpathSync (p, cache) {\n  if (ok) {\n    return origRealpathSync(p, cache)\n  }\n\n  try {\n    return origRealpathSync(p, cache)\n  } catch (er) {\n    if (newError(er)) {\n      return old.realpathSync(p, cache)\n    } else {\n      throw er\n    }\n  }\n}\n\nfunction monkeypatch () {\n  fs.realpath = realpath\n  fs.realpathSync = realpathSync\n}\n\nfunction unmonkeypatch () {\n  fs.realpath = origRealpath\n  fs.realpathSync = origRealpathSync\n}\n\n\n//# sourceURL=webpack:///./node_modules/fs.realpath/index.js?");

/***/ }),

/***/ "./node_modules/fs.realpath/old.js":
/*!*****************************************!*\
  !*** ./node_modules/fs.realpath/old.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar pathModule = __webpack_require__(/*! path */ \"path\");\nvar isWindows = process.platform === 'win32';\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\n// JavaScript implementation of realpath, ported from node pre-v6\n\nvar DEBUG = process.env.NODE_DEBUG && /fs/.test(process.env.NODE_DEBUG);\n\nfunction rethrow() {\n  // Only enable in debug mode. A backtrace uses ~1000 bytes of heap space and\n  // is fairly slow to generate.\n  var callback;\n  if (DEBUG) {\n    var backtrace = new Error;\n    callback = debugCallback;\n  } else\n    callback = missingCallback;\n\n  return callback;\n\n  function debugCallback(err) {\n    if (err) {\n      backtrace.message = err.message;\n      err = backtrace;\n      missingCallback(err);\n    }\n  }\n\n  function missingCallback(err) {\n    if (err) {\n      if (process.throwDeprecation)\n        throw err;  // Forgot a callback but don't know where? Use NODE_DEBUG=fs\n      else if (!process.noDeprecation) {\n        var msg = 'fs: missing callback ' + (err.stack || err.message);\n        if (process.traceDeprecation)\n          console.trace(msg);\n        else\n          console.error(msg);\n      }\n    }\n  }\n}\n\nfunction maybeCallback(cb) {\n  return typeof cb === 'function' ? cb : rethrow();\n}\n\nvar normalize = pathModule.normalize;\n\n// Regexp that finds the next partion of a (partial) path\n// result is [base_with_slash, base], e.g. ['somedir/', 'somedir']\nif (isWindows) {\n  var nextPartRe = /(.*?)(?:[\\/\\\\]+|$)/g;\n} else {\n  var nextPartRe = /(.*?)(?:[\\/]+|$)/g;\n}\n\n// Regex to find the device root, including trailing slash. E.g. 'c:\\\\'.\nif (isWindows) {\n  var splitRootRe = /^(?:[a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/][^\\\\\\/]+)?[\\\\\\/]*/;\n} else {\n  var splitRootRe = /^[\\/]*/;\n}\n\nexports.realpathSync = function realpathSync(p, cache) {\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return cache[p];\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows && !knownHard[base]) {\n      fs.lstatSync(base);\n      knownHard[base] = true;\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  // NB: p.length changes.\n  while (pos < p.length) {\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      continue;\n    }\n\n    var resolvedLink;\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // some known symbolic link.  no need to stat again.\n      resolvedLink = cache[base];\n    } else {\n      var stat = fs.lstatSync(base);\n      if (!stat.isSymbolicLink()) {\n        knownHard[base] = true;\n        if (cache) cache[base] = base;\n        continue;\n      }\n\n      // read the link if it wasn't read before\n      // dev/ino always return 0 on windows, so skip the check.\n      var linkTarget = null;\n      if (!isWindows) {\n        var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n        if (seenLinks.hasOwnProperty(id)) {\n          linkTarget = seenLinks[id];\n        }\n      }\n      if (linkTarget === null) {\n        fs.statSync(base);\n        linkTarget = fs.readlinkSync(base);\n      }\n      resolvedLink = pathModule.resolve(previous, linkTarget);\n      // track this, if given a cache.\n      if (cache) cache[base] = resolvedLink;\n      if (!isWindows) seenLinks[id] = linkTarget;\n    }\n\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n\n  if (cache) cache[original] = p;\n\n  return p;\n};\n\n\nexports.realpath = function realpath(p, cache, cb) {\n  if (typeof cb !== 'function') {\n    cb = maybeCallback(cache);\n    cache = null;\n  }\n\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return process.nextTick(cb.bind(null, null, cache[p]));\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows && !knownHard[base]) {\n      fs.lstat(base, function(err) {\n        if (err) return cb(err);\n        knownHard[base] = true;\n        LOOP();\n      });\n    } else {\n      process.nextTick(LOOP);\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  function LOOP() {\n    // stop if scanned past end of path\n    if (pos >= p.length) {\n      if (cache) cache[original] = p;\n      return cb(null, p);\n    }\n\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      return process.nextTick(LOOP);\n    }\n\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // known symbolic link.  no need to stat again.\n      return gotResolvedLink(cache[base]);\n    }\n\n    return fs.lstat(base, gotStat);\n  }\n\n  function gotStat(err, stat) {\n    if (err) return cb(err);\n\n    // if not a symlink, skip to the next path part\n    if (!stat.isSymbolicLink()) {\n      knownHard[base] = true;\n      if (cache) cache[base] = base;\n      return process.nextTick(LOOP);\n    }\n\n    // stat & read the link if not read before\n    // call gotTarget as soon as the link target is known\n    // dev/ino always return 0 on windows, so skip the check.\n    if (!isWindows) {\n      var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n      if (seenLinks.hasOwnProperty(id)) {\n        return gotTarget(null, seenLinks[id], base);\n      }\n    }\n    fs.stat(base, function(err) {\n      if (err) return cb(err);\n\n      fs.readlink(base, function(err, target) {\n        if (!isWindows) seenLinks[id] = target;\n        gotTarget(err, target);\n      });\n    });\n  }\n\n  function gotTarget(err, target, base) {\n    if (err) return cb(err);\n\n    var resolvedLink = pathModule.resolve(previous, target);\n    if (cache) cache[base] = resolvedLink;\n    gotResolvedLink(resolvedLink);\n  }\n\n  function gotResolvedLink(resolvedLink) {\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n};\n\n\n//# sourceURL=webpack:///./node_modules/fs.realpath/old.js?");

/***/ }),

/***/ "./node_modules/glob/common.js":
/*!*************************************!*\
  !*** ./node_modules/glob/common.js ***!
  \*************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("exports.alphasort = alphasort\nexports.alphasorti = alphasorti\nexports.setopts = setopts\nexports.ownProp = ownProp\nexports.makeAbs = makeAbs\nexports.finish = finish\nexports.mark = mark\nexports.isIgnored = isIgnored\nexports.childrenIgnored = childrenIgnored\n\nfunction ownProp (obj, field) {\n  return Object.prototype.hasOwnProperty.call(obj, field)\n}\n\nvar path = __webpack_require__(/*! path */ \"path\")\nvar minimatch = __webpack_require__(/*! minimatch */ \"./node_modules/minimatch/minimatch.js\")\nvar isAbsolute = __webpack_require__(/*! path-is-absolute */ \"./node_modules/path-is-absolute/index.js\")\nvar Minimatch = minimatch.Minimatch\n\nfunction alphasorti (a, b) {\n  return a.toLowerCase().localeCompare(b.toLowerCase())\n}\n\nfunction alphasort (a, b) {\n  return a.localeCompare(b)\n}\n\nfunction setupIgnores (self, options) {\n  self.ignore = options.ignore || []\n\n  if (!Array.isArray(self.ignore))\n    self.ignore = [self.ignore]\n\n  if (self.ignore.length) {\n    self.ignore = self.ignore.map(ignoreMap)\n  }\n}\n\n// ignore patterns are always in dot:true mode.\nfunction ignoreMap (pattern) {\n  var gmatcher = null\n  if (pattern.slice(-3) === '/**') {\n    var gpattern = pattern.replace(/(\\/\\*\\*)+$/, '')\n    gmatcher = new Minimatch(gpattern, { dot: true })\n  }\n\n  return {\n    matcher: new Minimatch(pattern, { dot: true }),\n    gmatcher: gmatcher\n  }\n}\n\nfunction setopts (self, pattern, options) {\n  if (!options)\n    options = {}\n\n  // base-matching: just use globstar for that.\n  if (options.matchBase && -1 === pattern.indexOf(\"/\")) {\n    if (options.noglobstar) {\n      throw new Error(\"base matching requires globstar\")\n    }\n    pattern = \"**/\" + pattern\n  }\n\n  self.silent = !!options.silent\n  self.pattern = pattern\n  self.strict = options.strict !== false\n  self.realpath = !!options.realpath\n  self.realpathCache = options.realpathCache || Object.create(null)\n  self.follow = !!options.follow\n  self.dot = !!options.dot\n  self.mark = !!options.mark\n  self.nodir = !!options.nodir\n  if (self.nodir)\n    self.mark = true\n  self.sync = !!options.sync\n  self.nounique = !!options.nounique\n  self.nonull = !!options.nonull\n  self.nosort = !!options.nosort\n  self.nocase = !!options.nocase\n  self.stat = !!options.stat\n  self.noprocess = !!options.noprocess\n  self.absolute = !!options.absolute\n\n  self.maxLength = options.maxLength || Infinity\n  self.cache = options.cache || Object.create(null)\n  self.statCache = options.statCache || Object.create(null)\n  self.symlinks = options.symlinks || Object.create(null)\n\n  setupIgnores(self, options)\n\n  self.changedCwd = false\n  var cwd = process.cwd()\n  if (!ownProp(options, \"cwd\"))\n    self.cwd = cwd\n  else {\n    self.cwd = path.resolve(options.cwd)\n    self.changedCwd = self.cwd !== cwd\n  }\n\n  self.root = options.root || path.resolve(self.cwd, \"/\")\n  self.root = path.resolve(self.root)\n  if (process.platform === \"win32\")\n    self.root = self.root.replace(/\\\\/g, \"/\")\n\n  // TODO: is an absolute `cwd` supposed to be resolved against `root`?\n  // e.g. { cwd: '/test', root: __dirname } === path.join(__dirname, '/test')\n  self.cwdAbs = isAbsolute(self.cwd) ? self.cwd : makeAbs(self, self.cwd)\n  if (process.platform === \"win32\")\n    self.cwdAbs = self.cwdAbs.replace(/\\\\/g, \"/\")\n  self.nomount = !!options.nomount\n\n  // disable comments and negation in Minimatch.\n  // Note that they are not supported in Glob itself anyway.\n  options.nonegate = true\n  options.nocomment = true\n\n  self.minimatch = new Minimatch(pattern, options)\n  self.options = self.minimatch.options\n}\n\nfunction finish (self) {\n  var nou = self.nounique\n  var all = nou ? [] : Object.create(null)\n\n  for (var i = 0, l = self.matches.length; i < l; i ++) {\n    var matches = self.matches[i]\n    if (!matches || Object.keys(matches).length === 0) {\n      if (self.nonull) {\n        // do like the shell, and spit out the literal glob\n        var literal = self.minimatch.globSet[i]\n        if (nou)\n          all.push(literal)\n        else\n          all[literal] = true\n      }\n    } else {\n      // had matches\n      var m = Object.keys(matches)\n      if (nou)\n        all.push.apply(all, m)\n      else\n        m.forEach(function (m) {\n          all[m] = true\n        })\n    }\n  }\n\n  if (!nou)\n    all = Object.keys(all)\n\n  if (!self.nosort)\n    all = all.sort(self.nocase ? alphasorti : alphasort)\n\n  // at *some* point we statted all of these\n  if (self.mark) {\n    for (var i = 0; i < all.length; i++) {\n      all[i] = self._mark(all[i])\n    }\n    if (self.nodir) {\n      all = all.filter(function (e) {\n        var notDir = !(/\\/$/.test(e))\n        var c = self.cache[e] || self.cache[makeAbs(self, e)]\n        if (notDir && c)\n          notDir = c !== 'DIR' && !Array.isArray(c)\n        return notDir\n      })\n    }\n  }\n\n  if (self.ignore.length)\n    all = all.filter(function(m) {\n      return !isIgnored(self, m)\n    })\n\n  self.found = all\n}\n\nfunction mark (self, p) {\n  var abs = makeAbs(self, p)\n  var c = self.cache[abs]\n  var m = p\n  if (c) {\n    var isDir = c === 'DIR' || Array.isArray(c)\n    var slash = p.slice(-1) === '/'\n\n    if (isDir && !slash)\n      m += '/'\n    else if (!isDir && slash)\n      m = m.slice(0, -1)\n\n    if (m !== p) {\n      var mabs = makeAbs(self, m)\n      self.statCache[mabs] = self.statCache[abs]\n      self.cache[mabs] = self.cache[abs]\n    }\n  }\n\n  return m\n}\n\n// lotta situps...\nfunction makeAbs (self, f) {\n  var abs = f\n  if (f.charAt(0) === '/') {\n    abs = path.join(self.root, f)\n  } else if (isAbsolute(f) || f === '') {\n    abs = f\n  } else if (self.changedCwd) {\n    abs = path.resolve(self.cwd, f)\n  } else {\n    abs = path.resolve(f)\n  }\n\n  if (process.platform === 'win32')\n    abs = abs.replace(/\\\\/g, '/')\n\n  return abs\n}\n\n\n// Return true, if pattern ends with globstar '**', for the accompanying parent directory.\n// Ex:- If node_modules/** is the pattern, add 'node_modules' to ignore list along with it's contents\nfunction isIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return item.matcher.match(path) || !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n\nfunction childrenIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n\n\n//# sourceURL=webpack:///./node_modules/glob/common.js?");

/***/ }),

/***/ "./node_modules/glob/glob.js":
/*!***********************************!*\
  !*** ./node_modules/glob/glob.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Approach:\n//\n// 1. Get the minimatch set\n// 2. For each pattern in the set, PROCESS(pattern, false)\n// 3. Store matches per-set, then uniq them\n//\n// PROCESS(pattern, inGlobStar)\n// Get the first [n] items from pattern that are all strings\n// Join these together.  This is PREFIX.\n//   If there is no more remaining, then stat(PREFIX) and\n//   add to matches if it succeeds.  END.\n//\n// If inGlobStar and PREFIX is symlink and points to dir\n//   set ENTRIES = []\n// else readdir(PREFIX) as ENTRIES\n//   If fail, END\n//\n// with ENTRIES\n//   If pattern[n] is GLOBSTAR\n//     // handle the case where the globstar match is empty\n//     // by pruning it out, and testing the resulting pattern\n//     PROCESS(pattern[0..n] + pattern[n+1 .. $], false)\n//     // handle other cases.\n//     for ENTRY in ENTRIES (not dotfiles)\n//       // attach globstar + tail onto the entry\n//       // Mark that this entry is a globstar match\n//       PROCESS(pattern[0..n] + ENTRY + pattern[n .. $], true)\n//\n//   else // not globstar\n//     for ENTRY in ENTRIES (not dotfiles, unless pattern[n] is dot)\n//       Test ENTRY against pattern[n]\n//       If fails, continue\n//       If passes, PROCESS(pattern[0..n] + item + pattern[n+1 .. $])\n//\n// Caveat:\n//   Cache all stats and readdirs results to minimize syscall.  Since all\n//   we ever care about is existence and directory-ness, we can just keep\n//   `true` for files, and [children,...] for directories, or `false` for\n//   things that don't exist.\n\nmodule.exports = glob\n\nvar fs = __webpack_require__(/*! fs */ \"fs\")\nvar rp = __webpack_require__(/*! fs.realpath */ \"./node_modules/fs.realpath/index.js\")\nvar minimatch = __webpack_require__(/*! minimatch */ \"./node_modules/minimatch/minimatch.js\")\nvar Minimatch = minimatch.Minimatch\nvar inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\")\nvar EE = __webpack_require__(/*! events */ \"events\").EventEmitter\nvar path = __webpack_require__(/*! path */ \"path\")\nvar assert = __webpack_require__(/*! assert */ \"assert\")\nvar isAbsolute = __webpack_require__(/*! path-is-absolute */ \"./node_modules/path-is-absolute/index.js\")\nvar globSync = __webpack_require__(/*! ./sync.js */ \"./node_modules/glob/sync.js\")\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/glob/common.js\")\nvar alphasort = common.alphasort\nvar alphasorti = common.alphasorti\nvar setopts = common.setopts\nvar ownProp = common.ownProp\nvar inflight = __webpack_require__(/*! inflight */ \"./node_modules/inflight/inflight.js\")\nvar util = __webpack_require__(/*! util */ \"util\")\nvar childrenIgnored = common.childrenIgnored\nvar isIgnored = common.isIgnored\n\nvar once = __webpack_require__(/*! once */ \"./node_modules/once/once.js\")\n\nfunction glob (pattern, options, cb) {\n  if (typeof options === 'function') cb = options, options = {}\n  if (!options) options = {}\n\n  if (options.sync) {\n    if (cb)\n      throw new TypeError('callback provided to sync glob')\n    return globSync(pattern, options)\n  }\n\n  return new Glob(pattern, options, cb)\n}\n\nglob.sync = globSync\nvar GlobSync = glob.GlobSync = globSync.GlobSync\n\n// old api surface\nglob.glob = glob\n\nfunction extend (origin, add) {\n  if (add === null || typeof add !== 'object') {\n    return origin\n  }\n\n  var keys = Object.keys(add)\n  var i = keys.length\n  while (i--) {\n    origin[keys[i]] = add[keys[i]]\n  }\n  return origin\n}\n\nglob.hasMagic = function (pattern, options_) {\n  var options = extend({}, options_)\n  options.noprocess = true\n\n  var g = new Glob(pattern, options)\n  var set = g.minimatch.set\n\n  if (!pattern)\n    return false\n\n  if (set.length > 1)\n    return true\n\n  for (var j = 0; j < set[0].length; j++) {\n    if (typeof set[0][j] !== 'string')\n      return true\n  }\n\n  return false\n}\n\nglob.Glob = Glob\ninherits(Glob, EE)\nfunction Glob (pattern, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = null\n  }\n\n  if (options && options.sync) {\n    if (cb)\n      throw new TypeError('callback provided to sync glob')\n    return new GlobSync(pattern, options)\n  }\n\n  if (!(this instanceof Glob))\n    return new Glob(pattern, options, cb)\n\n  setopts(this, pattern, options)\n  this._didRealPath = false\n\n  // process each pattern in the minimatch set\n  var n = this.minimatch.set.length\n\n  // The matches are stored as {<filename>: true,...} so that\n  // duplicates are automagically pruned.\n  // Later, we do an Object.keys() on these.\n  // Keep them as a list so we can fill in when nonull is set.\n  this.matches = new Array(n)\n\n  if (typeof cb === 'function') {\n    cb = once(cb)\n    this.on('error', cb)\n    this.on('end', function (matches) {\n      cb(null, matches)\n    })\n  }\n\n  var self = this\n  this._processing = 0\n\n  this._emitQueue = []\n  this._processQueue = []\n  this.paused = false\n\n  if (this.noprocess)\n    return this\n\n  if (n === 0)\n    return done()\n\n  var sync = true\n  for (var i = 0; i < n; i ++) {\n    this._process(this.minimatch.set[i], i, false, done)\n  }\n  sync = false\n\n  function done () {\n    --self._processing\n    if (self._processing <= 0) {\n      if (sync) {\n        process.nextTick(function () {\n          self._finish()\n        })\n      } else {\n        self._finish()\n      }\n    }\n  }\n}\n\nGlob.prototype._finish = function () {\n  assert(this instanceof Glob)\n  if (this.aborted)\n    return\n\n  if (this.realpath && !this._didRealpath)\n    return this._realpath()\n\n  common.finish(this)\n  this.emit('end', this.found)\n}\n\nGlob.prototype._realpath = function () {\n  if (this._didRealpath)\n    return\n\n  this._didRealpath = true\n\n  var n = this.matches.length\n  if (n === 0)\n    return this._finish()\n\n  var self = this\n  for (var i = 0; i < this.matches.length; i++)\n    this._realpathSet(i, next)\n\n  function next () {\n    if (--n === 0)\n      self._finish()\n  }\n}\n\nGlob.prototype._realpathSet = function (index, cb) {\n  var matchset = this.matches[index]\n  if (!matchset)\n    return cb()\n\n  var found = Object.keys(matchset)\n  var self = this\n  var n = found.length\n\n  if (n === 0)\n    return cb()\n\n  var set = this.matches[index] = Object.create(null)\n  found.forEach(function (p, i) {\n    // If there's a problem with the stat, then it means that\n    // one or more of the links in the realpath couldn't be\n    // resolved.  just return the abs value in that case.\n    p = self._makeAbs(p)\n    rp.realpath(p, self.realpathCache, function (er, real) {\n      if (!er)\n        set[real] = true\n      else if (er.syscall === 'stat')\n        set[p] = true\n      else\n        self.emit('error', er) // srsly wtf right here\n\n      if (--n === 0) {\n        self.matches[index] = set\n        cb()\n      }\n    })\n  })\n}\n\nGlob.prototype._mark = function (p) {\n  return common.mark(this, p)\n}\n\nGlob.prototype._makeAbs = function (f) {\n  return common.makeAbs(this, f)\n}\n\nGlob.prototype.abort = function () {\n  this.aborted = true\n  this.emit('abort')\n}\n\nGlob.prototype.pause = function () {\n  if (!this.paused) {\n    this.paused = true\n    this.emit('pause')\n  }\n}\n\nGlob.prototype.resume = function () {\n  if (this.paused) {\n    this.emit('resume')\n    this.paused = false\n    if (this._emitQueue.length) {\n      var eq = this._emitQueue.slice(0)\n      this._emitQueue.length = 0\n      for (var i = 0; i < eq.length; i ++) {\n        var e = eq[i]\n        this._emitMatch(e[0], e[1])\n      }\n    }\n    if (this._processQueue.length) {\n      var pq = this._processQueue.slice(0)\n      this._processQueue.length = 0\n      for (var i = 0; i < pq.length; i ++) {\n        var p = pq[i]\n        this._processing--\n        this._process(p[0], p[1], p[2], p[3])\n      }\n    }\n  }\n}\n\nGlob.prototype._process = function (pattern, index, inGlobStar, cb) {\n  assert(this instanceof Glob)\n  assert(typeof cb === 'function')\n\n  if (this.aborted)\n    return\n\n  this._processing++\n  if (this.paused) {\n    this._processQueue.push([pattern, index, inGlobStar, cb])\n    return\n  }\n\n  //console.error('PROCESS %d', this._processing, pattern)\n\n  // Get the first [n] parts of pattern that are all strings.\n  var n = 0\n  while (typeof pattern[n] === 'string') {\n    n ++\n  }\n  // now n is the index of the first one that is *not* a string.\n\n  // see if there's anything else\n  var prefix\n  switch (n) {\n    // if not, then this is rather simple\n    case pattern.length:\n      this._processSimple(pattern.join('/'), index, cb)\n      return\n\n    case 0:\n      // pattern *starts* with some non-trivial item.\n      // going to readdir(cwd), but not include the prefix in matches.\n      prefix = null\n      break\n\n    default:\n      // pattern has some string bits in the front.\n      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n      // or 'relative' like '../baz'\n      prefix = pattern.slice(0, n).join('/')\n      break\n  }\n\n  var remain = pattern.slice(n)\n\n  // get the list of entries.\n  var read\n  if (prefix === null)\n    read = '.'\n  else if (isAbsolute(prefix) || isAbsolute(pattern.join('/'))) {\n    if (!prefix || !isAbsolute(prefix))\n      prefix = '/' + prefix\n    read = prefix\n  } else\n    read = prefix\n\n  var abs = this._makeAbs(read)\n\n  //if ignored, skip _processing\n  if (childrenIgnored(this, read))\n    return cb()\n\n  var isGlobStar = remain[0] === minimatch.GLOBSTAR\n  if (isGlobStar)\n    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar, cb)\n  else\n    this._processReaddir(prefix, read, abs, remain, index, inGlobStar, cb)\n}\n\nGlob.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n  var self = this\n  this._readdir(abs, inGlobStar, function (er, entries) {\n    return self._processReaddir2(prefix, read, abs, remain, index, inGlobStar, entries, cb)\n  })\n}\n\nGlob.prototype._processReaddir2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n\n  // if the abs isn't a dir, then nothing can match!\n  if (!entries)\n    return cb()\n\n  // It will only match dot entries if it starts with a dot, or if\n  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n  var pn = remain[0]\n  var negate = !!this.minimatch.negate\n  var rawGlob = pn._glob\n  var dotOk = this.dot || rawGlob.charAt(0) === '.'\n\n  var matchedEntries = []\n  for (var i = 0; i < entries.length; i++) {\n    var e = entries[i]\n    if (e.charAt(0) !== '.' || dotOk) {\n      var m\n      if (negate && !prefix) {\n        m = !e.match(pn)\n      } else {\n        m = e.match(pn)\n      }\n      if (m)\n        matchedEntries.push(e)\n    }\n  }\n\n  //console.error('prd2', prefix, entries, remain[0]._glob, matchedEntries)\n\n  var len = matchedEntries.length\n  // If there are no matched entries, then nothing matches.\n  if (len === 0)\n    return cb()\n\n  // if this is the last remaining pattern bit, then no need for\n  // an additional stat *unless* the user has specified mark or\n  // stat explicitly.  We know they exist, since readdir returned\n  // them.\n\n  if (remain.length === 1 && !this.mark && !this.stat) {\n    if (!this.matches[index])\n      this.matches[index] = Object.create(null)\n\n    for (var i = 0; i < len; i ++) {\n      var e = matchedEntries[i]\n      if (prefix) {\n        if (prefix !== '/')\n          e = prefix + '/' + e\n        else\n          e = prefix + e\n      }\n\n      if (e.charAt(0) === '/' && !this.nomount) {\n        e = path.join(this.root, e)\n      }\n      this._emitMatch(index, e)\n    }\n    // This was the last one, and no stats were needed\n    return cb()\n  }\n\n  // now test all matched entries as stand-ins for that part\n  // of the pattern.\n  remain.shift()\n  for (var i = 0; i < len; i ++) {\n    var e = matchedEntries[i]\n    var newPattern\n    if (prefix) {\n      if (prefix !== '/')\n        e = prefix + '/' + e\n      else\n        e = prefix + e\n    }\n    this._process([e].concat(remain), index, inGlobStar, cb)\n  }\n  cb()\n}\n\nGlob.prototype._emitMatch = function (index, e) {\n  if (this.aborted)\n    return\n\n  if (isIgnored(this, e))\n    return\n\n  if (this.paused) {\n    this._emitQueue.push([index, e])\n    return\n  }\n\n  var abs = isAbsolute(e) ? e : this._makeAbs(e)\n\n  if (this.mark)\n    e = this._mark(e)\n\n  if (this.absolute)\n    e = abs\n\n  if (this.matches[index][e])\n    return\n\n  if (this.nodir) {\n    var c = this.cache[abs]\n    if (c === 'DIR' || Array.isArray(c))\n      return\n  }\n\n  this.matches[index][e] = true\n\n  var st = this.statCache[abs]\n  if (st)\n    this.emit('stat', e, st)\n\n  this.emit('match', e)\n}\n\nGlob.prototype._readdirInGlobStar = function (abs, cb) {\n  if (this.aborted)\n    return\n\n  // follow all symlinked directories forever\n  // just proceed as if this is a non-globstar situation\n  if (this.follow)\n    return this._readdir(abs, false, cb)\n\n  var lstatkey = 'lstat\\0' + abs\n  var self = this\n  var lstatcb = inflight(lstatkey, lstatcb_)\n\n  if (lstatcb)\n    fs.lstat(abs, lstatcb)\n\n  function lstatcb_ (er, lstat) {\n    if (er && er.code === 'ENOENT')\n      return cb()\n\n    var isSym = lstat && lstat.isSymbolicLink()\n    self.symlinks[abs] = isSym\n\n    // If it's not a symlink or a dir, then it's definitely a regular file.\n    // don't bother doing a readdir in that case.\n    if (!isSym && lstat && !lstat.isDirectory()) {\n      self.cache[abs] = 'FILE'\n      cb()\n    } else\n      self._readdir(abs, false, cb)\n  }\n}\n\nGlob.prototype._readdir = function (abs, inGlobStar, cb) {\n  if (this.aborted)\n    return\n\n  cb = inflight('readdir\\0'+abs+'\\0'+inGlobStar, cb)\n  if (!cb)\n    return\n\n  //console.error('RD %j %j', +inGlobStar, abs)\n  if (inGlobStar && !ownProp(this.symlinks, abs))\n    return this._readdirInGlobStar(abs, cb)\n\n  if (ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n    if (!c || c === 'FILE')\n      return cb()\n\n    if (Array.isArray(c))\n      return cb(null, c)\n  }\n\n  var self = this\n  fs.readdir(abs, readdirCb(this, abs, cb))\n}\n\nfunction readdirCb (self, abs, cb) {\n  return function (er, entries) {\n    if (er)\n      self._readdirError(abs, er, cb)\n    else\n      self._readdirEntries(abs, entries, cb)\n  }\n}\n\nGlob.prototype._readdirEntries = function (abs, entries, cb) {\n  if (this.aborted)\n    return\n\n  // if we haven't asked to stat everything, then just\n  // assume that everything in there exists, so we can avoid\n  // having to stat it a second time.\n  if (!this.mark && !this.stat) {\n    for (var i = 0; i < entries.length; i ++) {\n      var e = entries[i]\n      if (abs === '/')\n        e = abs + e\n      else\n        e = abs + '/' + e\n      this.cache[e] = true\n    }\n  }\n\n  this.cache[abs] = entries\n  return cb(null, entries)\n}\n\nGlob.prototype._readdirError = function (f, er, cb) {\n  if (this.aborted)\n    return\n\n  // handle errors, and cache the information\n  switch (er.code) {\n    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n    case 'ENOTDIR': // totally normal. means it *does* exist.\n      var abs = this._makeAbs(f)\n      this.cache[abs] = 'FILE'\n      if (abs === this.cwdAbs) {\n        var error = new Error(er.code + ' invalid cwd ' + this.cwd)\n        error.path = this.cwd\n        error.code = er.code\n        this.emit('error', error)\n        this.abort()\n      }\n      break\n\n    case 'ENOENT': // not terribly unusual\n    case 'ELOOP':\n    case 'ENAMETOOLONG':\n    case 'UNKNOWN':\n      this.cache[this._makeAbs(f)] = false\n      break\n\n    default: // some unusual error.  Treat as failure.\n      this.cache[this._makeAbs(f)] = false\n      if (this.strict) {\n        this.emit('error', er)\n        // If the error is handled, then we abort\n        // if not, we threw out of here\n        this.abort()\n      }\n      if (!this.silent)\n        console.error('glob error', er)\n      break\n  }\n\n  return cb()\n}\n\nGlob.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n  var self = this\n  this._readdir(abs, inGlobStar, function (er, entries) {\n    self._processGlobStar2(prefix, read, abs, remain, index, inGlobStar, entries, cb)\n  })\n}\n\n\nGlob.prototype._processGlobStar2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n  //console.error('pgs2', prefix, remain[0], entries)\n\n  // no entries means not a dir, so it can never have matches\n  // foo.txt/** doesn't match foo.txt\n  if (!entries)\n    return cb()\n\n  // test without the globstar, and with every child both below\n  // and replacing the globstar.\n  var remainWithoutGlobStar = remain.slice(1)\n  var gspref = prefix ? [ prefix ] : []\n  var noGlobStar = gspref.concat(remainWithoutGlobStar)\n\n  // the noGlobStar pattern exits the inGlobStar state\n  this._process(noGlobStar, index, false, cb)\n\n  var isSym = this.symlinks[abs]\n  var len = entries.length\n\n  // If it's a symlink, and we're in a globstar, then stop\n  if (isSym && inGlobStar)\n    return cb()\n\n  for (var i = 0; i < len; i++) {\n    var e = entries[i]\n    if (e.charAt(0) === '.' && !this.dot)\n      continue\n\n    // these two cases enter the inGlobStar state\n    var instead = gspref.concat(entries[i], remainWithoutGlobStar)\n    this._process(instead, index, true, cb)\n\n    var below = gspref.concat(entries[i], remain)\n    this._process(below, index, true, cb)\n  }\n\n  cb()\n}\n\nGlob.prototype._processSimple = function (prefix, index, cb) {\n  // XXX review this.  Shouldn't it be doing the mounting etc\n  // before doing stat?  kinda weird?\n  var self = this\n  this._stat(prefix, function (er, exists) {\n    self._processSimple2(prefix, index, er, exists, cb)\n  })\n}\nGlob.prototype._processSimple2 = function (prefix, index, er, exists, cb) {\n\n  //console.error('ps2', prefix, exists)\n\n  if (!this.matches[index])\n    this.matches[index] = Object.create(null)\n\n  // If it doesn't exist, then just mark the lack of results\n  if (!exists)\n    return cb()\n\n  if (prefix && isAbsolute(prefix) && !this.nomount) {\n    var trail = /[\\/\\\\]$/.test(prefix)\n    if (prefix.charAt(0) === '/') {\n      prefix = path.join(this.root, prefix)\n    } else {\n      prefix = path.resolve(this.root, prefix)\n      if (trail)\n        prefix += '/'\n    }\n  }\n\n  if (process.platform === 'win32')\n    prefix = prefix.replace(/\\\\/g, '/')\n\n  // Mark this as a match\n  this._emitMatch(index, prefix)\n  cb()\n}\n\n// Returns either 'DIR', 'FILE', or false\nGlob.prototype._stat = function (f, cb) {\n  var abs = this._makeAbs(f)\n  var needDir = f.slice(-1) === '/'\n\n  if (f.length > this.maxLength)\n    return cb()\n\n  if (!this.stat && ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n\n    if (Array.isArray(c))\n      c = 'DIR'\n\n    // It exists, but maybe not how we need it\n    if (!needDir || c === 'DIR')\n      return cb(null, c)\n\n    if (needDir && c === 'FILE')\n      return cb()\n\n    // otherwise we have to stat, because maybe c=true\n    // if we know it exists, but not what it is.\n  }\n\n  var exists\n  var stat = this.statCache[abs]\n  if (stat !== undefined) {\n    if (stat === false)\n      return cb(null, stat)\n    else {\n      var type = stat.isDirectory() ? 'DIR' : 'FILE'\n      if (needDir && type === 'FILE')\n        return cb()\n      else\n        return cb(null, type, stat)\n    }\n  }\n\n  var self = this\n  var statcb = inflight('stat\\0' + abs, lstatcb_)\n  if (statcb)\n    fs.lstat(abs, statcb)\n\n  function lstatcb_ (er, lstat) {\n    if (lstat && lstat.isSymbolicLink()) {\n      // If it's a symlink, then treat it as the target, unless\n      // the target does not exist, then treat it as a file.\n      return fs.stat(abs, function (er, stat) {\n        if (er)\n          self._stat2(f, abs, null, lstat, cb)\n        else\n          self._stat2(f, abs, er, stat, cb)\n      })\n    } else {\n      self._stat2(f, abs, er, lstat, cb)\n    }\n  }\n}\n\nGlob.prototype._stat2 = function (f, abs, er, stat, cb) {\n  if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n    this.statCache[abs] = false\n    return cb()\n  }\n\n  var needDir = f.slice(-1) === '/'\n  this.statCache[abs] = stat\n\n  if (abs.slice(-1) === '/' && stat && !stat.isDirectory())\n    return cb(null, false, stat)\n\n  var c = true\n  if (stat)\n    c = stat.isDirectory() ? 'DIR' : 'FILE'\n  this.cache[abs] = this.cache[abs] || c\n\n  if (needDir && c === 'FILE')\n    return cb()\n\n  return cb(null, c, stat)\n}\n\n\n//# sourceURL=webpack:///./node_modules/glob/glob.js?");

/***/ }),

/***/ "./node_modules/glob/sync.js":
/*!***********************************!*\
  !*** ./node_modules/glob/sync.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = globSync\nglobSync.GlobSync = GlobSync\n\nvar fs = __webpack_require__(/*! fs */ \"fs\")\nvar rp = __webpack_require__(/*! fs.realpath */ \"./node_modules/fs.realpath/index.js\")\nvar minimatch = __webpack_require__(/*! minimatch */ \"./node_modules/minimatch/minimatch.js\")\nvar Minimatch = minimatch.Minimatch\nvar Glob = __webpack_require__(/*! ./glob.js */ \"./node_modules/glob/glob.js\").Glob\nvar util = __webpack_require__(/*! util */ \"util\")\nvar path = __webpack_require__(/*! path */ \"path\")\nvar assert = __webpack_require__(/*! assert */ \"assert\")\nvar isAbsolute = __webpack_require__(/*! path-is-absolute */ \"./node_modules/path-is-absolute/index.js\")\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/glob/common.js\")\nvar alphasort = common.alphasort\nvar alphasorti = common.alphasorti\nvar setopts = common.setopts\nvar ownProp = common.ownProp\nvar childrenIgnored = common.childrenIgnored\nvar isIgnored = common.isIgnored\n\nfunction globSync (pattern, options) {\n  if (typeof options === 'function' || arguments.length === 3)\n    throw new TypeError('callback provided to sync glob\\n'+\n                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n  return new GlobSync(pattern, options).found\n}\n\nfunction GlobSync (pattern, options) {\n  if (!pattern)\n    throw new Error('must provide pattern')\n\n  if (typeof options === 'function' || arguments.length === 3)\n    throw new TypeError('callback provided to sync glob\\n'+\n                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n  if (!(this instanceof GlobSync))\n    return new GlobSync(pattern, options)\n\n  setopts(this, pattern, options)\n\n  if (this.noprocess)\n    return this\n\n  var n = this.minimatch.set.length\n  this.matches = new Array(n)\n  for (var i = 0; i < n; i ++) {\n    this._process(this.minimatch.set[i], i, false)\n  }\n  this._finish()\n}\n\nGlobSync.prototype._finish = function () {\n  assert(this instanceof GlobSync)\n  if (this.realpath) {\n    var self = this\n    this.matches.forEach(function (matchset, index) {\n      var set = self.matches[index] = Object.create(null)\n      for (var p in matchset) {\n        try {\n          p = self._makeAbs(p)\n          var real = rp.realpathSync(p, self.realpathCache)\n          set[real] = true\n        } catch (er) {\n          if (er.syscall === 'stat')\n            set[self._makeAbs(p)] = true\n          else\n            throw er\n        }\n      }\n    })\n  }\n  common.finish(this)\n}\n\n\nGlobSync.prototype._process = function (pattern, index, inGlobStar) {\n  assert(this instanceof GlobSync)\n\n  // Get the first [n] parts of pattern that are all strings.\n  var n = 0\n  while (typeof pattern[n] === 'string') {\n    n ++\n  }\n  // now n is the index of the first one that is *not* a string.\n\n  // See if there's anything else\n  var prefix\n  switch (n) {\n    // if not, then this is rather simple\n    case pattern.length:\n      this._processSimple(pattern.join('/'), index)\n      return\n\n    case 0:\n      // pattern *starts* with some non-trivial item.\n      // going to readdir(cwd), but not include the prefix in matches.\n      prefix = null\n      break\n\n    default:\n      // pattern has some string bits in the front.\n      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n      // or 'relative' like '../baz'\n      prefix = pattern.slice(0, n).join('/')\n      break\n  }\n\n  var remain = pattern.slice(n)\n\n  // get the list of entries.\n  var read\n  if (prefix === null)\n    read = '.'\n  else if (isAbsolute(prefix) || isAbsolute(pattern.join('/'))) {\n    if (!prefix || !isAbsolute(prefix))\n      prefix = '/' + prefix\n    read = prefix\n  } else\n    read = prefix\n\n  var abs = this._makeAbs(read)\n\n  //if ignored, skip processing\n  if (childrenIgnored(this, read))\n    return\n\n  var isGlobStar = remain[0] === minimatch.GLOBSTAR\n  if (isGlobStar)\n    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar)\n  else\n    this._processReaddir(prefix, read, abs, remain, index, inGlobStar)\n}\n\n\nGlobSync.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar) {\n  var entries = this._readdir(abs, inGlobStar)\n\n  // if the abs isn't a dir, then nothing can match!\n  if (!entries)\n    return\n\n  // It will only match dot entries if it starts with a dot, or if\n  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n  var pn = remain[0]\n  var negate = !!this.minimatch.negate\n  var rawGlob = pn._glob\n  var dotOk = this.dot || rawGlob.charAt(0) === '.'\n\n  var matchedEntries = []\n  for (var i = 0; i < entries.length; i++) {\n    var e = entries[i]\n    if (e.charAt(0) !== '.' || dotOk) {\n      var m\n      if (negate && !prefix) {\n        m = !e.match(pn)\n      } else {\n        m = e.match(pn)\n      }\n      if (m)\n        matchedEntries.push(e)\n    }\n  }\n\n  var len = matchedEntries.length\n  // If there are no matched entries, then nothing matches.\n  if (len === 0)\n    return\n\n  // if this is the last remaining pattern bit, then no need for\n  // an additional stat *unless* the user has specified mark or\n  // stat explicitly.  We know they exist, since readdir returned\n  // them.\n\n  if (remain.length === 1 && !this.mark && !this.stat) {\n    if (!this.matches[index])\n      this.matches[index] = Object.create(null)\n\n    for (var i = 0; i < len; i ++) {\n      var e = matchedEntries[i]\n      if (prefix) {\n        if (prefix.slice(-1) !== '/')\n          e = prefix + '/' + e\n        else\n          e = prefix + e\n      }\n\n      if (e.charAt(0) === '/' && !this.nomount) {\n        e = path.join(this.root, e)\n      }\n      this._emitMatch(index, e)\n    }\n    // This was the last one, and no stats were needed\n    return\n  }\n\n  // now test all matched entries as stand-ins for that part\n  // of the pattern.\n  remain.shift()\n  for (var i = 0; i < len; i ++) {\n    var e = matchedEntries[i]\n    var newPattern\n    if (prefix)\n      newPattern = [prefix, e]\n    else\n      newPattern = [e]\n    this._process(newPattern.concat(remain), index, inGlobStar)\n  }\n}\n\n\nGlobSync.prototype._emitMatch = function (index, e) {\n  if (isIgnored(this, e))\n    return\n\n  var abs = this._makeAbs(e)\n\n  if (this.mark)\n    e = this._mark(e)\n\n  if (this.absolute) {\n    e = abs\n  }\n\n  if (this.matches[index][e])\n    return\n\n  if (this.nodir) {\n    var c = this.cache[abs]\n    if (c === 'DIR' || Array.isArray(c))\n      return\n  }\n\n  this.matches[index][e] = true\n\n  if (this.stat)\n    this._stat(e)\n}\n\n\nGlobSync.prototype._readdirInGlobStar = function (abs) {\n  // follow all symlinked directories forever\n  // just proceed as if this is a non-globstar situation\n  if (this.follow)\n    return this._readdir(abs, false)\n\n  var entries\n  var lstat\n  var stat\n  try {\n    lstat = fs.lstatSync(abs)\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      // lstat failed, doesn't exist\n      return null\n    }\n  }\n\n  var isSym = lstat && lstat.isSymbolicLink()\n  this.symlinks[abs] = isSym\n\n  // If it's not a symlink or a dir, then it's definitely a regular file.\n  // don't bother doing a readdir in that case.\n  if (!isSym && lstat && !lstat.isDirectory())\n    this.cache[abs] = 'FILE'\n  else\n    entries = this._readdir(abs, false)\n\n  return entries\n}\n\nGlobSync.prototype._readdir = function (abs, inGlobStar) {\n  var entries\n\n  if (inGlobStar && !ownProp(this.symlinks, abs))\n    return this._readdirInGlobStar(abs)\n\n  if (ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n    if (!c || c === 'FILE')\n      return null\n\n    if (Array.isArray(c))\n      return c\n  }\n\n  try {\n    return this._readdirEntries(abs, fs.readdirSync(abs))\n  } catch (er) {\n    this._readdirError(abs, er)\n    return null\n  }\n}\n\nGlobSync.prototype._readdirEntries = function (abs, entries) {\n  // if we haven't asked to stat everything, then just\n  // assume that everything in there exists, so we can avoid\n  // having to stat it a second time.\n  if (!this.mark && !this.stat) {\n    for (var i = 0; i < entries.length; i ++) {\n      var e = entries[i]\n      if (abs === '/')\n        e = abs + e\n      else\n        e = abs + '/' + e\n      this.cache[e] = true\n    }\n  }\n\n  this.cache[abs] = entries\n\n  // mark and cache dir-ness\n  return entries\n}\n\nGlobSync.prototype._readdirError = function (f, er) {\n  // handle errors, and cache the information\n  switch (er.code) {\n    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n    case 'ENOTDIR': // totally normal. means it *does* exist.\n      var abs = this._makeAbs(f)\n      this.cache[abs] = 'FILE'\n      if (abs === this.cwdAbs) {\n        var error = new Error(er.code + ' invalid cwd ' + this.cwd)\n        error.path = this.cwd\n        error.code = er.code\n        throw error\n      }\n      break\n\n    case 'ENOENT': // not terribly unusual\n    case 'ELOOP':\n    case 'ENAMETOOLONG':\n    case 'UNKNOWN':\n      this.cache[this._makeAbs(f)] = false\n      break\n\n    default: // some unusual error.  Treat as failure.\n      this.cache[this._makeAbs(f)] = false\n      if (this.strict)\n        throw er\n      if (!this.silent)\n        console.error('glob error', er)\n      break\n  }\n}\n\nGlobSync.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar) {\n\n  var entries = this._readdir(abs, inGlobStar)\n\n  // no entries means not a dir, so it can never have matches\n  // foo.txt/** doesn't match foo.txt\n  if (!entries)\n    return\n\n  // test without the globstar, and with every child both below\n  // and replacing the globstar.\n  var remainWithoutGlobStar = remain.slice(1)\n  var gspref = prefix ? [ prefix ] : []\n  var noGlobStar = gspref.concat(remainWithoutGlobStar)\n\n  // the noGlobStar pattern exits the inGlobStar state\n  this._process(noGlobStar, index, false)\n\n  var len = entries.length\n  var isSym = this.symlinks[abs]\n\n  // If it's a symlink, and we're in a globstar, then stop\n  if (isSym && inGlobStar)\n    return\n\n  for (var i = 0; i < len; i++) {\n    var e = entries[i]\n    if (e.charAt(0) === '.' && !this.dot)\n      continue\n\n    // these two cases enter the inGlobStar state\n    var instead = gspref.concat(entries[i], remainWithoutGlobStar)\n    this._process(instead, index, true)\n\n    var below = gspref.concat(entries[i], remain)\n    this._process(below, index, true)\n  }\n}\n\nGlobSync.prototype._processSimple = function (prefix, index) {\n  // XXX review this.  Shouldn't it be doing the mounting etc\n  // before doing stat?  kinda weird?\n  var exists = this._stat(prefix)\n\n  if (!this.matches[index])\n    this.matches[index] = Object.create(null)\n\n  // If it doesn't exist, then just mark the lack of results\n  if (!exists)\n    return\n\n  if (prefix && isAbsolute(prefix) && !this.nomount) {\n    var trail = /[\\/\\\\]$/.test(prefix)\n    if (prefix.charAt(0) === '/') {\n      prefix = path.join(this.root, prefix)\n    } else {\n      prefix = path.resolve(this.root, prefix)\n      if (trail)\n        prefix += '/'\n    }\n  }\n\n  if (process.platform === 'win32')\n    prefix = prefix.replace(/\\\\/g, '/')\n\n  // Mark this as a match\n  this._emitMatch(index, prefix)\n}\n\n// Returns either 'DIR', 'FILE', or false\nGlobSync.prototype._stat = function (f) {\n  var abs = this._makeAbs(f)\n  var needDir = f.slice(-1) === '/'\n\n  if (f.length > this.maxLength)\n    return false\n\n  if (!this.stat && ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n\n    if (Array.isArray(c))\n      c = 'DIR'\n\n    // It exists, but maybe not how we need it\n    if (!needDir || c === 'DIR')\n      return c\n\n    if (needDir && c === 'FILE')\n      return false\n\n    // otherwise we have to stat, because maybe c=true\n    // if we know it exists, but not what it is.\n  }\n\n  var exists\n  var stat = this.statCache[abs]\n  if (!stat) {\n    var lstat\n    try {\n      lstat = fs.lstatSync(abs)\n    } catch (er) {\n      if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n        this.statCache[abs] = false\n        return false\n      }\n    }\n\n    if (lstat && lstat.isSymbolicLink()) {\n      try {\n        stat = fs.statSync(abs)\n      } catch (er) {\n        stat = lstat\n      }\n    } else {\n      stat = lstat\n    }\n  }\n\n  this.statCache[abs] = stat\n\n  var c = true\n  if (stat)\n    c = stat.isDirectory() ? 'DIR' : 'FILE'\n\n  this.cache[abs] = this.cache[abs] || c\n\n  if (needDir && c === 'FILE')\n    return false\n\n  return c\n}\n\nGlobSync.prototype._mark = function (p) {\n  return common.mark(this, p)\n}\n\nGlobSync.prototype._makeAbs = function (f) {\n  return common.makeAbs(this, f)\n}\n\n\n//# sourceURL=webpack:///./node_modules/glob/sync.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/clone.js":
/*!*******************************************!*\
  !*** ./node_modules/graceful-fs/clone.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nmodule.exports = clone\n\nfunction clone (obj) {\n  if (obj === null || typeof obj !== 'object')\n    return obj\n\n  if (obj instanceof Object)\n    var copy = { __proto__: obj.__proto__ }\n  else\n    var copy = Object.create(null)\n\n  Object.getOwnPropertyNames(obj).forEach(function (key) {\n    Object.defineProperty(copy, key, Object.getOwnPropertyDescriptor(obj, key))\n  })\n\n  return copy\n}\n\n\n//# sourceURL=webpack:///./node_modules/graceful-fs/clone.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/graceful-fs.js":
/*!*************************************************!*\
  !*** ./node_modules/graceful-fs/graceful-fs.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var fs = __webpack_require__(/*! fs */ \"fs\")\nvar polyfills = __webpack_require__(/*! ./polyfills.js */ \"./node_modules/graceful-fs/polyfills.js\")\nvar legacy = __webpack_require__(/*! ./legacy-streams.js */ \"./node_modules/graceful-fs/legacy-streams.js\")\nvar clone = __webpack_require__(/*! ./clone.js */ \"./node_modules/graceful-fs/clone.js\")\n\nvar util = __webpack_require__(/*! util */ \"util\")\n\n/* istanbul ignore next - node 0.x polyfill */\nvar gracefulQueue\nvar previousSymbol\n\n/* istanbul ignore else - node 0.x polyfill */\nif (typeof Symbol === 'function' && typeof Symbol.for === 'function') {\n  gracefulQueue = Symbol.for('graceful-fs.queue')\n  // This is used in testing by future versions\n  previousSymbol = Symbol.for('graceful-fs.previous')\n} else {\n  gracefulQueue = '___graceful-fs.queue'\n  previousSymbol = '___graceful-fs.previous'\n}\n\nfunction noop () {}\n\nvar debug = noop\nif (util.debuglog)\n  debug = util.debuglog('gfs4')\nelse if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || ''))\n  debug = function() {\n    var m = util.format.apply(util, arguments)\n    m = 'GFS4: ' + m.split(/\\n/).join('\\nGFS4: ')\n    console.error(m)\n  }\n\n// Once time initialization\nif (!global[gracefulQueue]) {\n  // This queue can be shared by multiple loaded instances\n  var queue = []\n  Object.defineProperty(global, gracefulQueue, {\n    get: function() {\n      return queue\n    }\n  })\n\n  // Patch fs.close/closeSync to shared queue version, because we need\n  // to retry() whenever a close happens *anywhere* in the program.\n  // This is essential when multiple graceful-fs instances are\n  // in play at the same time.\n  fs.close = (function (fs$close) {\n    function close (fd, cb) {\n      return fs$close.call(fs, fd, function (err) {\n        // This function uses the graceful-fs shared queue\n        if (!err) {\n          retry()\n        }\n\n        if (typeof cb === 'function')\n          cb.apply(this, arguments)\n      })\n    }\n\n    Object.defineProperty(close, previousSymbol, {\n      value: fs$close\n    })\n    return close\n  })(fs.close)\n\n  fs.closeSync = (function (fs$closeSync) {\n    function closeSync (fd) {\n      // This function uses the graceful-fs shared queue\n      fs$closeSync.apply(fs, arguments)\n      retry()\n    }\n\n    Object.defineProperty(closeSync, previousSymbol, {\n      value: fs$closeSync\n    })\n    return closeSync\n  })(fs.closeSync)\n\n  if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || '')) {\n    process.on('exit', function() {\n      debug(global[gracefulQueue])\n      __webpack_require__(/*! assert */ \"assert\").equal(global[gracefulQueue].length, 0)\n    })\n  }\n}\n\nmodule.exports = patch(clone(fs))\nif (process.env.TEST_GRACEFUL_FS_GLOBAL_PATCH && !fs.__patched) {\n    module.exports = patch(fs)\n    fs.__patched = true;\n}\n\nfunction patch (fs) {\n  // Everything that references the open() function needs to be in here\n  polyfills(fs)\n  fs.gracefulify = patch\n\n  fs.createReadStream = createReadStream\n  fs.createWriteStream = createWriteStream\n  var fs$readFile = fs.readFile\n  fs.readFile = readFile\n  function readFile (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$readFile(path, options, cb)\n\n    function go$readFile (path, options, cb) {\n      return fs$readFile(path, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$readFile, [path, options, cb]])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n          retry()\n        }\n      })\n    }\n  }\n\n  var fs$writeFile = fs.writeFile\n  fs.writeFile = writeFile\n  function writeFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$writeFile(path, data, options, cb)\n\n    function go$writeFile (path, data, options, cb) {\n      return fs$writeFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$writeFile, [path, data, options, cb]])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n          retry()\n        }\n      })\n    }\n  }\n\n  var fs$appendFile = fs.appendFile\n  if (fs$appendFile)\n    fs.appendFile = appendFile\n  function appendFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$appendFile(path, data, options, cb)\n\n    function go$appendFile (path, data, options, cb) {\n      return fs$appendFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$appendFile, [path, data, options, cb]])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n          retry()\n        }\n      })\n    }\n  }\n\n  var fs$readdir = fs.readdir\n  fs.readdir = readdir\n  function readdir (path, options, cb) {\n    var args = [path]\n    if (typeof options !== 'function') {\n      args.push(options)\n    } else {\n      cb = options\n    }\n    args.push(go$readdir$cb)\n\n    return go$readdir(args)\n\n    function go$readdir$cb (err, files) {\n      if (files && files.sort)\n        files.sort()\n\n      if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n        enqueue([go$readdir, [args]])\n\n      else {\n        if (typeof cb === 'function')\n          cb.apply(this, arguments)\n        retry()\n      }\n    }\n  }\n\n  function go$readdir (args) {\n    return fs$readdir.apply(fs, args)\n  }\n\n  if (process.version.substr(0, 4) === 'v0.8') {\n    var legStreams = legacy(fs)\n    ReadStream = legStreams.ReadStream\n    WriteStream = legStreams.WriteStream\n  }\n\n  var fs$ReadStream = fs.ReadStream\n  if (fs$ReadStream) {\n    ReadStream.prototype = Object.create(fs$ReadStream.prototype)\n    ReadStream.prototype.open = ReadStream$open\n  }\n\n  var fs$WriteStream = fs.WriteStream\n  if (fs$WriteStream) {\n    WriteStream.prototype = Object.create(fs$WriteStream.prototype)\n    WriteStream.prototype.open = WriteStream$open\n  }\n\n  Object.defineProperty(fs, 'ReadStream', {\n    get: function () {\n      return ReadStream\n    },\n    set: function (val) {\n      ReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  Object.defineProperty(fs, 'WriteStream', {\n    get: function () {\n      return WriteStream\n    },\n    set: function (val) {\n      WriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  // legacy names\n  Object.defineProperty(fs, 'FileReadStream', {\n    get: function () {\n      return ReadStream\n    },\n    set: function (val) {\n      ReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  Object.defineProperty(fs, 'FileWriteStream', {\n    get: function () {\n      return WriteStream\n    },\n    set: function (val) {\n      WriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  function ReadStream (path, options) {\n    if (this instanceof ReadStream)\n      return fs$ReadStream.apply(this, arguments), this\n    else\n      return ReadStream.apply(Object.create(ReadStream.prototype), arguments)\n  }\n\n  function ReadStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        if (that.autoClose)\n          that.destroy()\n\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n        that.read()\n      }\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (this instanceof WriteStream)\n      return fs$WriteStream.apply(this, arguments), this\n    else\n      return WriteStream.apply(Object.create(WriteStream.prototype), arguments)\n  }\n\n  function WriteStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        that.destroy()\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n      }\n    })\n  }\n\n  function createReadStream (path, options) {\n    return new fs.ReadStream(path, options)\n  }\n\n  function createWriteStream (path, options) {\n    return new fs.WriteStream(path, options)\n  }\n\n  var fs$open = fs.open\n  fs.open = open\n  function open (path, flags, mode, cb) {\n    if (typeof mode === 'function')\n      cb = mode, mode = null\n\n    return go$open(path, flags, mode, cb)\n\n    function go$open (path, flags, mode, cb) {\n      return fs$open(path, flags, mode, function (err, fd) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$open, [path, flags, mode, cb]])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n          retry()\n        }\n      })\n    }\n  }\n\n  return fs\n}\n\nfunction enqueue (elem) {\n  debug('ENQUEUE', elem[0].name, elem[1])\n  global[gracefulQueue].push(elem)\n}\n\nfunction retry () {\n  var elem = global[gracefulQueue].shift()\n  if (elem) {\n    debug('RETRY', elem[0].name, elem[1])\n    elem[0].apply(null, elem[1])\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/graceful-fs/graceful-fs.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/legacy-streams.js":
/*!****************************************************!*\
  !*** ./node_modules/graceful-fs/legacy-streams.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var Stream = __webpack_require__(/*! stream */ \"stream\").Stream\n\nmodule.exports = legacy\n\nfunction legacy (fs) {\n  return {\n    ReadStream: ReadStream,\n    WriteStream: WriteStream\n  }\n\n  function ReadStream (path, options) {\n    if (!(this instanceof ReadStream)) return new ReadStream(path, options);\n\n    Stream.call(this);\n\n    var self = this;\n\n    this.path = path;\n    this.fd = null;\n    this.readable = true;\n    this.paused = false;\n\n    this.flags = 'r';\n    this.mode = 438; /*=0666*/\n    this.bufferSize = 64 * 1024;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.encoding) this.setEncoding(this.encoding);\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.end === undefined) {\n        this.end = Infinity;\n      } else if ('number' !== typeof this.end) {\n        throw TypeError('end must be a Number');\n      }\n\n      if (this.start > this.end) {\n        throw new Error('start must be <= end');\n      }\n\n      this.pos = this.start;\n    }\n\n    if (this.fd !== null) {\n      process.nextTick(function() {\n        self._read();\n      });\n      return;\n    }\n\n    fs.open(this.path, this.flags, this.mode, function (err, fd) {\n      if (err) {\n        self.emit('error', err);\n        self.readable = false;\n        return;\n      }\n\n      self.fd = fd;\n      self.emit('open', fd);\n      self._read();\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (!(this instanceof WriteStream)) return new WriteStream(path, options);\n\n    Stream.call(this);\n\n    this.path = path;\n    this.fd = null;\n    this.writable = true;\n\n    this.flags = 'w';\n    this.encoding = 'binary';\n    this.mode = 438; /*=0666*/\n    this.bytesWritten = 0;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.start < 0) {\n        throw new Error('start must be >= zero');\n      }\n\n      this.pos = this.start;\n    }\n\n    this.busy = false;\n    this._queue = [];\n\n    if (this.fd === null) {\n      this._open = fs.open;\n      this._queue.push([this._open, this.path, this.flags, this.mode, undefined]);\n      this.flush();\n    }\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/graceful-fs/legacy-streams.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/polyfills.js":
/*!***********************************************!*\
  !*** ./node_modules/graceful-fs/polyfills.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var constants = __webpack_require__(/*! constants */ \"constants\")\n\nvar origCwd = process.cwd\nvar cwd = null\n\nvar platform = process.env.GRACEFUL_FS_PLATFORM || process.platform\n\nprocess.cwd = function() {\n  if (!cwd)\n    cwd = origCwd.call(process)\n  return cwd\n}\ntry {\n  process.cwd()\n} catch (er) {}\n\nvar chdir = process.chdir\nprocess.chdir = function(d) {\n  cwd = null\n  chdir.call(process, d)\n}\n\nmodule.exports = patch\n\nfunction patch (fs) {\n  // (re-)implement some things that are known busted or missing.\n\n  // lchmod, broken prior to 0.6.2\n  // back-port the fix here.\n  if (constants.hasOwnProperty('O_SYMLINK') &&\n      process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n    patchLchmod(fs)\n  }\n\n  // lutimes implementation, or no-op\n  if (!fs.lutimes) {\n    patchLutimes(fs)\n  }\n\n  // https://github.com/isaacs/node-graceful-fs/issues/4\n  // Chown should not fail on einval or eperm if non-root.\n  // It should not fail on enosys ever, as this just indicates\n  // that a fs doesn't support the intended operation.\n\n  fs.chown = chownFix(fs.chown)\n  fs.fchown = chownFix(fs.fchown)\n  fs.lchown = chownFix(fs.lchown)\n\n  fs.chmod = chmodFix(fs.chmod)\n  fs.fchmod = chmodFix(fs.fchmod)\n  fs.lchmod = chmodFix(fs.lchmod)\n\n  fs.chownSync = chownFixSync(fs.chownSync)\n  fs.fchownSync = chownFixSync(fs.fchownSync)\n  fs.lchownSync = chownFixSync(fs.lchownSync)\n\n  fs.chmodSync = chmodFixSync(fs.chmodSync)\n  fs.fchmodSync = chmodFixSync(fs.fchmodSync)\n  fs.lchmodSync = chmodFixSync(fs.lchmodSync)\n\n  fs.stat = statFix(fs.stat)\n  fs.fstat = statFix(fs.fstat)\n  fs.lstat = statFix(fs.lstat)\n\n  fs.statSync = statFixSync(fs.statSync)\n  fs.fstatSync = statFixSync(fs.fstatSync)\n  fs.lstatSync = statFixSync(fs.lstatSync)\n\n  // if lchmod/lchown do not exist, then make them no-ops\n  if (!fs.lchmod) {\n    fs.lchmod = function (path, mode, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchmodSync = function () {}\n  }\n  if (!fs.lchown) {\n    fs.lchown = function (path, uid, gid, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchownSync = function () {}\n  }\n\n  // on Windows, A/V software can lock the directory, causing this\n  // to fail with an EACCES or EPERM if the directory contains newly\n  // created files.  Try again on failure, for up to 60 seconds.\n\n  // Set the timeout this long because some Windows Anti-Virus, such as Parity\n  // bit9, may lock files for up to a minute, causing npm package install\n  // failures. Also, take care to yield the scheduler. Windows scheduling gives\n  // CPU to a busy looping process, which can cause the program causing the lock\n  // contention to be starved of CPU by node, so the contention doesn't resolve.\n  if (platform === \"win32\") {\n    fs.rename = (function (fs$rename) { return function (from, to, cb) {\n      var start = Date.now()\n      var backoff = 0;\n      fs$rename(from, to, function CB (er) {\n        if (er\n            && (er.code === \"EACCES\" || er.code === \"EPERM\")\n            && Date.now() - start < 60000) {\n          setTimeout(function() {\n            fs.stat(to, function (stater, st) {\n              if (stater && stater.code === \"ENOENT\")\n                fs$rename(from, to, CB);\n              else\n                cb(er)\n            })\n          }, backoff)\n          if (backoff < 100)\n            backoff += 10;\n          return;\n        }\n        if (cb) cb(er)\n      })\n    }})(fs.rename)\n  }\n\n  // if read() returns EAGAIN, then just try it again.\n  fs.read = (function (fs$read) {\n    function read (fd, buffer, offset, length, position, callback_) {\n      var callback\n      if (callback_ && typeof callback_ === 'function') {\n        var eagCounter = 0\n        callback = function (er, _, __) {\n          if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n            eagCounter ++\n            return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n          }\n          callback_.apply(this, arguments)\n        }\n      }\n      return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n    }\n\n    // This ensures `util.promisify` works as it does for native `fs.read`.\n    read.__proto__ = fs$read\n    return read\n  })(fs.read)\n\n  fs.readSync = (function (fs$readSync) { return function (fd, buffer, offset, length, position) {\n    var eagCounter = 0\n    while (true) {\n      try {\n        return fs$readSync.call(fs, fd, buffer, offset, length, position)\n      } catch (er) {\n        if (er.code === 'EAGAIN' && eagCounter < 10) {\n          eagCounter ++\n          continue\n        }\n        throw er\n      }\n    }\n  }})(fs.readSync)\n\n  function patchLchmod (fs) {\n    fs.lchmod = function (path, mode, callback) {\n      fs.open( path\n             , constants.O_WRONLY | constants.O_SYMLINK\n             , mode\n             , function (err, fd) {\n        if (err) {\n          if (callback) callback(err)\n          return\n        }\n        // prefer to return the chmod error, if one occurs,\n        // but still try to close, and report closing errors if they occur.\n        fs.fchmod(fd, mode, function (err) {\n          fs.close(fd, function(err2) {\n            if (callback) callback(err || err2)\n          })\n        })\n      })\n    }\n\n    fs.lchmodSync = function (path, mode) {\n      var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode)\n\n      // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n      var threw = true\n      var ret\n      try {\n        ret = fs.fchmodSync(fd, mode)\n        threw = false\n      } finally {\n        if (threw) {\n          try {\n            fs.closeSync(fd)\n          } catch (er) {}\n        } else {\n          fs.closeSync(fd)\n        }\n      }\n      return ret\n    }\n  }\n\n  function patchLutimes (fs) {\n    if (constants.hasOwnProperty(\"O_SYMLINK\")) {\n      fs.lutimes = function (path, at, mt, cb) {\n        fs.open(path, constants.O_SYMLINK, function (er, fd) {\n          if (er) {\n            if (cb) cb(er)\n            return\n          }\n          fs.futimes(fd, at, mt, function (er) {\n            fs.close(fd, function (er2) {\n              if (cb) cb(er || er2)\n            })\n          })\n        })\n      }\n\n      fs.lutimesSync = function (path, at, mt) {\n        var fd = fs.openSync(path, constants.O_SYMLINK)\n        var ret\n        var threw = true\n        try {\n          ret = fs.futimesSync(fd, at, mt)\n          threw = false\n        } finally {\n          if (threw) {\n            try {\n              fs.closeSync(fd)\n            } catch (er) {}\n          } else {\n            fs.closeSync(fd)\n          }\n        }\n        return ret\n      }\n\n    } else {\n      fs.lutimes = function (_a, _b, _c, cb) { if (cb) process.nextTick(cb) }\n      fs.lutimesSync = function () {}\n    }\n  }\n\n  function chmodFix (orig) {\n    if (!orig) return orig\n    return function (target, mode, cb) {\n      return orig.call(fs, target, mode, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chmodFixSync (orig) {\n    if (!orig) return orig\n    return function (target, mode) {\n      try {\n        return orig.call(fs, target, mode)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n\n  function chownFix (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid, cb) {\n      return orig.call(fs, target, uid, gid, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chownFixSync (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid) {\n      try {\n        return orig.call(fs, target, uid, gid)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n  function statFix (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options, cb) {\n      if (typeof options === 'function') {\n        cb = options\n        options = null\n      }\n      function callback (er, stats) {\n        if (stats) {\n          if (stats.uid < 0) stats.uid += 0x100000000\n          if (stats.gid < 0) stats.gid += 0x100000000\n        }\n        if (cb) cb.apply(this, arguments)\n      }\n      return options ? orig.call(fs, target, options, callback)\n        : orig.call(fs, target, callback)\n    }\n  }\n\n  function statFixSync (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options) {\n      var stats = options ? orig.call(fs, target, options)\n        : orig.call(fs, target)\n      if (stats.uid < 0) stats.uid += 0x100000000\n      if (stats.gid < 0) stats.gid += 0x100000000\n      return stats;\n    }\n  }\n\n  // ENOSYS means that the fs doesn't support the op. Just ignore\n  // that, because it doesn't matter.\n  //\n  // if there's no getuid, or if getuid() is something other\n  // than 0, and the error is EINVAL or EPERM, then just ignore\n  // it.\n  //\n  // This specific case is a silent failure in cp, install, tar,\n  // and most other unix tools that manage permissions.\n  //\n  // When running as root, or if other types of errors are\n  // encountered, then it's strict.\n  function chownErOk (er) {\n    if (!er)\n      return true\n\n    if (er.code === \"ENOSYS\")\n      return true\n\n    var nonroot = !process.getuid || process.getuid() !== 0\n    if (nonroot) {\n      if (er.code === \"EINVAL\" || er.code === \"EPERM\")\n        return true\n    }\n\n    return false\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/graceful-fs/polyfills.js?");

/***/ }),

/***/ "./node_modules/immediate/lib/index.js":
/*!*********************************************!*\
  !*** ./node_modules/immediate/lib/index.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar Mutation = global.MutationObserver || global.WebKitMutationObserver;\n\nvar scheduleDrain;\n\nif (process.browser) {\n  if (Mutation) {\n    var called = 0;\n    var observer = new Mutation(nextTick);\n    var element = global.document.createTextNode('');\n    observer.observe(element, {\n      characterData: true\n    });\n    scheduleDrain = function () {\n      element.data = (called = ++called % 2);\n    };\n  } else if (!global.setImmediate && typeof global.MessageChannel !== 'undefined') {\n    var channel = new global.MessageChannel();\n    channel.port1.onmessage = nextTick;\n    scheduleDrain = function () {\n      channel.port2.postMessage(0);\n    };\n  } else if ('document' in global && 'onreadystatechange' in global.document.createElement('script')) {\n    scheduleDrain = function () {\n\n      // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n      // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n      var scriptEl = global.document.createElement('script');\n      scriptEl.onreadystatechange = function () {\n        nextTick();\n\n        scriptEl.onreadystatechange = null;\n        scriptEl.parentNode.removeChild(scriptEl);\n        scriptEl = null;\n      };\n      global.document.documentElement.appendChild(scriptEl);\n    };\n  } else {\n    scheduleDrain = function () {\n      setTimeout(nextTick, 0);\n    };\n  }\n} else {\n  scheduleDrain = function () {\n    process.nextTick(nextTick);\n  };\n}\n\nvar draining;\nvar queue = [];\n//named nextTick for less confusing stack traces\nfunction nextTick() {\n  draining = true;\n  var i, oldQueue;\n  var len = queue.length;\n  while (len) {\n    oldQueue = queue;\n    queue = [];\n    i = -1;\n    while (++i < len) {\n      oldQueue[i]();\n    }\n    len = queue.length;\n  }\n  draining = false;\n}\n\nmodule.exports = immediate;\nfunction immediate(task) {\n  if (queue.push(task) === 1 && !draining) {\n    scheduleDrain();\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/immediate/lib/index.js?");

/***/ }),

/***/ "./node_modules/inflight/inflight.js":
/*!*******************************************!*\
  !*** ./node_modules/inflight/inflight.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var wrappy = __webpack_require__(/*! wrappy */ \"./node_modules/wrappy/wrappy.js\")\nvar reqs = Object.create(null)\nvar once = __webpack_require__(/*! once */ \"./node_modules/once/once.js\")\n\nmodule.exports = wrappy(inflight)\n\nfunction inflight (key, cb) {\n  if (reqs[key]) {\n    reqs[key].push(cb)\n    return null\n  } else {\n    reqs[key] = [cb]\n    return makeres(key)\n  }\n}\n\nfunction makeres (key) {\n  return once(function RES () {\n    var cbs = reqs[key]\n    var len = cbs.length\n    var args = slice(arguments)\n\n    // XXX It's somewhat ambiguous whether a new callback added in this\n    // pass should be queued for later execution if something in the\n    // list of callbacks throws, or if it should just be discarded.\n    // However, it's such an edge case that it hardly matters, and either\n    // choice is likely as surprising as the other.\n    // As it happens, we do go ahead and schedule it for later execution.\n    try {\n      for (var i = 0; i < len; i++) {\n        cbs[i].apply(null, args)\n      }\n    } finally {\n      if (cbs.length > len) {\n        // added more in the interim.\n        // de-zalgo, just in case, but don't call again.\n        cbs.splice(0, len)\n        process.nextTick(function () {\n          RES.apply(null, args)\n        })\n      } else {\n        delete reqs[key]\n      }\n    }\n  })\n}\n\nfunction slice (args) {\n  var length = args.length\n  var array = []\n\n  for (var i = 0; i < length; i++) array[i] = args[i]\n  return array\n}\n\n\n//# sourceURL=webpack:///./node_modules/inflight/inflight.js?");

/***/ }),

/***/ "./node_modules/inherits/inherits.js":
/*!*******************************************!*\
  !*** ./node_modules/inherits/inherits.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("try {\n  var util = __webpack_require__(/*! util */ \"util\");\n  /* istanbul ignore next */\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  /* istanbul ignore next */\n  module.exports = __webpack_require__(/*! ./inherits_browser.js */ \"./node_modules/inherits/inherits_browser.js\");\n}\n\n\n//# sourceURL=webpack:///./node_modules/inherits/inherits.js?");

/***/ }),

/***/ "./node_modules/inherits/inherits_browser.js":
/*!***************************************************!*\
  !*** ./node_modules/inherits/inherits_browser.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/inherits/inherits_browser.js?");

/***/ }),

/***/ "./node_modules/isarray/index.js":
/*!***************************************!*\
  !*** ./node_modules/isarray/index.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n\n//# sourceURL=webpack:///./node_modules/isarray/index.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/arrayReader.js":
/*!***********************************************!*\
  !*** ./node_modules/jszip/lib/arrayReader.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar DataReader = __webpack_require__(/*! ./dataReader */ \"./node_modules/jszip/lib/dataReader.js\");\n\nfunction ArrayReader(data) {\n    if (data) {\n        this.data = data;\n        this.length = this.data.length;\n        this.index = 0;\n        this.zero = 0;\n\n        for(var i = 0; i < this.data.length; i++) {\n            data[i] = data[i] & 0xFF;\n        }\n    }\n}\nArrayReader.prototype = new DataReader();\n/**\n * @see DataReader.byteAt\n */\nArrayReader.prototype.byteAt = function(i) {\n    return this.data[this.zero + i];\n};\n/**\n * @see DataReader.lastIndexOfSignature\n */\nArrayReader.prototype.lastIndexOfSignature = function(sig) {\n    var sig0 = sig.charCodeAt(0),\n        sig1 = sig.charCodeAt(1),\n        sig2 = sig.charCodeAt(2),\n        sig3 = sig.charCodeAt(3);\n    for (var i = this.length - 4; i >= 0; --i) {\n        if (this.data[i] === sig0 && this.data[i + 1] === sig1 && this.data[i + 2] === sig2 && this.data[i + 3] === sig3) {\n            return i - this.zero;\n        }\n    }\n\n    return -1;\n};\n/**\n * @see DataReader.readData\n */\nArrayReader.prototype.readData = function(size) {\n    this.checkOffset(size);\n    if(size === 0) {\n        return [];\n    }\n    var result = this.data.slice(this.zero + this.index, this.zero + this.index + size);\n    this.index += size;\n    return result;\n};\nmodule.exports = ArrayReader;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/arrayReader.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/base64.js":
/*!******************************************!*\
  !*** ./node_modules/jszip/lib/base64.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n// private property\nvar _keyStr = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\";\n\n\n// public method for encoding\nexports.encode = function(input, utf8) {\n    var output = \"\";\n    var chr1, chr2, chr3, enc1, enc2, enc3, enc4;\n    var i = 0;\n\n    while (i < input.length) {\n\n        chr1 = input.charCodeAt(i++);\n        chr2 = input.charCodeAt(i++);\n        chr3 = input.charCodeAt(i++);\n\n        enc1 = chr1 >> 2;\n        enc2 = ((chr1 & 3) << 4) | (chr2 >> 4);\n        enc3 = ((chr2 & 15) << 2) | (chr3 >> 6);\n        enc4 = chr3 & 63;\n\n        if (isNaN(chr2)) {\n            enc3 = enc4 = 64;\n        }\n        else if (isNaN(chr3)) {\n            enc4 = 64;\n        }\n\n        output = output + _keyStr.charAt(enc1) + _keyStr.charAt(enc2) + _keyStr.charAt(enc3) + _keyStr.charAt(enc4);\n\n    }\n\n    return output;\n};\n\n// public method for decoding\nexports.decode = function(input, utf8) {\n    var output = \"\";\n    var chr1, chr2, chr3;\n    var enc1, enc2, enc3, enc4;\n    var i = 0;\n\n    input = input.replace(/[^A-Za-z0-9\\+\\/\\=]/g, \"\");\n\n    while (i < input.length) {\n\n        enc1 = _keyStr.indexOf(input.charAt(i++));\n        enc2 = _keyStr.indexOf(input.charAt(i++));\n        enc3 = _keyStr.indexOf(input.charAt(i++));\n        enc4 = _keyStr.indexOf(input.charAt(i++));\n\n        chr1 = (enc1 << 2) | (enc2 >> 4);\n        chr2 = ((enc2 & 15) << 4) | (enc3 >> 2);\n        chr3 = ((enc3 & 3) << 6) | enc4;\n\n        output = output + String.fromCharCode(chr1);\n\n        if (enc3 != 64) {\n            output = output + String.fromCharCode(chr2);\n        }\n        if (enc4 != 64) {\n            output = output + String.fromCharCode(chr3);\n        }\n\n    }\n\n    return output;\n\n};\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/base64.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/compressedObject.js":
/*!****************************************************!*\
  !*** ./node_modules/jszip/lib/compressedObject.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nfunction CompressedObject() {\n    this.compressedSize = 0;\n    this.uncompressedSize = 0;\n    this.crc32 = 0;\n    this.compressionMethod = null;\n    this.compressedContent = null;\n}\n\nCompressedObject.prototype = {\n    /**\n     * Return the decompressed content in an unspecified format.\n     * The format will depend on the decompressor.\n     * @return {Object} the decompressed content.\n     */\n    getContent: function() {\n        return null; // see implementation\n    },\n    /**\n     * Return the compressed content in an unspecified format.\n     * The format will depend on the compressed conten source.\n     * @return {Object} the compressed content.\n     */\n    getCompressedContent: function() {\n        return null; // see implementation\n    }\n};\nmodule.exports = CompressedObject;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/compressedObject.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/compressions.js":
/*!************************************************!*\
  !*** ./node_modules/jszip/lib/compressions.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nexports.STORE = {\n    magic: \"\\x00\\x00\",\n    compress: function(content, compressionOptions) {\n        return content; // no compression\n    },\n    uncompress: function(content) {\n        return content; // no compression\n    },\n    compressInputType: null,\n    uncompressInputType: null\n};\nexports.DEFLATE = __webpack_require__(/*! ./flate */ \"./node_modules/jszip/lib/flate.js\");\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/compressions.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/crc32.js":
/*!*****************************************!*\
  !*** ./node_modules/jszip/lib/crc32.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\n\nvar table = [\n    0x00000000, 0x77073096, 0xEE0E612C, 0x990951BA,\n    0x076DC419, 0x706AF48F, 0xE963A535, 0x9E6495A3,\n    0x0EDB8832, 0x79DCB8A4, 0xE0D5E91E, 0x97D2D988,\n    0x09B64C2B, 0x7EB17CBD, 0xE7B82D07, 0x90BF1D91,\n    0x1DB71064, 0x6AB020F2, 0xF3B97148, 0x84BE41DE,\n    0x1ADAD47D, 0x6DDDE4EB, 0xF4D4B551, 0x83D385C7,\n    0x136C9856, 0x646BA8C0, 0xFD62F97A, 0x8A65C9EC,\n    0x14015C4F, 0x63066CD9, 0xFA0F3D63, 0x8D080DF5,\n    0x3B6E20C8, 0x4C69105E, 0xD56041E4, 0xA2677172,\n    0x3C03E4D1, 0x4B04D447, 0xD20D85FD, 0xA50AB56B,\n    0x35B5A8FA, 0x42B2986C, 0xDBBBC9D6, 0xACBCF940,\n    0x32D86CE3, 0x45DF5C75, 0xDCD60DCF, 0xABD13D59,\n    0x26D930AC, 0x51DE003A, 0xC8D75180, 0xBFD06116,\n    0x21B4F4B5, 0x56B3C423, 0xCFBA9599, 0xB8BDA50F,\n    0x2802B89E, 0x5F058808, 0xC60CD9B2, 0xB10BE924,\n    0x2F6F7C87, 0x58684C11, 0xC1611DAB, 0xB6662D3D,\n    0x76DC4190, 0x01DB7106, 0x98D220BC, 0xEFD5102A,\n    0x71B18589, 0x06B6B51F, 0x9FBFE4A5, 0xE8B8D433,\n    0x7807C9A2, 0x0F00F934, 0x9609A88E, 0xE10E9818,\n    0x7F6A0DBB, 0x086D3D2D, 0x91646C97, 0xE6635C01,\n    0x6B6B51F4, 0x1C6C6162, 0x856530D8, 0xF262004E,\n    0x6C0695ED, 0x1B01A57B, 0x8208F4C1, 0xF50FC457,\n    0x65B0D9C6, 0x12B7E950, 0x8BBEB8EA, 0xFCB9887C,\n    0x62DD1DDF, 0x15DA2D49, 0x8CD37CF3, 0xFBD44C65,\n    0x4DB26158, 0x3AB551CE, 0xA3BC0074, 0xD4BB30E2,\n    0x4ADFA541, 0x3DD895D7, 0xA4D1C46D, 0xD3D6F4FB,\n    0x4369E96A, 0x346ED9FC, 0xAD678846, 0xDA60B8D0,\n    0x44042D73, 0x33031DE5, 0xAA0A4C5F, 0xDD0D7CC9,\n    0x5005713C, 0x270241AA, 0xBE0B1010, 0xC90C2086,\n    0x5768B525, 0x206F85B3, 0xB966D409, 0xCE61E49F,\n    0x5EDEF90E, 0x29D9C998, 0xB0D09822, 0xC7D7A8B4,\n    0x59B33D17, 0x2EB40D81, 0xB7BD5C3B, 0xC0BA6CAD,\n    0xEDB88320, 0x9ABFB3B6, 0x03B6E20C, 0x74B1D29A,\n    0xEAD54739, 0x9DD277AF, 0x04DB2615, 0x73DC1683,\n    0xE3630B12, 0x94643B84, 0x0D6D6A3E, 0x7A6A5AA8,\n    0xE40ECF0B, 0x9309FF9D, 0x0A00AE27, 0x7D079EB1,\n    0xF00F9344, 0x8708A3D2, 0x1E01F268, 0x6906C2FE,\n    0xF762575D, 0x806567CB, 0x196C3671, 0x6E6B06E7,\n    0xFED41B76, 0x89D32BE0, 0x10DA7A5A, 0x67DD4ACC,\n    0xF9B9DF6F, 0x8EBEEFF9, 0x17B7BE43, 0x60B08ED5,\n    0xD6D6A3E8, 0xA1D1937E, 0x38D8C2C4, 0x4FDFF252,\n    0xD1BB67F1, 0xA6BC5767, 0x3FB506DD, 0x48B2364B,\n    0xD80D2BDA, 0xAF0A1B4C, 0x36034AF6, 0x41047A60,\n    0xDF60EFC3, 0xA867DF55, 0x316E8EEF, 0x4669BE79,\n    0xCB61B38C, 0xBC66831A, 0x256FD2A0, 0x5268E236,\n    0xCC0C7795, 0xBB0B4703, 0x220216B9, 0x5505262F,\n    0xC5BA3BBE, 0xB2BD0B28, 0x2BB45A92, 0x5CB36A04,\n    0xC2D7FFA7, 0xB5D0CF31, 0x2CD99E8B, 0x5BDEAE1D,\n    0x9B64C2B0, 0xEC63F226, 0x756AA39C, 0x026D930A,\n    0x9C0906A9, 0xEB0E363F, 0x72076785, 0x05005713,\n    0x95BF4A82, 0xE2B87A14, 0x7BB12BAE, 0x0CB61B38,\n    0x92D28E9B, 0xE5D5BE0D, 0x7CDCEFB7, 0x0BDBDF21,\n    0x86D3D2D4, 0xF1D4E242, 0x68DDB3F8, 0x1FDA836E,\n    0x81BE16CD, 0xF6B9265B, 0x6FB077E1, 0x18B74777,\n    0x88085AE6, 0xFF0F6A70, 0x66063BCA, 0x11010B5C,\n    0x8F659EFF, 0xF862AE69, 0x616BFFD3, 0x166CCF45,\n    0xA00AE278, 0xD70DD2EE, 0x4E048354, 0x3903B3C2,\n    0xA7672661, 0xD06016F7, 0x4969474D, 0x3E6E77DB,\n    0xAED16A4A, 0xD9D65ADC, 0x40DF0B66, 0x37D83BF0,\n    0xA9BCAE53, 0xDEBB9EC5, 0x47B2CF7F, 0x30B5FFE9,\n    0xBDBDF21C, 0xCABAC28A, 0x53B39330, 0x24B4A3A6,\n    0xBAD03605, 0xCDD70693, 0x54DE5729, 0x23D967BF,\n    0xB3667A2E, 0xC4614AB8, 0x5D681B02, 0x2A6F2B94,\n    0xB40BBE37, 0xC30C8EA1, 0x5A05DF1B, 0x2D02EF8D\n];\n\n/**\n *\n *  Javascript crc32\n *  http://www.webtoolkit.info/\n *\n */\nmodule.exports = function crc32(input, crc) {\n    if (typeof input === \"undefined\" || !input.length) {\n        return 0;\n    }\n\n    var isArray = utils.getTypeOf(input) !== \"string\";\n\n    if (typeof(crc) == \"undefined\") {\n        crc = 0;\n    }\n    var x = 0;\n    var y = 0;\n    var b = 0;\n\n    crc = crc ^ (-1);\n    for (var i = 0, iTop = input.length; i < iTop; i++) {\n        b = isArray ? input[i] : input.charCodeAt(i);\n        y = (crc ^ b) & 0xFF;\n        x = table[y];\n        crc = (crc >>> 8) ^ x;\n    }\n\n    return crc ^ (-1);\n};\n// vim: set shiftwidth=4 softtabstop=4:\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/crc32.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/dataReader.js":
/*!**********************************************!*\
  !*** ./node_modules/jszip/lib/dataReader.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\n\nfunction DataReader(data) {\n    this.data = null; // type : see implementation\n    this.length = 0;\n    this.index = 0;\n    this.zero = 0;\n}\nDataReader.prototype = {\n    /**\n     * Check that the offset will not go too far.\n     * @param {string} offset the additional offset to check.\n     * @throws {Error} an Error if the offset is out of bounds.\n     */\n    checkOffset: function(offset) {\n        this.checkIndex(this.index + offset);\n    },\n    /**\n     * Check that the specifed index will not be too far.\n     * @param {string} newIndex the index to check.\n     * @throws {Error} an Error if the index is out of bounds.\n     */\n    checkIndex: function(newIndex) {\n        if (this.length < this.zero + newIndex || newIndex < 0) {\n            throw new Error(\"End of data reached (data length = \" + this.length + \", asked index = \" + (newIndex) + \"). Corrupted zip ?\");\n        }\n    },\n    /**\n     * Change the index.\n     * @param {number} newIndex The new index.\n     * @throws {Error} if the new index is out of the data.\n     */\n    setIndex: function(newIndex) {\n        this.checkIndex(newIndex);\n        this.index = newIndex;\n    },\n    /**\n     * Skip the next n bytes.\n     * @param {number} n the number of bytes to skip.\n     * @throws {Error} if the new index is out of the data.\n     */\n    skip: function(n) {\n        this.setIndex(this.index + n);\n    },\n    /**\n     * Get the byte at the specified index.\n     * @param {number} i the index to use.\n     * @return {number} a byte.\n     */\n    byteAt: function(i) {\n        // see implementations\n    },\n    /**\n     * Get the next number with a given byte size.\n     * @param {number} size the number of bytes to read.\n     * @return {number} the corresponding number.\n     */\n    readInt: function(size) {\n        var result = 0,\n            i;\n        this.checkOffset(size);\n        for (i = this.index + size - 1; i >= this.index; i--) {\n            result = (result << 8) + this.byteAt(i);\n        }\n        this.index += size;\n        return result;\n    },\n    /**\n     * Get the next string with a given byte size.\n     * @param {number} size the number of bytes to read.\n     * @return {string} the corresponding string.\n     */\n    readString: function(size) {\n        return utils.transformTo(\"string\", this.readData(size));\n    },\n    /**\n     * Get raw data without conversion, <size> bytes.\n     * @param {number} size the number of bytes to read.\n     * @return {Object} the raw data, implementation specific.\n     */\n    readData: function(size) {\n        // see implementations\n    },\n    /**\n     * Find the last occurence of a zip signature (4 bytes).\n     * @param {string} sig the signature to find.\n     * @return {number} the index of the last occurence, -1 if not found.\n     */\n    lastIndexOfSignature: function(sig) {\n        // see implementations\n    },\n    /**\n     * Get the next date.\n     * @return {Date} the date.\n     */\n    readDate: function() {\n        var dostime = this.readInt(4);\n        return new Date(\n        ((dostime >> 25) & 0x7f) + 1980, // year\n        ((dostime >> 21) & 0x0f) - 1, // month\n        (dostime >> 16) & 0x1f, // day\n        (dostime >> 11) & 0x1f, // hour\n        (dostime >> 5) & 0x3f, // minute\n        (dostime & 0x1f) << 1); // second\n    }\n};\nmodule.exports = DataReader;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/dataReader.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/defaults.js":
/*!********************************************!*\
  !*** ./node_modules/jszip/lib/defaults.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nexports.base64 = false;\nexports.binary = false;\nexports.dir = false;\nexports.createFolders = false;\nexports.date = null;\nexports.compression = null;\nexports.compressionOptions = null;\nexports.comment = null;\nexports.unixPermissions = null;\nexports.dosPermissions = null;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/defaults.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/deprecatedPublicUtils.js":
/*!*********************************************************!*\
  !*** ./node_modules/jszip/lib/deprecatedPublicUtils.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.string2binary = function(str) {\n    return utils.string2binary(str);\n};\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.string2Uint8Array = function(str) {\n    return utils.transformTo(\"uint8array\", str);\n};\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.uint8Array2String = function(array) {\n    return utils.transformTo(\"string\", array);\n};\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.string2Blob = function(str) {\n    var buffer = utils.transformTo(\"arraybuffer\", str);\n    return utils.arrayBuffer2Blob(buffer);\n};\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.arrayBuffer2Blob = function(buffer) {\n    return utils.arrayBuffer2Blob(buffer);\n};\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.transformTo = function(outputType, input) {\n    return utils.transformTo(outputType, input);\n};\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.getTypeOf = function(input) {\n    return utils.getTypeOf(input);\n};\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.checkSupport = function(type) {\n    return utils.checkSupport(type);\n};\n\n/**\n * @deprecated\n * This value will be removed in a future version without replacement.\n */\nexports.MAX_VALUE_16BITS = utils.MAX_VALUE_16BITS;\n\n/**\n * @deprecated\n * This value will be removed in a future version without replacement.\n */\nexports.MAX_VALUE_32BITS = utils.MAX_VALUE_32BITS;\n\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.pretty = function(str) {\n    return utils.pretty(str);\n};\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.findCompression = function(compressionMethod) {\n    return utils.findCompression(compressionMethod);\n};\n\n/**\n * @deprecated\n * This function will be removed in a future version without replacement.\n */\nexports.isRegExp = function (object) {\n    return utils.isRegExp(object);\n};\n\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/deprecatedPublicUtils.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/flate.js":
/*!*****************************************!*\
  !*** ./node_modules/jszip/lib/flate.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar USE_TYPEDARRAY = (typeof Uint8Array !== 'undefined') && (typeof Uint16Array !== 'undefined') && (typeof Uint32Array !== 'undefined');\n\nvar pako = __webpack_require__(/*! pako */ \"./node_modules/pako/index.js\");\nexports.uncompressInputType = USE_TYPEDARRAY ? \"uint8array\" : \"array\";\nexports.compressInputType = USE_TYPEDARRAY ? \"uint8array\" : \"array\";\n\nexports.magic = \"\\x08\\x00\";\nexports.compress = function(input, compressionOptions) {\n    return pako.deflateRaw(input, {\n        level : compressionOptions.level || -1 // default compression\n    });\n};\nexports.uncompress =  function(input) {\n    return pako.inflateRaw(input);\n};\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/flate.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/index.js":
/*!*****************************************!*\
  !*** ./node_modules/jszip/lib/index.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar base64 = __webpack_require__(/*! ./base64 */ \"./node_modules/jszip/lib/base64.js\");\n\n/**\nUsage:\n   zip = new JSZip();\n   zip.file(\"hello.txt\", \"Hello, World!\").file(\"tempfile\", \"nothing\");\n   zip.folder(\"images\").file(\"smile.gif\", base64Data, {base64: true});\n   zip.file(\"Xmas.txt\", \"Ho ho ho !\", {date : new Date(\"December 25, 2007 00:00:01\")});\n   zip.remove(\"tempfile\");\n\n   base64zip = zip.generate();\n\n**/\n\n/**\n * Representation a of zip file in js\n * @constructor\n * @param {String=|ArrayBuffer=|Uint8Array=} data the data to load, if any (optional).\n * @param {Object=} options the options for creating this objects (optional).\n */\nfunction JSZip(data, options) {\n    // if this constructor isused without`new`, itadds `new` beforeitself:\n    if(!(this instanceof JSZip)) return new JSZip(data, options);\n\n    // object containing the files :\n    // {\n    //   \"folder/\" : {...},\n    //   \"folder/data.txt\" : {...}\n    // }\n    this.files = {};\n\n    this.comment = null;\n\n    // Where we are in the hierarchy\n    this.root = \"\";\n    if (data) {\n        this.load(data, options);\n    }\n    this.clone = function() {\n        var newObj = new JSZip();\n        for (var i in this) {\n            if (typeof this[i] !== \"function\") {\n                newObj[i] = this[i];\n            }\n        }\n        return newObj;\n    };\n}\nJSZip.prototype = __webpack_require__(/*! ./object */ \"./node_modules/jszip/lib/object.js\");\nJSZip.prototype.load = __webpack_require__(/*! ./load */ \"./node_modules/jszip/lib/load.js\");\nJSZip.support = __webpack_require__(/*! ./support */ \"./node_modules/jszip/lib/support.js\");\nJSZip.defaults = __webpack_require__(/*! ./defaults */ \"./node_modules/jszip/lib/defaults.js\");\n\n/**\n * @deprecated\n * This namespace will be removed in a future version without replacement.\n */\nJSZip.utils = __webpack_require__(/*! ./deprecatedPublicUtils */ \"./node_modules/jszip/lib/deprecatedPublicUtils.js\");\n\nJSZip.base64 = {\n    /**\n     * @deprecated\n     * This method will be removed in a future version without replacement.\n     */\n    encode : function(input) {\n        return base64.encode(input);\n    },\n    /**\n     * @deprecated\n     * This method will be removed in a future version without replacement.\n     */\n    decode : function(input) {\n        return base64.decode(input);\n    }\n};\nJSZip.compressions = __webpack_require__(/*! ./compressions */ \"./node_modules/jszip/lib/compressions.js\");\nmodule.exports = JSZip;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/index.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/load.js":
/*!****************************************!*\
  !*** ./node_modules/jszip/lib/load.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar base64 = __webpack_require__(/*! ./base64 */ \"./node_modules/jszip/lib/base64.js\");\nvar utf8 = __webpack_require__(/*! ./utf8 */ \"./node_modules/jszip/lib/utf8.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\nvar ZipEntries = __webpack_require__(/*! ./zipEntries */ \"./node_modules/jszip/lib/zipEntries.js\");\nmodule.exports = function(data, options) {\n    var files, zipEntries, i, input;\n    options = utils.extend(options || {}, {\n        base64: false,\n        checkCRC32: false,\n        optimizedBinaryString : false,\n        createFolders: false,\n        decodeFileName: utf8.utf8decode\n    });\n    if (options.base64) {\n        data = base64.decode(data);\n    }\n\n    zipEntries = new ZipEntries(data, options);\n    files = zipEntries.files;\n    for (i = 0; i < files.length; i++) {\n        input = files[i];\n        this.file(input.fileNameStr, input.decompressed, {\n            binary: true,\n            optimizedBinaryString: true,\n            date: input.date,\n            dir: input.dir,\n            comment : input.fileCommentStr.length ? input.fileCommentStr : null,\n            unixPermissions : input.unixPermissions,\n            dosPermissions : input.dosPermissions,\n            createFolders: options.createFolders\n        });\n    }\n    if (zipEntries.zipComment.length) {\n        this.comment = zipEntries.zipComment;\n    }\n\n    return this;\n};\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/load.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/nodeBuffer.js":
/*!**********************************************!*\
  !*** ./node_modules/jszip/lib/nodeBuffer.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nmodule.exports = function(data, encoding){\n    return new Buffer(data, encoding);\n};\nmodule.exports.test = function(b){\n    return Buffer.isBuffer(b);\n};\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/nodeBuffer.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/nodeBufferReader.js":
/*!****************************************************!*\
  !*** ./node_modules/jszip/lib/nodeBufferReader.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar Uint8ArrayReader = __webpack_require__(/*! ./uint8ArrayReader */ \"./node_modules/jszip/lib/uint8ArrayReader.js\");\n\nfunction NodeBufferReader(data) {\n    this.data = data;\n    this.length = this.data.length;\n    this.index = 0;\n    this.zero = 0;\n}\nNodeBufferReader.prototype = new Uint8ArrayReader();\n\n/**\n * @see DataReader.readData\n */\nNodeBufferReader.prototype.readData = function(size) {\n    this.checkOffset(size);\n    var result = this.data.slice(this.zero + this.index, this.zero + this.index + size);\n    this.index += size;\n    return result;\n};\nmodule.exports = NodeBufferReader;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/nodeBufferReader.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/object.js":
/*!******************************************!*\
  !*** ./node_modules/jszip/lib/object.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/jszip/lib/support.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\nvar crc32 = __webpack_require__(/*! ./crc32 */ \"./node_modules/jszip/lib/crc32.js\");\nvar signature = __webpack_require__(/*! ./signature */ \"./node_modules/jszip/lib/signature.js\");\nvar defaults = __webpack_require__(/*! ./defaults */ \"./node_modules/jszip/lib/defaults.js\");\nvar base64 = __webpack_require__(/*! ./base64 */ \"./node_modules/jszip/lib/base64.js\");\nvar compressions = __webpack_require__(/*! ./compressions */ \"./node_modules/jszip/lib/compressions.js\");\nvar CompressedObject = __webpack_require__(/*! ./compressedObject */ \"./node_modules/jszip/lib/compressedObject.js\");\nvar nodeBuffer = __webpack_require__(/*! ./nodeBuffer */ \"./node_modules/jszip/lib/nodeBuffer.js\");\nvar utf8 = __webpack_require__(/*! ./utf8 */ \"./node_modules/jszip/lib/utf8.js\");\nvar StringWriter = __webpack_require__(/*! ./stringWriter */ \"./node_modules/jszip/lib/stringWriter.js\");\nvar Uint8ArrayWriter = __webpack_require__(/*! ./uint8ArrayWriter */ \"./node_modules/jszip/lib/uint8ArrayWriter.js\");\n\n/**\n * Returns the raw data of a ZipObject, decompress the content if necessary.\n * @param {ZipObject} file the file to use.\n * @return {String|ArrayBuffer|Uint8Array|Buffer} the data.\n */\nvar getRawData = function(file) {\n    if (file._data instanceof CompressedObject) {\n        file._data = file._data.getContent();\n        file.options.binary = true;\n        file.options.base64 = false;\n\n        if (utils.getTypeOf(file._data) === \"uint8array\") {\n            var copy = file._data;\n            // when reading an arraybuffer, the CompressedObject mechanism will keep it and subarray() a Uint8Array.\n            // if we request a file in the same format, we might get the same Uint8Array or its ArrayBuffer (the original zip file).\n            file._data = new Uint8Array(copy.length);\n            // with an empty Uint8Array, Opera fails with a \"Offset larger than array size\"\n            if (copy.length !== 0) {\n                file._data.set(copy, 0);\n            }\n        }\n    }\n    return file._data;\n};\n\n/**\n * Returns the data of a ZipObject in a binary form. If the content is an unicode string, encode it.\n * @param {ZipObject} file the file to use.\n * @return {String|ArrayBuffer|Uint8Array|Buffer} the data.\n */\nvar getBinaryData = function(file) {\n    var result = getRawData(file),\n        type = utils.getTypeOf(result);\n    if (type === \"string\") {\n        if (!file.options.binary) {\n            // unicode text !\n            // unicode string => binary string is a painful process, check if we can avoid it.\n            if (support.nodebuffer) {\n                return nodeBuffer(result, \"utf-8\");\n            }\n        }\n        return file.asBinary();\n    }\n    return result;\n};\n\n/**\n * Transform this._data into a string.\n * @param {function} filter a function String -> String, applied if not null on the result.\n * @return {String} the string representing this._data.\n */\nvar dataToString = function(asUTF8) {\n    var result = getRawData(this);\n    if (result === null || typeof result === \"undefined\") {\n        return \"\";\n    }\n    // if the data is a base64 string, we decode it before checking the encoding !\n    if (this.options.base64) {\n        result = base64.decode(result);\n    }\n    if (asUTF8 && this.options.binary) {\n        // JSZip.prototype.utf8decode supports arrays as input\n        // skip to array => string step, utf8decode will do it.\n        result = out.utf8decode(result);\n    }\n    else {\n        // no utf8 transformation, do the array => string step.\n        result = utils.transformTo(\"string\", result);\n    }\n\n    if (!asUTF8 && !this.options.binary) {\n        result = utils.transformTo(\"string\", out.utf8encode(result));\n    }\n    return result;\n};\n/**\n * A simple object representing a file in the zip file.\n * @constructor\n * @param {string} name the name of the file\n * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data\n * @param {Object} options the options of the file\n */\nvar ZipObject = function(name, data, options) {\n    this.name = name;\n    this.dir = options.dir;\n    this.date = options.date;\n    this.comment = options.comment;\n    this.unixPermissions = options.unixPermissions;\n    this.dosPermissions = options.dosPermissions;\n\n    this._data = data;\n    this.options = options;\n\n    /*\n     * This object contains initial values for dir and date.\n     * With them, we can check if the user changed the deprecated metadata in\n     * `ZipObject#options` or not.\n     */\n    this._initialMetadata = {\n      dir : options.dir,\n      date : options.date\n    };\n};\n\nZipObject.prototype = {\n    /**\n     * Return the content as UTF8 string.\n     * @return {string} the UTF8 string.\n     */\n    asText: function() {\n        return dataToString.call(this, true);\n    },\n    /**\n     * Returns the binary content.\n     * @return {string} the content as binary.\n     */\n    asBinary: function() {\n        return dataToString.call(this, false);\n    },\n    /**\n     * Returns the content as a nodejs Buffer.\n     * @return {Buffer} the content as a Buffer.\n     */\n    asNodeBuffer: function() {\n        var result = getBinaryData(this);\n        return utils.transformTo(\"nodebuffer\", result);\n    },\n    /**\n     * Returns the content as an Uint8Array.\n     * @return {Uint8Array} the content as an Uint8Array.\n     */\n    asUint8Array: function() {\n        var result = getBinaryData(this);\n        return utils.transformTo(\"uint8array\", result);\n    },\n    /**\n     * Returns the content as an ArrayBuffer.\n     * @return {ArrayBuffer} the content as an ArrayBufer.\n     */\n    asArrayBuffer: function() {\n        return this.asUint8Array().buffer;\n    }\n};\n\n/**\n * Transform an integer into a string in hexadecimal.\n * @private\n * @param {number} dec the number to convert.\n * @param {number} bytes the number of bytes to generate.\n * @returns {string} the result.\n */\nvar decToHex = function(dec, bytes) {\n    var hex = \"\",\n        i;\n    for (i = 0; i < bytes; i++) {\n        hex += String.fromCharCode(dec & 0xff);\n        dec = dec >>> 8;\n    }\n    return hex;\n};\n\n/**\n * Transforms the (incomplete) options from the user into the complete\n * set of options to create a file.\n * @private\n * @param {Object} o the options from the user.\n * @return {Object} the complete set of options.\n */\nvar prepareFileAttrs = function(o) {\n    o = o || {};\n    if (o.base64 === true && (o.binary === null || o.binary === undefined)) {\n        o.binary = true;\n    }\n    o = utils.extend(o, defaults);\n    o.date = o.date || new Date();\n    if (o.compression !== null) o.compression = o.compression.toUpperCase();\n\n    return o;\n};\n\n/**\n * Add a file in the current folder.\n * @private\n * @param {string} name the name of the file\n * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data of the file\n * @param {Object} o the options of the file\n * @return {Object} the new file.\n */\nvar fileAdd = function(name, data, o) {\n    // be sure sub folders exist\n    var dataType = utils.getTypeOf(data),\n        parent;\n\n    o = prepareFileAttrs(o);\n\n    if (typeof o.unixPermissions === \"string\") {\n        o.unixPermissions = parseInt(o.unixPermissions, 8);\n    }\n\n    // UNX_IFDIR  0040000 see zipinfo.c\n    if (o.unixPermissions && (o.unixPermissions & 0x4000)) {\n        o.dir = true;\n    }\n    // Bit 4    Directory\n    if (o.dosPermissions && (o.dosPermissions & 0x0010)) {\n        o.dir = true;\n    }\n\n    if (o.dir) {\n        name = forceTrailingSlash(name);\n    }\n\n    if (o.createFolders && (parent = parentFolder(name))) {\n        folderAdd.call(this, parent, true);\n    }\n\n    if (o.dir || data === null || typeof data === \"undefined\") {\n        o.base64 = false;\n        o.binary = false;\n        data = null;\n        dataType = null;\n    }\n    else if (dataType === \"string\") {\n        if (o.binary && !o.base64) {\n            // optimizedBinaryString == true means that the file has already been filtered with a 0xFF mask\n            if (o.optimizedBinaryString !== true) {\n                // this is a string, not in a base64 format.\n                // Be sure that this is a correct \"binary string\"\n                data = utils.string2binary(data);\n            }\n        }\n    }\n    else { // arraybuffer, uint8array, ...\n        o.base64 = false;\n        o.binary = true;\n\n        if (!dataType && !(data instanceof CompressedObject)) {\n            throw new Error(\"The data of '\" + name + \"' is in an unsupported format !\");\n        }\n\n        // special case : it's way easier to work with Uint8Array than with ArrayBuffer\n        if (dataType === \"arraybuffer\") {\n            data = utils.transformTo(\"uint8array\", data);\n        }\n    }\n\n    var object = new ZipObject(name, data, o);\n    this.files[name] = object;\n    return object;\n};\n\n/**\n * Find the parent folder of the path.\n * @private\n * @param {string} path the path to use\n * @return {string} the parent folder, or \"\"\n */\nvar parentFolder = function (path) {\n    if (path.slice(-1) == '/') {\n        path = path.substring(0, path.length - 1);\n    }\n    var lastSlash = path.lastIndexOf('/');\n    return (lastSlash > 0) ? path.substring(0, lastSlash) : \"\";\n};\n\n\n/**\n * Returns the path with a slash at the end.\n * @private\n * @param {String} path the path to check.\n * @return {String} the path with a trailing slash.\n */\nvar forceTrailingSlash = function(path) {\n    // Check the name ends with a /\n    if (path.slice(-1) != \"/\") {\n        path += \"/\"; // IE doesn't like substr(-1)\n    }\n    return path;\n};\n/**\n * Add a (sub) folder in the current folder.\n * @private\n * @param {string} name the folder's name\n * @param {boolean=} [createFolders] If true, automatically create sub\n *  folders. Defaults to false.\n * @return {Object} the new folder.\n */\nvar folderAdd = function(name, createFolders) {\n    createFolders = (typeof createFolders !== 'undefined') ? createFolders : false;\n\n    name = forceTrailingSlash(name);\n\n    // Does this folder already exist?\n    if (!this.files[name]) {\n        fileAdd.call(this, name, null, {\n            dir: true,\n            createFolders: createFolders\n        });\n    }\n    return this.files[name];\n};\n\n/**\n * Generate a JSZip.CompressedObject for a given zipOject.\n * @param {ZipObject} file the object to read.\n * @param {JSZip.compression} compression the compression to use.\n * @param {Object} compressionOptions the options to use when compressing.\n * @return {JSZip.CompressedObject} the compressed result.\n */\nvar generateCompressedObjectFrom = function(file, compression, compressionOptions) {\n    var result = new CompressedObject(),\n        content;\n\n    // the data has not been decompressed, we might reuse things !\n    if (file._data instanceof CompressedObject) {\n        result.uncompressedSize = file._data.uncompressedSize;\n        result.crc32 = file._data.crc32;\n\n        if (result.uncompressedSize === 0 || file.dir) {\n            compression = compressions['STORE'];\n            result.compressedContent = \"\";\n            result.crc32 = 0;\n        }\n        else if (file._data.compressionMethod === compression.magic) {\n            result.compressedContent = file._data.getCompressedContent();\n        }\n        else {\n            content = file._data.getContent();\n            // need to decompress / recompress\n            result.compressedContent = compression.compress(utils.transformTo(compression.compressInputType, content), compressionOptions);\n        }\n    }\n    else {\n        // have uncompressed data\n        content = getBinaryData(file);\n        if (!content || content.length === 0 || file.dir) {\n            compression = compressions['STORE'];\n            content = \"\";\n        }\n        result.uncompressedSize = content.length;\n        result.crc32 = crc32(content);\n        result.compressedContent = compression.compress(utils.transformTo(compression.compressInputType, content), compressionOptions);\n    }\n\n    result.compressedSize = result.compressedContent.length;\n    result.compressionMethod = compression.magic;\n\n    return result;\n};\n\n\n\n\n/**\n * Generate the UNIX part of the external file attributes.\n * @param {Object} unixPermissions the unix permissions or null.\n * @param {Boolean} isDir true if the entry is a directory, false otherwise.\n * @return {Number} a 32 bit integer.\n *\n * adapted from http://unix.stackexchange.com/questions/14705/the-zip-formats-external-file-attribute :\n *\n * TTTTsstrwxrwxrwx0000000000ADVSHR\n * ^^^^____________________________ file type, see zipinfo.c (UNX_*)\n *     ^^^_________________________ setuid, setgid, sticky\n *        ^^^^^^^^^________________ permissions\n *                 ^^^^^^^^^^______ not used ?\n *                           ^^^^^^ DOS attribute bits : Archive, Directory, Volume label, System file, Hidden, Read only\n */\nvar generateUnixExternalFileAttr = function (unixPermissions, isDir) {\n\n    var result = unixPermissions;\n    if (!unixPermissions) {\n        // I can't use octal values in strict mode, hence the hexa.\n        //  040775 => 0x41fd\n        // 0100664 => 0x81b4\n        result = isDir ? 0x41fd : 0x81b4;\n    }\n\n    return (result & 0xFFFF) << 16;\n};\n\n/**\n * Generate the DOS part of the external file attributes.\n * @param {Object} dosPermissions the dos permissions or null.\n * @param {Boolean} isDir true if the entry is a directory, false otherwise.\n * @return {Number} a 32 bit integer.\n *\n * Bit 0     Read-Only\n * Bit 1     Hidden\n * Bit 2     System\n * Bit 3     Volume Label\n * Bit 4     Directory\n * Bit 5     Archive\n */\nvar generateDosExternalFileAttr = function (dosPermissions, isDir) {\n\n    // the dir flag is already set for compatibility\n\n    return (dosPermissions || 0)  & 0x3F;\n};\n\n/**\n * Generate the various parts used in the construction of the final zip file.\n * @param {string} name the file name.\n * @param {ZipObject} file the file content.\n * @param {JSZip.CompressedObject} compressedObject the compressed object.\n * @param {number} offset the current offset from the start of the zip file.\n * @param {String} platform let's pretend we are this platform (change platform dependents fields)\n * @param {Function} encodeFileName the function to encode the file name / comment.\n * @return {object} the zip parts.\n */\nvar generateZipParts = function(name, file, compressedObject, offset, platform, encodeFileName) {\n    var data = compressedObject.compressedContent,\n        useCustomEncoding = encodeFileName !== utf8.utf8encode,\n        encodedFileName = utils.transformTo(\"string\", encodeFileName(file.name)),\n        utfEncodedFileName = utils.transformTo(\"string\", utf8.utf8encode(file.name)),\n        comment = file.comment || \"\",\n        encodedComment = utils.transformTo(\"string\", encodeFileName(comment)),\n        utfEncodedComment = utils.transformTo(\"string\", utf8.utf8encode(comment)),\n        useUTF8ForFileName = utfEncodedFileName.length !== file.name.length,\n        useUTF8ForComment = utfEncodedComment.length !== comment.length,\n        o = file.options,\n        dosTime,\n        dosDate,\n        extraFields = \"\",\n        unicodePathExtraField = \"\",\n        unicodeCommentExtraField = \"\",\n        dir, date;\n\n\n    // handle the deprecated options.dir\n    if (file._initialMetadata.dir !== file.dir) {\n        dir = file.dir;\n    } else {\n        dir = o.dir;\n    }\n\n    // handle the deprecated options.date\n    if(file._initialMetadata.date !== file.date) {\n        date = file.date;\n    } else {\n        date = o.date;\n    }\n\n    var extFileAttr = 0;\n    var versionMadeBy = 0;\n    if (dir) {\n        // dos or unix, we set the dos dir flag\n        extFileAttr |= 0x00010;\n    }\n    if(platform === \"UNIX\") {\n        versionMadeBy = 0x031E; // UNIX, version 3.0\n        extFileAttr |= generateUnixExternalFileAttr(file.unixPermissions, dir);\n    } else { // DOS or other, fallback to DOS\n        versionMadeBy = 0x0014; // DOS, version 2.0\n        extFileAttr |= generateDosExternalFileAttr(file.dosPermissions, dir);\n    }\n\n    // date\n    // @see http://www.delorie.com/djgpp/doc/rbinter/it/52/13.html\n    // @see http://www.delorie.com/djgpp/doc/rbinter/it/65/16.html\n    // @see http://www.delorie.com/djgpp/doc/rbinter/it/66/16.html\n\n    dosTime = date.getHours();\n    dosTime = dosTime << 6;\n    dosTime = dosTime | date.getMinutes();\n    dosTime = dosTime << 5;\n    dosTime = dosTime | date.getSeconds() / 2;\n\n    dosDate = date.getFullYear() - 1980;\n    dosDate = dosDate << 4;\n    dosDate = dosDate | (date.getMonth() + 1);\n    dosDate = dosDate << 5;\n    dosDate = dosDate | date.getDate();\n\n    if (useUTF8ForFileName) {\n        // set the unicode path extra field. unzip needs at least one extra\n        // field to correctly handle unicode path, so using the path is as good\n        // as any other information. This could improve the situation with\n        // other archive managers too.\n        // This field is usually used without the utf8 flag, with a non\n        // unicode path in the header (winrar, winzip). This helps (a bit)\n        // with the messy Windows' default compressed folders feature but\n        // breaks on p7zip which doesn't seek the unicode path extra field.\n        // So for now, UTF-8 everywhere !\n        unicodePathExtraField =\n            // Version\n            decToHex(1, 1) +\n            // NameCRC32\n            decToHex(crc32(encodedFileName), 4) +\n            // UnicodeName\n            utfEncodedFileName;\n\n        extraFields +=\n            // Info-ZIP Unicode Path Extra Field\n            \"\\x75\\x70\" +\n            // size\n            decToHex(unicodePathExtraField.length, 2) +\n            // content\n            unicodePathExtraField;\n    }\n\n    if(useUTF8ForComment) {\n\n        unicodeCommentExtraField =\n            // Version\n            decToHex(1, 1) +\n            // CommentCRC32\n            decToHex(this.crc32(encodedComment), 4) +\n            // UnicodeName\n            utfEncodedComment;\n\n        extraFields +=\n            // Info-ZIP Unicode Path Extra Field\n            \"\\x75\\x63\" +\n            // size\n            decToHex(unicodeCommentExtraField.length, 2) +\n            // content\n            unicodeCommentExtraField;\n    }\n\n    var header = \"\";\n\n    // version needed to extract\n    header += \"\\x0A\\x00\";\n    // general purpose bit flag\n    // set bit 11 if utf8\n    header += !useCustomEncoding && (useUTF8ForFileName || useUTF8ForComment) ? \"\\x00\\x08\" : \"\\x00\\x00\";\n    // compression method\n    header += compressedObject.compressionMethod;\n    // last mod file time\n    header += decToHex(dosTime, 2);\n    // last mod file date\n    header += decToHex(dosDate, 2);\n    // crc-32\n    header += decToHex(compressedObject.crc32, 4);\n    // compressed size\n    header += decToHex(compressedObject.compressedSize, 4);\n    // uncompressed size\n    header += decToHex(compressedObject.uncompressedSize, 4);\n    // file name length\n    header += decToHex(encodedFileName.length, 2);\n    // extra field length\n    header += decToHex(extraFields.length, 2);\n\n\n    var fileRecord = signature.LOCAL_FILE_HEADER + header + encodedFileName + extraFields;\n\n    var dirRecord = signature.CENTRAL_FILE_HEADER +\n    // version made by (00: DOS)\n    decToHex(versionMadeBy, 2) +\n    // file header (common to file and central directory)\n    header +\n    // file comment length\n    decToHex(encodedComment.length, 2) +\n    // disk number start\n    \"\\x00\\x00\" +\n    // internal file attributes TODO\n    \"\\x00\\x00\" +\n    // external file attributes\n    decToHex(extFileAttr, 4) +\n    // relative offset of local header\n    decToHex(offset, 4) +\n    // file name\n    encodedFileName +\n    // extra field\n    extraFields +\n    // file comment\n    encodedComment;\n\n    return {\n        fileRecord: fileRecord,\n        dirRecord: dirRecord,\n        compressedObject: compressedObject\n    };\n};\n\n\n// return the actual prototype of JSZip\nvar out = {\n    /**\n     * Read an existing zip and merge the data in the current JSZip object.\n     * The implementation is in jszip-load.js, don't forget to include it.\n     * @param {String|ArrayBuffer|Uint8Array|Buffer} stream  The stream to load\n     * @param {Object} options Options for loading the stream.\n     *  options.base64 : is the stream in base64 ? default : false\n     * @return {JSZip} the current JSZip object\n     */\n    load: function(stream, options) {\n        throw new Error(\"Load method is not defined. Is the file jszip-load.js included ?\");\n    },\n\n    /**\n     * Filter nested files/folders with the specified function.\n     * @param {Function} search the predicate to use :\n     * function (relativePath, file) {...}\n     * It takes 2 arguments : the relative path and the file.\n     * @return {Array} An array of matching elements.\n     */\n    filter: function(search) {\n        var result = [],\n            filename, relativePath, file, fileClone;\n        for (filename in this.files) {\n            if (!this.files.hasOwnProperty(filename)) {\n                continue;\n            }\n            file = this.files[filename];\n            // return a new object, don't let the user mess with our internal objects :)\n            fileClone = new ZipObject(file.name, file._data, utils.extend(file.options));\n            relativePath = filename.slice(this.root.length, filename.length);\n            if (filename.slice(0, this.root.length) === this.root && // the file is in the current root\n            search(relativePath, fileClone)) { // and the file matches the function\n                result.push(fileClone);\n            }\n        }\n        return result;\n    },\n\n    /**\n     * Add a file to the zip file, or search a file.\n     * @param   {string|RegExp} name The name of the file to add (if data is defined),\n     * the name of the file to find (if no data) or a regex to match files.\n     * @param   {String|ArrayBuffer|Uint8Array|Buffer} data  The file data, either raw or base64 encoded\n     * @param   {Object} o     File options\n     * @return  {JSZip|Object|Array} this JSZip object (when adding a file),\n     * a file (when searching by string) or an array of files (when searching by regex).\n     */\n    file: function(name, data, o) {\n        if (arguments.length === 1) {\n            if (utils.isRegExp(name)) {\n                var regexp = name;\n                return this.filter(function(relativePath, file) {\n                    return !file.dir && regexp.test(relativePath);\n                });\n            }\n            else { // text\n                return this.filter(function(relativePath, file) {\n                    return !file.dir && relativePath === name;\n                })[0] || null;\n            }\n        }\n        else { // more than one argument : we have data !\n            name = this.root + name;\n            fileAdd.call(this, name, data, o);\n        }\n        return this;\n    },\n\n    /**\n     * Add a directory to the zip file, or search.\n     * @param   {String|RegExp} arg The name of the directory to add, or a regex to search folders.\n     * @return  {JSZip} an object with the new directory as the root, or an array containing matching folders.\n     */\n    folder: function(arg) {\n        if (!arg) {\n            return this;\n        }\n\n        if (utils.isRegExp(arg)) {\n            return this.filter(function(relativePath, file) {\n                return file.dir && arg.test(relativePath);\n            });\n        }\n\n        // else, name is a new folder\n        var name = this.root + arg;\n        var newFolder = folderAdd.call(this, name);\n\n        // Allow chaining by returning a new object with this folder as the root\n        var ret = this.clone();\n        ret.root = newFolder.name;\n        return ret;\n    },\n\n    /**\n     * Delete a file, or a directory and all sub-files, from the zip\n     * @param {string} name the name of the file to delete\n     * @return {JSZip} this JSZip object\n     */\n    remove: function(name) {\n        name = this.root + name;\n        var file = this.files[name];\n        if (!file) {\n            // Look for any folders\n            if (name.slice(-1) != \"/\") {\n                name += \"/\";\n            }\n            file = this.files[name];\n        }\n\n        if (file && !file.dir) {\n            // file\n            delete this.files[name];\n        } else {\n            // maybe a folder, delete recursively\n            var kids = this.filter(function(relativePath, file) {\n                return file.name.slice(0, name.length) === name;\n            });\n            for (var i = 0; i < kids.length; i++) {\n                delete this.files[kids[i].name];\n            }\n        }\n\n        return this;\n    },\n\n    /**\n     * Generate the complete zip file\n     * @param {Object} options the options to generate the zip file :\n     * - base64, (deprecated, use type instead) true to generate base64.\n     * - compression, \"STORE\" by default.\n     * - type, \"base64\" by default. Values are : string, base64, uint8array, arraybuffer, blob.\n     * @return {String|Uint8Array|ArrayBuffer|Buffer|Blob} the zip file\n     */\n    generate: function(options) {\n        options = utils.extend(options || {}, {\n            base64: true,\n            compression: \"STORE\",\n            compressionOptions : null,\n            type: \"base64\",\n            platform: \"DOS\",\n            comment: null,\n            mimeType: 'application/zip',\n            encodeFileName: utf8.utf8encode\n        });\n\n        utils.checkSupport(options.type);\n\n        // accept nodejs `process.platform`\n        if(\n          options.platform === 'darwin' ||\n          options.platform === 'freebsd' ||\n          options.platform === 'linux' ||\n          options.platform === 'sunos'\n        ) {\n          options.platform = \"UNIX\";\n        }\n        if (options.platform === 'win32') {\n          options.platform = \"DOS\";\n        }\n\n        var zipData = [],\n            localDirLength = 0,\n            centralDirLength = 0,\n            writer, i,\n            encodedComment = utils.transformTo(\"string\", options.encodeFileName(options.comment || this.comment || \"\"));\n\n        // first, generate all the zip parts.\n        for (var name in this.files) {\n            if (!this.files.hasOwnProperty(name)) {\n                continue;\n            }\n            var file = this.files[name];\n\n            var compressionName = file.options.compression || options.compression.toUpperCase();\n            var compression = compressions[compressionName];\n            if (!compression) {\n                throw new Error(compressionName + \" is not a valid compression method !\");\n            }\n            var compressionOptions = file.options.compressionOptions || options.compressionOptions || {};\n\n            var compressedObject = generateCompressedObjectFrom.call(this, file, compression, compressionOptions);\n\n            var zipPart = generateZipParts.call(this, name, file, compressedObject, localDirLength, options.platform, options.encodeFileName);\n            localDirLength += zipPart.fileRecord.length + compressedObject.compressedSize;\n            centralDirLength += zipPart.dirRecord.length;\n            zipData.push(zipPart);\n        }\n\n        var dirEnd = \"\";\n\n        // end of central dir signature\n        dirEnd = signature.CENTRAL_DIRECTORY_END +\n        // number of this disk\n        \"\\x00\\x00\" +\n        // number of the disk with the start of the central directory\n        \"\\x00\\x00\" +\n        // total number of entries in the central directory on this disk\n        decToHex(zipData.length, 2) +\n        // total number of entries in the central directory\n        decToHex(zipData.length, 2) +\n        // size of the central directory   4 bytes\n        decToHex(centralDirLength, 4) +\n        // offset of start of central directory with respect to the starting disk number\n        decToHex(localDirLength, 4) +\n        // .ZIP file comment length\n        decToHex(encodedComment.length, 2) +\n        // .ZIP file comment\n        encodedComment;\n\n\n        // we have all the parts (and the total length)\n        // time to create a writer !\n        var typeName = options.type.toLowerCase();\n        if(typeName===\"uint8array\"||typeName===\"arraybuffer\"||typeName===\"blob\"||typeName===\"nodebuffer\") {\n            writer = new Uint8ArrayWriter(localDirLength + centralDirLength + dirEnd.length);\n        }else{\n            writer = new StringWriter(localDirLength + centralDirLength + dirEnd.length);\n        }\n\n        for (i = 0; i < zipData.length; i++) {\n            writer.append(zipData[i].fileRecord);\n            writer.append(zipData[i].compressedObject.compressedContent);\n        }\n        for (i = 0; i < zipData.length; i++) {\n            writer.append(zipData[i].dirRecord);\n        }\n\n        writer.append(dirEnd);\n\n        var zip = writer.finalize();\n\n\n\n        switch(options.type.toLowerCase()) {\n            // case \"zip is an Uint8Array\"\n            case \"uint8array\" :\n            case \"arraybuffer\" :\n            case \"nodebuffer\" :\n               return utils.transformTo(options.type.toLowerCase(), zip);\n            case \"blob\" :\n               return utils.arrayBuffer2Blob(utils.transformTo(\"arraybuffer\", zip), options.mimeType);\n            // case \"zip is a string\"\n            case \"base64\" :\n               return (options.base64) ? base64.encode(zip) : zip;\n            default : // case \"string\" :\n               return zip;\n         }\n\n    },\n\n    /**\n     * @deprecated\n     * This method will be removed in a future version without replacement.\n     */\n    crc32: function (input, crc) {\n        return crc32(input, crc);\n    },\n\n    /**\n     * @deprecated\n     * This method will be removed in a future version without replacement.\n     */\n    utf8encode: function (string) {\n        return utils.transformTo(\"string\", utf8.utf8encode(string));\n    },\n\n    /**\n     * @deprecated\n     * This method will be removed in a future version without replacement.\n     */\n    utf8decode: function (input) {\n        return utf8.utf8decode(input);\n    }\n};\nmodule.exports = out;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/object.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/signature.js":
/*!*********************************************!*\
  !*** ./node_modules/jszip/lib/signature.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nexports.LOCAL_FILE_HEADER = \"PK\\x03\\x04\";\nexports.CENTRAL_FILE_HEADER = \"PK\\x01\\x02\";\nexports.CENTRAL_DIRECTORY_END = \"PK\\x05\\x06\";\nexports.ZIP64_CENTRAL_DIRECTORY_LOCATOR = \"PK\\x06\\x07\";\nexports.ZIP64_CENTRAL_DIRECTORY_END = \"PK\\x06\\x06\";\nexports.DATA_DESCRIPTOR = \"PK\\x07\\x08\";\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/signature.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/stringReader.js":
/*!************************************************!*\
  !*** ./node_modules/jszip/lib/stringReader.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar DataReader = __webpack_require__(/*! ./dataReader */ \"./node_modules/jszip/lib/dataReader.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\n\nfunction StringReader(data, optimizedBinaryString) {\n    this.data = data;\n    if (!optimizedBinaryString) {\n        this.data = utils.string2binary(this.data);\n    }\n    this.length = this.data.length;\n    this.index = 0;\n    this.zero = 0;\n}\nStringReader.prototype = new DataReader();\n/**\n * @see DataReader.byteAt\n */\nStringReader.prototype.byteAt = function(i) {\n    return this.data.charCodeAt(this.zero + i);\n};\n/**\n * @see DataReader.lastIndexOfSignature\n */\nStringReader.prototype.lastIndexOfSignature = function(sig) {\n    return this.data.lastIndexOf(sig) - this.zero;\n};\n/**\n * @see DataReader.readData\n */\nStringReader.prototype.readData = function(size) {\n    this.checkOffset(size);\n    // this will work because the constructor applied the \"& 0xff\" mask.\n    var result = this.data.slice(this.zero + this.index, this.zero + this.index + size);\n    this.index += size;\n    return result;\n};\nmodule.exports = StringReader;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/stringReader.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/stringWriter.js":
/*!************************************************!*\
  !*** ./node_modules/jszip/lib/stringWriter.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\n\n/**\n * An object to write any content to a string.\n * @constructor\n */\nvar StringWriter = function() {\n    this.data = [];\n};\nStringWriter.prototype = {\n    /**\n     * Append any content to the current string.\n     * @param {Object} input the content to add.\n     */\n    append: function(input) {\n        input = utils.transformTo(\"string\", input);\n        this.data.push(input);\n    },\n    /**\n     * Finalize the construction an return the result.\n     * @return {string} the generated string.\n     */\n    finalize: function() {\n        return this.data.join(\"\");\n    }\n};\n\nmodule.exports = StringWriter;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/stringWriter.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/support.js":
/*!*******************************************!*\
  !*** ./node_modules/jszip/lib/support.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nexports.base64 = true;\nexports.array = true;\nexports.string = true;\nexports.arraybuffer = typeof ArrayBuffer !== \"undefined\" && typeof Uint8Array !== \"undefined\";\n// contains true if JSZip can read/generate nodejs Buffer, false otherwise.\n// Browserify will provide a Buffer implementation for browsers, which is\n// an augmented Uint8Array (i.e., can be used as either Buffer or U8).\nexports.nodebuffer = typeof Buffer !== \"undefined\";\n// contains true if JSZip can read/generate Uint8Array, false otherwise.\nexports.uint8array = typeof Uint8Array !== \"undefined\";\n\nif (typeof ArrayBuffer === \"undefined\") {\n    exports.blob = false;\n}\nelse {\n    var buffer = new ArrayBuffer(0);\n    try {\n        exports.blob = new Blob([buffer], {\n            type: \"application/zip\"\n        }).size === 0;\n    }\n    catch (e) {\n        try {\n            var Builder = window.BlobBuilder || window.WebKitBlobBuilder || window.MozBlobBuilder || window.MSBlobBuilder;\n            var builder = new Builder();\n            builder.append(buffer);\n            exports.blob = builder.getBlob('application/zip').size === 0;\n        }\n        catch (e) {\n            exports.blob = false;\n        }\n    }\n}\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/support.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/uint8ArrayReader.js":
/*!****************************************************!*\
  !*** ./node_modules/jszip/lib/uint8ArrayReader.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar ArrayReader = __webpack_require__(/*! ./arrayReader */ \"./node_modules/jszip/lib/arrayReader.js\");\n\nfunction Uint8ArrayReader(data) {\n    if (data) {\n        this.data = data;\n        this.length = this.data.length;\n        this.index = 0;\n        this.zero = 0;\n    }\n}\nUint8ArrayReader.prototype = new ArrayReader();\n/**\n * @see DataReader.readData\n */\nUint8ArrayReader.prototype.readData = function(size) {\n    this.checkOffset(size);\n    if(size === 0) {\n        // in IE10, when using subarray(idx, idx), we get the array [0x00] instead of [].\n        return new Uint8Array(0);\n    }\n    var result = this.data.subarray(this.zero + this.index, this.zero + this.index + size);\n    this.index += size;\n    return result;\n};\nmodule.exports = Uint8ArrayReader;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/uint8ArrayReader.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/uint8ArrayWriter.js":
/*!****************************************************!*\
  !*** ./node_modules/jszip/lib/uint8ArrayWriter.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\n\n/**\n * An object to write any content to an Uint8Array.\n * @constructor\n * @param {number} length The length of the array.\n */\nvar Uint8ArrayWriter = function(length) {\n    this.data = new Uint8Array(length);\n    this.index = 0;\n};\nUint8ArrayWriter.prototype = {\n    /**\n     * Append any content to the current array.\n     * @param {Object} input the content to add.\n     */\n    append: function(input) {\n        if (input.length !== 0) {\n            // with an empty Uint8Array, Opera fails with a \"Offset larger than array size\"\n            input = utils.transformTo(\"uint8array\", input);\n            this.data.set(input, this.index);\n            this.index += input.length;\n        }\n    },\n    /**\n     * Finalize the construction an return the result.\n     * @return {Uint8Array} the generated array.\n     */\n    finalize: function() {\n        return this.data;\n    }\n};\n\nmodule.exports = Uint8ArrayWriter;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/uint8ArrayWriter.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/utf8.js":
/*!****************************************!*\
  !*** ./node_modules/jszip/lib/utf8.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/jszip/lib/support.js\");\nvar nodeBuffer = __webpack_require__(/*! ./nodeBuffer */ \"./node_modules/jszip/lib/nodeBuffer.js\");\n\n/**\n * The following functions come from pako, from pako/lib/utils/strings\n * released under the MIT license, see pako https://github.com/nodeca/pako/\n */\n\n// Table with utf8 lengths (calculated by first byte of sequence)\n// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,\n// because max possible codepoint is 0x10ffff\nvar _utf8len = new Array(256);\nfor (var i=0; i<256; i++) {\n  _utf8len[i] = (i >= 252 ? 6 : i >= 248 ? 5 : i >= 240 ? 4 : i >= 224 ? 3 : i >= 192 ? 2 : 1);\n}\n_utf8len[254]=_utf8len[254]=1; // Invalid sequence start\n\n// convert string to array (typed, when possible)\nvar string2buf = function (str) {\n    var buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;\n\n    // count binary size\n    for (m_pos = 0; m_pos < str_len; m_pos++) {\n        c = str.charCodeAt(m_pos);\n        if ((c & 0xfc00) === 0xd800 && (m_pos+1 < str_len)) {\n            c2 = str.charCodeAt(m_pos+1);\n            if ((c2 & 0xfc00) === 0xdc00) {\n                c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n                m_pos++;\n            }\n        }\n        buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;\n    }\n\n    // allocate buffer\n    if (support.uint8array) {\n        buf = new Uint8Array(buf_len);\n    } else {\n        buf = new Array(buf_len);\n    }\n\n    // convert\n    for (i=0, m_pos = 0; i < buf_len; m_pos++) {\n        c = str.charCodeAt(m_pos);\n        if ((c & 0xfc00) === 0xd800 && (m_pos+1 < str_len)) {\n            c2 = str.charCodeAt(m_pos+1);\n            if ((c2 & 0xfc00) === 0xdc00) {\n                c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n                m_pos++;\n            }\n        }\n        if (c < 0x80) {\n            /* one byte */\n            buf[i++] = c;\n        } else if (c < 0x800) {\n            /* two bytes */\n            buf[i++] = 0xC0 | (c >>> 6);\n            buf[i++] = 0x80 | (c & 0x3f);\n        } else if (c < 0x10000) {\n            /* three bytes */\n            buf[i++] = 0xE0 | (c >>> 12);\n            buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n            buf[i++] = 0x80 | (c & 0x3f);\n        } else {\n            /* four bytes */\n            buf[i++] = 0xf0 | (c >>> 18);\n            buf[i++] = 0x80 | (c >>> 12 & 0x3f);\n            buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n            buf[i++] = 0x80 | (c & 0x3f);\n        }\n    }\n\n    return buf;\n};\n\n// Calculate max possible position in utf8 buffer,\n// that will not break sequence. If that's not possible\n// - (very small limits) return max size as is.\n//\n// buf[] - utf8 bytes array\n// max   - length limit (mandatory);\nvar utf8border = function(buf, max) {\n    var pos;\n\n    max = max || buf.length;\n    if (max > buf.length) { max = buf.length; }\n\n    // go back from last position, until start of sequence found\n    pos = max-1;\n    while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }\n\n    // Fuckup - very small and broken sequence,\n    // return max, because we should return something anyway.\n    if (pos < 0) { return max; }\n\n    // If we came to start of buffer - that means vuffer is too small,\n    // return max too.\n    if (pos === 0) { return max; }\n\n    return (pos + _utf8len[buf[pos]] > max) ? pos : max;\n};\n\n// convert array to string\nvar buf2string = function (buf) {\n    var str, i, out, c, c_len;\n    var len = buf.length;\n\n    // Reserve max possible length (2 words per char)\n    // NB: by unknown reasons, Array is significantly faster for\n    //     String.fromCharCode.apply than Uint16Array.\n    var utf16buf = new Array(len*2);\n\n    for (out=0, i=0; i<len;) {\n        c = buf[i++];\n        // quick process ascii\n        if (c < 0x80) { utf16buf[out++] = c; continue; }\n\n        c_len = _utf8len[c];\n        // skip 5 & 6 byte codes\n        if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len-1; continue; }\n\n        // apply mask on first byte\n        c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;\n        // join the rest\n        while (c_len > 1 && i < len) {\n            c = (c << 6) | (buf[i++] & 0x3f);\n            c_len--;\n        }\n\n        // terminated by end of string?\n        if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }\n\n        if (c < 0x10000) {\n            utf16buf[out++] = c;\n        } else {\n            c -= 0x10000;\n            utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);\n            utf16buf[out++] = 0xdc00 | (c & 0x3ff);\n        }\n    }\n\n    // shrinkBuf(utf16buf, out)\n    if (utf16buf.length !== out) {\n        if(utf16buf.subarray) {\n            utf16buf = utf16buf.subarray(0, out);\n        } else {\n            utf16buf.length = out;\n        }\n    }\n\n    // return String.fromCharCode.apply(null, utf16buf);\n    return utils.applyFromCharCode(utf16buf);\n};\n\n\n// That's all for the pako functions.\n\n\n/**\n * Transform a javascript string into an array (typed if possible) of bytes,\n * UTF-8 encoded.\n * @param {String} str the string to encode\n * @return {Array|Uint8Array|Buffer} the UTF-8 encoded string.\n */\nexports.utf8encode = function utf8encode(str) {\n    if (support.nodebuffer) {\n        return nodeBuffer(str, \"utf-8\");\n    }\n\n    return string2buf(str);\n};\n\n\n/**\n * Transform a bytes array (or a representation) representing an UTF-8 encoded\n * string into a javascript string.\n * @param {Array|Uint8Array|Buffer} buf the data de decode\n * @return {String} the decoded string.\n */\nexports.utf8decode = function utf8decode(buf) {\n    if (support.nodebuffer) {\n        return utils.transformTo(\"nodebuffer\", buf).toString(\"utf-8\");\n    }\n\n    buf = utils.transformTo(support.uint8array ? \"uint8array\" : \"array\", buf);\n\n    // return buf2string(buf);\n    // Chrome prefers to work with \"small\" chunks of data\n    // for the method buf2string.\n    // Firefox and Chrome has their own shortcut, IE doesn't seem to really care.\n    var result = [], k = 0, len = buf.length, chunk = 65536;\n    while (k < len) {\n        var nextBoundary = utf8border(buf, Math.min(k + chunk, len));\n        if (support.uint8array) {\n            result.push(buf2string(buf.subarray(k, nextBoundary)));\n        } else {\n            result.push(buf2string(buf.slice(k, nextBoundary)));\n        }\n        k = nextBoundary;\n    }\n    return result.join(\"\");\n\n};\n// vim: set shiftwidth=4 softtabstop=4:\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/utf8.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/utils.js":
/*!*****************************************!*\
  !*** ./node_modules/jszip/lib/utils.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/jszip/lib/support.js\");\nvar compressions = __webpack_require__(/*! ./compressions */ \"./node_modules/jszip/lib/compressions.js\");\nvar nodeBuffer = __webpack_require__(/*! ./nodeBuffer */ \"./node_modules/jszip/lib/nodeBuffer.js\");\n/**\n * Convert a string to a \"binary string\" : a string containing only char codes between 0 and 255.\n * @param {string} str the string to transform.\n * @return {String} the binary string.\n */\nexports.string2binary = function(str) {\n    var result = \"\";\n    for (var i = 0; i < str.length; i++) {\n        result += String.fromCharCode(str.charCodeAt(i) & 0xff);\n    }\n    return result;\n};\nexports.arrayBuffer2Blob = function(buffer, mimeType) {\n    exports.checkSupport(\"blob\");\n\tmimeType = mimeType || 'application/zip';\n\n    try {\n        // Blob constructor\n        return new Blob([buffer], {\n            type: mimeType\n        });\n    }\n    catch (e) {\n\n        try {\n            // deprecated, browser only, old way\n            var Builder = window.BlobBuilder || window.WebKitBlobBuilder || window.MozBlobBuilder || window.MSBlobBuilder;\n            var builder = new Builder();\n            builder.append(buffer);\n            return builder.getBlob(mimeType);\n        }\n        catch (e) {\n\n            // well, fuck ?!\n            throw new Error(\"Bug : can't construct the Blob.\");\n        }\n    }\n\n\n};\n/**\n * The identity function.\n * @param {Object} input the input.\n * @return {Object} the same input.\n */\nfunction identity(input) {\n    return input;\n}\n\n/**\n * Fill in an array with a string.\n * @param {String} str the string to use.\n * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to fill in (will be mutated).\n * @return {Array|ArrayBuffer|Uint8Array|Buffer} the updated array.\n */\nfunction stringToArrayLike(str, array) {\n    for (var i = 0; i < str.length; ++i) {\n        array[i] = str.charCodeAt(i) & 0xFF;\n    }\n    return array;\n}\n\n/**\n * Transform an array-like object to a string.\n * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.\n * @return {String} the result.\n */\nfunction arrayLikeToString(array) {\n    // Performances notes :\n    // --------------------\n    // String.fromCharCode.apply(null, array) is the fastest, see\n    // see http://jsperf.com/converting-a-uint8array-to-a-string/2\n    // but the stack is limited (and we can get huge arrays !).\n    //\n    // result += String.fromCharCode(array[i]); generate too many strings !\n    //\n    // This code is inspired by http://jsperf.com/arraybuffer-to-string-apply-performance/2\n    var chunk = 65536;\n    var result = [],\n        len = array.length,\n        type = exports.getTypeOf(array),\n        k = 0,\n        canUseApply = true;\n      try {\n         switch(type) {\n            case \"uint8array\":\n               String.fromCharCode.apply(null, new Uint8Array(0));\n               break;\n            case \"nodebuffer\":\n               String.fromCharCode.apply(null, nodeBuffer(0));\n               break;\n         }\n      } catch(e) {\n         canUseApply = false;\n      }\n\n      // no apply : slow and painful algorithm\n      // default browser on android 4.*\n      if (!canUseApply) {\n         var resultStr = \"\";\n         for(var i = 0; i < array.length;i++) {\n            resultStr += String.fromCharCode(array[i]);\n         }\n    return resultStr;\n    }\n    while (k < len && chunk > 1) {\n        try {\n            if (type === \"array\" || type === \"nodebuffer\") {\n                result.push(String.fromCharCode.apply(null, array.slice(k, Math.min(k + chunk, len))));\n            }\n            else {\n                result.push(String.fromCharCode.apply(null, array.subarray(k, Math.min(k + chunk, len))));\n            }\n            k += chunk;\n        }\n        catch (e) {\n            chunk = Math.floor(chunk / 2);\n        }\n    }\n    return result.join(\"\");\n}\n\nexports.applyFromCharCode = arrayLikeToString;\n\n\n/**\n * Copy the data from an array-like to an other array-like.\n * @param {Array|ArrayBuffer|Uint8Array|Buffer} arrayFrom the origin array.\n * @param {Array|ArrayBuffer|Uint8Array|Buffer} arrayTo the destination array which will be mutated.\n * @return {Array|ArrayBuffer|Uint8Array|Buffer} the updated destination array.\n */\nfunction arrayLikeToArrayLike(arrayFrom, arrayTo) {\n    for (var i = 0; i < arrayFrom.length; i++) {\n        arrayTo[i] = arrayFrom[i];\n    }\n    return arrayTo;\n}\n\n// a matrix containing functions to transform everything into everything.\nvar transform = {};\n\n// string to ?\ntransform[\"string\"] = {\n    \"string\": identity,\n    \"array\": function(input) {\n        return stringToArrayLike(input, new Array(input.length));\n    },\n    \"arraybuffer\": function(input) {\n        return transform[\"string\"][\"uint8array\"](input).buffer;\n    },\n    \"uint8array\": function(input) {\n        return stringToArrayLike(input, new Uint8Array(input.length));\n    },\n    \"nodebuffer\": function(input) {\n        return stringToArrayLike(input, nodeBuffer(input.length));\n    }\n};\n\n// array to ?\ntransform[\"array\"] = {\n    \"string\": arrayLikeToString,\n    \"array\": identity,\n    \"arraybuffer\": function(input) {\n        return (new Uint8Array(input)).buffer;\n    },\n    \"uint8array\": function(input) {\n        return new Uint8Array(input);\n    },\n    \"nodebuffer\": function(input) {\n        return nodeBuffer(input);\n    }\n};\n\n// arraybuffer to ?\ntransform[\"arraybuffer\"] = {\n    \"string\": function(input) {\n        return arrayLikeToString(new Uint8Array(input));\n    },\n    \"array\": function(input) {\n        return arrayLikeToArrayLike(new Uint8Array(input), new Array(input.byteLength));\n    },\n    \"arraybuffer\": identity,\n    \"uint8array\": function(input) {\n        return new Uint8Array(input);\n    },\n    \"nodebuffer\": function(input) {\n        return nodeBuffer(new Uint8Array(input));\n    }\n};\n\n// uint8array to ?\ntransform[\"uint8array\"] = {\n    \"string\": arrayLikeToString,\n    \"array\": function(input) {\n        return arrayLikeToArrayLike(input, new Array(input.length));\n    },\n    \"arraybuffer\": function(input) {\n        return input.buffer;\n    },\n    \"uint8array\": identity,\n    \"nodebuffer\": function(input) {\n        return nodeBuffer(input);\n    }\n};\n\n// nodebuffer to ?\ntransform[\"nodebuffer\"] = {\n    \"string\": arrayLikeToString,\n    \"array\": function(input) {\n        return arrayLikeToArrayLike(input, new Array(input.length));\n    },\n    \"arraybuffer\": function(input) {\n        return transform[\"nodebuffer\"][\"uint8array\"](input).buffer;\n    },\n    \"uint8array\": function(input) {\n        return arrayLikeToArrayLike(input, new Uint8Array(input.length));\n    },\n    \"nodebuffer\": identity\n};\n\n/**\n * Transform an input into any type.\n * The supported output type are : string, array, uint8array, arraybuffer, nodebuffer.\n * If no output type is specified, the unmodified input will be returned.\n * @param {String} outputType the output type.\n * @param {String|Array|ArrayBuffer|Uint8Array|Buffer} input the input to convert.\n * @throws {Error} an Error if the browser doesn't support the requested output type.\n */\nexports.transformTo = function(outputType, input) {\n    if (!input) {\n        // undefined, null, etc\n        // an empty string won't harm.\n        input = \"\";\n    }\n    if (!outputType) {\n        return input;\n    }\n    exports.checkSupport(outputType);\n    var inputType = exports.getTypeOf(input);\n    var result = transform[inputType][outputType](input);\n    return result;\n};\n\n/**\n * Return the type of the input.\n * The type will be in a format valid for JSZip.utils.transformTo : string, array, uint8array, arraybuffer.\n * @param {Object} input the input to identify.\n * @return {String} the (lowercase) type of the input.\n */\nexports.getTypeOf = function(input) {\n    if (typeof input === \"string\") {\n        return \"string\";\n    }\n    if (Object.prototype.toString.call(input) === \"[object Array]\") {\n        return \"array\";\n    }\n    if (support.nodebuffer && nodeBuffer.test(input)) {\n        return \"nodebuffer\";\n    }\n    if (support.uint8array && input instanceof Uint8Array) {\n        return \"uint8array\";\n    }\n    if (support.arraybuffer && input instanceof ArrayBuffer) {\n        return \"arraybuffer\";\n    }\n};\n\n/**\n * Throw an exception if the type is not supported.\n * @param {String} type the type to check.\n * @throws {Error} an Error if the browser doesn't support the requested type.\n */\nexports.checkSupport = function(type) {\n    var supported = support[type.toLowerCase()];\n    if (!supported) {\n        throw new Error(type + \" is not supported by this browser\");\n    }\n};\nexports.MAX_VALUE_16BITS = 65535;\nexports.MAX_VALUE_32BITS = -1; // well, \"\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\" is parsed as -1\n\n/**\n * Prettify a string read as binary.\n * @param {string} str the string to prettify.\n * @return {string} a pretty string.\n */\nexports.pretty = function(str) {\n    var res = '',\n        code, i;\n    for (i = 0; i < (str || \"\").length; i++) {\n        code = str.charCodeAt(i);\n        res += '\\\\x' + (code < 16 ? \"0\" : \"\") + code.toString(16).toUpperCase();\n    }\n    return res;\n};\n\n/**\n * Find a compression registered in JSZip.\n * @param {string} compressionMethod the method magic to find.\n * @return {Object|null} the JSZip compression object, null if none found.\n */\nexports.findCompression = function(compressionMethod) {\n    for (var method in compressions) {\n        if (!compressions.hasOwnProperty(method)) {\n            continue;\n        }\n        if (compressions[method].magic === compressionMethod) {\n            return compressions[method];\n        }\n    }\n    return null;\n};\n/**\n* Cross-window, cross-Node-context regular expression detection\n* @param  {Object}  object Anything\n* @return {Boolean}        true if the object is a regular expression,\n* false otherwise\n*/\nexports.isRegExp = function (object) {\n    return Object.prototype.toString.call(object) === \"[object RegExp]\";\n};\n\n/**\n * Merge the objects passed as parameters into a new one.\n * @private\n * @param {...Object} var_args All objects to merge.\n * @return {Object} a new object with the data of the others.\n */\nexports.extend = function() {\n    var result = {}, i, attr;\n    for (i = 0; i < arguments.length; i++) { // arguments is not enumerable in some browsers\n        for (attr in arguments[i]) {\n            if (arguments[i].hasOwnProperty(attr) && typeof result[attr] === \"undefined\") {\n                result[attr] = arguments[i][attr];\n            }\n        }\n    }\n    return result;\n};\n\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/utils.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/zipEntries.js":
/*!**********************************************!*\
  !*** ./node_modules/jszip/lib/zipEntries.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar StringReader = __webpack_require__(/*! ./stringReader */ \"./node_modules/jszip/lib/stringReader.js\");\nvar NodeBufferReader = __webpack_require__(/*! ./nodeBufferReader */ \"./node_modules/jszip/lib/nodeBufferReader.js\");\nvar Uint8ArrayReader = __webpack_require__(/*! ./uint8ArrayReader */ \"./node_modules/jszip/lib/uint8ArrayReader.js\");\nvar ArrayReader = __webpack_require__(/*! ./arrayReader */ \"./node_modules/jszip/lib/arrayReader.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\nvar sig = __webpack_require__(/*! ./signature */ \"./node_modules/jszip/lib/signature.js\");\nvar ZipEntry = __webpack_require__(/*! ./zipEntry */ \"./node_modules/jszip/lib/zipEntry.js\");\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/jszip/lib/support.js\");\nvar jszipProto = __webpack_require__(/*! ./object */ \"./node_modules/jszip/lib/object.js\");\n//  class ZipEntries {{{\n/**\n * All the entries in the zip file.\n * @constructor\n * @param {String|ArrayBuffer|Uint8Array} data the binary stream to load.\n * @param {Object} loadOptions Options for loading the stream.\n */\nfunction ZipEntries(data, loadOptions) {\n    this.files = [];\n    this.loadOptions = loadOptions;\n    if (data) {\n        this.load(data);\n    }\n}\nZipEntries.prototype = {\n    /**\n     * Check that the reader is on the speficied signature.\n     * @param {string} expectedSignature the expected signature.\n     * @throws {Error} if it is an other signature.\n     */\n    checkSignature: function(expectedSignature) {\n        var signature = this.reader.readString(4);\n        if (signature !== expectedSignature) {\n            throw new Error(\"Corrupted zip or bug : unexpected signature \" + \"(\" + utils.pretty(signature) + \", expected \" + utils.pretty(expectedSignature) + \")\");\n        }\n    },\n    /**\n     * Check if the given signature is at the given index.\n     * @param {number} askedIndex the index to check.\n     * @param {string} expectedSignature the signature to expect.\n     * @return {boolean} true if the signature is here, false otherwise.\n     */\n    isSignature: function(askedIndex, expectedSignature) {\n        var currentIndex = this.reader.index;\n        this.reader.setIndex(askedIndex);\n        var signature = this.reader.readString(4);\n        var result = signature === expectedSignature;\n        this.reader.setIndex(currentIndex);\n        return result;\n    },\n    /**\n     * Read the end of the central directory.\n     */\n    readBlockEndOfCentral: function() {\n        this.diskNumber = this.reader.readInt(2);\n        this.diskWithCentralDirStart = this.reader.readInt(2);\n        this.centralDirRecordsOnThisDisk = this.reader.readInt(2);\n        this.centralDirRecords = this.reader.readInt(2);\n        this.centralDirSize = this.reader.readInt(4);\n        this.centralDirOffset = this.reader.readInt(4);\n\n        this.zipCommentLength = this.reader.readInt(2);\n        // warning : the encoding depends of the system locale\n        // On a linux machine with LANG=en_US.utf8, this field is utf8 encoded.\n        // On a windows machine, this field is encoded with the localized windows code page.\n        var zipComment = this.reader.readData(this.zipCommentLength);\n        var decodeParamType = support.uint8array ? \"uint8array\" : \"array\";\n        // To get consistent behavior with the generation part, we will assume that\n        // this is utf8 encoded unless specified otherwise.\n        var decodeContent = utils.transformTo(decodeParamType, zipComment);\n        this.zipComment = this.loadOptions.decodeFileName(decodeContent);\n    },\n    /**\n     * Read the end of the Zip 64 central directory.\n     * Not merged with the method readEndOfCentral :\n     * The end of central can coexist with its Zip64 brother,\n     * I don't want to read the wrong number of bytes !\n     */\n    readBlockZip64EndOfCentral: function() {\n        this.zip64EndOfCentralSize = this.reader.readInt(8);\n        this.versionMadeBy = this.reader.readString(2);\n        this.versionNeeded = this.reader.readInt(2);\n        this.diskNumber = this.reader.readInt(4);\n        this.diskWithCentralDirStart = this.reader.readInt(4);\n        this.centralDirRecordsOnThisDisk = this.reader.readInt(8);\n        this.centralDirRecords = this.reader.readInt(8);\n        this.centralDirSize = this.reader.readInt(8);\n        this.centralDirOffset = this.reader.readInt(8);\n\n        this.zip64ExtensibleData = {};\n        var extraDataSize = this.zip64EndOfCentralSize - 44,\n            index = 0,\n            extraFieldId,\n            extraFieldLength,\n            extraFieldValue;\n        while (index < extraDataSize) {\n            extraFieldId = this.reader.readInt(2);\n            extraFieldLength = this.reader.readInt(4);\n            extraFieldValue = this.reader.readString(extraFieldLength);\n            this.zip64ExtensibleData[extraFieldId] = {\n                id: extraFieldId,\n                length: extraFieldLength,\n                value: extraFieldValue\n            };\n        }\n    },\n    /**\n     * Read the end of the Zip 64 central directory locator.\n     */\n    readBlockZip64EndOfCentralLocator: function() {\n        this.diskWithZip64CentralDirStart = this.reader.readInt(4);\n        this.relativeOffsetEndOfZip64CentralDir = this.reader.readInt(8);\n        this.disksCount = this.reader.readInt(4);\n        if (this.disksCount > 1) {\n            throw new Error(\"Multi-volumes zip are not supported\");\n        }\n    },\n    /**\n     * Read the local files, based on the offset read in the central part.\n     */\n    readLocalFiles: function() {\n        var i, file;\n        for (i = 0; i < this.files.length; i++) {\n            file = this.files[i];\n            this.reader.setIndex(file.localHeaderOffset);\n            this.checkSignature(sig.LOCAL_FILE_HEADER);\n            file.readLocalPart(this.reader);\n            file.handleUTF8();\n            file.processAttributes();\n        }\n    },\n    /**\n     * Read the central directory.\n     */\n    readCentralDir: function() {\n        var file;\n\n        this.reader.setIndex(this.centralDirOffset);\n        while (this.reader.readString(4) === sig.CENTRAL_FILE_HEADER) {\n            file = new ZipEntry({\n                zip64: this.zip64\n            }, this.loadOptions);\n            file.readCentralPart(this.reader);\n            this.files.push(file);\n        }\n\n        if (this.centralDirRecords !== this.files.length) {\n            if (this.centralDirRecords !== 0 && this.files.length === 0) {\n                // We expected some records but couldn't find ANY.\n                // This is really suspicious, as if something went wrong.\n                throw new Error(\"Corrupted zip or bug: expected \" + this.centralDirRecords + \" records in central dir, got \" + this.files.length);\n            } else {\n                // We found some records but not all.\n                // Something is wrong but we got something for the user: no error here.\n                // console.warn(\"expected\", this.centralDirRecords, \"records in central dir, got\", this.files.length);\n            }\n        }\n    },\n    /**\n     * Read the end of central directory.\n     */\n    readEndOfCentral: function() {\n        var offset = this.reader.lastIndexOfSignature(sig.CENTRAL_DIRECTORY_END);\n        if (offset < 0) {\n            // Check if the content is a truncated zip or complete garbage.\n            // A \"LOCAL_FILE_HEADER\" is not required at the beginning (auto\n            // extractible zip for example) but it can give a good hint.\n            // If an ajax request was used without responseType, we will also\n            // get unreadable data.\n            var isGarbage = !this.isSignature(0, sig.LOCAL_FILE_HEADER);\n\n            if (isGarbage) {\n                throw new Error(\"Can't find end of central directory : is this a zip file ? \" +\n                                \"If it is, see http://stuk.github.io/jszip/documentation/howto/read_zip.html\");\n            } else {\n                throw new Error(\"Corrupted zip : can't find end of central directory\");\n            }\n        }\n        this.reader.setIndex(offset);\n        var endOfCentralDirOffset = offset;\n        this.checkSignature(sig.CENTRAL_DIRECTORY_END);\n        this.readBlockEndOfCentral();\n\n\n        /* extract from the zip spec :\n            4)  If one of the fields in the end of central directory\n                record is too small to hold required data, the field\n                should be set to -1 (0xFFFF or 0xFFFFFFFF) and the\n                ZIP64 format record should be created.\n            5)  The end of central directory record and the\n                Zip64 end of central directory locator record must\n                reside on the same disk when splitting or spanning\n                an archive.\n         */\n        if (this.diskNumber === utils.MAX_VALUE_16BITS || this.diskWithCentralDirStart === utils.MAX_VALUE_16BITS || this.centralDirRecordsOnThisDisk === utils.MAX_VALUE_16BITS || this.centralDirRecords === utils.MAX_VALUE_16BITS || this.centralDirSize === utils.MAX_VALUE_32BITS || this.centralDirOffset === utils.MAX_VALUE_32BITS) {\n            this.zip64 = true;\n\n            /*\n            Warning : the zip64 extension is supported, but ONLY if the 64bits integer read from\n            the zip file can fit into a 32bits integer. This cannot be solved : Javascript represents\n            all numbers as 64-bit double precision IEEE 754 floating point numbers.\n            So, we have 53bits for integers and bitwise operations treat everything as 32bits.\n            see https://developer.mozilla.org/en-US/docs/JavaScript/Reference/Operators/Bitwise_Operators\n            and http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-262.pdf section 8.5\n            */\n\n            // should look for a zip64 EOCD locator\n            offset = this.reader.lastIndexOfSignature(sig.ZIP64_CENTRAL_DIRECTORY_LOCATOR);\n            if (offset < 0) {\n                throw new Error(\"Corrupted zip : can't find the ZIP64 end of central directory locator\");\n            }\n            this.reader.setIndex(offset);\n            this.checkSignature(sig.ZIP64_CENTRAL_DIRECTORY_LOCATOR);\n            this.readBlockZip64EndOfCentralLocator();\n\n            // now the zip64 EOCD record\n            if (!this.isSignature(this.relativeOffsetEndOfZip64CentralDir, sig.ZIP64_CENTRAL_DIRECTORY_END)) {\n                // console.warn(\"ZIP64 end of central directory not where expected.\");\n                this.relativeOffsetEndOfZip64CentralDir = this.reader.lastIndexOfSignature(sig.ZIP64_CENTRAL_DIRECTORY_END);\n                if (this.relativeOffsetEndOfZip64CentralDir < 0) {\n                    throw new Error(\"Corrupted zip : can't find the ZIP64 end of central directory\");\n                }\n            }\n            this.reader.setIndex(this.relativeOffsetEndOfZip64CentralDir);\n            this.checkSignature(sig.ZIP64_CENTRAL_DIRECTORY_END);\n            this.readBlockZip64EndOfCentral();\n        }\n\n        var expectedEndOfCentralDirOffset = this.centralDirOffset + this.centralDirSize;\n        if (this.zip64) {\n            expectedEndOfCentralDirOffset += 20; // end of central dir 64 locator\n            expectedEndOfCentralDirOffset += 12 /* should not include the leading 12 bytes */ + this.zip64EndOfCentralSize;\n        }\n\n        var extraBytes = endOfCentralDirOffset - expectedEndOfCentralDirOffset;\n\n        if (extraBytes > 0) {\n            // console.warn(extraBytes, \"extra bytes at beginning or within zipfile\");\n            if (this.isSignature(endOfCentralDirOffset, sig.CENTRAL_FILE_HEADER)) {\n                // The offsets seem wrong, but we have something at the specified offset.\n                // So we keep it.\n            } else {\n                // the offset is wrong, update the \"zero\" of the reader\n                // this happens if data has been prepended (crx files for example)\n                this.reader.zero = extraBytes;\n            }\n        } else if (extraBytes < 0) {\n            throw new Error(\"Corrupted zip: missing \" + Math.abs(extraBytes) + \" bytes.\");\n        }\n    },\n    prepareReader: function(data) {\n        var type = utils.getTypeOf(data);\n        utils.checkSupport(type);\n        if (type === \"string\" && !support.uint8array) {\n            this.reader = new StringReader(data, this.loadOptions.optimizedBinaryString);\n        }\n        else if (type === \"nodebuffer\") {\n            this.reader = new NodeBufferReader(data);\n        }\n        else if (support.uint8array) {\n            this.reader = new Uint8ArrayReader(utils.transformTo(\"uint8array\", data));\n        } else if (support.array) {\n            this.reader = new ArrayReader(utils.transformTo(\"array\", data));\n        } else {\n            throw new Error(\"Unexpected error: unsupported type '\" + type + \"'\");\n        }\n    },\n    /**\n     * Read a zip file and create ZipEntries.\n     * @param {String|ArrayBuffer|Uint8Array|Buffer} data the binary string representing a zip file.\n     */\n    load: function(data) {\n        this.prepareReader(data);\n        this.readEndOfCentral();\n        this.readCentralDir();\n        this.readLocalFiles();\n    }\n};\n// }}} end of ZipEntries\nmodule.exports = ZipEntries;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/zipEntries.js?");

/***/ }),

/***/ "./node_modules/jszip/lib/zipEntry.js":
/*!********************************************!*\
  !*** ./node_modules/jszip/lib/zipEntry.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar StringReader = __webpack_require__(/*! ./stringReader */ \"./node_modules/jszip/lib/stringReader.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/jszip/lib/utils.js\");\nvar CompressedObject = __webpack_require__(/*! ./compressedObject */ \"./node_modules/jszip/lib/compressedObject.js\");\nvar jszipProto = __webpack_require__(/*! ./object */ \"./node_modules/jszip/lib/object.js\");\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/jszip/lib/support.js\");\n\nvar MADE_BY_DOS = 0x00;\nvar MADE_BY_UNIX = 0x03;\n\n// class ZipEntry {{{\n/**\n * An entry in the zip file.\n * @constructor\n * @param {Object} options Options of the current file.\n * @param {Object} loadOptions Options for loading the stream.\n */\nfunction ZipEntry(options, loadOptions) {\n    this.options = options;\n    this.loadOptions = loadOptions;\n}\nZipEntry.prototype = {\n    /**\n     * say if the file is encrypted.\n     * @return {boolean} true if the file is encrypted, false otherwise.\n     */\n    isEncrypted: function() {\n        // bit 1 is set\n        return (this.bitFlag & 0x0001) === 0x0001;\n    },\n    /**\n     * say if the file has utf-8 filename/comment.\n     * @return {boolean} true if the filename/comment is in utf-8, false otherwise.\n     */\n    useUTF8: function() {\n        // bit 11 is set\n        return (this.bitFlag & 0x0800) === 0x0800;\n    },\n    /**\n     * Prepare the function used to generate the compressed content from this ZipFile.\n     * @param {DataReader} reader the reader to use.\n     * @param {number} from the offset from where we should read the data.\n     * @param {number} length the length of the data to read.\n     * @return {Function} the callback to get the compressed content (the type depends of the DataReader class).\n     */\n    prepareCompressedContent: function(reader, from, length) {\n        return function() {\n            var previousIndex = reader.index;\n            reader.setIndex(from);\n            var compressedFileData = reader.readData(length);\n            reader.setIndex(previousIndex);\n\n            return compressedFileData;\n        };\n    },\n    /**\n     * Prepare the function used to generate the uncompressed content from this ZipFile.\n     * @param {DataReader} reader the reader to use.\n     * @param {number} from the offset from where we should read the data.\n     * @param {number} length the length of the data to read.\n     * @param {JSZip.compression} compression the compression used on this file.\n     * @param {number} uncompressedSize the uncompressed size to expect.\n     * @return {Function} the callback to get the uncompressed content (the type depends of the DataReader class).\n     */\n    prepareContent: function(reader, from, length, compression, uncompressedSize) {\n        return function() {\n\n            var compressedFileData = utils.transformTo(compression.uncompressInputType, this.getCompressedContent());\n            var uncompressedFileData = compression.uncompress(compressedFileData);\n\n            if (uncompressedFileData.length !== uncompressedSize) {\n                throw new Error(\"Bug : uncompressed data size mismatch\");\n            }\n\n            return uncompressedFileData;\n        };\n    },\n    /**\n     * Read the local part of a zip file and add the info in this object.\n     * @param {DataReader} reader the reader to use.\n     */\n    readLocalPart: function(reader) {\n        var compression, localExtraFieldsLength;\n\n        // we already know everything from the central dir !\n        // If the central dir data are false, we are doomed.\n        // On the bright side, the local part is scary  : zip64, data descriptors, both, etc.\n        // The less data we get here, the more reliable this should be.\n        // Let's skip the whole header and dash to the data !\n        reader.skip(22);\n        // in some zip created on windows, the filename stored in the central dir contains \\ instead of /.\n        // Strangely, the filename here is OK.\n        // I would love to treat these zip files as corrupted (see http://www.info-zip.org/FAQ.html#backslashes\n        // or APPNOTE#4.4.17.1, \"All slashes MUST be forward slashes '/'\") but there are a lot of bad zip generators...\n        // Search \"unzip mismatching \"local\" filename continuing with \"central\" filename version\" on\n        // the internet.\n        //\n        // I think I see the logic here : the central directory is used to display\n        // content and the local directory is used to extract the files. Mixing / and \\\n        // may be used to display \\ to windows users and use / when extracting the files.\n        // Unfortunately, this lead also to some issues : http://seclists.org/fulldisclosure/2009/Sep/394\n        this.fileNameLength = reader.readInt(2);\n        localExtraFieldsLength = reader.readInt(2); // can't be sure this will be the same as the central dir\n        this.fileName = reader.readData(this.fileNameLength);\n        reader.skip(localExtraFieldsLength);\n\n        if (this.compressedSize == -1 || this.uncompressedSize == -1) {\n            throw new Error(\"Bug or corrupted zip : didn't get enough informations from the central directory \" + \"(compressedSize == -1 || uncompressedSize == -1)\");\n        }\n\n        compression = utils.findCompression(this.compressionMethod);\n        if (compression === null) { // no compression found\n            throw new Error(\"Corrupted zip : compression \" + utils.pretty(this.compressionMethod) + \" unknown (inner file : \" +  utils.transformTo(\"string\", this.fileName) + \")\");\n        }\n        this.decompressed = new CompressedObject();\n        this.decompressed.compressedSize = this.compressedSize;\n        this.decompressed.uncompressedSize = this.uncompressedSize;\n        this.decompressed.crc32 = this.crc32;\n        this.decompressed.compressionMethod = this.compressionMethod;\n        this.decompressed.getCompressedContent = this.prepareCompressedContent(reader, reader.index, this.compressedSize, compression);\n        this.decompressed.getContent = this.prepareContent(reader, reader.index, this.compressedSize, compression, this.uncompressedSize);\n\n        // we need to compute the crc32...\n        if (this.loadOptions.checkCRC32) {\n            this.decompressed = utils.transformTo(\"string\", this.decompressed.getContent());\n            if (jszipProto.crc32(this.decompressed) !== this.crc32) {\n                throw new Error(\"Corrupted zip : CRC32 mismatch\");\n            }\n        }\n    },\n\n    /**\n     * Read the central part of a zip file and add the info in this object.\n     * @param {DataReader} reader the reader to use.\n     */\n    readCentralPart: function(reader) {\n        this.versionMadeBy = reader.readInt(2);\n        this.versionNeeded = reader.readInt(2);\n        this.bitFlag = reader.readInt(2);\n        this.compressionMethod = reader.readString(2);\n        this.date = reader.readDate();\n        this.crc32 = reader.readInt(4);\n        this.compressedSize = reader.readInt(4);\n        this.uncompressedSize = reader.readInt(4);\n        this.fileNameLength = reader.readInt(2);\n        this.extraFieldsLength = reader.readInt(2);\n        this.fileCommentLength = reader.readInt(2);\n        this.diskNumberStart = reader.readInt(2);\n        this.internalFileAttributes = reader.readInt(2);\n        this.externalFileAttributes = reader.readInt(4);\n        this.localHeaderOffset = reader.readInt(4);\n\n        if (this.isEncrypted()) {\n            throw new Error(\"Encrypted zip are not supported\");\n        }\n\n        this.fileName = reader.readData(this.fileNameLength);\n        this.readExtraFields(reader);\n        this.parseZIP64ExtraField(reader);\n        this.fileComment = reader.readData(this.fileCommentLength);\n    },\n\n    /**\n     * Parse the external file attributes and get the unix/dos permissions.\n     */\n    processAttributes: function () {\n        this.unixPermissions = null;\n        this.dosPermissions = null;\n        var madeBy = this.versionMadeBy >> 8;\n\n        // Check if we have the DOS directory flag set.\n        // We look for it in the DOS and UNIX permissions\n        // but some unknown platform could set it as a compatibility flag.\n        this.dir = this.externalFileAttributes & 0x0010 ? true : false;\n\n        if(madeBy === MADE_BY_DOS) {\n            // first 6 bits (0 to 5)\n            this.dosPermissions = this.externalFileAttributes & 0x3F;\n        }\n\n        if(madeBy === MADE_BY_UNIX) {\n            this.unixPermissions = (this.externalFileAttributes >> 16) & 0xFFFF;\n            // the octal permissions are in (this.unixPermissions & 0x01FF).toString(8);\n        }\n\n        // fail safe : if the name ends with a / it probably means a folder\n        if (!this.dir && this.fileNameStr.slice(-1) === '/') {\n            this.dir = true;\n        }\n    },\n\n    /**\n     * Parse the ZIP64 extra field and merge the info in the current ZipEntry.\n     * @param {DataReader} reader the reader to use.\n     */\n    parseZIP64ExtraField: function(reader) {\n\n        if (!this.extraFields[0x0001]) {\n            return;\n        }\n\n        // should be something, preparing the extra reader\n        var extraReader = new StringReader(this.extraFields[0x0001].value);\n\n        // I really hope that these 64bits integer can fit in 32 bits integer, because js\n        // won't let us have more.\n        if (this.uncompressedSize === utils.MAX_VALUE_32BITS) {\n            this.uncompressedSize = extraReader.readInt(8);\n        }\n        if (this.compressedSize === utils.MAX_VALUE_32BITS) {\n            this.compressedSize = extraReader.readInt(8);\n        }\n        if (this.localHeaderOffset === utils.MAX_VALUE_32BITS) {\n            this.localHeaderOffset = extraReader.readInt(8);\n        }\n        if (this.diskNumberStart === utils.MAX_VALUE_32BITS) {\n            this.diskNumberStart = extraReader.readInt(4);\n        }\n    },\n    /**\n     * Read the central part of a zip file and add the info in this object.\n     * @param {DataReader} reader the reader to use.\n     */\n    readExtraFields: function(reader) {\n        var start = reader.index,\n            extraFieldId,\n            extraFieldLength,\n            extraFieldValue;\n\n        this.extraFields = this.extraFields || {};\n\n        while (reader.index < start + this.extraFieldsLength) {\n            extraFieldId = reader.readInt(2);\n            extraFieldLength = reader.readInt(2);\n            extraFieldValue = reader.readString(extraFieldLength);\n\n            this.extraFields[extraFieldId] = {\n                id: extraFieldId,\n                length: extraFieldLength,\n                value: extraFieldValue\n            };\n        }\n    },\n    /**\n     * Apply an UTF8 transformation if needed.\n     */\n    handleUTF8: function() {\n        var decodeParamType = support.uint8array ? \"uint8array\" : \"array\";\n        if (this.useUTF8()) {\n            this.fileNameStr = jszipProto.utf8decode(this.fileName);\n            this.fileCommentStr = jszipProto.utf8decode(this.fileComment);\n        } else {\n            var upath = this.findExtraFieldUnicodePath();\n            if (upath !== null) {\n                this.fileNameStr = upath;\n            } else {\n                var fileNameByteArray =  utils.transformTo(decodeParamType, this.fileName);\n                this.fileNameStr = this.loadOptions.decodeFileName(fileNameByteArray);\n            }\n\n            var ucomment = this.findExtraFieldUnicodeComment();\n            if (ucomment !== null) {\n                this.fileCommentStr = ucomment;\n            } else {\n                var commentByteArray =  utils.transformTo(decodeParamType, this.fileComment);\n                this.fileCommentStr = this.loadOptions.decodeFileName(commentByteArray);\n            }\n        }\n    },\n\n    /**\n     * Find the unicode path declared in the extra field, if any.\n     * @return {String} the unicode path, null otherwise.\n     */\n    findExtraFieldUnicodePath: function() {\n        var upathField = this.extraFields[0x7075];\n        if (upathField) {\n            var extraReader = new StringReader(upathField.value);\n\n            // wrong version\n            if (extraReader.readInt(1) !== 1) {\n                return null;\n            }\n\n            // the crc of the filename changed, this field is out of date.\n            if (jszipProto.crc32(this.fileName) !== extraReader.readInt(4)) {\n                return null;\n            }\n\n            return jszipProto.utf8decode(extraReader.readString(upathField.length - 5));\n        }\n        return null;\n    },\n\n    /**\n     * Find the unicode comment declared in the extra field, if any.\n     * @return {String} the unicode comment, null otherwise.\n     */\n    findExtraFieldUnicodeComment: function() {\n        var ucommentField = this.extraFields[0x6375];\n        if (ucommentField) {\n            var extraReader = new StringReader(ucommentField.value);\n\n            // wrong version\n            if (extraReader.readInt(1) !== 1) {\n                return null;\n            }\n\n            // the crc of the comment changed, this field is out of date.\n            if (jszipProto.crc32(this.fileComment) !== extraReader.readInt(4)) {\n                return null;\n            }\n\n            return jszipProto.utf8decode(extraReader.readString(ucommentField.length - 5));\n        }\n        return null;\n    }\n};\nmodule.exports = ZipEntry;\n\n\n//# sourceURL=webpack:///./node_modules/jszip/lib/zipEntry.js?");

/***/ }),

/***/ "./node_modules/lie/lib/index.js":
/*!***************************************!*\
  !*** ./node_modules/lie/lib/index.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar immediate = __webpack_require__(/*! immediate */ \"./node_modules/immediate/lib/index.js\");\n\n/* istanbul ignore next */\nfunction INTERNAL() {}\n\nvar handlers = {};\n\nvar REJECTED = ['REJECTED'];\nvar FULFILLED = ['FULFILLED'];\nvar PENDING = ['PENDING'];\n/* istanbul ignore else */\nif (!process.browser) {\n  // in which we actually take advantage of JS scoping\n  var UNHANDLED = ['UNHANDLED'];\n}\n\nmodule.exports = Promise;\n\nfunction Promise(resolver) {\n  if (typeof resolver !== 'function') {\n    throw new TypeError('resolver must be a function');\n  }\n  this.state = PENDING;\n  this.queue = [];\n  this.outcome = void 0;\n  /* istanbul ignore else */\n  if (!process.browser) {\n    this.handled = UNHANDLED;\n  }\n  if (resolver !== INTERNAL) {\n    safelyResolveThenable(this, resolver);\n  }\n}\n\nPromise.prototype.finally = function (callback) {\n  if (typeof callback !== 'function') {\n    return this;\n  }\n  var p = this.constructor;\n  return this.then(resolve, reject);\n\n  function resolve(value) {\n    function yes () {\n      return value;\n    }\n    return p.resolve(callback()).then(yes);\n  }\n  function reject(reason) {\n    function no () {\n      throw reason;\n    }\n    return p.resolve(callback()).then(no);\n  }\n};\nPromise.prototype.catch = function (onRejected) {\n  return this.then(null, onRejected);\n};\nPromise.prototype.then = function (onFulfilled, onRejected) {\n  if (typeof onFulfilled !== 'function' && this.state === FULFILLED ||\n    typeof onRejected !== 'function' && this.state === REJECTED) {\n    return this;\n  }\n  var promise = new this.constructor(INTERNAL);\n  /* istanbul ignore else */\n  if (!process.browser) {\n    if (this.handled === UNHANDLED) {\n      this.handled = null;\n    }\n  }\n  if (this.state !== PENDING) {\n    var resolver = this.state === FULFILLED ? onFulfilled : onRejected;\n    unwrap(promise, resolver, this.outcome);\n  } else {\n    this.queue.push(new QueueItem(promise, onFulfilled, onRejected));\n  }\n\n  return promise;\n};\nfunction QueueItem(promise, onFulfilled, onRejected) {\n  this.promise = promise;\n  if (typeof onFulfilled === 'function') {\n    this.onFulfilled = onFulfilled;\n    this.callFulfilled = this.otherCallFulfilled;\n  }\n  if (typeof onRejected === 'function') {\n    this.onRejected = onRejected;\n    this.callRejected = this.otherCallRejected;\n  }\n}\nQueueItem.prototype.callFulfilled = function (value) {\n  handlers.resolve(this.promise, value);\n};\nQueueItem.prototype.otherCallFulfilled = function (value) {\n  unwrap(this.promise, this.onFulfilled, value);\n};\nQueueItem.prototype.callRejected = function (value) {\n  handlers.reject(this.promise, value);\n};\nQueueItem.prototype.otherCallRejected = function (value) {\n  unwrap(this.promise, this.onRejected, value);\n};\n\nfunction unwrap(promise, func, value) {\n  immediate(function () {\n    var returnValue;\n    try {\n      returnValue = func(value);\n    } catch (e) {\n      return handlers.reject(promise, e);\n    }\n    if (returnValue === promise) {\n      handlers.reject(promise, new TypeError('Cannot resolve promise with itself'));\n    } else {\n      handlers.resolve(promise, returnValue);\n    }\n  });\n}\n\nhandlers.resolve = function (self, value) {\n  var result = tryCatch(getThen, value);\n  if (result.status === 'error') {\n    return handlers.reject(self, result.value);\n  }\n  var thenable = result.value;\n\n  if (thenable) {\n    safelyResolveThenable(self, thenable);\n  } else {\n    self.state = FULFILLED;\n    self.outcome = value;\n    var i = -1;\n    var len = self.queue.length;\n    while (++i < len) {\n      self.queue[i].callFulfilled(value);\n    }\n  }\n  return self;\n};\nhandlers.reject = function (self, error) {\n  self.state = REJECTED;\n  self.outcome = error;\n  /* istanbul ignore else */\n  if (!process.browser) {\n    if (self.handled === UNHANDLED) {\n      immediate(function () {\n        if (self.handled === UNHANDLED) {\n          process.emit('unhandledRejection', error, self);\n        }\n      });\n    }\n  }\n  var i = -1;\n  var len = self.queue.length;\n  while (++i < len) {\n    self.queue[i].callRejected(error);\n  }\n  return self;\n};\n\nfunction getThen(obj) {\n  // Make sure we only access the accessor once as required by the spec\n  var then = obj && obj.then;\n  if (obj && (typeof obj === 'object' || typeof obj === 'function') && typeof then === 'function') {\n    return function appyThen() {\n      then.apply(obj, arguments);\n    };\n  }\n}\n\nfunction safelyResolveThenable(self, thenable) {\n  // Either fulfill, reject or reject with error\n  var called = false;\n  function onError(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.reject(self, value);\n  }\n\n  function onSuccess(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.resolve(self, value);\n  }\n\n  function tryToUnwrap() {\n    thenable(onSuccess, onError);\n  }\n\n  var result = tryCatch(tryToUnwrap);\n  if (result.status === 'error') {\n    onError(result.value);\n  }\n}\n\nfunction tryCatch(func, value) {\n  var out = {};\n  try {\n    out.value = func(value);\n    out.status = 'success';\n  } catch (e) {\n    out.status = 'error';\n    out.value = e;\n  }\n  return out;\n}\n\nPromise.resolve = resolve;\nfunction resolve(value) {\n  if (value instanceof this) {\n    return value;\n  }\n  return handlers.resolve(new this(INTERNAL), value);\n}\n\nPromise.reject = reject;\nfunction reject(reason) {\n  var promise = new this(INTERNAL);\n  return handlers.reject(promise, reason);\n}\n\nPromise.all = all;\nfunction all(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var values = new Array(len);\n  var resolved = 0;\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    allResolver(iterable[i], i);\n  }\n  return promise;\n  function allResolver(value, i) {\n    self.resolve(value).then(resolveFromAll, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n    function resolveFromAll(outValue) {\n      values[i] = outValue;\n      if (++resolved === len && !called) {\n        called = true;\n        handlers.resolve(promise, values);\n      }\n    }\n  }\n}\n\nPromise.race = race;\nfunction race(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    resolver(iterable[i]);\n  }\n  return promise;\n  function resolver(value) {\n    self.resolve(value).then(function (response) {\n      if (!called) {\n        called = true;\n        handlers.resolve(promise, response);\n      }\n    }, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/lie/lib/index.js?");

/***/ }),

/***/ "./node_modules/minimatch/minimatch.js":
/*!*********************************************!*\
  !*** ./node_modules/minimatch/minimatch.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = minimatch\nminimatch.Minimatch = Minimatch\n\nvar path = { sep: '/' }\ntry {\n  path = __webpack_require__(/*! path */ \"path\")\n} catch (er) {}\n\nvar GLOBSTAR = minimatch.GLOBSTAR = Minimatch.GLOBSTAR = {}\nvar expand = __webpack_require__(/*! brace-expansion */ \"./node_modules/brace-expansion/index.js\")\n\nvar plTypes = {\n  '!': { open: '(?:(?!(?:', close: '))[^/]*?)'},\n  '?': { open: '(?:', close: ')?' },\n  '+': { open: '(?:', close: ')+' },\n  '*': { open: '(?:', close: ')*' },\n  '@': { open: '(?:', close: ')' }\n}\n\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nvar qmark = '[^/]'\n\n// * => any number of characters\nvar star = qmark + '*?'\n\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nvar twoStarDot = '(?:(?!(?:\\\\\\/|^)(?:\\\\.{1,2})($|\\\\\\/)).)*?'\n\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nvar twoStarNoDot = '(?:(?!(?:\\\\\\/|^)\\\\.).)*?'\n\n// characters that need to be escaped in RegExp.\nvar reSpecials = charSet('().*{}+?[]^$\\\\!')\n\n// \"abc\" -> { a:true, b:true, c:true }\nfunction charSet (s) {\n  return s.split('').reduce(function (set, c) {\n    set[c] = true\n    return set\n  }, {})\n}\n\n// normalizes slashes.\nvar slashSplit = /\\/+/\n\nminimatch.filter = filter\nfunction filter (pattern, options) {\n  options = options || {}\n  return function (p, i, list) {\n    return minimatch(p, pattern, options)\n  }\n}\n\nfunction ext (a, b) {\n  a = a || {}\n  b = b || {}\n  var t = {}\n  Object.keys(b).forEach(function (k) {\n    t[k] = b[k]\n  })\n  Object.keys(a).forEach(function (k) {\n    t[k] = a[k]\n  })\n  return t\n}\n\nminimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return minimatch\n\n  var orig = minimatch\n\n  var m = function minimatch (p, pattern, options) {\n    return orig.minimatch(p, pattern, ext(def, options))\n  }\n\n  m.Minimatch = function Minimatch (pattern, options) {\n    return new orig.Minimatch(pattern, ext(def, options))\n  }\n\n  return m\n}\n\nMinimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return Minimatch\n  return minimatch.defaults(def).Minimatch\n}\n\nfunction minimatch (p, pattern, options) {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n\n  // shortcut: comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false\n  }\n\n  // \"\" only matches \"\"\n  if (pattern.trim() === '') return p === ''\n\n  return new Minimatch(pattern, options).match(p)\n}\n\nfunction Minimatch (pattern, options) {\n  if (!(this instanceof Minimatch)) {\n    return new Minimatch(pattern, options)\n  }\n\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n  pattern = pattern.trim()\n\n  // windows support: need to use /, not \\\n  if (path.sep !== '/') {\n    pattern = pattern.split(path.sep).join('/')\n  }\n\n  this.options = options\n  this.set = []\n  this.pattern = pattern\n  this.regexp = null\n  this.negate = false\n  this.comment = false\n  this.empty = false\n\n  // make the set of regexps etc.\n  this.make()\n}\n\nMinimatch.prototype.debug = function () {}\n\nMinimatch.prototype.make = make\nfunction make () {\n  // don't do it more than once.\n  if (this._made) return\n\n  var pattern = this.pattern\n  var options = this.options\n\n  // empty patterns and comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    this.comment = true\n    return\n  }\n  if (!pattern) {\n    this.empty = true\n    return\n  }\n\n  // step 1: figure out negation, etc.\n  this.parseNegate()\n\n  // step 2: expand braces\n  var set = this.globSet = this.braceExpand()\n\n  if (options.debug) this.debug = console.error\n\n  this.debug(this.pattern, set)\n\n  // step 3: now we have a set, so turn each one into a series of path-portion\n  // matching patterns.\n  // These will be regexps, except in the case of \"**\", which is\n  // set to the GLOBSTAR object for globstar behavior,\n  // and will not contain any / characters\n  set = this.globParts = set.map(function (s) {\n    return s.split(slashSplit)\n  })\n\n  this.debug(this.pattern, set)\n\n  // glob --> regexps\n  set = set.map(function (s, si, set) {\n    return s.map(this.parse, this)\n  }, this)\n\n  this.debug(this.pattern, set)\n\n  // filter out everything that didn't compile properly.\n  set = set.filter(function (s) {\n    return s.indexOf(false) === -1\n  })\n\n  this.debug(this.pattern, set)\n\n  this.set = set\n}\n\nMinimatch.prototype.parseNegate = parseNegate\nfunction parseNegate () {\n  var pattern = this.pattern\n  var negate = false\n  var options = this.options\n  var negateOffset = 0\n\n  if (options.nonegate) return\n\n  for (var i = 0, l = pattern.length\n    ; i < l && pattern.charAt(i) === '!'\n    ; i++) {\n    negate = !negate\n    negateOffset++\n  }\n\n  if (negateOffset) this.pattern = pattern.substr(negateOffset)\n  this.negate = negate\n}\n\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nminimatch.braceExpand = function (pattern, options) {\n  return braceExpand(pattern, options)\n}\n\nMinimatch.prototype.braceExpand = braceExpand\n\nfunction braceExpand (pattern, options) {\n  if (!options) {\n    if (this instanceof Minimatch) {\n      options = this.options\n    } else {\n      options = {}\n    }\n  }\n\n  pattern = typeof pattern === 'undefined'\n    ? this.pattern : pattern\n\n  if (typeof pattern === 'undefined') {\n    throw new TypeError('undefined pattern')\n  }\n\n  if (options.nobrace ||\n    !pattern.match(/\\{.*\\}/)) {\n    // shortcut. no need to expand.\n    return [pattern]\n  }\n\n  return expand(pattern)\n}\n\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\nMinimatch.prototype.parse = parse\nvar SUBPARSE = {}\nfunction parse (pattern, isSub) {\n  if (pattern.length > 1024 * 64) {\n    throw new TypeError('pattern is too long')\n  }\n\n  var options = this.options\n\n  // shortcuts\n  if (!options.noglobstar && pattern === '**') return GLOBSTAR\n  if (pattern === '') return ''\n\n  var re = ''\n  var hasMagic = !!options.nocase\n  var escaping = false\n  // ? => one single character\n  var patternListStack = []\n  var negativeLists = []\n  var stateChar\n  var inClass = false\n  var reClassStart = -1\n  var classStart = -1\n  // . and .. never match anything that doesn't start with .,\n  // even when options.dot is set.\n  var patternStart = pattern.charAt(0) === '.' ? '' // anything\n  // not (start or / followed by . or .. followed by / or end)\n  : options.dot ? '(?!(?:^|\\\\\\/)\\\\.{1,2}(?:$|\\\\\\/))'\n  : '(?!\\\\.)'\n  var self = this\n\n  function clearStateChar () {\n    if (stateChar) {\n      // we had some state-tracking character\n      // that wasn't consumed by this pass.\n      switch (stateChar) {\n        case '*':\n          re += star\n          hasMagic = true\n        break\n        case '?':\n          re += qmark\n          hasMagic = true\n        break\n        default:\n          re += '\\\\' + stateChar\n        break\n      }\n      self.debug('clearStateChar %j %j', stateChar, re)\n      stateChar = false\n    }\n  }\n\n  for (var i = 0, len = pattern.length, c\n    ; (i < len) && (c = pattern.charAt(i))\n    ; i++) {\n    this.debug('%s\\t%s %s %j', pattern, i, re, c)\n\n    // skip over any that are escaped.\n    if (escaping && reSpecials[c]) {\n      re += '\\\\' + c\n      escaping = false\n      continue\n    }\n\n    switch (c) {\n      case '/':\n        // completely not allowed, even escaped.\n        // Should already be path-split by now.\n        return false\n\n      case '\\\\':\n        clearStateChar()\n        escaping = true\n      continue\n\n      // the various stateChar values\n      // for the \"extglob\" stuff.\n      case '?':\n      case '*':\n      case '+':\n      case '@':\n      case '!':\n        this.debug('%s\\t%s %s %j <-- stateChar', pattern, i, re, c)\n\n        // all of those are literals inside a class, except that\n        // the glob [!a] means [^a] in regexp\n        if (inClass) {\n          this.debug('  in class')\n          if (c === '!' && i === classStart + 1) c = '^'\n          re += c\n          continue\n        }\n\n        // if we already have a stateChar, then it means\n        // that there was something like ** or +? in there.\n        // Handle the stateChar, then proceed with this one.\n        self.debug('call clearStateChar %j', stateChar)\n        clearStateChar()\n        stateChar = c\n        // if extglob is disabled, then +(asdf|foo) isn't a thing.\n        // just clear the statechar *now*, rather than even diving into\n        // the patternList stuff.\n        if (options.noext) clearStateChar()\n      continue\n\n      case '(':\n        if (inClass) {\n          re += '('\n          continue\n        }\n\n        if (!stateChar) {\n          re += '\\\\('\n          continue\n        }\n\n        patternListStack.push({\n          type: stateChar,\n          start: i - 1,\n          reStart: re.length,\n          open: plTypes[stateChar].open,\n          close: plTypes[stateChar].close\n        })\n        // negation is (?:(?!js)[^/]*)\n        re += stateChar === '!' ? '(?:(?!(?:' : '(?:'\n        this.debug('plType %j %j', stateChar, re)\n        stateChar = false\n      continue\n\n      case ')':\n        if (inClass || !patternListStack.length) {\n          re += '\\\\)'\n          continue\n        }\n\n        clearStateChar()\n        hasMagic = true\n        var pl = patternListStack.pop()\n        // negation is (?:(?!js)[^/]*)\n        // The others are (?:<pattern>)<type>\n        re += pl.close\n        if (pl.type === '!') {\n          negativeLists.push(pl)\n        }\n        pl.reEnd = re.length\n      continue\n\n      case '|':\n        if (inClass || !patternListStack.length || escaping) {\n          re += '\\\\|'\n          escaping = false\n          continue\n        }\n\n        clearStateChar()\n        re += '|'\n      continue\n\n      // these are mostly the same in regexp and glob\n      case '[':\n        // swallow any state-tracking char before the [\n        clearStateChar()\n\n        if (inClass) {\n          re += '\\\\' + c\n          continue\n        }\n\n        inClass = true\n        classStart = i\n        reClassStart = re.length\n        re += c\n      continue\n\n      case ']':\n        //  a right bracket shall lose its special\n        //  meaning and represent itself in\n        //  a bracket expression if it occurs\n        //  first in the list.  -- POSIX.2 2.8.3.2\n        if (i === classStart + 1 || !inClass) {\n          re += '\\\\' + c\n          escaping = false\n          continue\n        }\n\n        // handle the case where we left a class open.\n        // \"[z-a]\" is valid, equivalent to \"\\[z-a\\]\"\n        if (inClass) {\n          // split where the last [ was, make sure we don't have\n          // an invalid re. if so, re-walk the contents of the\n          // would-be class to re-translate any characters that\n          // were passed through as-is\n          // TODO: It would probably be faster to determine this\n          // without a try/catch and a new RegExp, but it's tricky\n          // to do safely.  For now, this is safe and works.\n          var cs = pattern.substring(classStart + 1, i)\n          try {\n            RegExp('[' + cs + ']')\n          } catch (er) {\n            // not a valid class!\n            var sp = this.parse(cs, SUBPARSE)\n            re = re.substr(0, reClassStart) + '\\\\[' + sp[0] + '\\\\]'\n            hasMagic = hasMagic || sp[1]\n            inClass = false\n            continue\n          }\n        }\n\n        // finish up the class.\n        hasMagic = true\n        inClass = false\n        re += c\n      continue\n\n      default:\n        // swallow any state char that wasn't consumed\n        clearStateChar()\n\n        if (escaping) {\n          // no need\n          escaping = false\n        } else if (reSpecials[c]\n          && !(c === '^' && inClass)) {\n          re += '\\\\'\n        }\n\n        re += c\n\n    } // switch\n  } // for\n\n  // handle the case where we left a class open.\n  // \"[abc\" is valid, equivalent to \"\\[abc\"\n  if (inClass) {\n    // split where the last [ was, and escape it\n    // this is a huge pita.  We now have to re-walk\n    // the contents of the would-be class to re-translate\n    // any characters that were passed through as-is\n    cs = pattern.substr(classStart + 1)\n    sp = this.parse(cs, SUBPARSE)\n    re = re.substr(0, reClassStart) + '\\\\[' + sp[0]\n    hasMagic = hasMagic || sp[1]\n  }\n\n  // handle the case where we had a +( thing at the *end*\n  // of the pattern.\n  // each pattern list stack adds 3 chars, and we need to go through\n  // and escape any | chars that were passed through as-is for the regexp.\n  // Go through and escape them, taking care not to double-escape any\n  // | chars that were already escaped.\n  for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {\n    var tail = re.slice(pl.reStart + pl.open.length)\n    this.debug('setting tail', re, pl)\n    // maybe some even number of \\, then maybe 1 \\, followed by a |\n    tail = tail.replace(/((?:\\\\{2}){0,64})(\\\\?)\\|/g, function (_, $1, $2) {\n      if (!$2) {\n        // the | isn't already escaped, so escape it.\n        $2 = '\\\\'\n      }\n\n      // need to escape all those slashes *again*, without escaping the\n      // one that we need for escaping the | character.  As it works out,\n      // escaping an even number of slashes can be done by simply repeating\n      // it exactly after itself.  That's why this trick works.\n      //\n      // I am sorry that you have to see this.\n      return $1 + $1 + $2 + '|'\n    })\n\n    this.debug('tail=%j\\n   %s', tail, tail, pl, re)\n    var t = pl.type === '*' ? star\n      : pl.type === '?' ? qmark\n      : '\\\\' + pl.type\n\n    hasMagic = true\n    re = re.slice(0, pl.reStart) + t + '\\\\(' + tail\n  }\n\n  // handle trailing things that only matter at the very end.\n  clearStateChar()\n  if (escaping) {\n    // trailing \\\\\n    re += '\\\\\\\\'\n  }\n\n  // only need to apply the nodot start if the re starts with\n  // something that could conceivably capture a dot\n  var addPatternStart = false\n  switch (re.charAt(0)) {\n    case '.':\n    case '[':\n    case '(': addPatternStart = true\n  }\n\n  // Hack to work around lack of negative lookbehind in JS\n  // A pattern like: *.!(x).!(y|z) needs to ensure that a name\n  // like 'a.xyz.yz' doesn't match.  So, the first negative\n  // lookahead, has to look ALL the way ahead, to the end of\n  // the pattern.\n  for (var n = negativeLists.length - 1; n > -1; n--) {\n    var nl = negativeLists[n]\n\n    var nlBefore = re.slice(0, nl.reStart)\n    var nlFirst = re.slice(nl.reStart, nl.reEnd - 8)\n    var nlLast = re.slice(nl.reEnd - 8, nl.reEnd)\n    var nlAfter = re.slice(nl.reEnd)\n\n    nlLast += nlAfter\n\n    // Handle nested stuff like *(*.js|!(*.json)), where open parens\n    // mean that we should *not* include the ) in the bit that is considered\n    // \"after\" the negated section.\n    var openParensBefore = nlBefore.split('(').length - 1\n    var cleanAfter = nlAfter\n    for (i = 0; i < openParensBefore; i++) {\n      cleanAfter = cleanAfter.replace(/\\)[+*?]?/, '')\n    }\n    nlAfter = cleanAfter\n\n    var dollar = ''\n    if (nlAfter === '' && isSub !== SUBPARSE) {\n      dollar = '$'\n    }\n    var newRe = nlBefore + nlFirst + nlAfter + dollar + nlLast\n    re = newRe\n  }\n\n  // if the re is not \"\" at this point, then we need to make sure\n  // it doesn't match against an empty path part.\n  // Otherwise a/* will match a/, which it should not.\n  if (re !== '' && hasMagic) {\n    re = '(?=.)' + re\n  }\n\n  if (addPatternStart) {\n    re = patternStart + re\n  }\n\n  // parsing just a piece of a larger pattern.\n  if (isSub === SUBPARSE) {\n    return [re, hasMagic]\n  }\n\n  // skip the regexp for non-magical patterns\n  // unescape anything in it, though, so that it'll be\n  // an exact match against a file etc.\n  if (!hasMagic) {\n    return globUnescape(pattern)\n  }\n\n  var flags = options.nocase ? 'i' : ''\n  try {\n    var regExp = new RegExp('^' + re + '$', flags)\n  } catch (er) {\n    // If it was an invalid regular expression, then it can't match\n    // anything.  This trick looks for a character after the end of\n    // the string, which is of course impossible, except in multi-line\n    // mode, but it's not a /m regex.\n    return new RegExp('$.')\n  }\n\n  regExp._glob = pattern\n  regExp._src = re\n\n  return regExp\n}\n\nminimatch.makeRe = function (pattern, options) {\n  return new Minimatch(pattern, options || {}).makeRe()\n}\n\nMinimatch.prototype.makeRe = makeRe\nfunction makeRe () {\n  if (this.regexp || this.regexp === false) return this.regexp\n\n  // at this point, this.set is a 2d array of partial\n  // pattern strings, or \"**\".\n  //\n  // It's better to use .match().  This function shouldn't\n  // be used, really, but it's pretty convenient sometimes,\n  // when you just want to work with a regex.\n  var set = this.set\n\n  if (!set.length) {\n    this.regexp = false\n    return this.regexp\n  }\n  var options = this.options\n\n  var twoStar = options.noglobstar ? star\n    : options.dot ? twoStarDot\n    : twoStarNoDot\n  var flags = options.nocase ? 'i' : ''\n\n  var re = set.map(function (pattern) {\n    return pattern.map(function (p) {\n      return (p === GLOBSTAR) ? twoStar\n      : (typeof p === 'string') ? regExpEscape(p)\n      : p._src\n    }).join('\\\\\\/')\n  }).join('|')\n\n  // must match entire pattern\n  // ending in a * or ** will make it less strict.\n  re = '^(?:' + re + ')$'\n\n  // can match anything, as long as it's not this.\n  if (this.negate) re = '^(?!' + re + ').*$'\n\n  try {\n    this.regexp = new RegExp(re, flags)\n  } catch (ex) {\n    this.regexp = false\n  }\n  return this.regexp\n}\n\nminimatch.match = function (list, pattern, options) {\n  options = options || {}\n  var mm = new Minimatch(pattern, options)\n  list = list.filter(function (f) {\n    return mm.match(f)\n  })\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern)\n  }\n  return list\n}\n\nMinimatch.prototype.match = match\nfunction match (f, partial) {\n  this.debug('match', f, this.pattern)\n  // short-circuit in the case of busted things.\n  // comments, etc.\n  if (this.comment) return false\n  if (this.empty) return f === ''\n\n  if (f === '/' && partial) return true\n\n  var options = this.options\n\n  // windows: need to use /, not \\\n  if (path.sep !== '/') {\n    f = f.split(path.sep).join('/')\n  }\n\n  // treat the test path as a set of pathparts.\n  f = f.split(slashSplit)\n  this.debug(this.pattern, 'split', f)\n\n  // just ONE of the pattern sets in this.set needs to match\n  // in order for it to be valid.  If negating, then just one\n  // match means that we have failed.\n  // Either way, return on the first hit.\n\n  var set = this.set\n  this.debug(this.pattern, 'set', set)\n\n  // Find the basename of the path by looking for the last non-empty segment\n  var filename\n  var i\n  for (i = f.length - 1; i >= 0; i--) {\n    filename = f[i]\n    if (filename) break\n  }\n\n  for (i = 0; i < set.length; i++) {\n    var pattern = set[i]\n    var file = f\n    if (options.matchBase && pattern.length === 1) {\n      file = [filename]\n    }\n    var hit = this.matchOne(file, pattern, partial)\n    if (hit) {\n      if (options.flipNegate) return true\n      return !this.negate\n    }\n  }\n\n  // didn't get any hits.  this is success if it's a negative\n  // pattern, failure otherwise.\n  if (options.flipNegate) return false\n  return this.negate\n}\n\n// set partial to true to test if, for example,\n// \"/a/b\" matches the start of \"/*/b/*/d\"\n// Partial means, if you run out of file before you run\n// out of pattern, then that's fine, as long as all\n// the parts match.\nMinimatch.prototype.matchOne = function (file, pattern, partial) {\n  var options = this.options\n\n  this.debug('matchOne',\n    { 'this': this, file: file, pattern: pattern })\n\n  this.debug('matchOne', file.length, pattern.length)\n\n  for (var fi = 0,\n      pi = 0,\n      fl = file.length,\n      pl = pattern.length\n      ; (fi < fl) && (pi < pl)\n      ; fi++, pi++) {\n    this.debug('matchOne loop')\n    var p = pattern[pi]\n    var f = file[fi]\n\n    this.debug(pattern, p, f)\n\n    // should be impossible.\n    // some invalid regexp stuff in the set.\n    if (p === false) return false\n\n    if (p === GLOBSTAR) {\n      this.debug('GLOBSTAR', [pattern, p, f])\n\n      // \"**\"\n      // a/**/b/**/c would match the following:\n      // a/b/x/y/z/c\n      // a/x/y/z/b/c\n      // a/b/x/b/x/c\n      // a/b/c\n      // To do this, take the rest of the pattern after\n      // the **, and see if it would match the file remainder.\n      // If so, return success.\n      // If not, the ** \"swallows\" a segment, and try again.\n      // This is recursively awful.\n      //\n      // a/**/b/**/c matching a/b/x/y/z/c\n      // - a matches a\n      // - doublestar\n      //   - matchOne(b/x/y/z/c, b/**/c)\n      //     - b matches b\n      //     - doublestar\n      //       - matchOne(x/y/z/c, c) -> no\n      //       - matchOne(y/z/c, c) -> no\n      //       - matchOne(z/c, c) -> no\n      //       - matchOne(c, c) yes, hit\n      var fr = fi\n      var pr = pi + 1\n      if (pr === pl) {\n        this.debug('** at the end')\n        // a ** at the end will just swallow the rest.\n        // We have found a match.\n        // however, it will not swallow /.x, unless\n        // options.dot is set.\n        // . and .. are *never* matched by **, for explosively\n        // exponential reasons.\n        for (; fi < fl; fi++) {\n          if (file[fi] === '.' || file[fi] === '..' ||\n            (!options.dot && file[fi].charAt(0) === '.')) return false\n        }\n        return true\n      }\n\n      // ok, let's see if we can swallow whatever we can.\n      while (fr < fl) {\n        var swallowee = file[fr]\n\n        this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee)\n\n        // XXX remove this slice.  Just pass the start index.\n        if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n          this.debug('globstar found match!', fr, fl, swallowee)\n          // found a match.\n          return true\n        } else {\n          // can't swallow \".\" or \"..\" ever.\n          // can only swallow \".foo\" when explicitly asked.\n          if (swallowee === '.' || swallowee === '..' ||\n            (!options.dot && swallowee.charAt(0) === '.')) {\n            this.debug('dot detected!', file, fr, pattern, pr)\n            break\n          }\n\n          // ** swallows a segment, and continue.\n          this.debug('globstar swallow a segment, and continue')\n          fr++\n        }\n      }\n\n      // no match was found.\n      // However, in partial mode, we can't say this is necessarily over.\n      // If there's more *pattern* left, then\n      if (partial) {\n        // ran out of file\n        this.debug('\\n>>> no match, partial?', file, fr, pattern, pr)\n        if (fr === fl) return true\n      }\n      return false\n    }\n\n    // something other than **\n    // non-magic patterns just have to match exactly\n    // patterns with magic have been turned into regexps.\n    var hit\n    if (typeof p === 'string') {\n      if (options.nocase) {\n        hit = f.toLowerCase() === p.toLowerCase()\n      } else {\n        hit = f === p\n      }\n      this.debug('string match', p, f, hit)\n    } else {\n      hit = f.match(p)\n      this.debug('pattern match', p, f, hit)\n    }\n\n    if (!hit) return false\n  }\n\n  // Note: ending in / means that we'll get a final \"\"\n  // at the end of the pattern.  This can only match a\n  // corresponding \"\" at the end of the file.\n  // If the file ends in /, then it can only match a\n  // a pattern that ends in /, unless the pattern just\n  // doesn't have any more for it. But, a/b/ should *not*\n  // match \"a/b/*\", even though \"\" matches against the\n  // [^/]*? pattern, except in partial mode, where it might\n  // simply not be reached yet.\n  // However, a/b/ should still satisfy a/*\n\n  // now either we fell off the end of the pattern, or we're done.\n  if (fi === fl && pi === pl) {\n    // ran out of pattern and filename at the same time.\n    // an exact hit!\n    return true\n  } else if (fi === fl) {\n    // ran out of file, but still had pattern left.\n    // this is ok if we're doing the match as part of\n    // a glob fs traversal.\n    return partial\n  } else if (pi === pl) {\n    // ran out of pattern, still have file left.\n    // this is only acceptable if we're on the very last\n    // empty segment of a file with a trailing slash.\n    // a/* should match a/b/\n    var emptyFileEnd = (fi === fl - 1) && (file[fi] === '')\n    return emptyFileEnd\n  }\n\n  // should be unreachable.\n  throw new Error('wtf?')\n}\n\n// replace stuff like \\* with *\nfunction globUnescape (s) {\n  return s.replace(/\\\\(.)/g, '$1')\n}\n\nfunction regExpEscape (s) {\n  return s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\n}\n\n\n//# sourceURL=webpack:///./node_modules/minimatch/minimatch.js?");

/***/ }),

/***/ "./node_modules/mkdirp/index.js":
/*!**************************************!*\
  !*** ./node_modules/mkdirp/index.js ***!
  \**************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var path = __webpack_require__(/*! path */ \"path\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar _0777 = parseInt('0777', 8);\n\nmodule.exports = mkdirP.mkdirp = mkdirP.mkdirP = mkdirP;\n\nfunction mkdirP (p, opts, f, made) {\n    if (typeof opts === 'function') {\n        f = opts;\n        opts = {};\n    }\n    else if (!opts || typeof opts !== 'object') {\n        opts = { mode: opts };\n    }\n    \n    var mode = opts.mode;\n    var xfs = opts.fs || fs;\n    \n    if (mode === undefined) {\n        mode = _0777 & (~process.umask());\n    }\n    if (!made) made = null;\n    \n    var cb = f || function () {};\n    p = path.resolve(p);\n    \n    xfs.mkdir(p, mode, function (er) {\n        if (!er) {\n            made = made || p;\n            return cb(null, made);\n        }\n        switch (er.code) {\n            case 'ENOENT':\n                mkdirP(path.dirname(p), opts, function (er, made) {\n                    if (er) cb(er, made);\n                    else mkdirP(p, opts, cb, made);\n                });\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                xfs.stat(p, function (er2, stat) {\n                    // if the stat fails, then that's super weird.\n                    // let the original error be the failure reason.\n                    if (er2 || !stat.isDirectory()) cb(er, made)\n                    else cb(null, made);\n                });\n                break;\n        }\n    });\n}\n\nmkdirP.sync = function sync (p, opts, made) {\n    if (!opts || typeof opts !== 'object') {\n        opts = { mode: opts };\n    }\n    \n    var mode = opts.mode;\n    var xfs = opts.fs || fs;\n    \n    if (mode === undefined) {\n        mode = _0777 & (~process.umask());\n    }\n    if (!made) made = null;\n\n    p = path.resolve(p);\n\n    try {\n        xfs.mkdirSync(p, mode);\n        made = made || p;\n    }\n    catch (err0) {\n        switch (err0.code) {\n            case 'ENOENT' :\n                made = sync(path.dirname(p), opts, made);\n                sync(p, opts, made);\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                var stat;\n                try {\n                    stat = xfs.statSync(p);\n                }\n                catch (err1) {\n                    throw err0;\n                }\n                if (!stat.isDirectory()) throw err0;\n                break;\n        }\n    }\n\n    return made;\n};\n\n\n//# sourceURL=webpack:///./node_modules/mkdirp/index.js?");

/***/ }),

/***/ "./node_modules/node-ssh/lib/helpers.js":
/*!**********************************************!*\
  !*** ./node_modules/node-ssh/lib/helpers.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.exists = exists;\nexports.mkdirSftp = mkdirSftp;\nexports.normalizeConfig = normalizeConfig;\nexports.normalizePutFilesOptions = normalizePutFilesOptions;\nexports.normalizePutDirectoryOptions = normalizePutDirectoryOptions;\nexports.generateCallback = generateCallback;\nexports.readdir = exports.stat = void 0;\n\nvar _fs = _interopRequireDefault(__webpack_require__(/*! fs */ \"fs\"));\n\nvar _path = _interopRequireDefault(__webpack_require__(/*! path */ \"path\"));\n\nvar _sbPromisify = _interopRequireDefault(__webpack_require__(/*! sb-promisify */ \"./node_modules/sb-promisify/lib/index.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }\n\nfunction _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err); } _next(undefined); }); }; }\n\nconst CODE_REGEXP = /Error: (E[\\S]+): /;\nconst DEFAULT_CONCURRENCY = 5;\nconst readFile = (0, _sbPromisify.default)(_fs.default.readFile);\nconst stat = (0, _sbPromisify.default)(_fs.default.stat);\nexports.stat = stat;\nconst readdir = (0, _sbPromisify.default)(_fs.default.readdir);\nexports.readdir = readdir;\n\nfunction transformError(givenError) {\n  const code = CODE_REGEXP.exec(givenError);\n\n  if (code) {\n    // eslint-disable-next-line no-param-reassign,prefer-destructuring\n    givenError.code = code[1];\n  }\n\n  return givenError;\n}\n\nfunction exists(filePath) {\n  return new Promise(function (resolve) {\n    _fs.default.access(filePath, _fs.default.R_OK, function (error) {\n      resolve(!error);\n    });\n  });\n}\n\nfunction mkdirSftp(_x, _x2) {\n  return _mkdirSftp.apply(this, arguments);\n}\n\nfunction _mkdirSftp() {\n  _mkdirSftp = _asyncToGenerator(function* (path, sftp) {\n    let stats;\n\n    try {\n      stats = yield (0, _sbPromisify.default)(sftp.stat).call(sftp, path);\n    } catch (_) {\n      /* No Op */\n    }\n\n    if (stats) {\n      if (stats.isDirectory()) {\n        // Already exists, nothing to worry about\n        return;\n      }\n\n      throw new Error('mkdir() failed, target already exists and is not a directory');\n    }\n\n    try {\n      yield (0, _sbPromisify.default)(sftp.mkdir).call(sftp, path);\n    } catch (error) {\n      throw transformError(error);\n    }\n  });\n  return _mkdirSftp.apply(this, arguments);\n}\n\nfunction normalizeConfig(_x3) {\n  return _normalizeConfig.apply(this, arguments);\n}\n\nfunction _normalizeConfig() {\n  _normalizeConfig = _asyncToGenerator(function* (givenConfig) {\n    const config = Object.assign({}, givenConfig);\n\n    if (config.username && typeof config.username !== 'string') {\n      throw new Error('config.username must be a valid string');\n    }\n\n    if (typeof config.host !== 'undefined') {\n      if (typeof config.host !== 'string' || !config.host) {\n        throw new Error('config.host must be a valid string');\n      }\n    } else if (typeof config.sock !== 'undefined') {\n      if (!config.sock || typeof config.sock !== 'object') {\n        throw new Error('config.sock must be a valid object');\n      }\n    } else {\n      throw new Error('config.host or config.sock must be provided');\n    }\n\n    if (config.privateKey) {\n      const privateKey = config.privateKey;\n\n      if (typeof privateKey !== 'string') {\n        throw new Error('config.privateKey must be a string');\n      }\n\n      if (!(privateKey.includes('BEGIN') && privateKey.includes('KEY'))) {\n        try {\n          config.privateKey = yield readFile(privateKey, 'utf8');\n        } catch (error) {\n          if (error.code === 'ENOENT') {\n            throw new Error(`config.privateKey does not exist at ${privateKey}`);\n          }\n\n          throw error;\n        }\n      }\n    } else if (config.password) {\n      const password = config.password;\n\n      if (typeof password !== 'string') {\n        throw new Error('config.password must be a string');\n      }\n    }\n\n    config.tryKeyboard = !!config.tryKeyboard;\n\n    if (config.tryKeyboard === true) {\n      if (typeof config.onKeyboardInteractive !== 'function') {\n        config.onKeyboardInteractive = (name, instructions, instructionsLang, prompts, finish) => {\n          if (prompts.length > 0 && prompts[0].prompt.toLowerCase().includes('password')) {\n            finish([config.password]);\n          }\n        };\n      }\n    } else {\n      config.onKeyboardInteractive = null;\n    }\n\n    return config;\n  });\n  return _normalizeConfig.apply(this, arguments);\n}\n\nfunction normalizePutFilesOptions(givenConfig) {\n  const config = {};\n\n  if (givenConfig.sftpOptions && typeof givenConfig.sftpOptions === 'object') {\n    config.sftpOptions = givenConfig.sftpOptions;\n  } else config.sftpOptions = {};\n\n  if (typeof givenConfig.concurrency === 'number') {\n    config.concurrency = givenConfig.concurrency;\n  } else config.concurrency = DEFAULT_CONCURRENCY;\n\n  if (typeof givenConfig.sftp === 'object') {\n    config.sftp = givenConfig.sftp;\n  } else config.sftp = null;\n\n  return config;\n}\n\nfunction normalizePutDirectoryOptions(givenConfig) {\n  const config = normalizePutFilesOptions(givenConfig);\n\n  if (givenConfig.tick) {\n    if (typeof givenConfig.tick !== 'function') {\n      throw new Error('config.tick must be a function');\n    }\n\n    config.tick = givenConfig.tick;\n  } else {\n    config.tick = function () {};\n  }\n\n  if (givenConfig.validate) {\n    if (typeof givenConfig.validate !== 'function') {\n      throw new Error('config.validate must be a function');\n    }\n\n    config.validate = givenConfig.validate;\n  } else {\n    config.validate = function (path) {\n      return _path.default.basename(path).substr(0, 1) !== '.';\n    };\n  }\n\n  config.recursive = {}.hasOwnProperty.call(givenConfig, 'recursive') ? !!givenConfig.recursive : true;\n  return config;\n}\n\nfunction generateCallback(resolve, reject) {\n  return function (error, result) {\n    if (error) {\n      reject(error);\n    } else {\n      resolve(result);\n    }\n  };\n}\n\n//# sourceURL=webpack:///./node_modules/node-ssh/lib/helpers.js?");

/***/ }),

/***/ "./node_modules/node-ssh/lib/index.js":
/*!********************************************!*\
  !*** ./node_modules/node-ssh/lib/index.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar _path = _interopRequireDefault(__webpack_require__(/*! path */ \"path\"));\n\nvar _ssh = _interopRequireDefault(__webpack_require__(/*! ssh2 */ \"./node_modules/ssh2/lib/client.js\"));\n\nvar _pMap = _interopRequireDefault(__webpack_require__(/*! p-map */ \"./node_modules/p-map/index.js\"));\n\nvar _assert = _interopRequireDefault(__webpack_require__(/*! assert */ \"assert\"));\n\nvar _sbScandir = _interopRequireDefault(__webpack_require__(/*! sb-scandir */ \"./node_modules/sb-scandir/lib/index.js\"));\n\nvar _shellEscape = _interopRequireDefault(__webpack_require__(/*! shell-escape */ \"./node_modules/shell-escape/shell-escape.js\"));\n\nvar Helpers = _interopRequireWildcard(__webpack_require__(/*! ./helpers */ \"./node_modules/node-ssh/lib/helpers.js\"));\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = Object.defineProperty && Object.getOwnPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : {}; if (desc.get || desc.set) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } } newObj.default = obj; return newObj; } }\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }\n\nfunction _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err); } _next(undefined); }); }; }\n\nclass SSH {\n  constructor() {\n    this.connection = null;\n  }\n\n  connect(givenConfig) {\n    const connection = new _ssh.default();\n    this.connection = connection;\n    return new Promise(function (resolve) {\n      resolve(Helpers.normalizeConfig(givenConfig));\n    }).then(config => new Promise((resolve, reject) => {\n      connection.on('error', reject);\n\n      if (config.onKeyboardInteractive) {\n        connection.on('keyboard-interactive', config.onKeyboardInteractive);\n      }\n\n      connection.on('ready', () => {\n        connection.removeListener('error', reject);\n        resolve(this);\n      });\n      connection.on('end', () => {\n        if (this.connection === connection) {\n          this.connection = null;\n        }\n      });\n      connection.on('close', () => {\n        if (this.connection === connection) {\n          this.connection = null;\n        }\n\n        const error = new Error('No response from server'); // $FlowIgnore: Custom attribute\n\n        error.code = 'ETIMEDOUT';\n        reject(error);\n      });\n      connection.connect(config);\n    }));\n  }\n\n  requestShell() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      const connection = _this.connection;\n      (0, _assert.default)(connection, 'Not connected to server');\n      return new Promise(function (resolve, reject) {\n        connection.shell(Helpers.generateCallback(resolve, reject));\n      });\n    })();\n  }\n\n  requestSFTP() {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      const connection = _this2.connection;\n      (0, _assert.default)(connection, 'Not connected to server');\n      return new Promise(function (resolve, reject) {\n        connection.sftp(Helpers.generateCallback(resolve, reject));\n      });\n    })();\n  }\n\n  mkdir(path, type = 'sftp', givenSftp = null) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      (0, _assert.default)(_this3.connection, 'Not connected to server');\n      (0, _assert.default)(type === 'exec' || type === 'sftp', 'Type should either be sftp or exec');\n\n      if (type === 'exec') {\n        const output = yield _this3.exec('mkdir', ['-p', path]);\n\n        if (output.stdout) {\n          throw new Error(output.stdout);\n        }\n      } else {\n        (0, _assert.default)(!givenSftp || typeof givenSftp === 'object', 'sftp must be an object');\n        const sftp = givenSftp || (yield _this3.requestSFTP());\n\n        const makeSftpDirectory = retry => Helpers.mkdirSftp(path, sftp).catch(error => {\n          if (retry && error && (error.message === 'No such file' || error.code === 'ENOENT')) {\n            return _this3.mkdir(_path.default.dirname(path), 'sftp', sftp).then(() => makeSftpDirectory(false));\n          }\n\n          throw error;\n        });\n\n        try {\n          yield makeSftpDirectory(true);\n        } finally {\n          if (!givenSftp) {\n            sftp.end();\n          }\n        }\n      }\n    })();\n  }\n\n  exec(command, parameters = [], options = {}) {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      (0, _assert.default)(_this4.connection, 'Not connected to server');\n      (0, _assert.default)(typeof options === 'object' && options, 'options must be an Object');\n      (0, _assert.default)(!options.cwd || typeof options.cwd === 'string', 'options.cwd must be a string');\n      (0, _assert.default)(!options.stdin || typeof options.stdin === 'string', 'options.stdin must be a string');\n      (0, _assert.default)(!options.stream || ['stdout', 'stderr', 'both'].indexOf(options.stream) !== -1, 'options.stream must be among \"stdout\", \"stderr\" and \"both\"');\n      (0, _assert.default)(!options.options || typeof options.options === 'object', 'options.options must be an object');\n      const output = yield _this4.execCommand([command].concat((0, _shellEscape.default)(parameters)).join(' '), options);\n\n      if (!options.stream || options.stream === 'stdout') {\n        if (output.stderr) {\n          throw new Error(output.stderr);\n        }\n\n        return output.stdout;\n      }\n\n      if (options.stream === 'stderr') {\n        return output.stderr;\n      }\n\n      return output;\n    })();\n  }\n\n  execCommand(givenCommand, options = {}) {\n    var _this5 = this;\n\n    return _asyncToGenerator(function* () {\n      let command = givenCommand;\n      const connection = _this5.connection;\n      (0, _assert.default)(connection, 'Not connected to server');\n      (0, _assert.default)(typeof options === 'object' && options, 'options must be an Object');\n      (0, _assert.default)(!options.cwd || typeof options.cwd === 'string', 'options.cwd must be a string');\n      (0, _assert.default)(!options.stdin || typeof options.stdin === 'string', 'options.stdin must be a string');\n      (0, _assert.default)(!options.options || typeof options.options === 'object', 'options.options must be an object');\n\n      if (options.cwd) {\n        // NOTE: Output piping cd command to hide directory non-existent errors\n        command = `cd ${(0, _shellEscape.default)([options.cwd])} 1> /dev/null 2> /dev/null; ${command}`;\n      }\n\n      const output = {\n        stdout: [],\n        stderr: []\n      };\n      return new Promise(function (resolve, reject) {\n        connection.exec(command, options.options || {}, Helpers.generateCallback(function (stream) {\n          stream.on('data', function (chunk) {\n            if (options.onStdout) options.onStdout(chunk);\n            output.stdout.push(chunk);\n          });\n          stream.stderr.on('data', function (chunk) {\n            if (options.onStderr) options.onStderr(chunk);\n            output.stderr.push(chunk);\n          });\n\n          if (options.stdin) {\n            stream.write(options.stdin);\n            stream.end();\n          }\n\n          stream.on('close', function (code, signal) {\n            resolve({\n              code,\n              signal,\n              stdout: output.stdout.join('').trim(),\n              stderr: output.stderr.join('').trim()\n            });\n          });\n        }, reject));\n      });\n    })();\n  }\n\n  getFile(localFile, remoteFile, givenSftp = null, givenOpts = null) {\n    var _this6 = this;\n\n    return _asyncToGenerator(function* () {\n      (0, _assert.default)(_this6.connection, 'Not connected to server');\n      (0, _assert.default)(typeof localFile === 'string' && localFile, 'localFile must be a string');\n      (0, _assert.default)(typeof remoteFile === 'string' && remoteFile, 'remoteFile must be a string');\n      (0, _assert.default)(!givenSftp || typeof givenSftp === 'object', 'sftp must be an object');\n      (0, _assert.default)(!givenOpts || typeof givenOpts === 'object', 'opts must be an object');\n      const opts = givenOpts || {};\n      const sftp = givenSftp || (yield _this6.requestSFTP());\n\n      try {\n        yield new Promise(function (resolve, reject) {\n          sftp.fastGet(remoteFile, localFile, opts, Helpers.generateCallback(resolve, reject));\n        });\n      } finally {\n        if (!givenSftp) {\n          sftp.end();\n        }\n      }\n    })();\n  }\n\n  putFile(localFile, remoteFile, givenSftp = null, givenOpts = null) {\n    var _this7 = this;\n\n    return _asyncToGenerator(function* () {\n      (0, _assert.default)(_this7.connection, 'Not connected to server');\n      (0, _assert.default)(typeof localFile === 'string' && localFile, 'localFile must be a string');\n      (0, _assert.default)(typeof remoteFile === 'string' && remoteFile, 'remoteFile must be a string');\n      (0, _assert.default)(!givenSftp || typeof givenSftp === 'object', 'sftp must be an object');\n      (0, _assert.default)(!givenOpts || typeof givenOpts === 'object', 'opts must be an object');\n      (0, _assert.default)((yield Helpers.exists(localFile)), `localFile does not exist at ${localFile}`);\n      const that = _this7;\n      const opts = givenOpts || {};\n      const sftp = givenSftp || (yield _this7.requestSFTP());\n\n      function putFile(retry) {\n        return new Promise(function (resolve, reject) {\n          sftp.fastPut(localFile, remoteFile, opts, Helpers.generateCallback(resolve, function (error) {\n            if (error.message === 'No such file' && retry) {\n              resolve(that.mkdir(_path.default.dirname(remoteFile), 'sftp', sftp).then(() => putFile(false)));\n            } else {\n              reject(error);\n            }\n          }));\n        });\n      }\n\n      try {\n        yield putFile(true);\n      } finally {\n        if (!givenSftp) {\n          sftp.end();\n        }\n      }\n    })();\n  }\n\n  putFiles(files, givenConfig = {}) {\n    var _this8 = this;\n\n    return _asyncToGenerator(function* () {\n      (0, _assert.default)(_this8.connection, 'Not connected to server');\n      (0, _assert.default)(Array.isArray(files), 'files must be an array');\n\n      for (let i = 0, length = files.length; i < length; ++i) {\n        const file = files[i];\n        (0, _assert.default)(file, 'files items must be valid objects');\n        (0, _assert.default)(file.local && typeof file.local === 'string', `files[${i}].local must be a string`);\n        (0, _assert.default)(file.remote && typeof file.remote === 'string', `files[${i}].remote must be a string`);\n      }\n\n      const transferred = [];\n      const config = Helpers.normalizePutFilesOptions(givenConfig);\n      const sftp = config.sftp || (yield _this8.requestSFTP());\n\n      try {\n        yield (0, _pMap.default)(files,\n        /*#__PURE__*/\n        function () {\n          var _ref = _asyncToGenerator(function* (file) {\n            yield _this8.putFile(file.local, file.remote, sftp, config.sftpOptions);\n            transferred.push(file);\n          });\n\n          return function (_x) {\n            return _ref.apply(this, arguments);\n          };\n        }());\n      } catch (error) {\n        error.transferred = transferred;\n        throw error;\n      } finally {\n        if (!sftp) {\n          sftp.end();\n        }\n      }\n    })();\n  }\n\n  putDirectory(localDirectory, remoteDirectory, givenConfig = {}) {\n    var _this9 = this;\n\n    return _asyncToGenerator(function* () {\n      (0, _assert.default)(_this9.connection, 'Not connected to server');\n      (0, _assert.default)(typeof localDirectory === 'string' && localDirectory, 'localDirectory must be a string');\n      (0, _assert.default)(typeof remoteDirectory === 'string' && remoteDirectory, 'remoteDirectory must be a string');\n      (0, _assert.default)((yield Helpers.exists(localDirectory)), `localDirectory does not exist at ${localDirectory}`);\n      (0, _assert.default)((yield Helpers.stat(localDirectory)).isDirectory(), `localDirectory is not a directory at ${localDirectory}`);\n      (0, _assert.default)(typeof givenConfig === 'object' && givenConfig, 'config must be an object');\n      const config = Helpers.normalizePutDirectoryOptions(givenConfig);\n      const sftp = config.sftp || (yield _this9.requestSFTP());\n      const scanned = yield (0, _sbScandir.default)(localDirectory, config.recursive, config.validate);\n      const files = scanned.files.map(i => _path.default.relative(localDirectory, i));\n      const directories = scanned.directories.map(i => _path.default.relative(localDirectory, i));\n      let failed = false;\n      let directoriesQueue = Promise.resolve();\n      const directoriesCreated = new Set();\n\n      const createDirectory =\n      /*#__PURE__*/\n      function () {\n        var _ref2 = _asyncToGenerator(function* (path) {\n          if (!directoriesCreated.has(path)) {\n            directoriesCreated.add(path);\n            directoriesQueue = directoriesQueue.then(() => _this9.mkdir(path, 'sftp', sftp));\n            yield directoriesQueue;\n          }\n        });\n\n        return function createDirectory(_x2) {\n          return _ref2.apply(this, arguments);\n        };\n      }();\n\n      try {\n        yield (0, _pMap.default)(files,\n        /*#__PURE__*/\n        function () {\n          var _ref3 = _asyncToGenerator(function* (file) {\n            const localFile = _path.default.join(localDirectory, file);\n\n            const remoteFile = _path.default.join(remoteDirectory, file).split(_path.default.sep).join('/');\n\n            const remoteFileDirectory = _path.default.dirname(remoteFile);\n\n            yield createDirectory(remoteFileDirectory);\n\n            try {\n              yield _this9.putFile(localFile, remoteFile, sftp, config.sftpOptions);\n              config.tick(localFile, remoteFile, null);\n            } catch (_) {\n              failed = true;\n              config.tick(localFile, remoteFile, _);\n            }\n          });\n\n          return function (_x3) {\n            return _ref3.apply(this, arguments);\n          };\n        }(), {\n          concurrency: config.concurrency\n        });\n        yield (0, _pMap.default)(directories,\n        /*#__PURE__*/\n        function () {\n          var _ref4 = _asyncToGenerator(function* (entry) {\n            const remoteEntry = _path.default.join(remoteDirectory, entry).split(_path.default.sep).join('/');\n\n            yield createDirectory(remoteEntry);\n          });\n\n          return function (_x4) {\n            return _ref4.apply(this, arguments);\n          };\n        }(), {\n          concurrency: config.concurrency\n        });\n      } finally {\n        if (!config.sftp) {\n          sftp.end();\n        }\n      }\n\n      return !failed;\n    })();\n  }\n\n  dispose() {\n    if (this.connection) {\n      this.connection.end();\n    }\n  }\n\n}\n\nmodule.exports = SSH;\n\n//# sourceURL=webpack:///./node_modules/node-ssh/lib/index.js?");

/***/ }),

/***/ "./node_modules/once/once.js":
/*!***********************************!*\
  !*** ./node_modules/once/once.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var wrappy = __webpack_require__(/*! wrappy */ \"./node_modules/wrappy/wrappy.js\")\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n\n\n//# sourceURL=webpack:///./node_modules/once/once.js?");

/***/ }),

/***/ "./node_modules/p-map/index.js":
/*!*************************************!*\
  !*** ./node_modules/p-map/index.js ***!
  \*************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nconst pMap = (iterable, mapper, options) => new Promise((resolve, reject) => {\n\toptions = Object.assign({\n\t\tconcurrency: Infinity\n\t}, options);\n\n\tif (typeof mapper !== 'function') {\n\t\tthrow new TypeError('Mapper function is required');\n\t}\n\n\tconst {concurrency} = options;\n\n\tif (!(typeof concurrency === 'number' && concurrency >= 1)) {\n\t\tthrow new TypeError(`Expected \\`concurrency\\` to be a number from 1 and up, got \\`${concurrency}\\` (${typeof concurrency})`);\n\t}\n\n\tconst ret = [];\n\tconst iterator = iterable[Symbol.iterator]();\n\tlet isRejected = false;\n\tlet isIterableDone = false;\n\tlet resolvingCount = 0;\n\tlet currentIndex = 0;\n\n\tconst next = () => {\n\t\tif (isRejected) {\n\t\t\treturn;\n\t\t}\n\n\t\tconst nextItem = iterator.next();\n\t\tconst i = currentIndex;\n\t\tcurrentIndex++;\n\n\t\tif (nextItem.done) {\n\t\t\tisIterableDone = true;\n\n\t\t\tif (resolvingCount === 0) {\n\t\t\t\tresolve(ret);\n\t\t\t}\n\n\t\t\treturn;\n\t\t}\n\n\t\tresolvingCount++;\n\n\t\tPromise.resolve(nextItem.value)\n\t\t\t.then(element => mapper(element, i))\n\t\t\t.then(\n\t\t\t\tvalue => {\n\t\t\t\t\tret[i] = value;\n\t\t\t\t\tresolvingCount--;\n\t\t\t\t\tnext();\n\t\t\t\t},\n\t\t\t\terror => {\n\t\t\t\t\tisRejected = true;\n\t\t\t\t\treject(error);\n\t\t\t\t}\n\t\t\t);\n\t};\n\n\tfor (let i = 0; i < concurrency; i++) {\n\t\tnext();\n\n\t\tif (isIterableDone) {\n\t\t\tbreak;\n\t\t}\n\t}\n});\n\nmodule.exports = pMap;\n// TODO: Remove this for the next major release\nmodule.exports.default = pMap;\n\n\n//# sourceURL=webpack:///./node_modules/p-map/index.js?");

/***/ }),

/***/ "./node_modules/pako/index.js":
/*!************************************!*\
  !*** ./node_modules/pako/index.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Top level file is just a mixin of submodules & constants\n\n\nvar assign    = __webpack_require__(/*! ./lib/utils/common */ \"./node_modules/pako/lib/utils/common.js\").assign;\n\nvar deflate   = __webpack_require__(/*! ./lib/deflate */ \"./node_modules/pako/lib/deflate.js\");\nvar inflate   = __webpack_require__(/*! ./lib/inflate */ \"./node_modules/pako/lib/inflate.js\");\nvar constants = __webpack_require__(/*! ./lib/zlib/constants */ \"./node_modules/pako/lib/zlib/constants.js\");\n\nvar pako = {};\n\nassign(pako, deflate, inflate, constants);\n\nmodule.exports = pako;\n\n\n//# sourceURL=webpack:///./node_modules/pako/index.js?");

/***/ }),

/***/ "./node_modules/pako/lib/deflate.js":
/*!******************************************!*\
  !*** ./node_modules/pako/lib/deflate.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n\nvar zlib_deflate = __webpack_require__(/*! ./zlib/deflate */ \"./node_modules/pako/lib/zlib/deflate.js\");\nvar utils        = __webpack_require__(/*! ./utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar strings      = __webpack_require__(/*! ./utils/strings */ \"./node_modules/pako/lib/utils/strings.js\");\nvar msg          = __webpack_require__(/*! ./zlib/messages */ \"./node_modules/pako/lib/zlib/messages.js\");\nvar ZStream      = __webpack_require__(/*! ./zlib/zstream */ \"./node_modules/pako/lib/zlib/zstream.js\");\n\nvar toString = Object.prototype.toString;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nvar Z_NO_FLUSH      = 0;\nvar Z_FINISH        = 4;\n\nvar Z_OK            = 0;\nvar Z_STREAM_END    = 1;\nvar Z_SYNC_FLUSH    = 2;\n\nvar Z_DEFAULT_COMPRESSION = -1;\n\nvar Z_DEFAULT_STRATEGY    = 0;\n\nvar Z_DEFLATED  = 8;\n\n/* ===========================================================================*/\n\n\n/**\n * class Deflate\n *\n * Generic JS-style wrapper for zlib calls. If you don't need\n * streaming behaviour - use more simple functions: [[deflate]],\n * [[deflateRaw]] and [[gzip]].\n **/\n\n/* internal\n * Deflate.chunks -> Array\n *\n * Chunks of output data, if [[Deflate#onData]] not overridden.\n **/\n\n/**\n * Deflate.result -> Uint8Array|Array\n *\n * Compressed result, generated by default [[Deflate#onData]]\n * and [[Deflate#onEnd]] handlers. Filled after you push last chunk\n * (call [[Deflate#push]] with `Z_FINISH` / `true` param)  or if you\n * push a chunk with explicit flush (call [[Deflate#push]] with\n * `Z_SYNC_FLUSH` param).\n **/\n\n/**\n * Deflate.err -> Number\n *\n * Error code after deflate finished. 0 (Z_OK) on success.\n * You will not need it in real life, because deflate errors\n * are possible only on wrong options or bad `onData` / `onEnd`\n * custom handlers.\n **/\n\n/**\n * Deflate.msg -> String\n *\n * Error message, if [[Deflate.err]] != 0\n **/\n\n\n/**\n * new Deflate(options)\n * - options (Object): zlib deflate options.\n *\n * Creates new deflator instance with specified params. Throws exception\n * on bad params. Supported options:\n *\n * - `level`\n * - `windowBits`\n * - `memLevel`\n * - `strategy`\n * - `dictionary`\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Additional options, for internal needs:\n *\n * - `chunkSize` - size of generated data chunks (16K by default)\n * - `raw` (Boolean) - do raw deflate\n * - `gzip` (Boolean) - create gzip wrapper\n * - `to` (String) - if equal to 'string', then result will be \"binary string\"\n *    (each char code [0..255])\n * - `header` (Object) - custom header for gzip\n *   - `text` (Boolean) - true if compressed data believed to be text\n *   - `time` (Number) - modification time, unix timestamp\n *   - `os` (Number) - operation system code\n *   - `extra` (Array) - array of bytes with extra data (max 65536)\n *   - `name` (String) - file name (binary string)\n *   - `comment` (String) - comment (binary string)\n *   - `hcrc` (Boolean) - true if header crc should be added\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])\n *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);\n *\n * var deflate = new pako.Deflate({ level: 3});\n *\n * deflate.push(chunk1, false);\n * deflate.push(chunk2, true);  // true -> last chunk\n *\n * if (deflate.err) { throw new Error(deflate.err); }\n *\n * console.log(deflate.result);\n * ```\n **/\nfunction Deflate(options) {\n  if (!(this instanceof Deflate)) return new Deflate(options);\n\n  this.options = utils.assign({\n    level: Z_DEFAULT_COMPRESSION,\n    method: Z_DEFLATED,\n    chunkSize: 16384,\n    windowBits: 15,\n    memLevel: 8,\n    strategy: Z_DEFAULT_STRATEGY,\n    to: ''\n  }, options || {});\n\n  var opt = this.options;\n\n  if (opt.raw && (opt.windowBits > 0)) {\n    opt.windowBits = -opt.windowBits;\n  }\n\n  else if (opt.gzip && (opt.windowBits > 0) && (opt.windowBits < 16)) {\n    opt.windowBits += 16;\n  }\n\n  this.err    = 0;      // error code, if happens (0 = Z_OK)\n  this.msg    = '';     // error message\n  this.ended  = false;  // used to avoid multiple onEnd() calls\n  this.chunks = [];     // chunks of compressed data\n\n  this.strm = new ZStream();\n  this.strm.avail_out = 0;\n\n  var status = zlib_deflate.deflateInit2(\n    this.strm,\n    opt.level,\n    opt.method,\n    opt.windowBits,\n    opt.memLevel,\n    opt.strategy\n  );\n\n  if (status !== Z_OK) {\n    throw new Error(msg[status]);\n  }\n\n  if (opt.header) {\n    zlib_deflate.deflateSetHeader(this.strm, opt.header);\n  }\n\n  if (opt.dictionary) {\n    var dict;\n    // Convert data if needed\n    if (typeof opt.dictionary === 'string') {\n      // If we need to compress text, change encoding to utf8.\n      dict = strings.string2buf(opt.dictionary);\n    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {\n      dict = new Uint8Array(opt.dictionary);\n    } else {\n      dict = opt.dictionary;\n    }\n\n    status = zlib_deflate.deflateSetDictionary(this.strm, dict);\n\n    if (status !== Z_OK) {\n      throw new Error(msg[status]);\n    }\n\n    this._dict_set = true;\n  }\n}\n\n/**\n * Deflate#push(data[, mode]) -> Boolean\n * - data (Uint8Array|Array|ArrayBuffer|String): input data. Strings will be\n *   converted to utf8 byte sequence.\n * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.\n *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.\n *\n * Sends input data to deflate pipe, generating [[Deflate#onData]] calls with\n * new compressed chunks. Returns `true` on success. The last data block must have\n * mode Z_FINISH (or `true`). That will flush internal pending buffers and call\n * [[Deflate#onEnd]]. For interim explicit flushes (without ending the stream) you\n * can use mode Z_SYNC_FLUSH, keeping the compression context.\n *\n * On fail call [[Deflate#onEnd]] with error code and return false.\n *\n * We strongly recommend to use `Uint8Array` on input for best speed (output\n * array format is detected automatically). Also, don't skip last param and always\n * use the same type in your code (boolean or number). That will improve JS speed.\n *\n * For regular `Array`-s make sure all elements are [0..255].\n *\n * ##### Example\n *\n * ```javascript\n * push(chunk, false); // push one of data chunks\n * ...\n * push(chunk, true);  // push last chunk\n * ```\n **/\nDeflate.prototype.push = function (data, mode) {\n  var strm = this.strm;\n  var chunkSize = this.options.chunkSize;\n  var status, _mode;\n\n  if (this.ended) { return false; }\n\n  _mode = (mode === ~~mode) ? mode : ((mode === true) ? Z_FINISH : Z_NO_FLUSH);\n\n  // Convert data if needed\n  if (typeof data === 'string') {\n    // If we need to compress text, change encoding to utf8.\n    strm.input = strings.string2buf(data);\n  } else if (toString.call(data) === '[object ArrayBuffer]') {\n    strm.input = new Uint8Array(data);\n  } else {\n    strm.input = data;\n  }\n\n  strm.next_in = 0;\n  strm.avail_in = strm.input.length;\n\n  do {\n    if (strm.avail_out === 0) {\n      strm.output = new utils.Buf8(chunkSize);\n      strm.next_out = 0;\n      strm.avail_out = chunkSize;\n    }\n    status = zlib_deflate.deflate(strm, _mode);    /* no bad return value */\n\n    if (status !== Z_STREAM_END && status !== Z_OK) {\n      this.onEnd(status);\n      this.ended = true;\n      return false;\n    }\n    if (strm.avail_out === 0 || (strm.avail_in === 0 && (_mode === Z_FINISH || _mode === Z_SYNC_FLUSH))) {\n      if (this.options.to === 'string') {\n        this.onData(strings.buf2binstring(utils.shrinkBuf(strm.output, strm.next_out)));\n      } else {\n        this.onData(utils.shrinkBuf(strm.output, strm.next_out));\n      }\n    }\n  } while ((strm.avail_in > 0 || strm.avail_out === 0) && status !== Z_STREAM_END);\n\n  // Finalize on the last chunk.\n  if (_mode === Z_FINISH) {\n    status = zlib_deflate.deflateEnd(this.strm);\n    this.onEnd(status);\n    this.ended = true;\n    return status === Z_OK;\n  }\n\n  // callback interim results if Z_SYNC_FLUSH.\n  if (_mode === Z_SYNC_FLUSH) {\n    this.onEnd(Z_OK);\n    strm.avail_out = 0;\n    return true;\n  }\n\n  return true;\n};\n\n\n/**\n * Deflate#onData(chunk) -> Void\n * - chunk (Uint8Array|Array|String): output data. Type of array depends\n *   on js engine support. When string output requested, each chunk\n *   will be string.\n *\n * By default, stores data blocks in `chunks[]` property and glue\n * those in `onEnd`. Override this handler, if you need another behaviour.\n **/\nDeflate.prototype.onData = function (chunk) {\n  this.chunks.push(chunk);\n};\n\n\n/**\n * Deflate#onEnd(status) -> Void\n * - status (Number): deflate status. 0 (Z_OK) on success,\n *   other if not.\n *\n * Called once after you tell deflate that the input stream is\n * complete (Z_FINISH) or should be flushed (Z_SYNC_FLUSH)\n * or if an error happened. By default - join collected chunks,\n * free memory and fill `results` / `err` properties.\n **/\nDeflate.prototype.onEnd = function (status) {\n  // On success - join\n  if (status === Z_OK) {\n    if (this.options.to === 'string') {\n      this.result = this.chunks.join('');\n    } else {\n      this.result = utils.flattenChunks(this.chunks);\n    }\n  }\n  this.chunks = [];\n  this.err = status;\n  this.msg = this.strm.msg;\n};\n\n\n/**\n * deflate(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * Compress `data` with deflate algorithm and `options`.\n *\n * Supported options are:\n *\n * - level\n * - windowBits\n * - memLevel\n * - strategy\n * - dictionary\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Sugar (options):\n *\n * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify\n *   negative windowBits implicitly.\n * - `to` (String) - if equal to 'string', then result will be \"binary string\"\n *    (each char code [0..255])\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , data = Uint8Array([1,2,3,4,5,6,7,8,9]);\n *\n * console.log(pako.deflate(data));\n * ```\n **/\nfunction deflate(input, options) {\n  var deflator = new Deflate(options);\n\n  deflator.push(input, true);\n\n  // That will never happens, if you don't cheat with options :)\n  if (deflator.err) { throw deflator.msg || msg[deflator.err]; }\n\n  return deflator.result;\n}\n\n\n/**\n * deflateRaw(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * The same as [[deflate]], but creates raw data, without wrapper\n * (header and adler32 crc).\n **/\nfunction deflateRaw(input, options) {\n  options = options || {};\n  options.raw = true;\n  return deflate(input, options);\n}\n\n\n/**\n * gzip(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * The same as [[deflate]], but create gzip wrapper instead of\n * deflate one.\n **/\nfunction gzip(input, options) {\n  options = options || {};\n  options.gzip = true;\n  return deflate(input, options);\n}\n\n\nexports.Deflate = Deflate;\nexports.deflate = deflate;\nexports.deflateRaw = deflateRaw;\nexports.gzip = gzip;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/deflate.js?");

/***/ }),

/***/ "./node_modules/pako/lib/inflate.js":
/*!******************************************!*\
  !*** ./node_modules/pako/lib/inflate.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n\nvar zlib_inflate = __webpack_require__(/*! ./zlib/inflate */ \"./node_modules/pako/lib/zlib/inflate.js\");\nvar utils        = __webpack_require__(/*! ./utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar strings      = __webpack_require__(/*! ./utils/strings */ \"./node_modules/pako/lib/utils/strings.js\");\nvar c            = __webpack_require__(/*! ./zlib/constants */ \"./node_modules/pako/lib/zlib/constants.js\");\nvar msg          = __webpack_require__(/*! ./zlib/messages */ \"./node_modules/pako/lib/zlib/messages.js\");\nvar ZStream      = __webpack_require__(/*! ./zlib/zstream */ \"./node_modules/pako/lib/zlib/zstream.js\");\nvar GZheader     = __webpack_require__(/*! ./zlib/gzheader */ \"./node_modules/pako/lib/zlib/gzheader.js\");\n\nvar toString = Object.prototype.toString;\n\n/**\n * class Inflate\n *\n * Generic JS-style wrapper for zlib calls. If you don't need\n * streaming behaviour - use more simple functions: [[inflate]]\n * and [[inflateRaw]].\n **/\n\n/* internal\n * inflate.chunks -> Array\n *\n * Chunks of output data, if [[Inflate#onData]] not overridden.\n **/\n\n/**\n * Inflate.result -> Uint8Array|Array|String\n *\n * Uncompressed result, generated by default [[Inflate#onData]]\n * and [[Inflate#onEnd]] handlers. Filled after you push last chunk\n * (call [[Inflate#push]] with `Z_FINISH` / `true` param) or if you\n * push a chunk with explicit flush (call [[Inflate#push]] with\n * `Z_SYNC_FLUSH` param).\n **/\n\n/**\n * Inflate.err -> Number\n *\n * Error code after inflate finished. 0 (Z_OK) on success.\n * Should be checked if broken data possible.\n **/\n\n/**\n * Inflate.msg -> String\n *\n * Error message, if [[Inflate.err]] != 0\n **/\n\n\n/**\n * new Inflate(options)\n * - options (Object): zlib inflate options.\n *\n * Creates new inflator instance with specified params. Throws exception\n * on bad params. Supported options:\n *\n * - `windowBits`\n * - `dictionary`\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Additional options, for internal needs:\n *\n * - `chunkSize` - size of generated data chunks (16K by default)\n * - `raw` (Boolean) - do raw inflate\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n * By default, when no options set, autodetect deflate/gzip data format via\n * wrapper header.\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])\n *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);\n *\n * var inflate = new pako.Inflate({ level: 3});\n *\n * inflate.push(chunk1, false);\n * inflate.push(chunk2, true);  // true -> last chunk\n *\n * if (inflate.err) { throw new Error(inflate.err); }\n *\n * console.log(inflate.result);\n * ```\n **/\nfunction Inflate(options) {\n  if (!(this instanceof Inflate)) return new Inflate(options);\n\n  this.options = utils.assign({\n    chunkSize: 16384,\n    windowBits: 0,\n    to: ''\n  }, options || {});\n\n  var opt = this.options;\n\n  // Force window size for `raw` data, if not set directly,\n  // because we have no header for autodetect.\n  if (opt.raw && (opt.windowBits >= 0) && (opt.windowBits < 16)) {\n    opt.windowBits = -opt.windowBits;\n    if (opt.windowBits === 0) { opt.windowBits = -15; }\n  }\n\n  // If `windowBits` not defined (and mode not raw) - set autodetect flag for gzip/deflate\n  if ((opt.windowBits >= 0) && (opt.windowBits < 16) &&\n      !(options && options.windowBits)) {\n    opt.windowBits += 32;\n  }\n\n  // Gzip header has no info about windows size, we can do autodetect only\n  // for deflate. So, if window size not set, force it to max when gzip possible\n  if ((opt.windowBits > 15) && (opt.windowBits < 48)) {\n    // bit 3 (16) -> gzipped data\n    // bit 4 (32) -> autodetect gzip/deflate\n    if ((opt.windowBits & 15) === 0) {\n      opt.windowBits |= 15;\n    }\n  }\n\n  this.err    = 0;      // error code, if happens (0 = Z_OK)\n  this.msg    = '';     // error message\n  this.ended  = false;  // used to avoid multiple onEnd() calls\n  this.chunks = [];     // chunks of compressed data\n\n  this.strm   = new ZStream();\n  this.strm.avail_out = 0;\n\n  var status  = zlib_inflate.inflateInit2(\n    this.strm,\n    opt.windowBits\n  );\n\n  if (status !== c.Z_OK) {\n    throw new Error(msg[status]);\n  }\n\n  this.header = new GZheader();\n\n  zlib_inflate.inflateGetHeader(this.strm, this.header);\n\n  // Setup dictionary\n  if (opt.dictionary) {\n    // Convert data if needed\n    if (typeof opt.dictionary === 'string') {\n      opt.dictionary = strings.string2buf(opt.dictionary);\n    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {\n      opt.dictionary = new Uint8Array(opt.dictionary);\n    }\n    if (opt.raw) { //In raw mode we need to set the dictionary early\n      status = zlib_inflate.inflateSetDictionary(this.strm, opt.dictionary);\n      if (status !== c.Z_OK) {\n        throw new Error(msg[status]);\n      }\n    }\n  }\n}\n\n/**\n * Inflate#push(data[, mode]) -> Boolean\n * - data (Uint8Array|Array|ArrayBuffer|String): input data\n * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.\n *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.\n *\n * Sends input data to inflate pipe, generating [[Inflate#onData]] calls with\n * new output chunks. Returns `true` on success. The last data block must have\n * mode Z_FINISH (or `true`). That will flush internal pending buffers and call\n * [[Inflate#onEnd]]. For interim explicit flushes (without ending the stream) you\n * can use mode Z_SYNC_FLUSH, keeping the decompression context.\n *\n * On fail call [[Inflate#onEnd]] with error code and return false.\n *\n * We strongly recommend to use `Uint8Array` on input for best speed (output\n * format is detected automatically). Also, don't skip last param and always\n * use the same type in your code (boolean or number). That will improve JS speed.\n *\n * For regular `Array`-s make sure all elements are [0..255].\n *\n * ##### Example\n *\n * ```javascript\n * push(chunk, false); // push one of data chunks\n * ...\n * push(chunk, true);  // push last chunk\n * ```\n **/\nInflate.prototype.push = function (data, mode) {\n  var strm = this.strm;\n  var chunkSize = this.options.chunkSize;\n  var dictionary = this.options.dictionary;\n  var status, _mode;\n  var next_out_utf8, tail, utf8str;\n\n  // Flag to properly process Z_BUF_ERROR on testing inflate call\n  // when we check that all output data was flushed.\n  var allowBufError = false;\n\n  if (this.ended) { return false; }\n  _mode = (mode === ~~mode) ? mode : ((mode === true) ? c.Z_FINISH : c.Z_NO_FLUSH);\n\n  // Convert data if needed\n  if (typeof data === 'string') {\n    // Only binary strings can be decompressed on practice\n    strm.input = strings.binstring2buf(data);\n  } else if (toString.call(data) === '[object ArrayBuffer]') {\n    strm.input = new Uint8Array(data);\n  } else {\n    strm.input = data;\n  }\n\n  strm.next_in = 0;\n  strm.avail_in = strm.input.length;\n\n  do {\n    if (strm.avail_out === 0) {\n      strm.output = new utils.Buf8(chunkSize);\n      strm.next_out = 0;\n      strm.avail_out = chunkSize;\n    }\n\n    status = zlib_inflate.inflate(strm, c.Z_NO_FLUSH);    /* no bad return value */\n\n    if (status === c.Z_NEED_DICT && dictionary) {\n      status = zlib_inflate.inflateSetDictionary(this.strm, dictionary);\n    }\n\n    if (status === c.Z_BUF_ERROR && allowBufError === true) {\n      status = c.Z_OK;\n      allowBufError = false;\n    }\n\n    if (status !== c.Z_STREAM_END && status !== c.Z_OK) {\n      this.onEnd(status);\n      this.ended = true;\n      return false;\n    }\n\n    if (strm.next_out) {\n      if (strm.avail_out === 0 || status === c.Z_STREAM_END || (strm.avail_in === 0 && (_mode === c.Z_FINISH || _mode === c.Z_SYNC_FLUSH))) {\n\n        if (this.options.to === 'string') {\n\n          next_out_utf8 = strings.utf8border(strm.output, strm.next_out);\n\n          tail = strm.next_out - next_out_utf8;\n          utf8str = strings.buf2string(strm.output, next_out_utf8);\n\n          // move tail\n          strm.next_out = tail;\n          strm.avail_out = chunkSize - tail;\n          if (tail) { utils.arraySet(strm.output, strm.output, next_out_utf8, tail, 0); }\n\n          this.onData(utf8str);\n\n        } else {\n          this.onData(utils.shrinkBuf(strm.output, strm.next_out));\n        }\n      }\n    }\n\n    // When no more input data, we should check that internal inflate buffers\n    // are flushed. The only way to do it when avail_out = 0 - run one more\n    // inflate pass. But if output data not exists, inflate return Z_BUF_ERROR.\n    // Here we set flag to process this error properly.\n    //\n    // NOTE. Deflate does not return error in this case and does not needs such\n    // logic.\n    if (strm.avail_in === 0 && strm.avail_out === 0) {\n      allowBufError = true;\n    }\n\n  } while ((strm.avail_in > 0 || strm.avail_out === 0) && status !== c.Z_STREAM_END);\n\n  if (status === c.Z_STREAM_END) {\n    _mode = c.Z_FINISH;\n  }\n\n  // Finalize on the last chunk.\n  if (_mode === c.Z_FINISH) {\n    status = zlib_inflate.inflateEnd(this.strm);\n    this.onEnd(status);\n    this.ended = true;\n    return status === c.Z_OK;\n  }\n\n  // callback interim results if Z_SYNC_FLUSH.\n  if (_mode === c.Z_SYNC_FLUSH) {\n    this.onEnd(c.Z_OK);\n    strm.avail_out = 0;\n    return true;\n  }\n\n  return true;\n};\n\n\n/**\n * Inflate#onData(chunk) -> Void\n * - chunk (Uint8Array|Array|String): output data. Type of array depends\n *   on js engine support. When string output requested, each chunk\n *   will be string.\n *\n * By default, stores data blocks in `chunks[]` property and glue\n * those in `onEnd`. Override this handler, if you need another behaviour.\n **/\nInflate.prototype.onData = function (chunk) {\n  this.chunks.push(chunk);\n};\n\n\n/**\n * Inflate#onEnd(status) -> Void\n * - status (Number): inflate status. 0 (Z_OK) on success,\n *   other if not.\n *\n * Called either after you tell inflate that the input stream is\n * complete (Z_FINISH) or should be flushed (Z_SYNC_FLUSH)\n * or if an error happened. By default - join collected chunks,\n * free memory and fill `results` / `err` properties.\n **/\nInflate.prototype.onEnd = function (status) {\n  // On success - join\n  if (status === c.Z_OK) {\n    if (this.options.to === 'string') {\n      // Glue & convert here, until we teach pako to send\n      // utf8 aligned strings to onData\n      this.result = this.chunks.join('');\n    } else {\n      this.result = utils.flattenChunks(this.chunks);\n    }\n  }\n  this.chunks = [];\n  this.err = status;\n  this.msg = this.strm.msg;\n};\n\n\n/**\n * inflate(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Decompress `data` with inflate/ungzip and `options`. Autodetect\n * format via wrapper header by default. That's why we don't provide\n * separate `ungzip` method.\n *\n * Supported options are:\n *\n * - windowBits\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information.\n *\n * Sugar (options):\n *\n * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify\n *   negative windowBits implicitly.\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , input = pako.deflate([1,2,3,4,5,6,7,8,9])\n *   , output;\n *\n * try {\n *   output = pako.inflate(input);\n * } catch (err)\n *   console.log(err);\n * }\n * ```\n **/\nfunction inflate(input, options) {\n  var inflator = new Inflate(options);\n\n  inflator.push(input, true);\n\n  // That will never happens, if you don't cheat with options :)\n  if (inflator.err) { throw inflator.msg || msg[inflator.err]; }\n\n  return inflator.result;\n}\n\n\n/**\n * inflateRaw(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * The same as [[inflate]], but creates raw data, without wrapper\n * (header and adler32 crc).\n **/\nfunction inflateRaw(input, options) {\n  options = options || {};\n  options.raw = true;\n  return inflate(input, options);\n}\n\n\n/**\n * ungzip(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Just shortcut to [[inflate]], because it autodetects format\n * by header.content. Done for convenience.\n **/\n\n\nexports.Inflate = Inflate;\nexports.inflate = inflate;\nexports.inflateRaw = inflateRaw;\nexports.ungzip  = inflate;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/inflate.js?");

/***/ }),

/***/ "./node_modules/pako/lib/utils/common.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/utils/common.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n\nvar TYPED_OK =  (typeof Uint8Array !== 'undefined') &&\n                (typeof Uint16Array !== 'undefined') &&\n                (typeof Int32Array !== 'undefined');\n\nfunction _has(obj, key) {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nexports.assign = function (obj /*from1, from2, from3, ...*/) {\n  var sources = Array.prototype.slice.call(arguments, 1);\n  while (sources.length) {\n    var source = sources.shift();\n    if (!source) { continue; }\n\n    if (typeof source !== 'object') {\n      throw new TypeError(source + 'must be non-object');\n    }\n\n    for (var p in source) {\n      if (_has(source, p)) {\n        obj[p] = source[p];\n      }\n    }\n  }\n\n  return obj;\n};\n\n\n// reduce buffer size, avoiding mem copy\nexports.shrinkBuf = function (buf, size) {\n  if (buf.length === size) { return buf; }\n  if (buf.subarray) { return buf.subarray(0, size); }\n  buf.length = size;\n  return buf;\n};\n\n\nvar fnTyped = {\n  arraySet: function (dest, src, src_offs, len, dest_offs) {\n    if (src.subarray && dest.subarray) {\n      dest.set(src.subarray(src_offs, src_offs + len), dest_offs);\n      return;\n    }\n    // Fallback to ordinary array\n    for (var i = 0; i < len; i++) {\n      dest[dest_offs + i] = src[src_offs + i];\n    }\n  },\n  // Join array of chunks to single array.\n  flattenChunks: function (chunks) {\n    var i, l, len, pos, chunk, result;\n\n    // calculate data length\n    len = 0;\n    for (i = 0, l = chunks.length; i < l; i++) {\n      len += chunks[i].length;\n    }\n\n    // join chunks\n    result = new Uint8Array(len);\n    pos = 0;\n    for (i = 0, l = chunks.length; i < l; i++) {\n      chunk = chunks[i];\n      result.set(chunk, pos);\n      pos += chunk.length;\n    }\n\n    return result;\n  }\n};\n\nvar fnUntyped = {\n  arraySet: function (dest, src, src_offs, len, dest_offs) {\n    for (var i = 0; i < len; i++) {\n      dest[dest_offs + i] = src[src_offs + i];\n    }\n  },\n  // Join array of chunks to single array.\n  flattenChunks: function (chunks) {\n    return [].concat.apply([], chunks);\n  }\n};\n\n\n// Enable/Disable typed arrays use, for testing\n//\nexports.setTyped = function (on) {\n  if (on) {\n    exports.Buf8  = Uint8Array;\n    exports.Buf16 = Uint16Array;\n    exports.Buf32 = Int32Array;\n    exports.assign(exports, fnTyped);\n  } else {\n    exports.Buf8  = Array;\n    exports.Buf16 = Array;\n    exports.Buf32 = Array;\n    exports.assign(exports, fnUntyped);\n  }\n};\n\nexports.setTyped(TYPED_OK);\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/utils/common.js?");

/***/ }),

/***/ "./node_modules/pako/lib/utils/strings.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/utils/strings.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// String encode/decode helpers\n\n\n\nvar utils = __webpack_require__(/*! ./common */ \"./node_modules/pako/lib/utils/common.js\");\n\n\n// Quick check if we can use fast array to bin string conversion\n//\n// - apply(Array) can fail on Android 2.2\n// - apply(Uint8Array) can fail on iOS 5.1 Safari\n//\nvar STR_APPLY_OK = true;\nvar STR_APPLY_UIA_OK = true;\n\ntry { String.fromCharCode.apply(null, [ 0 ]); } catch (__) { STR_APPLY_OK = false; }\ntry { String.fromCharCode.apply(null, new Uint8Array(1)); } catch (__) { STR_APPLY_UIA_OK = false; }\n\n\n// Table with utf8 lengths (calculated by first byte of sequence)\n// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,\n// because max possible codepoint is 0x10ffff\nvar _utf8len = new utils.Buf8(256);\nfor (var q = 0; q < 256; q++) {\n  _utf8len[q] = (q >= 252 ? 6 : q >= 248 ? 5 : q >= 240 ? 4 : q >= 224 ? 3 : q >= 192 ? 2 : 1);\n}\n_utf8len[254] = _utf8len[254] = 1; // Invalid sequence start\n\n\n// convert string to array (typed, when possible)\nexports.string2buf = function (str) {\n  var buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;\n\n  // count binary size\n  for (m_pos = 0; m_pos < str_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;\n  }\n\n  // allocate buffer\n  buf = new utils.Buf8(buf_len);\n\n  // convert\n  for (i = 0, m_pos = 0; i < buf_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    if (c < 0x80) {\n      /* one byte */\n      buf[i++] = c;\n    } else if (c < 0x800) {\n      /* two bytes */\n      buf[i++] = 0xC0 | (c >>> 6);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else if (c < 0x10000) {\n      /* three bytes */\n      buf[i++] = 0xE0 | (c >>> 12);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else {\n      /* four bytes */\n      buf[i++] = 0xf0 | (c >>> 18);\n      buf[i++] = 0x80 | (c >>> 12 & 0x3f);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    }\n  }\n\n  return buf;\n};\n\n// Helper (used in 2 places)\nfunction buf2binstring(buf, len) {\n  // On Chrome, the arguments in a function call that are allowed is `65534`.\n  // If the length of the buffer is smaller than that, we can use this optimization,\n  // otherwise we will take a slower path.\n  if (len < 65534) {\n    if ((buf.subarray && STR_APPLY_UIA_OK) || (!buf.subarray && STR_APPLY_OK)) {\n      return String.fromCharCode.apply(null, utils.shrinkBuf(buf, len));\n    }\n  }\n\n  var result = '';\n  for (var i = 0; i < len; i++) {\n    result += String.fromCharCode(buf[i]);\n  }\n  return result;\n}\n\n\n// Convert byte array to binary string\nexports.buf2binstring = function (buf) {\n  return buf2binstring(buf, buf.length);\n};\n\n\n// Convert binary string (typed, when possible)\nexports.binstring2buf = function (str) {\n  var buf = new utils.Buf8(str.length);\n  for (var i = 0, len = buf.length; i < len; i++) {\n    buf[i] = str.charCodeAt(i);\n  }\n  return buf;\n};\n\n\n// convert array to string\nexports.buf2string = function (buf, max) {\n  var i, out, c, c_len;\n  var len = max || buf.length;\n\n  // Reserve max possible length (2 words per char)\n  // NB: by unknown reasons, Array is significantly faster for\n  //     String.fromCharCode.apply than Uint16Array.\n  var utf16buf = new Array(len * 2);\n\n  for (out = 0, i = 0; i < len;) {\n    c = buf[i++];\n    // quick process ascii\n    if (c < 0x80) { utf16buf[out++] = c; continue; }\n\n    c_len = _utf8len[c];\n    // skip 5 & 6 byte codes\n    if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len - 1; continue; }\n\n    // apply mask on first byte\n    c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;\n    // join the rest\n    while (c_len > 1 && i < len) {\n      c = (c << 6) | (buf[i++] & 0x3f);\n      c_len--;\n    }\n\n    // terminated by end of string?\n    if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }\n\n    if (c < 0x10000) {\n      utf16buf[out++] = c;\n    } else {\n      c -= 0x10000;\n      utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);\n      utf16buf[out++] = 0xdc00 | (c & 0x3ff);\n    }\n  }\n\n  return buf2binstring(utf16buf, out);\n};\n\n\n// Calculate max possible position in utf8 buffer,\n// that will not break sequence. If that's not possible\n// - (very small limits) return max size as is.\n//\n// buf[] - utf8 bytes array\n// max   - length limit (mandatory);\nexports.utf8border = function (buf, max) {\n  var pos;\n\n  max = max || buf.length;\n  if (max > buf.length) { max = buf.length; }\n\n  // go back from last position, until start of sequence found\n  pos = max - 1;\n  while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }\n\n  // Very small and broken sequence,\n  // return max, because we should return something anyway.\n  if (pos < 0) { return max; }\n\n  // If we came to start of buffer - that means buffer is too small,\n  // return max too.\n  if (pos === 0) { return max; }\n\n  return (pos + _utf8len[buf[pos]] > max) ? pos : max;\n};\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/utils/strings.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/adler32.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/adler32.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// Note: adler32 takes 12% for level 0 and 2% for level 6.\n// It isn't worth it to make additional optimizations as in original.\n// Small size is preferable.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction adler32(adler, buf, len, pos) {\n  var s1 = (adler & 0xffff) |0,\n      s2 = ((adler >>> 16) & 0xffff) |0,\n      n = 0;\n\n  while (len !== 0) {\n    // Set limit ~ twice less than 5552, to keep\n    // s2 in 31-bits, because we force signed ints.\n    // in other case %= will fail.\n    n = len > 2000 ? 2000 : len;\n    len -= n;\n\n    do {\n      s1 = (s1 + buf[pos++]) |0;\n      s2 = (s2 + s1) |0;\n    } while (--n);\n\n    s1 %= 65521;\n    s2 %= 65521;\n  }\n\n  return (s1 | (s2 << 16)) |0;\n}\n\n\nmodule.exports = adler32;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/adler32.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/constants.js":
/*!*************************************************!*\
  !*** ./node_modules/pako/lib/zlib/constants.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n\n  /* Allowed flush values; see deflate() and inflate() below for details */\n  Z_NO_FLUSH:         0,\n  Z_PARTIAL_FLUSH:    1,\n  Z_SYNC_FLUSH:       2,\n  Z_FULL_FLUSH:       3,\n  Z_FINISH:           4,\n  Z_BLOCK:            5,\n  Z_TREES:            6,\n\n  /* Return codes for the compression/decompression functions. Negative values\n  * are errors, positive values are used for special but normal events.\n  */\n  Z_OK:               0,\n  Z_STREAM_END:       1,\n  Z_NEED_DICT:        2,\n  Z_ERRNO:           -1,\n  Z_STREAM_ERROR:    -2,\n  Z_DATA_ERROR:      -3,\n  //Z_MEM_ERROR:     -4,\n  Z_BUF_ERROR:       -5,\n  //Z_VERSION_ERROR: -6,\n\n  /* compression levels */\n  Z_NO_COMPRESSION:         0,\n  Z_BEST_SPEED:             1,\n  Z_BEST_COMPRESSION:       9,\n  Z_DEFAULT_COMPRESSION:   -1,\n\n\n  Z_FILTERED:               1,\n  Z_HUFFMAN_ONLY:           2,\n  Z_RLE:                    3,\n  Z_FIXED:                  4,\n  Z_DEFAULT_STRATEGY:       0,\n\n  /* Possible values of the data_type field (though see inflate()) */\n  Z_BINARY:                 0,\n  Z_TEXT:                   1,\n  //Z_ASCII:                1, // = Z_TEXT (deprecated)\n  Z_UNKNOWN:                2,\n\n  /* The deflate compression method */\n  Z_DEFLATED:               8\n  //Z_NULL:                 null // Use -1 or null inline, depending on var type\n};\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/constants.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/crc32.js":
/*!*********************************************!*\
  !*** ./node_modules/pako/lib/zlib/crc32.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// Note: we can't get significant speed boost here.\n// So write code to minimize size - no pregenerated tables\n// and array tools dependencies.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// Use ordinary array, since untyped makes no boost here\nfunction makeTable() {\n  var c, table = [];\n\n  for (var n = 0; n < 256; n++) {\n    c = n;\n    for (var k = 0; k < 8; k++) {\n      c = ((c & 1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));\n    }\n    table[n] = c;\n  }\n\n  return table;\n}\n\n// Create table on load. Just 255 signed longs. Not a problem.\nvar crcTable = makeTable();\n\n\nfunction crc32(crc, buf, len, pos) {\n  var t = crcTable,\n      end = pos + len;\n\n  crc ^= -1;\n\n  for (var i = pos; i < end; i++) {\n    crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];\n  }\n\n  return (crc ^ (-1)); // >>> 0;\n}\n\n\nmodule.exports = crc32;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/crc32.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/deflate.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/deflate.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils   = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar trees   = __webpack_require__(/*! ./trees */ \"./node_modules/pako/lib/zlib/trees.js\");\nvar adler32 = __webpack_require__(/*! ./adler32 */ \"./node_modules/pako/lib/zlib/adler32.js\");\nvar crc32   = __webpack_require__(/*! ./crc32 */ \"./node_modules/pako/lib/zlib/crc32.js\");\nvar msg     = __webpack_require__(/*! ./messages */ \"./node_modules/pako/lib/zlib/messages.js\");\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n/* Allowed flush values; see deflate() and inflate() below for details */\nvar Z_NO_FLUSH      = 0;\nvar Z_PARTIAL_FLUSH = 1;\n//var Z_SYNC_FLUSH    = 2;\nvar Z_FULL_FLUSH    = 3;\nvar Z_FINISH        = 4;\nvar Z_BLOCK         = 5;\n//var Z_TREES         = 6;\n\n\n/* Return codes for the compression/decompression functions. Negative values\n * are errors, positive values are used for special but normal events.\n */\nvar Z_OK            = 0;\nvar Z_STREAM_END    = 1;\n//var Z_NEED_DICT     = 2;\n//var Z_ERRNO         = -1;\nvar Z_STREAM_ERROR  = -2;\nvar Z_DATA_ERROR    = -3;\n//var Z_MEM_ERROR     = -4;\nvar Z_BUF_ERROR     = -5;\n//var Z_VERSION_ERROR = -6;\n\n\n/* compression levels */\n//var Z_NO_COMPRESSION      = 0;\n//var Z_BEST_SPEED          = 1;\n//var Z_BEST_COMPRESSION    = 9;\nvar Z_DEFAULT_COMPRESSION = -1;\n\n\nvar Z_FILTERED            = 1;\nvar Z_HUFFMAN_ONLY        = 2;\nvar Z_RLE                 = 3;\nvar Z_FIXED               = 4;\nvar Z_DEFAULT_STRATEGY    = 0;\n\n/* Possible values of the data_type field (though see inflate()) */\n//var Z_BINARY              = 0;\n//var Z_TEXT                = 1;\n//var Z_ASCII               = 1; // = Z_TEXT\nvar Z_UNKNOWN             = 2;\n\n\n/* The deflate compression method */\nvar Z_DEFLATED  = 8;\n\n/*============================================================================*/\n\n\nvar MAX_MEM_LEVEL = 9;\n/* Maximum value for memLevel in deflateInit2 */\nvar MAX_WBITS = 15;\n/* 32K LZ77 window */\nvar DEF_MEM_LEVEL = 8;\n\n\nvar LENGTH_CODES  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\nvar LITERALS      = 256;\n/* number of literal bytes 0..255 */\nvar L_CODES       = LITERALS + 1 + LENGTH_CODES;\n/* number of Literal or Length codes, including the END_BLOCK code */\nvar D_CODES       = 30;\n/* number of distance codes */\nvar BL_CODES      = 19;\n/* number of codes used to transfer the bit lengths */\nvar HEAP_SIZE     = 2 * L_CODES + 1;\n/* maximum heap size */\nvar MAX_BITS  = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nvar MIN_MATCH = 3;\nvar MAX_MATCH = 258;\nvar MIN_LOOKAHEAD = (MAX_MATCH + MIN_MATCH + 1);\n\nvar PRESET_DICT = 0x20;\n\nvar INIT_STATE = 42;\nvar EXTRA_STATE = 69;\nvar NAME_STATE = 73;\nvar COMMENT_STATE = 91;\nvar HCRC_STATE = 103;\nvar BUSY_STATE = 113;\nvar FINISH_STATE = 666;\n\nvar BS_NEED_MORE      = 1; /* block not completed, need more input or more output */\nvar BS_BLOCK_DONE     = 2; /* block flush performed */\nvar BS_FINISH_STARTED = 3; /* finish started, need only more output at next deflate */\nvar BS_FINISH_DONE    = 4; /* finish done, accept no more input or output */\n\nvar OS_CODE = 0x03; // Unix :) . Don't detect, use this default.\n\nfunction err(strm, errorCode) {\n  strm.msg = msg[errorCode];\n  return errorCode;\n}\n\nfunction rank(f) {\n  return ((f) << 1) - ((f) > 4 ? 9 : 0);\n}\n\nfunction zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }\n\n\n/* =========================================================================\n * Flush as much pending output as possible. All deflate() output goes\n * through this function so some applications may wish to modify it\n * to avoid allocating a large strm->output buffer and copying into it.\n * (See also read_buf()).\n */\nfunction flush_pending(strm) {\n  var s = strm.state;\n\n  //_tr_flush_bits(s);\n  var len = s.pending;\n  if (len > strm.avail_out) {\n    len = strm.avail_out;\n  }\n  if (len === 0) { return; }\n\n  utils.arraySet(strm.output, s.pending_buf, s.pending_out, len, strm.next_out);\n  strm.next_out += len;\n  s.pending_out += len;\n  strm.total_out += len;\n  strm.avail_out -= len;\n  s.pending -= len;\n  if (s.pending === 0) {\n    s.pending_out = 0;\n  }\n}\n\n\nfunction flush_block_only(s, last) {\n  trees._tr_flush_block(s, (s.block_start >= 0 ? s.block_start : -1), s.strstart - s.block_start, last);\n  s.block_start = s.strstart;\n  flush_pending(s.strm);\n}\n\n\nfunction put_byte(s, b) {\n  s.pending_buf[s.pending++] = b;\n}\n\n\n/* =========================================================================\n * Put a short in the pending buffer. The 16-bit value is put in MSB order.\n * IN assertion: the stream state is correct and there is enough room in\n * pending_buf.\n */\nfunction putShortMSB(s, b) {\n//  put_byte(s, (Byte)(b >> 8));\n//  put_byte(s, (Byte)(b & 0xff));\n  s.pending_buf[s.pending++] = (b >>> 8) & 0xff;\n  s.pending_buf[s.pending++] = b & 0xff;\n}\n\n\n/* ===========================================================================\n * Read a new buffer from the current input stream, update the adler32\n * and total number of bytes read.  All deflate() input goes through\n * this function so some applications may wish to modify it to avoid\n * allocating a large strm->input buffer and copying from it.\n * (See also flush_pending()).\n */\nfunction read_buf(strm, buf, start, size) {\n  var len = strm.avail_in;\n\n  if (len > size) { len = size; }\n  if (len === 0) { return 0; }\n\n  strm.avail_in -= len;\n\n  // zmemcpy(buf, strm->next_in, len);\n  utils.arraySet(buf, strm.input, strm.next_in, len, start);\n  if (strm.state.wrap === 1) {\n    strm.adler = adler32(strm.adler, buf, len, start);\n  }\n\n  else if (strm.state.wrap === 2) {\n    strm.adler = crc32(strm.adler, buf, len, start);\n  }\n\n  strm.next_in += len;\n  strm.total_in += len;\n\n  return len;\n}\n\n\n/* ===========================================================================\n * Set match_start to the longest match starting at the given string and\n * return its length. Matches shorter or equal to prev_length are discarded,\n * in which case the result is equal to prev_length and match_start is\n * garbage.\n * IN assertions: cur_match is the head of the hash chain for the current\n *   string (strstart) and its distance is <= MAX_DIST, and prev_length >= 1\n * OUT assertion: the match length is not greater than s->lookahead.\n */\nfunction longest_match(s, cur_match) {\n  var chain_length = s.max_chain_length;      /* max hash chain length */\n  var scan = s.strstart; /* current string */\n  var match;                       /* matched string */\n  var len;                           /* length of current match */\n  var best_len = s.prev_length;              /* best match length so far */\n  var nice_match = s.nice_match;             /* stop if match long enough */\n  var limit = (s.strstart > (s.w_size - MIN_LOOKAHEAD)) ?\n      s.strstart - (s.w_size - MIN_LOOKAHEAD) : 0/*NIL*/;\n\n  var _win = s.window; // shortcut\n\n  var wmask = s.w_mask;\n  var prev  = s.prev;\n\n  /* Stop when cur_match becomes <= limit. To simplify the code,\n   * we prevent matches with the string of window index 0.\n   */\n\n  var strend = s.strstart + MAX_MATCH;\n  var scan_end1  = _win[scan + best_len - 1];\n  var scan_end   = _win[scan + best_len];\n\n  /* The code is optimized for HASH_BITS >= 8 and MAX_MATCH-2 multiple of 16.\n   * It is easy to get rid of this optimization if necessary.\n   */\n  // Assert(s->hash_bits >= 8 && MAX_MATCH == 258, \"Code too clever\");\n\n  /* Do not waste too much time if we already have a good match: */\n  if (s.prev_length >= s.good_match) {\n    chain_length >>= 2;\n  }\n  /* Do not look for matches beyond the end of the input. This is necessary\n   * to make deflate deterministic.\n   */\n  if (nice_match > s.lookahead) { nice_match = s.lookahead; }\n\n  // Assert((ulg)s->strstart <= s->window_size-MIN_LOOKAHEAD, \"need lookahead\");\n\n  do {\n    // Assert(cur_match < s->strstart, \"no future\");\n    match = cur_match;\n\n    /* Skip to next match if the match length cannot increase\n     * or if the match length is less than 2.  Note that the checks below\n     * for insufficient lookahead only occur occasionally for performance\n     * reasons.  Therefore uninitialized memory will be accessed, and\n     * conditional jumps will be made that depend on those values.\n     * However the length of the match is limited to the lookahead, so\n     * the output of deflate is not affected by the uninitialized values.\n     */\n\n    if (_win[match + best_len]     !== scan_end  ||\n        _win[match + best_len - 1] !== scan_end1 ||\n        _win[match]                !== _win[scan] ||\n        _win[++match]              !== _win[scan + 1]) {\n      continue;\n    }\n\n    /* The check at best_len-1 can be removed because it will be made\n     * again later. (This heuristic is not always a win.)\n     * It is not necessary to compare scan[2] and match[2] since they\n     * are always equal when the other bytes match, given that\n     * the hash keys are equal and that HASH_BITS >= 8.\n     */\n    scan += 2;\n    match++;\n    // Assert(*scan == *match, \"match[2]?\");\n\n    /* We check for insufficient lookahead only every 8th comparison;\n     * the 256th check will be made at strstart+258.\n     */\n    do {\n      /*jshint noempty:false*/\n    } while (_win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             scan < strend);\n\n    // Assert(scan <= s->window+(unsigned)(s->window_size-1), \"wild scan\");\n\n    len = MAX_MATCH - (strend - scan);\n    scan = strend - MAX_MATCH;\n\n    if (len > best_len) {\n      s.match_start = cur_match;\n      best_len = len;\n      if (len >= nice_match) {\n        break;\n      }\n      scan_end1  = _win[scan + best_len - 1];\n      scan_end   = _win[scan + best_len];\n    }\n  } while ((cur_match = prev[cur_match & wmask]) > limit && --chain_length !== 0);\n\n  if (best_len <= s.lookahead) {\n    return best_len;\n  }\n  return s.lookahead;\n}\n\n\n/* ===========================================================================\n * Fill the window when the lookahead becomes insufficient.\n * Updates strstart and lookahead.\n *\n * IN assertion: lookahead < MIN_LOOKAHEAD\n * OUT assertions: strstart <= window_size-MIN_LOOKAHEAD\n *    At least one byte has been read, or avail_in == 0; reads are\n *    performed for at least two bytes (required for the zip translate_eol\n *    option -- not supported here).\n */\nfunction fill_window(s) {\n  var _w_size = s.w_size;\n  var p, n, m, more, str;\n\n  //Assert(s->lookahead < MIN_LOOKAHEAD, \"already enough lookahead\");\n\n  do {\n    more = s.window_size - s.lookahead - s.strstart;\n\n    // JS ints have 32 bit, block below not needed\n    /* Deal with !@#$% 64K limit: */\n    //if (sizeof(int) <= 2) {\n    //    if (more == 0 && s->strstart == 0 && s->lookahead == 0) {\n    //        more = wsize;\n    //\n    //  } else if (more == (unsigned)(-1)) {\n    //        /* Very unlikely, but possible on 16 bit machine if\n    //         * strstart == 0 && lookahead == 1 (input done a byte at time)\n    //         */\n    //        more--;\n    //    }\n    //}\n\n\n    /* If the window is almost full and there is insufficient lookahead,\n     * move the upper half to the lower one to make room in the upper half.\n     */\n    if (s.strstart >= _w_size + (_w_size - MIN_LOOKAHEAD)) {\n\n      utils.arraySet(s.window, s.window, _w_size, _w_size, 0);\n      s.match_start -= _w_size;\n      s.strstart -= _w_size;\n      /* we now have strstart >= MAX_DIST */\n      s.block_start -= _w_size;\n\n      /* Slide the hash table (could be avoided with 32 bit values\n       at the expense of memory usage). We slide even when level == 0\n       to keep the hash table consistent if we switch back to level > 0\n       later. (Using level 0 permanently is not an optimal usage of\n       zlib, so we don't care about this pathological case.)\n       */\n\n      n = s.hash_size;\n      p = n;\n      do {\n        m = s.head[--p];\n        s.head[p] = (m >= _w_size ? m - _w_size : 0);\n      } while (--n);\n\n      n = _w_size;\n      p = n;\n      do {\n        m = s.prev[--p];\n        s.prev[p] = (m >= _w_size ? m - _w_size : 0);\n        /* If n is not on any hash chain, prev[n] is garbage but\n         * its value will never be used.\n         */\n      } while (--n);\n\n      more += _w_size;\n    }\n    if (s.strm.avail_in === 0) {\n      break;\n    }\n\n    /* If there was no sliding:\n     *    strstart <= WSIZE+MAX_DIST-1 && lookahead <= MIN_LOOKAHEAD - 1 &&\n     *    more == window_size - lookahead - strstart\n     * => more >= window_size - (MIN_LOOKAHEAD-1 + WSIZE + MAX_DIST-1)\n     * => more >= window_size - 2*WSIZE + 2\n     * In the BIG_MEM or MMAP case (not yet supported),\n     *   window_size == input_size + MIN_LOOKAHEAD  &&\n     *   strstart + s->lookahead <= input_size => more >= MIN_LOOKAHEAD.\n     * Otherwise, window_size == 2*WSIZE so more >= 2.\n     * If there was sliding, more >= WSIZE. So in all cases, more >= 2.\n     */\n    //Assert(more >= 2, \"more < 2\");\n    n = read_buf(s.strm, s.window, s.strstart + s.lookahead, more);\n    s.lookahead += n;\n\n    /* Initialize the hash value now that we have some input: */\n    if (s.lookahead + s.insert >= MIN_MATCH) {\n      str = s.strstart - s.insert;\n      s.ins_h = s.window[str];\n\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + 1]); */\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + 1]) & s.hash_mask;\n//#if MIN_MATCH != 3\n//        Call update_hash() MIN_MATCH-3 more times\n//#endif\n      while (s.insert) {\n        /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;\n\n        s.prev[str & s.w_mask] = s.head[s.ins_h];\n        s.head[s.ins_h] = str;\n        str++;\n        s.insert--;\n        if (s.lookahead + s.insert < MIN_MATCH) {\n          break;\n        }\n      }\n    }\n    /* If the whole input has less than MIN_MATCH bytes, ins_h is garbage,\n     * but this is not important since only literal bytes will be emitted.\n     */\n\n  } while (s.lookahead < MIN_LOOKAHEAD && s.strm.avail_in !== 0);\n\n  /* If the WIN_INIT bytes after the end of the current data have never been\n   * written, then zero those bytes in order to avoid memory check reports of\n   * the use of uninitialized (or uninitialised as Julian writes) bytes by\n   * the longest match routines.  Update the high water mark for the next\n   * time through here.  WIN_INIT is set to MAX_MATCH since the longest match\n   * routines allow scanning to strstart + MAX_MATCH, ignoring lookahead.\n   */\n//  if (s.high_water < s.window_size) {\n//    var curr = s.strstart + s.lookahead;\n//    var init = 0;\n//\n//    if (s.high_water < curr) {\n//      /* Previous high water mark below current data -- zero WIN_INIT\n//       * bytes or up to end of window, whichever is less.\n//       */\n//      init = s.window_size - curr;\n//      if (init > WIN_INIT)\n//        init = WIN_INIT;\n//      zmemzero(s->window + curr, (unsigned)init);\n//      s->high_water = curr + init;\n//    }\n//    else if (s->high_water < (ulg)curr + WIN_INIT) {\n//      /* High water mark at or above current data, but below current data\n//       * plus WIN_INIT -- zero out to current data plus WIN_INIT, or up\n//       * to end of window, whichever is less.\n//       */\n//      init = (ulg)curr + WIN_INIT - s->high_water;\n//      if (init > s->window_size - s->high_water)\n//        init = s->window_size - s->high_water;\n//      zmemzero(s->window + s->high_water, (unsigned)init);\n//      s->high_water += init;\n//    }\n//  }\n//\n//  Assert((ulg)s->strstart <= s->window_size - MIN_LOOKAHEAD,\n//    \"not enough room for search\");\n}\n\n/* ===========================================================================\n * Copy without compression as much as possible from the input stream, return\n * the current block state.\n * This function does not insert new strings in the dictionary since\n * uncompressible data is probably not useful. This function is used\n * only for the level=0 compression option.\n * NOTE: this function should be optimized to avoid extra copying from\n * window to pending_buf.\n */\nfunction deflate_stored(s, flush) {\n  /* Stored blocks are limited to 0xffff bytes, pending_buf is limited\n   * to pending_buf_size, and each stored block has a 5 byte header:\n   */\n  var max_block_size = 0xffff;\n\n  if (max_block_size > s.pending_buf_size - 5) {\n    max_block_size = s.pending_buf_size - 5;\n  }\n\n  /* Copy as much as possible from input to output: */\n  for (;;) {\n    /* Fill the window as much as possible: */\n    if (s.lookahead <= 1) {\n\n      //Assert(s->strstart < s->w_size+MAX_DIST(s) ||\n      //  s->block_start >= (long)s->w_size, \"slide too late\");\n//      if (!(s.strstart < s.w_size + (s.w_size - MIN_LOOKAHEAD) ||\n//        s.block_start >= s.w_size)) {\n//        throw  new Error(\"slide too late\");\n//      }\n\n      fill_window(s);\n      if (s.lookahead === 0 && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n\n      if (s.lookahead === 0) {\n        break;\n      }\n      /* flush the current block */\n    }\n    //Assert(s->block_start >= 0L, \"block gone\");\n//    if (s.block_start < 0) throw new Error(\"block gone\");\n\n    s.strstart += s.lookahead;\n    s.lookahead = 0;\n\n    /* Emit a stored block if pending_buf will be full: */\n    var max_start = s.block_start + max_block_size;\n\n    if (s.strstart === 0 || s.strstart >= max_start) {\n      /* strstart == 0 is possible when wraparound on 16-bit machine */\n      s.lookahead = s.strstart - max_start;\n      s.strstart = max_start;\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n\n\n    }\n    /* Flush if we may have to slide, otherwise block_start may become\n     * negative and the data will be gone:\n     */\n    if (s.strstart - s.block_start >= (s.w_size - MIN_LOOKAHEAD)) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n\n  s.insert = 0;\n\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n\n  if (s.strstart > s.block_start) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n\n  return BS_NEED_MORE;\n}\n\n/* ===========================================================================\n * Compress as much as possible from the input stream, return the current\n * block state.\n * This function does not perform lazy evaluation of matches and inserts\n * new strings in the dictionary only for unmatched strings or for short\n * matches. It is used only for the fast compression options.\n */\nfunction deflate_fast(s, flush) {\n  var hash_head;        /* head of the hash chain */\n  var bflush;           /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) {\n        break; /* flush the current block */\n      }\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     * At this point we have always match_length < MIN_MATCH\n     */\n    if (hash_head !== 0/*NIL*/ && ((s.strstart - hash_head) <= (s.w_size - MIN_LOOKAHEAD))) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n    }\n    if (s.match_length >= MIN_MATCH) {\n      // check_match(s, s.strstart, s.match_start, s.match_length); // for debug only\n\n      /*** _tr_tally_dist(s, s.strstart - s.match_start,\n                     s.match_length - MIN_MATCH, bflush); ***/\n      bflush = trees._tr_tally(s, s.strstart - s.match_start, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n\n      /* Insert new strings in the hash table only if the match length\n       * is not too large. This saves time but degrades compression.\n       */\n      if (s.match_length <= s.max_lazy_match/*max_insert_length*/ && s.lookahead >= MIN_MATCH) {\n        s.match_length--; /* string at strstart already in table */\n        do {\n          s.strstart++;\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n          /* strstart never exceeds WSIZE-MAX_MATCH, so there are\n           * always MIN_MATCH bytes ahead.\n           */\n        } while (--s.match_length !== 0);\n        s.strstart++;\n      } else\n      {\n        s.strstart += s.match_length;\n        s.match_length = 0;\n        s.ins_h = s.window[s.strstart];\n        /* UPDATE_HASH(s, s.ins_h, s.window[s.strstart+1]); */\n        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + 1]) & s.hash_mask;\n\n//#if MIN_MATCH != 3\n//                Call UPDATE_HASH() MIN_MATCH-3 more times\n//#endif\n        /* If lookahead < MIN_MATCH, ins_h is garbage, but it does not\n         * matter since it will be recomputed at next deflate call.\n         */\n      }\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s.window[s.strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = ((s.strstart < (MIN_MATCH - 1)) ? s.strstart : MIN_MATCH - 1);\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n}\n\n/* ===========================================================================\n * Same as above, but achieves better compression. We use a lazy\n * evaluation for matches: a match is finally adopted only if there is\n * no better match at the next window position.\n */\nfunction deflate_slow(s, flush) {\n  var hash_head;          /* head of hash chain */\n  var bflush;              /* set if current block must be flushed */\n\n  var max_insert;\n\n  /* Process the input block. */\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     */\n    s.prev_length = s.match_length;\n    s.prev_match = s.match_start;\n    s.match_length = MIN_MATCH - 1;\n\n    if (hash_head !== 0/*NIL*/ && s.prev_length < s.max_lazy_match &&\n        s.strstart - hash_head <= (s.w_size - MIN_LOOKAHEAD)/*MAX_DIST(s)*/) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n\n      if (s.match_length <= 5 &&\n         (s.strategy === Z_FILTERED || (s.match_length === MIN_MATCH && s.strstart - s.match_start > 4096/*TOO_FAR*/))) {\n\n        /* If prev_match is also MIN_MATCH, match_start is garbage\n         * but we will ignore the current match anyway.\n         */\n        s.match_length = MIN_MATCH - 1;\n      }\n    }\n    /* If there was a match at the previous step and the current\n     * match is not better, output the previous match:\n     */\n    if (s.prev_length >= MIN_MATCH && s.match_length <= s.prev_length) {\n      max_insert = s.strstart + s.lookahead - MIN_MATCH;\n      /* Do not insert strings in hash table beyond this. */\n\n      //check_match(s, s.strstart-1, s.prev_match, s.prev_length);\n\n      /***_tr_tally_dist(s, s.strstart - 1 - s.prev_match,\n                     s.prev_length - MIN_MATCH, bflush);***/\n      bflush = trees._tr_tally(s, s.strstart - 1 - s.prev_match, s.prev_length - MIN_MATCH);\n      /* Insert in hash table all strings up to the end of the match.\n       * strstart-1 and strstart are already inserted. If there is not\n       * enough lookahead, the last two strings are not inserted in\n       * the hash table.\n       */\n      s.lookahead -= s.prev_length - 1;\n      s.prev_length -= 2;\n      do {\n        if (++s.strstart <= max_insert) {\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n        }\n      } while (--s.prev_length !== 0);\n      s.match_available = 0;\n      s.match_length = MIN_MATCH - 1;\n      s.strstart++;\n\n      if (bflush) {\n        /*** FLUSH_BLOCK(s, 0); ***/\n        flush_block_only(s, false);\n        if (s.strm.avail_out === 0) {\n          return BS_NEED_MORE;\n        }\n        /***/\n      }\n\n    } else if (s.match_available) {\n      /* If there was no match at the previous position, output a\n       * single literal. If there was a match but the current match\n       * is longer, truncate the previous match to a single literal.\n       */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n      /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n      bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);\n\n      if (bflush) {\n        /*** FLUSH_BLOCK_ONLY(s, 0) ***/\n        flush_block_only(s, false);\n        /***/\n      }\n      s.strstart++;\n      s.lookahead--;\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n    } else {\n      /* There is no previous match to compare with, wait for\n       * the next step to decide.\n       */\n      s.match_available = 1;\n      s.strstart++;\n      s.lookahead--;\n    }\n  }\n  //Assert (flush != Z_NO_FLUSH, \"no flush?\");\n  if (s.match_available) {\n    //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n    /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n    bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);\n\n    s.match_available = 0;\n  }\n  s.insert = s.strstart < MIN_MATCH - 1 ? s.strstart : MIN_MATCH - 1;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n\n  return BS_BLOCK_DONE;\n}\n\n\n/* ===========================================================================\n * For Z_RLE, simply look for runs of bytes, generate matches only of distance\n * one.  Do not maintain a hash table.  (It will be regenerated if this run of\n * deflate switches away from Z_RLE.)\n */\nfunction deflate_rle(s, flush) {\n  var bflush;            /* set if current block must be flushed */\n  var prev;              /* byte at distance one to match */\n  var scan, strend;      /* scan goes up to strend for length of run */\n\n  var _win = s.window;\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the longest run, plus one for the unrolled loop.\n     */\n    if (s.lookahead <= MAX_MATCH) {\n      fill_window(s);\n      if (s.lookahead <= MAX_MATCH && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* See how many times the previous byte repeats */\n    s.match_length = 0;\n    if (s.lookahead >= MIN_MATCH && s.strstart > 0) {\n      scan = s.strstart - 1;\n      prev = _win[scan];\n      if (prev === _win[++scan] && prev === _win[++scan] && prev === _win[++scan]) {\n        strend = s.strstart + MAX_MATCH;\n        do {\n          /*jshint noempty:false*/\n        } while (prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 scan < strend);\n        s.match_length = MAX_MATCH - (strend - scan);\n        if (s.match_length > s.lookahead) {\n          s.match_length = s.lookahead;\n        }\n      }\n      //Assert(scan <= s->window+(uInt)(s->window_size-1), \"wild scan\");\n    }\n\n    /* Emit match if have run of MIN_MATCH or longer, else emit literal */\n    if (s.match_length >= MIN_MATCH) {\n      //check_match(s, s.strstart, s.strstart - 1, s.match_length);\n\n      /*** _tr_tally_dist(s, 1, s.match_length - MIN_MATCH, bflush); ***/\n      bflush = trees._tr_tally(s, 1, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n      s.strstart += s.match_length;\n      s.match_length = 0;\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n}\n\n/* ===========================================================================\n * For Z_HUFFMAN_ONLY, do not look for matches.  Do not maintain a hash table.\n * (It will be regenerated if this run of deflate switches away from Huffman.)\n */\nfunction deflate_huff(s, flush) {\n  var bflush;             /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we have a literal to write. */\n    if (s.lookahead === 0) {\n      fill_window(s);\n      if (s.lookahead === 0) {\n        if (flush === Z_NO_FLUSH) {\n          return BS_NEED_MORE;\n        }\n        break;      /* flush the current block */\n      }\n    }\n\n    /* Output a literal byte */\n    s.match_length = 0;\n    //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n    /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n    bflush = trees._tr_tally(s, 0, s.window[s.strstart]);\n    s.lookahead--;\n    s.strstart++;\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n}\n\n/* Values for max_lazy_match, good_match and max_chain_length, depending on\n * the desired pack level (0..9). The values given below have been tuned to\n * exclude worst case performance for pathological files. Better values may be\n * found for specific files.\n */\nfunction Config(good_length, max_lazy, nice_length, max_chain, func) {\n  this.good_length = good_length;\n  this.max_lazy = max_lazy;\n  this.nice_length = nice_length;\n  this.max_chain = max_chain;\n  this.func = func;\n}\n\nvar configuration_table;\n\nconfiguration_table = [\n  /*      good lazy nice chain */\n  new Config(0, 0, 0, 0, deflate_stored),          /* 0 store only */\n  new Config(4, 4, 8, 4, deflate_fast),            /* 1 max speed, no lazy matches */\n  new Config(4, 5, 16, 8, deflate_fast),           /* 2 */\n  new Config(4, 6, 32, 32, deflate_fast),          /* 3 */\n\n  new Config(4, 4, 16, 16, deflate_slow),          /* 4 lazy matches */\n  new Config(8, 16, 32, 32, deflate_slow),         /* 5 */\n  new Config(8, 16, 128, 128, deflate_slow),       /* 6 */\n  new Config(8, 32, 128, 256, deflate_slow),       /* 7 */\n  new Config(32, 128, 258, 1024, deflate_slow),    /* 8 */\n  new Config(32, 258, 258, 4096, deflate_slow)     /* 9 max compression */\n];\n\n\n/* ===========================================================================\n * Initialize the \"longest match\" routines for a new zlib stream\n */\nfunction lm_init(s) {\n  s.window_size = 2 * s.w_size;\n\n  /*** CLEAR_HASH(s); ***/\n  zero(s.head); // Fill with NIL (= 0);\n\n  /* Set the default configuration parameters:\n   */\n  s.max_lazy_match = configuration_table[s.level].max_lazy;\n  s.good_match = configuration_table[s.level].good_length;\n  s.nice_match = configuration_table[s.level].nice_length;\n  s.max_chain_length = configuration_table[s.level].max_chain;\n\n  s.strstart = 0;\n  s.block_start = 0;\n  s.lookahead = 0;\n  s.insert = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  s.ins_h = 0;\n}\n\n\nfunction DeflateState() {\n  this.strm = null;            /* pointer back to this zlib stream */\n  this.status = 0;            /* as the name implies */\n  this.pending_buf = null;      /* output still pending */\n  this.pending_buf_size = 0;  /* size of pending_buf */\n  this.pending_out = 0;       /* next pending byte to output to the stream */\n  this.pending = 0;           /* nb of bytes in the pending buffer */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */\n  this.gzhead = null;         /* gzip header information to write */\n  this.gzindex = 0;           /* where in extra, name, or comment */\n  this.method = Z_DEFLATED; /* can only be DEFLATED */\n  this.last_flush = -1;   /* value of flush param for previous deflate call */\n\n  this.w_size = 0;  /* LZ77 window size (32K by default) */\n  this.w_bits = 0;  /* log2(w_size)  (8..16) */\n  this.w_mask = 0;  /* w_size - 1 */\n\n  this.window = null;\n  /* Sliding window. Input bytes are read into the second half of the window,\n   * and move to the first half later to keep a dictionary of at least wSize\n   * bytes. With this organization, matches are limited to a distance of\n   * wSize-MAX_MATCH bytes, but this ensures that IO is always\n   * performed with a length multiple of the block size.\n   */\n\n  this.window_size = 0;\n  /* Actual size of window: 2*wSize, except when the user input buffer\n   * is directly used as sliding window.\n   */\n\n  this.prev = null;\n  /* Link to older string with same hash index. To limit the size of this\n   * array to 64K, this link is maintained only for the last 32K strings.\n   * An index in this array is thus a window index modulo 32K.\n   */\n\n  this.head = null;   /* Heads of the hash chains or NIL. */\n\n  this.ins_h = 0;       /* hash index of string to be inserted */\n  this.hash_size = 0;   /* number of elements in hash table */\n  this.hash_bits = 0;   /* log2(hash_size) */\n  this.hash_mask = 0;   /* hash_size-1 */\n\n  this.hash_shift = 0;\n  /* Number of bits by which ins_h must be shifted at each input\n   * step. It must be such that after MIN_MATCH steps, the oldest\n   * byte no longer takes part in the hash key, that is:\n   *   hash_shift * MIN_MATCH >= hash_bits\n   */\n\n  this.block_start = 0;\n  /* Window position at the beginning of the current output block. Gets\n   * negative when the window is moved backwards.\n   */\n\n  this.match_length = 0;      /* length of best match */\n  this.prev_match = 0;        /* previous match */\n  this.match_available = 0;   /* set if previous match exists */\n  this.strstart = 0;          /* start of string to insert */\n  this.match_start = 0;       /* start of matching string */\n  this.lookahead = 0;         /* number of valid bytes ahead in window */\n\n  this.prev_length = 0;\n  /* Length of the best match at previous step. Matches not greater than this\n   * are discarded. This is used in the lazy match evaluation.\n   */\n\n  this.max_chain_length = 0;\n  /* To speed up deflation, hash chains are never searched beyond this\n   * length.  A higher limit improves compression ratio but degrades the\n   * speed.\n   */\n\n  this.max_lazy_match = 0;\n  /* Attempt to find a better match only when the current match is strictly\n   * smaller than this value. This mechanism is used only for compression\n   * levels >= 4.\n   */\n  // That's alias to max_lazy_match, don't use directly\n  //this.max_insert_length = 0;\n  /* Insert new strings in the hash table only if the match length is not\n   * greater than this length. This saves time but degrades compression.\n   * max_insert_length is used only for compression levels <= 3.\n   */\n\n  this.level = 0;     /* compression level (1..9) */\n  this.strategy = 0;  /* favor or force Huffman coding*/\n\n  this.good_match = 0;\n  /* Use a faster search when the previous match is longer than this */\n\n  this.nice_match = 0; /* Stop searching when current match exceeds this */\n\n              /* used by trees.c: */\n\n  /* Didn't use ct_data typedef below to suppress compiler warning */\n\n  // struct ct_data_s dyn_ltree[HEAP_SIZE];   /* literal and length tree */\n  // struct ct_data_s dyn_dtree[2*D_CODES+1]; /* distance tree */\n  // struct ct_data_s bl_tree[2*BL_CODES+1];  /* Huffman tree for bit lengths */\n\n  // Use flat array of DOUBLE size, with interleaved fata,\n  // because JS does not support effective\n  this.dyn_ltree  = new utils.Buf16(HEAP_SIZE * 2);\n  this.dyn_dtree  = new utils.Buf16((2 * D_CODES + 1) * 2);\n  this.bl_tree    = new utils.Buf16((2 * BL_CODES + 1) * 2);\n  zero(this.dyn_ltree);\n  zero(this.dyn_dtree);\n  zero(this.bl_tree);\n\n  this.l_desc   = null;         /* desc. for literal tree */\n  this.d_desc   = null;         /* desc. for distance tree */\n  this.bl_desc  = null;         /* desc. for bit length tree */\n\n  //ush bl_count[MAX_BITS+1];\n  this.bl_count = new utils.Buf16(MAX_BITS + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  //int heap[2*L_CODES+1];      /* heap used to build the Huffman trees */\n  this.heap = new utils.Buf16(2 * L_CODES + 1);  /* heap used to build the Huffman trees */\n  zero(this.heap);\n\n  this.heap_len = 0;               /* number of elements in the heap */\n  this.heap_max = 0;               /* element of largest frequency */\n  /* The sons of heap[n] are heap[2*n] and heap[2*n+1]. heap[0] is not used.\n   * The same heap array is used to build all trees.\n   */\n\n  this.depth = new utils.Buf16(2 * L_CODES + 1); //uch depth[2*L_CODES+1];\n  zero(this.depth);\n  /* Depth of each subtree used as tie breaker for trees of equal frequency\n   */\n\n  this.l_buf = 0;          /* buffer index for literals or lengths */\n\n  this.lit_bufsize = 0;\n  /* Size of match buffer for literals/lengths.  There are 4 reasons for\n   * limiting lit_bufsize to 64K:\n   *   - frequencies can be kept in 16 bit counters\n   *   - if compression is not successful for the first block, all input\n   *     data is still in the window so we can still emit a stored block even\n   *     when input comes from standard input.  (This can also be done for\n   *     all blocks if lit_bufsize is not greater than 32K.)\n   *   - if compression is not successful for a file smaller than 64K, we can\n   *     even emit a stored file instead of a stored block (saving 5 bytes).\n   *     This is applicable only for zip (not gzip or zlib).\n   *   - creating new Huffman trees less frequently may not provide fast\n   *     adaptation to changes in the input data statistics. (Take for\n   *     example a binary file with poorly compressible code followed by\n   *     a highly compressible string table.) Smaller buffer sizes give\n   *     fast adaptation but have of course the overhead of transmitting\n   *     trees more frequently.\n   *   - I can't count above 4\n   */\n\n  this.last_lit = 0;      /* running index in l_buf */\n\n  this.d_buf = 0;\n  /* Buffer index for distances. To simplify the code, d_buf and l_buf have\n   * the same number of elements. To use different lengths, an extra flag\n   * array would be necessary.\n   */\n\n  this.opt_len = 0;       /* bit length of current block with optimal trees */\n  this.static_len = 0;    /* bit length of current block with static trees */\n  this.matches = 0;       /* number of string matches in current block */\n  this.insert = 0;        /* bytes at end of window left to insert */\n\n\n  this.bi_buf = 0;\n  /* Output buffer. bits are inserted starting at the bottom (least\n   * significant bits).\n   */\n  this.bi_valid = 0;\n  /* Number of valid bits in bi_buf.  All bits above the last valid bit\n   * are always zero.\n   */\n\n  // Used for window memory init. We safely ignore it for JS. That makes\n  // sense only for pointers and memory check tools.\n  //this.high_water = 0;\n  /* High water mark offset in window for initialized bytes -- bytes above\n   * this are set to zero in order to avoid memory check warnings when\n   * longest match routines access bytes past the input.  This is then\n   * updated to the new high water mark.\n   */\n}\n\n\nfunction deflateResetKeep(strm) {\n  var s;\n\n  if (!strm || !strm.state) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n  strm.total_in = strm.total_out = 0;\n  strm.data_type = Z_UNKNOWN;\n\n  s = strm.state;\n  s.pending = 0;\n  s.pending_out = 0;\n\n  if (s.wrap < 0) {\n    s.wrap = -s.wrap;\n    /* was made negative by deflate(..., Z_FINISH); */\n  }\n  s.status = (s.wrap ? INIT_STATE : BUSY_STATE);\n  strm.adler = (s.wrap === 2) ?\n    0  // crc32(0, Z_NULL, 0)\n  :\n    1; // adler32(0, Z_NULL, 0)\n  s.last_flush = Z_NO_FLUSH;\n  trees._tr_init(s);\n  return Z_OK;\n}\n\n\nfunction deflateReset(strm) {\n  var ret = deflateResetKeep(strm);\n  if (ret === Z_OK) {\n    lm_init(strm.state);\n  }\n  return ret;\n}\n\n\nfunction deflateSetHeader(strm, head) {\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  if (strm.state.wrap !== 2) { return Z_STREAM_ERROR; }\n  strm.state.gzhead = head;\n  return Z_OK;\n}\n\n\nfunction deflateInit2(strm, level, method, windowBits, memLevel, strategy) {\n  if (!strm) { // === Z_NULL\n    return Z_STREAM_ERROR;\n  }\n  var wrap = 1;\n\n  if (level === Z_DEFAULT_COMPRESSION) {\n    level = 6;\n  }\n\n  if (windowBits < 0) { /* suppress zlib wrapper */\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n\n  else if (windowBits > 15) {\n    wrap = 2;           /* write gzip wrapper instead */\n    windowBits -= 16;\n  }\n\n\n  if (memLevel < 1 || memLevel > MAX_MEM_LEVEL || method !== Z_DEFLATED ||\n    windowBits < 8 || windowBits > 15 || level < 0 || level > 9 ||\n    strategy < 0 || strategy > Z_FIXED) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n\n  if (windowBits === 8) {\n    windowBits = 9;\n  }\n  /* until 256-byte window bug fixed */\n\n  var s = new DeflateState();\n\n  strm.state = s;\n  s.strm = strm;\n\n  s.wrap = wrap;\n  s.gzhead = null;\n  s.w_bits = windowBits;\n  s.w_size = 1 << s.w_bits;\n  s.w_mask = s.w_size - 1;\n\n  s.hash_bits = memLevel + 7;\n  s.hash_size = 1 << s.hash_bits;\n  s.hash_mask = s.hash_size - 1;\n  s.hash_shift = ~~((s.hash_bits + MIN_MATCH - 1) / MIN_MATCH);\n\n  s.window = new utils.Buf8(s.w_size * 2);\n  s.head = new utils.Buf16(s.hash_size);\n  s.prev = new utils.Buf16(s.w_size);\n\n  // Don't need mem init magic for JS.\n  //s.high_water = 0;  /* nothing written to s->window yet */\n\n  s.lit_bufsize = 1 << (memLevel + 6); /* 16K elements by default */\n\n  s.pending_buf_size = s.lit_bufsize * 4;\n\n  //overlay = (ushf *) ZALLOC(strm, s->lit_bufsize, sizeof(ush)+2);\n  //s->pending_buf = (uchf *) overlay;\n  s.pending_buf = new utils.Buf8(s.pending_buf_size);\n\n  // It is offset from `s.pending_buf` (size is `s.lit_bufsize * 2`)\n  //s->d_buf = overlay + s->lit_bufsize/sizeof(ush);\n  s.d_buf = 1 * s.lit_bufsize;\n\n  //s->l_buf = s->pending_buf + (1+sizeof(ush))*s->lit_bufsize;\n  s.l_buf = (1 + 2) * s.lit_bufsize;\n\n  s.level = level;\n  s.strategy = strategy;\n  s.method = method;\n\n  return deflateReset(strm);\n}\n\nfunction deflateInit(strm, level) {\n  return deflateInit2(strm, level, Z_DEFLATED, MAX_WBITS, DEF_MEM_LEVEL, Z_DEFAULT_STRATEGY);\n}\n\n\nfunction deflate(strm, flush) {\n  var old_flush, s;\n  var beg, val; // for gzip header write only\n\n  if (!strm || !strm.state ||\n    flush > Z_BLOCK || flush < 0) {\n    return strm ? err(strm, Z_STREAM_ERROR) : Z_STREAM_ERROR;\n  }\n\n  s = strm.state;\n\n  if (!strm.output ||\n      (!strm.input && strm.avail_in !== 0) ||\n      (s.status === FINISH_STATE && flush !== Z_FINISH)) {\n    return err(strm, (strm.avail_out === 0) ? Z_BUF_ERROR : Z_STREAM_ERROR);\n  }\n\n  s.strm = strm; /* just in case */\n  old_flush = s.last_flush;\n  s.last_flush = flush;\n\n  /* Write the header */\n  if (s.status === INIT_STATE) {\n\n    if (s.wrap === 2) { // GZIP header\n      strm.adler = 0;  //crc32(0L, Z_NULL, 0);\n      put_byte(s, 31);\n      put_byte(s, 139);\n      put_byte(s, 8);\n      if (!s.gzhead) { // s->gzhead == Z_NULL\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, s.level === 9 ? 2 :\n                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                     4 : 0));\n        put_byte(s, OS_CODE);\n        s.status = BUSY_STATE;\n      }\n      else {\n        put_byte(s, (s.gzhead.text ? 1 : 0) +\n                    (s.gzhead.hcrc ? 2 : 0) +\n                    (!s.gzhead.extra ? 0 : 4) +\n                    (!s.gzhead.name ? 0 : 8) +\n                    (!s.gzhead.comment ? 0 : 16)\n        );\n        put_byte(s, s.gzhead.time & 0xff);\n        put_byte(s, (s.gzhead.time >> 8) & 0xff);\n        put_byte(s, (s.gzhead.time >> 16) & 0xff);\n        put_byte(s, (s.gzhead.time >> 24) & 0xff);\n        put_byte(s, s.level === 9 ? 2 :\n                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                     4 : 0));\n        put_byte(s, s.gzhead.os & 0xff);\n        if (s.gzhead.extra && s.gzhead.extra.length) {\n          put_byte(s, s.gzhead.extra.length & 0xff);\n          put_byte(s, (s.gzhead.extra.length >> 8) & 0xff);\n        }\n        if (s.gzhead.hcrc) {\n          strm.adler = crc32(strm.adler, s.pending_buf, s.pending, 0);\n        }\n        s.gzindex = 0;\n        s.status = EXTRA_STATE;\n      }\n    }\n    else // DEFLATE header\n    {\n      var header = (Z_DEFLATED + ((s.w_bits - 8) << 4)) << 8;\n      var level_flags = -1;\n\n      if (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2) {\n        level_flags = 0;\n      } else if (s.level < 6) {\n        level_flags = 1;\n      } else if (s.level === 6) {\n        level_flags = 2;\n      } else {\n        level_flags = 3;\n      }\n      header |= (level_flags << 6);\n      if (s.strstart !== 0) { header |= PRESET_DICT; }\n      header += 31 - (header % 31);\n\n      s.status = BUSY_STATE;\n      putShortMSB(s, header);\n\n      /* Save the adler32 of the preset dictionary: */\n      if (s.strstart !== 0) {\n        putShortMSB(s, strm.adler >>> 16);\n        putShortMSB(s, strm.adler & 0xffff);\n      }\n      strm.adler = 1; // adler32(0L, Z_NULL, 0);\n    }\n  }\n\n//#ifdef GZIP\n  if (s.status === EXTRA_STATE) {\n    if (s.gzhead.extra/* != Z_NULL*/) {\n      beg = s.pending;  /* start of bytes to update crc */\n\n      while (s.gzindex < (s.gzhead.extra.length & 0xffff)) {\n        if (s.pending === s.pending_buf_size) {\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          flush_pending(strm);\n          beg = s.pending;\n          if (s.pending === s.pending_buf_size) {\n            break;\n          }\n        }\n        put_byte(s, s.gzhead.extra[s.gzindex] & 0xff);\n        s.gzindex++;\n      }\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      if (s.gzindex === s.gzhead.extra.length) {\n        s.gzindex = 0;\n        s.status = NAME_STATE;\n      }\n    }\n    else {\n      s.status = NAME_STATE;\n    }\n  }\n  if (s.status === NAME_STATE) {\n    if (s.gzhead.name/* != Z_NULL*/) {\n      beg = s.pending;  /* start of bytes to update crc */\n      //int val;\n\n      do {\n        if (s.pending === s.pending_buf_size) {\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          flush_pending(strm);\n          beg = s.pending;\n          if (s.pending === s.pending_buf_size) {\n            val = 1;\n            break;\n          }\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.name.length) {\n          val = s.gzhead.name.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      if (val === 0) {\n        s.gzindex = 0;\n        s.status = COMMENT_STATE;\n      }\n    }\n    else {\n      s.status = COMMENT_STATE;\n    }\n  }\n  if (s.status === COMMENT_STATE) {\n    if (s.gzhead.comment/* != Z_NULL*/) {\n      beg = s.pending;  /* start of bytes to update crc */\n      //int val;\n\n      do {\n        if (s.pending === s.pending_buf_size) {\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          flush_pending(strm);\n          beg = s.pending;\n          if (s.pending === s.pending_buf_size) {\n            val = 1;\n            break;\n          }\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.comment.length) {\n          val = s.gzhead.comment.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      if (val === 0) {\n        s.status = HCRC_STATE;\n      }\n    }\n    else {\n      s.status = HCRC_STATE;\n    }\n  }\n  if (s.status === HCRC_STATE) {\n    if (s.gzhead.hcrc) {\n      if (s.pending + 2 > s.pending_buf_size) {\n        flush_pending(strm);\n      }\n      if (s.pending + 2 <= s.pending_buf_size) {\n        put_byte(s, strm.adler & 0xff);\n        put_byte(s, (strm.adler >> 8) & 0xff);\n        strm.adler = 0; //crc32(0L, Z_NULL, 0);\n        s.status = BUSY_STATE;\n      }\n    }\n    else {\n      s.status = BUSY_STATE;\n    }\n  }\n//#endif\n\n  /* Flush as much pending output as possible */\n  if (s.pending !== 0) {\n    flush_pending(strm);\n    if (strm.avail_out === 0) {\n      /* Since avail_out is 0, deflate will be called again with\n       * more output space, but possibly with both pending and\n       * avail_in equal to zero. There won't be anything to do,\n       * but this is not an error situation so make sure we\n       * return OK instead of BUF_ERROR at next call of deflate:\n       */\n      s.last_flush = -1;\n      return Z_OK;\n    }\n\n    /* Make sure there is something to do and avoid duplicate consecutive\n     * flushes. For repeated and useless calls with Z_FINISH, we keep\n     * returning Z_STREAM_END instead of Z_BUF_ERROR.\n     */\n  } else if (strm.avail_in === 0 && rank(flush) <= rank(old_flush) &&\n    flush !== Z_FINISH) {\n    return err(strm, Z_BUF_ERROR);\n  }\n\n  /* User must not provide more input after the first FINISH: */\n  if (s.status === FINISH_STATE && strm.avail_in !== 0) {\n    return err(strm, Z_BUF_ERROR);\n  }\n\n  /* Start a new block or continue the current one.\n   */\n  if (strm.avail_in !== 0 || s.lookahead !== 0 ||\n    (flush !== Z_NO_FLUSH && s.status !== FINISH_STATE)) {\n    var bstate = (s.strategy === Z_HUFFMAN_ONLY) ? deflate_huff(s, flush) :\n      (s.strategy === Z_RLE ? deflate_rle(s, flush) :\n        configuration_table[s.level].func(s, flush));\n\n    if (bstate === BS_FINISH_STARTED || bstate === BS_FINISH_DONE) {\n      s.status = FINISH_STATE;\n    }\n    if (bstate === BS_NEED_MORE || bstate === BS_FINISH_STARTED) {\n      if (strm.avail_out === 0) {\n        s.last_flush = -1;\n        /* avoid BUF_ERROR next call, see above */\n      }\n      return Z_OK;\n      /* If flush != Z_NO_FLUSH && avail_out == 0, the next call\n       * of deflate should use the same flush parameter to make sure\n       * that the flush is complete. So we don't have to output an\n       * empty block here, this will be done at next call. This also\n       * ensures that for a very small output buffer, we emit at most\n       * one empty block.\n       */\n    }\n    if (bstate === BS_BLOCK_DONE) {\n      if (flush === Z_PARTIAL_FLUSH) {\n        trees._tr_align(s);\n      }\n      else if (flush !== Z_BLOCK) { /* FULL_FLUSH or SYNC_FLUSH */\n\n        trees._tr_stored_block(s, 0, 0, false);\n        /* For a full flush, this empty block will be recognized\n         * as a special marker by inflate_sync().\n         */\n        if (flush === Z_FULL_FLUSH) {\n          /*** CLEAR_HASH(s); ***/             /* forget history */\n          zero(s.head); // Fill with NIL (= 0);\n\n          if (s.lookahead === 0) {\n            s.strstart = 0;\n            s.block_start = 0;\n            s.insert = 0;\n          }\n        }\n      }\n      flush_pending(strm);\n      if (strm.avail_out === 0) {\n        s.last_flush = -1; /* avoid BUF_ERROR at next call, see above */\n        return Z_OK;\n      }\n    }\n  }\n  //Assert(strm->avail_out > 0, \"bug2\");\n  //if (strm.avail_out <= 0) { throw new Error(\"bug2\");}\n\n  if (flush !== Z_FINISH) { return Z_OK; }\n  if (s.wrap <= 0) { return Z_STREAM_END; }\n\n  /* Write the trailer */\n  if (s.wrap === 2) {\n    put_byte(s, strm.adler & 0xff);\n    put_byte(s, (strm.adler >> 8) & 0xff);\n    put_byte(s, (strm.adler >> 16) & 0xff);\n    put_byte(s, (strm.adler >> 24) & 0xff);\n    put_byte(s, strm.total_in & 0xff);\n    put_byte(s, (strm.total_in >> 8) & 0xff);\n    put_byte(s, (strm.total_in >> 16) & 0xff);\n    put_byte(s, (strm.total_in >> 24) & 0xff);\n  }\n  else\n  {\n    putShortMSB(s, strm.adler >>> 16);\n    putShortMSB(s, strm.adler & 0xffff);\n  }\n\n  flush_pending(strm);\n  /* If avail_out is zero, the application will call deflate again\n   * to flush the rest.\n   */\n  if (s.wrap > 0) { s.wrap = -s.wrap; }\n  /* write the trailer only once! */\n  return s.pending !== 0 ? Z_OK : Z_STREAM_END;\n}\n\nfunction deflateEnd(strm) {\n  var status;\n\n  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  status = strm.state.status;\n  if (status !== INIT_STATE &&\n    status !== EXTRA_STATE &&\n    status !== NAME_STATE &&\n    status !== COMMENT_STATE &&\n    status !== HCRC_STATE &&\n    status !== BUSY_STATE &&\n    status !== FINISH_STATE\n  ) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n  strm.state = null;\n\n  return status === BUSY_STATE ? err(strm, Z_DATA_ERROR) : Z_OK;\n}\n\n\n/* =========================================================================\n * Initializes the compression dictionary from the given byte\n * sequence without producing any compressed output.\n */\nfunction deflateSetDictionary(strm, dictionary) {\n  var dictLength = dictionary.length;\n\n  var s;\n  var str, n;\n  var wrap;\n  var avail;\n  var next;\n  var input;\n  var tmpDict;\n\n  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  s = strm.state;\n  wrap = s.wrap;\n\n  if (wrap === 2 || (wrap === 1 && s.status !== INIT_STATE) || s.lookahead) {\n    return Z_STREAM_ERROR;\n  }\n\n  /* when using zlib wrappers, compute Adler-32 for provided dictionary */\n  if (wrap === 1) {\n    /* adler32(strm->adler, dictionary, dictLength); */\n    strm.adler = adler32(strm.adler, dictionary, dictLength, 0);\n  }\n\n  s.wrap = 0;   /* avoid computing Adler-32 in read_buf */\n\n  /* if dictionary would fill window, just replace the history */\n  if (dictLength >= s.w_size) {\n    if (wrap === 0) {            /* already empty otherwise */\n      /*** CLEAR_HASH(s); ***/\n      zero(s.head); // Fill with NIL (= 0);\n      s.strstart = 0;\n      s.block_start = 0;\n      s.insert = 0;\n    }\n    /* use the tail */\n    // dictionary = dictionary.slice(dictLength - s.w_size);\n    tmpDict = new utils.Buf8(s.w_size);\n    utils.arraySet(tmpDict, dictionary, dictLength - s.w_size, s.w_size, 0);\n    dictionary = tmpDict;\n    dictLength = s.w_size;\n  }\n  /* insert dictionary into window and hash */\n  avail = strm.avail_in;\n  next = strm.next_in;\n  input = strm.input;\n  strm.avail_in = dictLength;\n  strm.next_in = 0;\n  strm.input = dictionary;\n  fill_window(s);\n  while (s.lookahead >= MIN_MATCH) {\n    str = s.strstart;\n    n = s.lookahead - (MIN_MATCH - 1);\n    do {\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;\n\n      s.prev[str & s.w_mask] = s.head[s.ins_h];\n\n      s.head[s.ins_h] = str;\n      str++;\n    } while (--n);\n    s.strstart = str;\n    s.lookahead = MIN_MATCH - 1;\n    fill_window(s);\n  }\n  s.strstart += s.lookahead;\n  s.block_start = s.strstart;\n  s.insert = s.lookahead;\n  s.lookahead = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  strm.next_in = next;\n  strm.input = input;\n  strm.avail_in = avail;\n  s.wrap = wrap;\n  return Z_OK;\n}\n\n\nexports.deflateInit = deflateInit;\nexports.deflateInit2 = deflateInit2;\nexports.deflateReset = deflateReset;\nexports.deflateResetKeep = deflateResetKeep;\nexports.deflateSetHeader = deflateSetHeader;\nexports.deflate = deflate;\nexports.deflateEnd = deflateEnd;\nexports.deflateSetDictionary = deflateSetDictionary;\nexports.deflateInfo = 'pako deflate (from Nodeca project)';\n\n/* Not implemented\nexports.deflateBound = deflateBound;\nexports.deflateCopy = deflateCopy;\nexports.deflateParams = deflateParams;\nexports.deflatePending = deflatePending;\nexports.deflatePrime = deflatePrime;\nexports.deflateTune = deflateTune;\n*/\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/deflate.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/gzheader.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/zlib/gzheader.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction GZheader() {\n  /* true if compressed data believed to be text */\n  this.text       = 0;\n  /* modification time */\n  this.time       = 0;\n  /* extra flags (not used when writing a gzip file) */\n  this.xflags     = 0;\n  /* operating system */\n  this.os         = 0;\n  /* pointer to extra field or Z_NULL if none */\n  this.extra      = null;\n  /* extra field length (valid if extra != Z_NULL) */\n  this.extra_len  = 0; // Actually, we don't need it in JS,\n                       // but leave for few code modifications\n\n  //\n  // Setup limits is not necessary because in js we should not preallocate memory\n  // for inflate use constant limit in 65536 bytes\n  //\n\n  /* space at extra (only when reading header) */\n  // this.extra_max  = 0;\n  /* pointer to zero-terminated file name or Z_NULL */\n  this.name       = '';\n  /* space at name (only when reading header) */\n  // this.name_max   = 0;\n  /* pointer to zero-terminated comment or Z_NULL */\n  this.comment    = '';\n  /* space at comment (only when reading header) */\n  // this.comm_max   = 0;\n  /* true if there was or will be a header crc */\n  this.hcrc       = 0;\n  /* true when done reading gzip header (not used when writing a gzip file) */\n  this.done       = false;\n}\n\nmodule.exports = GZheader;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/gzheader.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/inffast.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/inffast.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// See state defs from inflate.js\nvar BAD = 30;       /* got a data error -- remain here until reset */\nvar TYPE = 12;      /* i: waiting for type bits, including last-flag bit */\n\n/*\n   Decode literal, length, and distance codes and write out the resulting\n   literal and match bytes until either not enough input or output is\n   available, an end-of-block is encountered, or a data error is encountered.\n   When large enough input and output buffers are supplied to inflate(), for\n   example, a 16K input buffer and a 64K output buffer, more than 95% of the\n   inflate execution time is spent in this routine.\n\n   Entry assumptions:\n\n        state.mode === LEN\n        strm.avail_in >= 6\n        strm.avail_out >= 258\n        start >= strm.avail_out\n        state.bits < 8\n\n   On return, state.mode is one of:\n\n        LEN -- ran out of enough output space or enough available input\n        TYPE -- reached end of block code, inflate() to interpret next block\n        BAD -- error in block data\n\n   Notes:\n\n    - The maximum input bits used by a length/distance pair is 15 bits for the\n      length code, 5 bits for the length extra, 15 bits for the distance code,\n      and 13 bits for the distance extra.  This totals 48 bits, or six bytes.\n      Therefore if strm.avail_in >= 6, then there is enough input to avoid\n      checking for available input while decoding.\n\n    - The maximum bytes that a single length/distance pair can output is 258\n      bytes, which is the maximum length that can be coded.  inflate_fast()\n      requires strm.avail_out >= 258 for each loop to avoid checking for\n      output space.\n */\nmodule.exports = function inflate_fast(strm, start) {\n  var state;\n  var _in;                    /* local strm.input */\n  var last;                   /* have enough input while in < last */\n  var _out;                   /* local strm.output */\n  var beg;                    /* inflate()'s initial strm.output */\n  var end;                    /* while out < end, enough space available */\n//#ifdef INFLATE_STRICT\n  var dmax;                   /* maximum distance from zlib header */\n//#endif\n  var wsize;                  /* window size or zero if not using window */\n  var whave;                  /* valid bytes in the window */\n  var wnext;                  /* window write index */\n  // Use `s_window` instead `window`, avoid conflict with instrumentation tools\n  var s_window;               /* allocated sliding window, if wsize != 0 */\n  var hold;                   /* local strm.hold */\n  var bits;                   /* local strm.bits */\n  var lcode;                  /* local strm.lencode */\n  var dcode;                  /* local strm.distcode */\n  var lmask;                  /* mask for first level of length codes */\n  var dmask;                  /* mask for first level of distance codes */\n  var here;                   /* retrieved table entry */\n  var op;                     /* code bits, operation, extra bits, or */\n                              /*  window position, window bytes to copy */\n  var len;                    /* match length, unused bytes */\n  var dist;                   /* match distance */\n  var from;                   /* where to copy match from */\n  var from_source;\n\n\n  var input, output; // JS specific, because we have no pointers\n\n  /* copy state to local variables */\n  state = strm.state;\n  //here = state.here;\n  _in = strm.next_in;\n  input = strm.input;\n  last = _in + (strm.avail_in - 5);\n  _out = strm.next_out;\n  output = strm.output;\n  beg = _out - (start - strm.avail_out);\n  end = _out + (strm.avail_out - 257);\n//#ifdef INFLATE_STRICT\n  dmax = state.dmax;\n//#endif\n  wsize = state.wsize;\n  whave = state.whave;\n  wnext = state.wnext;\n  s_window = state.window;\n  hold = state.hold;\n  bits = state.bits;\n  lcode = state.lencode;\n  dcode = state.distcode;\n  lmask = (1 << state.lenbits) - 1;\n  dmask = (1 << state.distbits) - 1;\n\n\n  /* decode literals and length/distances until end-of-block or not enough\n     input data or output space */\n\n  top:\n  do {\n    if (bits < 15) {\n      hold += input[_in++] << bits;\n      bits += 8;\n      hold += input[_in++] << bits;\n      bits += 8;\n    }\n\n    here = lcode[hold & lmask];\n\n    dolen:\n    for (;;) { // Goto emulation\n      op = here >>> 24/*here.bits*/;\n      hold >>>= op;\n      bits -= op;\n      op = (here >>> 16) & 0xff/*here.op*/;\n      if (op === 0) {                          /* literal */\n        //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n        //        \"inflate:         literal '%c'\\n\" :\n        //        \"inflate:         literal 0x%02x\\n\", here.val));\n        output[_out++] = here & 0xffff/*here.val*/;\n      }\n      else if (op & 16) {                     /* length base */\n        len = here & 0xffff/*here.val*/;\n        op &= 15;                           /* number of extra bits */\n        if (op) {\n          if (bits < op) {\n            hold += input[_in++] << bits;\n            bits += 8;\n          }\n          len += hold & ((1 << op) - 1);\n          hold >>>= op;\n          bits -= op;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", len));\n        if (bits < 15) {\n          hold += input[_in++] << bits;\n          bits += 8;\n          hold += input[_in++] << bits;\n          bits += 8;\n        }\n        here = dcode[hold & dmask];\n\n        dodist:\n        for (;;) { // goto emulation\n          op = here >>> 24/*here.bits*/;\n          hold >>>= op;\n          bits -= op;\n          op = (here >>> 16) & 0xff/*here.op*/;\n\n          if (op & 16) {                      /* distance base */\n            dist = here & 0xffff/*here.val*/;\n            op &= 15;                       /* number of extra bits */\n            if (bits < op) {\n              hold += input[_in++] << bits;\n              bits += 8;\n              if (bits < op) {\n                hold += input[_in++] << bits;\n                bits += 8;\n              }\n            }\n            dist += hold & ((1 << op) - 1);\n//#ifdef INFLATE_STRICT\n            if (dist > dmax) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break top;\n            }\n//#endif\n            hold >>>= op;\n            bits -= op;\n            //Tracevv((stderr, \"inflate:         distance %u\\n\", dist));\n            op = _out - beg;                /* max distance in output */\n            if (dist > op) {                /* see if copy from window */\n              op = dist - op;               /* distance back in window */\n              if (op > whave) {\n                if (state.sane) {\n                  strm.msg = 'invalid distance too far back';\n                  state.mode = BAD;\n                  break top;\n                }\n\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//                if (len <= op - whave) {\n//                  do {\n//                    output[_out++] = 0;\n//                  } while (--len);\n//                  continue top;\n//                }\n//                len -= op - whave;\n//                do {\n//                  output[_out++] = 0;\n//                } while (--op > whave);\n//                if (op === 0) {\n//                  from = _out - dist;\n//                  do {\n//                    output[_out++] = output[from++];\n//                  } while (--len);\n//                  continue top;\n//                }\n//#endif\n              }\n              from = 0; // window index\n              from_source = s_window;\n              if (wnext === 0) {           /* very common case */\n                from += wsize - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              else if (wnext < op) {      /* wrap around window */\n                from += wsize + wnext - op;\n                op -= wnext;\n                if (op < len) {         /* some from end of window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = 0;\n                  if (wnext < len) {  /* some from start of window */\n                    op = wnext;\n                    len -= op;\n                    do {\n                      output[_out++] = s_window[from++];\n                    } while (--op);\n                    from = _out - dist;      /* rest from output */\n                    from_source = output;\n                  }\n                }\n              }\n              else {                      /* contiguous in window */\n                from += wnext - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              while (len > 2) {\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                len -= 3;\n              }\n              if (len) {\n                output[_out++] = from_source[from++];\n                if (len > 1) {\n                  output[_out++] = from_source[from++];\n                }\n              }\n            }\n            else {\n              from = _out - dist;          /* copy direct from output */\n              do {                        /* minimum length is three */\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                len -= 3;\n              } while (len > 2);\n              if (len) {\n                output[_out++] = output[from++];\n                if (len > 1) {\n                  output[_out++] = output[from++];\n                }\n              }\n            }\n          }\n          else if ((op & 64) === 0) {          /* 2nd level distance code */\n            here = dcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n            continue dodist;\n          }\n          else {\n            strm.msg = 'invalid distance code';\n            state.mode = BAD;\n            break top;\n          }\n\n          break; // need to emulate goto via \"continue\"\n        }\n      }\n      else if ((op & 64) === 0) {              /* 2nd level length code */\n        here = lcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n        continue dolen;\n      }\n      else if (op & 32) {                     /* end-of-block */\n        //Tracevv((stderr, \"inflate:         end of block\\n\"));\n        state.mode = TYPE;\n        break top;\n      }\n      else {\n        strm.msg = 'invalid literal/length code';\n        state.mode = BAD;\n        break top;\n      }\n\n      break; // need to emulate goto via \"continue\"\n    }\n  } while (_in < last && _out < end);\n\n  /* return unused bytes (on entry, bits < 8, so in won't go too far back) */\n  len = bits >> 3;\n  _in -= len;\n  bits -= len << 3;\n  hold &= (1 << bits) - 1;\n\n  /* update state and return */\n  strm.next_in = _in;\n  strm.next_out = _out;\n  strm.avail_in = (_in < last ? 5 + (last - _in) : 5 - (_in - last));\n  strm.avail_out = (_out < end ? 257 + (end - _out) : 257 - (_out - end));\n  state.hold = hold;\n  state.bits = bits;\n  return;\n};\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/inffast.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/inflate.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/inflate.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils         = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar adler32       = __webpack_require__(/*! ./adler32 */ \"./node_modules/pako/lib/zlib/adler32.js\");\nvar crc32         = __webpack_require__(/*! ./crc32 */ \"./node_modules/pako/lib/zlib/crc32.js\");\nvar inflate_fast  = __webpack_require__(/*! ./inffast */ \"./node_modules/pako/lib/zlib/inffast.js\");\nvar inflate_table = __webpack_require__(/*! ./inftrees */ \"./node_modules/pako/lib/zlib/inftrees.js\");\n\nvar CODES = 0;\nvar LENS = 1;\nvar DISTS = 2;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n/* Allowed flush values; see deflate() and inflate() below for details */\n//var Z_NO_FLUSH      = 0;\n//var Z_PARTIAL_FLUSH = 1;\n//var Z_SYNC_FLUSH    = 2;\n//var Z_FULL_FLUSH    = 3;\nvar Z_FINISH        = 4;\nvar Z_BLOCK         = 5;\nvar Z_TREES         = 6;\n\n\n/* Return codes for the compression/decompression functions. Negative values\n * are errors, positive values are used for special but normal events.\n */\nvar Z_OK            = 0;\nvar Z_STREAM_END    = 1;\nvar Z_NEED_DICT     = 2;\n//var Z_ERRNO         = -1;\nvar Z_STREAM_ERROR  = -2;\nvar Z_DATA_ERROR    = -3;\nvar Z_MEM_ERROR     = -4;\nvar Z_BUF_ERROR     = -5;\n//var Z_VERSION_ERROR = -6;\n\n/* The deflate compression method */\nvar Z_DEFLATED  = 8;\n\n\n/* STATES ====================================================================*/\n/* ===========================================================================*/\n\n\nvar    HEAD = 1;       /* i: waiting for magic header */\nvar    FLAGS = 2;      /* i: waiting for method and flags (gzip) */\nvar    TIME = 3;       /* i: waiting for modification time (gzip) */\nvar    OS = 4;         /* i: waiting for extra flags and operating system (gzip) */\nvar    EXLEN = 5;      /* i: waiting for extra length (gzip) */\nvar    EXTRA = 6;      /* i: waiting for extra bytes (gzip) */\nvar    NAME = 7;       /* i: waiting for end of file name (gzip) */\nvar    COMMENT = 8;    /* i: waiting for end of comment (gzip) */\nvar    HCRC = 9;       /* i: waiting for header crc (gzip) */\nvar    DICTID = 10;    /* i: waiting for dictionary check value */\nvar    DICT = 11;      /* waiting for inflateSetDictionary() call */\nvar        TYPE = 12;      /* i: waiting for type bits, including last-flag bit */\nvar        TYPEDO = 13;    /* i: same, but skip check to exit inflate on new block */\nvar        STORED = 14;    /* i: waiting for stored size (length and complement) */\nvar        COPY_ = 15;     /* i/o: same as COPY below, but only first time in */\nvar        COPY = 16;      /* i/o: waiting for input or output to copy stored block */\nvar        TABLE = 17;     /* i: waiting for dynamic block table lengths */\nvar        LENLENS = 18;   /* i: waiting for code length code lengths */\nvar        CODELENS = 19;  /* i: waiting for length/lit and distance code lengths */\nvar            LEN_ = 20;      /* i: same as LEN below, but only first time in */\nvar            LEN = 21;       /* i: waiting for length/lit/eob code */\nvar            LENEXT = 22;    /* i: waiting for length extra bits */\nvar            DIST = 23;      /* i: waiting for distance code */\nvar            DISTEXT = 24;   /* i: waiting for distance extra bits */\nvar            MATCH = 25;     /* o: waiting for output space to copy string */\nvar            LIT = 26;       /* o: waiting for output space to write literal */\nvar    CHECK = 27;     /* i: waiting for 32-bit check value */\nvar    LENGTH = 28;    /* i: waiting for 32-bit length (gzip) */\nvar    DONE = 29;      /* finished check, done -- remain here until reset */\nvar    BAD = 30;       /* got a data error -- remain here until reset */\nvar    MEM = 31;       /* got an inflate() memory error -- remain here until reset */\nvar    SYNC = 32;      /* looking for synchronization bytes to restart inflate() */\n\n/* ===========================================================================*/\n\n\n\nvar ENOUGH_LENS = 852;\nvar ENOUGH_DISTS = 592;\n//var ENOUGH =  (ENOUGH_LENS+ENOUGH_DISTS);\n\nvar MAX_WBITS = 15;\n/* 32K LZ77 window */\nvar DEF_WBITS = MAX_WBITS;\n\n\nfunction zswap32(q) {\n  return  (((q >>> 24) & 0xff) +\n          ((q >>> 8) & 0xff00) +\n          ((q & 0xff00) << 8) +\n          ((q & 0xff) << 24));\n}\n\n\nfunction InflateState() {\n  this.mode = 0;             /* current inflate mode */\n  this.last = false;          /* true if processing last block */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */\n  this.havedict = false;      /* true if dictionary provided */\n  this.flags = 0;             /* gzip header method and flags (0 if zlib) */\n  this.dmax = 0;              /* zlib header max distance (INFLATE_STRICT) */\n  this.check = 0;             /* protected copy of check value */\n  this.total = 0;             /* protected copy of output count */\n  // TODO: may be {}\n  this.head = null;           /* where to save gzip header information */\n\n  /* sliding window */\n  this.wbits = 0;             /* log base 2 of requested window size */\n  this.wsize = 0;             /* window size or zero if not using window */\n  this.whave = 0;             /* valid bytes in the window */\n  this.wnext = 0;             /* window write index */\n  this.window = null;         /* allocated sliding window, if needed */\n\n  /* bit accumulator */\n  this.hold = 0;              /* input bit accumulator */\n  this.bits = 0;              /* number of bits in \"in\" */\n\n  /* for string and stored block copying */\n  this.length = 0;            /* literal or length of data to copy */\n  this.offset = 0;            /* distance back to copy string from */\n\n  /* for table and code decoding */\n  this.extra = 0;             /* extra bits needed */\n\n  /* fixed and dynamic code tables */\n  this.lencode = null;          /* starting table for length/literal codes */\n  this.distcode = null;         /* starting table for distance codes */\n  this.lenbits = 0;           /* index bits for lencode */\n  this.distbits = 0;          /* index bits for distcode */\n\n  /* dynamic table building */\n  this.ncode = 0;             /* number of code length code lengths */\n  this.nlen = 0;              /* number of length code lengths */\n  this.ndist = 0;             /* number of distance code lengths */\n  this.have = 0;              /* number of code lengths in lens[] */\n  this.next = null;              /* next available space in codes[] */\n\n  this.lens = new utils.Buf16(320); /* temporary storage for code lengths */\n  this.work = new utils.Buf16(288); /* work area for code table building */\n\n  /*\n   because we don't have pointers in js, we use lencode and distcode directly\n   as buffers so we don't need codes\n  */\n  //this.codes = new utils.Buf32(ENOUGH);       /* space for code tables */\n  this.lendyn = null;              /* dynamic table for length/literal codes (JS specific) */\n  this.distdyn = null;             /* dynamic table for distance codes (JS specific) */\n  this.sane = 0;                   /* if false, allow invalid distance too far */\n  this.back = 0;                   /* bits back of last unprocessed length/lit */\n  this.was = 0;                    /* initial length of match */\n}\n\nfunction inflateResetKeep(strm) {\n  var state;\n\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  strm.total_in = strm.total_out = state.total = 0;\n  strm.msg = ''; /*Z_NULL*/\n  if (state.wrap) {       /* to support ill-conceived Java test suite */\n    strm.adler = state.wrap & 1;\n  }\n  state.mode = HEAD;\n  state.last = 0;\n  state.havedict = 0;\n  state.dmax = 32768;\n  state.head = null/*Z_NULL*/;\n  state.hold = 0;\n  state.bits = 0;\n  //state.lencode = state.distcode = state.next = state.codes;\n  state.lencode = state.lendyn = new utils.Buf32(ENOUGH_LENS);\n  state.distcode = state.distdyn = new utils.Buf32(ENOUGH_DISTS);\n\n  state.sane = 1;\n  state.back = -1;\n  //Tracev((stderr, \"inflate: reset\\n\"));\n  return Z_OK;\n}\n\nfunction inflateReset(strm) {\n  var state;\n\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  state.wsize = 0;\n  state.whave = 0;\n  state.wnext = 0;\n  return inflateResetKeep(strm);\n\n}\n\nfunction inflateReset2(strm, windowBits) {\n  var wrap;\n  var state;\n\n  /* get the state */\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n\n  /* extract wrap request from windowBits parameter */\n  if (windowBits < 0) {\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n  else {\n    wrap = (windowBits >> 4) + 1;\n    if (windowBits < 48) {\n      windowBits &= 15;\n    }\n  }\n\n  /* set number of window bits, free window if different */\n  if (windowBits && (windowBits < 8 || windowBits > 15)) {\n    return Z_STREAM_ERROR;\n  }\n  if (state.window !== null && state.wbits !== windowBits) {\n    state.window = null;\n  }\n\n  /* update state and reset the rest of it */\n  state.wrap = wrap;\n  state.wbits = windowBits;\n  return inflateReset(strm);\n}\n\nfunction inflateInit2(strm, windowBits) {\n  var ret;\n  var state;\n\n  if (!strm) { return Z_STREAM_ERROR; }\n  //strm.msg = Z_NULL;                 /* in case we return an error */\n\n  state = new InflateState();\n\n  //if (state === Z_NULL) return Z_MEM_ERROR;\n  //Tracev((stderr, \"inflate: allocated\\n\"));\n  strm.state = state;\n  state.window = null/*Z_NULL*/;\n  ret = inflateReset2(strm, windowBits);\n  if (ret !== Z_OK) {\n    strm.state = null/*Z_NULL*/;\n  }\n  return ret;\n}\n\nfunction inflateInit(strm) {\n  return inflateInit2(strm, DEF_WBITS);\n}\n\n\n/*\n Return state with length and distance decoding tables and index sizes set to\n fixed code decoding.  Normally this returns fixed tables from inffixed.h.\n If BUILDFIXED is defined, then instead this routine builds the tables the\n first time it's called, and returns those tables the first time and\n thereafter.  This reduces the size of the code by about 2K bytes, in\n exchange for a little execution time.  However, BUILDFIXED should not be\n used for threaded applications, since the rewriting of the tables and virgin\n may not be thread-safe.\n */\nvar virgin = true;\n\nvar lenfix, distfix; // We have no pointers in JS, so keep tables separate\n\nfunction fixedtables(state) {\n  /* build fixed huffman tables if first call (may not be thread safe) */\n  if (virgin) {\n    var sym;\n\n    lenfix = new utils.Buf32(512);\n    distfix = new utils.Buf32(32);\n\n    /* literal/length table */\n    sym = 0;\n    while (sym < 144) { state.lens[sym++] = 8; }\n    while (sym < 256) { state.lens[sym++] = 9; }\n    while (sym < 280) { state.lens[sym++] = 7; }\n    while (sym < 288) { state.lens[sym++] = 8; }\n\n    inflate_table(LENS,  state.lens, 0, 288, lenfix,   0, state.work, { bits: 9 });\n\n    /* distance table */\n    sym = 0;\n    while (sym < 32) { state.lens[sym++] = 5; }\n\n    inflate_table(DISTS, state.lens, 0, 32,   distfix, 0, state.work, { bits: 5 });\n\n    /* do this just once */\n    virgin = false;\n  }\n\n  state.lencode = lenfix;\n  state.lenbits = 9;\n  state.distcode = distfix;\n  state.distbits = 5;\n}\n\n\n/*\n Update the window with the last wsize (normally 32K) bytes written before\n returning.  If window does not exist yet, create it.  This is only called\n when a window is already in use, or when output has been written during this\n inflate call, but the end of the deflate stream has not been reached yet.\n It is also called to create a window for dictionary data when a dictionary\n is loaded.\n\n Providing output buffers larger than 32K to inflate() should provide a speed\n advantage, since only the last 32K of output is copied to the sliding window\n upon return from inflate(), and since all distances after the first 32K of\n output will fall in the output data, making match copies simpler and faster.\n The advantage may be dependent on the size of the processor's data caches.\n */\nfunction updatewindow(strm, src, end, copy) {\n  var dist;\n  var state = strm.state;\n\n  /* if it hasn't been done already, allocate space for the window */\n  if (state.window === null) {\n    state.wsize = 1 << state.wbits;\n    state.wnext = 0;\n    state.whave = 0;\n\n    state.window = new utils.Buf8(state.wsize);\n  }\n\n  /* copy state->wsize or less output bytes into the circular window */\n  if (copy >= state.wsize) {\n    utils.arraySet(state.window, src, end - state.wsize, state.wsize, 0);\n    state.wnext = 0;\n    state.whave = state.wsize;\n  }\n  else {\n    dist = state.wsize - state.wnext;\n    if (dist > copy) {\n      dist = copy;\n    }\n    //zmemcpy(state->window + state->wnext, end - copy, dist);\n    utils.arraySet(state.window, src, end - copy, dist, state.wnext);\n    copy -= dist;\n    if (copy) {\n      //zmemcpy(state->window, end - copy, copy);\n      utils.arraySet(state.window, src, end - copy, copy, 0);\n      state.wnext = copy;\n      state.whave = state.wsize;\n    }\n    else {\n      state.wnext += dist;\n      if (state.wnext === state.wsize) { state.wnext = 0; }\n      if (state.whave < state.wsize) { state.whave += dist; }\n    }\n  }\n  return 0;\n}\n\nfunction inflate(strm, flush) {\n  var state;\n  var input, output;          // input/output buffers\n  var next;                   /* next input INDEX */\n  var put;                    /* next output INDEX */\n  var have, left;             /* available input and output */\n  var hold;                   /* bit buffer */\n  var bits;                   /* bits in bit buffer */\n  var _in, _out;              /* save starting available input and output */\n  var copy;                   /* number of stored or match bytes to copy */\n  var from;                   /* where to copy match bytes from */\n  var from_source;\n  var here = 0;               /* current decoding table entry */\n  var here_bits, here_op, here_val; // paked \"here\" denormalized (JS specific)\n  //var last;                   /* parent table entry */\n  var last_bits, last_op, last_val; // paked \"last\" denormalized (JS specific)\n  var len;                    /* length to copy for repeats, bits to drop */\n  var ret;                    /* return code */\n  var hbuf = new utils.Buf8(4);    /* buffer for gzip header crc calculation */\n  var opts;\n\n  var n; // temporary var for NEED_BITS\n\n  var order = /* permutation of code lengths */\n    [ 16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15 ];\n\n\n  if (!strm || !strm.state || !strm.output ||\n      (!strm.input && strm.avail_in !== 0)) {\n    return Z_STREAM_ERROR;\n  }\n\n  state = strm.state;\n  if (state.mode === TYPE) { state.mode = TYPEDO; }    /* skip check */\n\n\n  //--- LOAD() ---\n  put = strm.next_out;\n  output = strm.output;\n  left = strm.avail_out;\n  next = strm.next_in;\n  input = strm.input;\n  have = strm.avail_in;\n  hold = state.hold;\n  bits = state.bits;\n  //---\n\n  _in = have;\n  _out = left;\n  ret = Z_OK;\n\n  inf_leave: // goto emulation\n  for (;;) {\n    switch (state.mode) {\n      case HEAD:\n        if (state.wrap === 0) {\n          state.mode = TYPEDO;\n          break;\n        }\n        //=== NEEDBITS(16);\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((state.wrap & 2) && hold === 0x8b1f) {  /* gzip header */\n          state.check = 0/*crc32(0L, Z_NULL, 0)*/;\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          state.mode = FLAGS;\n          break;\n        }\n        state.flags = 0;           /* expect zlib header */\n        if (state.head) {\n          state.head.done = false;\n        }\n        if (!(state.wrap & 1) ||   /* check if zlib header allowed */\n          (((hold & 0xff)/*BITS(8)*/ << 8) + (hold >> 8)) % 31) {\n          strm.msg = 'incorrect header check';\n          state.mode = BAD;\n          break;\n        }\n        if ((hold & 0x0f)/*BITS(4)*/ !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n        len = (hold & 0x0f)/*BITS(4)*/ + 8;\n        if (state.wbits === 0) {\n          state.wbits = len;\n        }\n        else if (len > state.wbits) {\n          strm.msg = 'invalid window size';\n          state.mode = BAD;\n          break;\n        }\n        state.dmax = 1 << len;\n        //Tracev((stderr, \"inflate:   zlib header ok\\n\"));\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = hold & 0x200 ? DICTID : TYPE;\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        break;\n      case FLAGS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.flags = hold;\n        if ((state.flags & 0xff) !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        if (state.flags & 0xe000) {\n          strm.msg = 'unknown header flags set';\n          state.mode = BAD;\n          break;\n        }\n        if (state.head) {\n          state.head.text = ((hold >> 8) & 1);\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = TIME;\n        /* falls through */\n      case TIME:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.time = hold;\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC4(state.check, hold)\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          hbuf[2] = (hold >>> 16) & 0xff;\n          hbuf[3] = (hold >>> 24) & 0xff;\n          state.check = crc32(state.check, hbuf, 4, 0);\n          //===\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = OS;\n        /* falls through */\n      case OS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.xflags = (hold & 0xff);\n          state.head.os = (hold >> 8);\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = EXLEN;\n        /* falls through */\n      case EXLEN:\n        if (state.flags & 0x0400) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length = hold;\n          if (state.head) {\n            state.head.extra_len = hold;\n          }\n          if (state.flags & 0x0200) {\n            //=== CRC2(state.check, hold);\n            hbuf[0] = hold & 0xff;\n            hbuf[1] = (hold >>> 8) & 0xff;\n            state.check = crc32(state.check, hbuf, 2, 0);\n            //===//\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        else if (state.head) {\n          state.head.extra = null/*Z_NULL*/;\n        }\n        state.mode = EXTRA;\n        /* falls through */\n      case EXTRA:\n        if (state.flags & 0x0400) {\n          copy = state.length;\n          if (copy > have) { copy = have; }\n          if (copy) {\n            if (state.head) {\n              len = state.head.extra_len - state.length;\n              if (!state.head.extra) {\n                // Use untyped array for more convenient processing later\n                state.head.extra = new Array(state.head.extra_len);\n              }\n              utils.arraySet(\n                state.head.extra,\n                input,\n                next,\n                // extra field is limited to 65536 bytes\n                // - no need for additional size check\n                copy,\n                /*len + copy > state.head.extra_max - len ? state.head.extra_max : copy,*/\n                len\n              );\n              //zmemcpy(state.head.extra + len, next,\n              //        len + copy > state.head.extra_max ?\n              //        state.head.extra_max - len : copy);\n            }\n            if (state.flags & 0x0200) {\n              state.check = crc32(state.check, input, copy, next);\n            }\n            have -= copy;\n            next += copy;\n            state.length -= copy;\n          }\n          if (state.length) { break inf_leave; }\n        }\n        state.length = 0;\n        state.mode = NAME;\n        /* falls through */\n      case NAME:\n        if (state.flags & 0x0800) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            // TODO: 2 or 1 bytes?\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.name_max*/)) {\n              state.head.name += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n\n          if (state.flags & 0x0200) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.name = null;\n        }\n        state.length = 0;\n        state.mode = COMMENT;\n        /* falls through */\n      case COMMENT:\n        if (state.flags & 0x1000) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.comm_max*/)) {\n              state.head.comment += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n          if (state.flags & 0x0200) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.comment = null;\n        }\n        state.mode = HCRC;\n        /* falls through */\n      case HCRC:\n        if (state.flags & 0x0200) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if (hold !== (state.check & 0xffff)) {\n            strm.msg = 'header crc mismatch';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        if (state.head) {\n          state.head.hcrc = ((state.flags >> 9) & 1);\n          state.head.done = true;\n        }\n        strm.adler = state.check = 0;\n        state.mode = TYPE;\n        break;\n      case DICTID:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        strm.adler = state.check = zswap32(hold);\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = DICT;\n        /* falls through */\n      case DICT:\n        if (state.havedict === 0) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          return Z_NEED_DICT;\n        }\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = TYPE;\n        /* falls through */\n      case TYPE:\n        if (flush === Z_BLOCK || flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case TYPEDO:\n        if (state.last) {\n          //--- BYTEBITS() ---//\n          hold >>>= bits & 7;\n          bits -= bits & 7;\n          //---//\n          state.mode = CHECK;\n          break;\n        }\n        //=== NEEDBITS(3); */\n        while (bits < 3) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.last = (hold & 0x01)/*BITS(1)*/;\n        //--- DROPBITS(1) ---//\n        hold >>>= 1;\n        bits -= 1;\n        //---//\n\n        switch ((hold & 0x03)/*BITS(2)*/) {\n          case 0:                             /* stored block */\n            //Tracev((stderr, \"inflate:     stored block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = STORED;\n            break;\n          case 1:                             /* fixed block */\n            fixedtables(state);\n            //Tracev((stderr, \"inflate:     fixed codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = LEN_;             /* decode codes */\n            if (flush === Z_TREES) {\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n              break inf_leave;\n            }\n            break;\n          case 2:                             /* dynamic block */\n            //Tracev((stderr, \"inflate:     dynamic codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = TABLE;\n            break;\n          case 3:\n            strm.msg = 'invalid block type';\n            state.mode = BAD;\n        }\n        //--- DROPBITS(2) ---//\n        hold >>>= 2;\n        bits -= 2;\n        //---//\n        break;\n      case STORED:\n        //--- BYTEBITS() ---// /* go to byte boundary */\n        hold >>>= bits & 7;\n        bits -= bits & 7;\n        //---//\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((hold & 0xffff) !== ((hold >>> 16) ^ 0xffff)) {\n          strm.msg = 'invalid stored block lengths';\n          state.mode = BAD;\n          break;\n        }\n        state.length = hold & 0xffff;\n        //Tracev((stderr, \"inflate:       stored length %u\\n\",\n        //        state.length));\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = COPY_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case COPY_:\n        state.mode = COPY;\n        /* falls through */\n      case COPY:\n        copy = state.length;\n        if (copy) {\n          if (copy > have) { copy = have; }\n          if (copy > left) { copy = left; }\n          if (copy === 0) { break inf_leave; }\n          //--- zmemcpy(put, next, copy); ---\n          utils.arraySet(output, input, next, copy, put);\n          //---//\n          have -= copy;\n          next += copy;\n          left -= copy;\n          put += copy;\n          state.length -= copy;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       stored end\\n\"));\n        state.mode = TYPE;\n        break;\n      case TABLE:\n        //=== NEEDBITS(14); */\n        while (bits < 14) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.nlen = (hold & 0x1f)/*BITS(5)*/ + 257;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ndist = (hold & 0x1f)/*BITS(5)*/ + 1;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ncode = (hold & 0x0f)/*BITS(4)*/ + 4;\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n//#ifndef PKZIP_BUG_WORKAROUND\n        if (state.nlen > 286 || state.ndist > 30) {\n          strm.msg = 'too many length or distance symbols';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracev((stderr, \"inflate:       table sizes ok\\n\"));\n        state.have = 0;\n        state.mode = LENLENS;\n        /* falls through */\n      case LENLENS:\n        while (state.have < state.ncode) {\n          //=== NEEDBITS(3);\n          while (bits < 3) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.lens[order[state.have++]] = (hold & 0x07);//BITS(3);\n          //--- DROPBITS(3) ---//\n          hold >>>= 3;\n          bits -= 3;\n          //---//\n        }\n        while (state.have < 19) {\n          state.lens[order[state.have++]] = 0;\n        }\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        //state.next = state.codes;\n        //state.lencode = state.next;\n        // Switch to use dynamic table\n        state.lencode = state.lendyn;\n        state.lenbits = 7;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(CODES, state.lens, 0, 19, state.lencode, 0, state.work, opts);\n        state.lenbits = opts.bits;\n\n        if (ret) {\n          strm.msg = 'invalid code lengths set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       code lengths ok\\n\"));\n        state.have = 0;\n        state.mode = CODELENS;\n        /* falls through */\n      case CODELENS:\n        while (state.have < state.nlen + state.ndist) {\n          for (;;) {\n            here = state.lencode[hold & ((1 << state.lenbits) - 1)];/*BITS(state.lenbits)*/\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          if (here_val < 16) {\n            //--- DROPBITS(here.bits) ---//\n            hold >>>= here_bits;\n            bits -= here_bits;\n            //---//\n            state.lens[state.have++] = here_val;\n          }\n          else {\n            if (here_val === 16) {\n              //=== NEEDBITS(here.bits + 2);\n              n = here_bits + 2;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              if (state.have === 0) {\n                strm.msg = 'invalid bit length repeat';\n                state.mode = BAD;\n                break;\n              }\n              len = state.lens[state.have - 1];\n              copy = 3 + (hold & 0x03);//BITS(2);\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n            }\n            else if (here_val === 17) {\n              //=== NEEDBITS(here.bits + 3);\n              n = here_bits + 3;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 3 + (hold & 0x07);//BITS(3);\n              //--- DROPBITS(3) ---//\n              hold >>>= 3;\n              bits -= 3;\n              //---//\n            }\n            else {\n              //=== NEEDBITS(here.bits + 7);\n              n = here_bits + 7;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 11 + (hold & 0x7f);//BITS(7);\n              //--- DROPBITS(7) ---//\n              hold >>>= 7;\n              bits -= 7;\n              //---//\n            }\n            if (state.have + copy > state.nlen + state.ndist) {\n              strm.msg = 'invalid bit length repeat';\n              state.mode = BAD;\n              break;\n            }\n            while (copy--) {\n              state.lens[state.have++] = len;\n            }\n          }\n        }\n\n        /* handle error breaks in while */\n        if (state.mode === BAD) { break; }\n\n        /* check for end-of-block code (better have one) */\n        if (state.lens[256] === 0) {\n          strm.msg = 'invalid code -- missing end-of-block';\n          state.mode = BAD;\n          break;\n        }\n\n        /* build code tables -- note: do not change the lenbits or distbits\n           values here (9 and 6) without reading the comments in inftrees.h\n           concerning the ENOUGH constants, which depend on those values */\n        state.lenbits = 9;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(LENS, state.lens, 0, state.nlen, state.lencode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.lenbits = opts.bits;\n        // state.lencode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid literal/lengths set';\n          state.mode = BAD;\n          break;\n        }\n\n        state.distbits = 6;\n        //state.distcode.copy(state.codes);\n        // Switch to use dynamic table\n        state.distcode = state.distdyn;\n        opts = { bits: state.distbits };\n        ret = inflate_table(DISTS, state.lens, state.nlen, state.ndist, state.distcode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.distbits = opts.bits;\n        // state.distcode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid distances set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, 'inflate:       codes ok\\n'));\n        state.mode = LEN_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case LEN_:\n        state.mode = LEN;\n        /* falls through */\n      case LEN:\n        if (have >= 6 && left >= 258) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          inflate_fast(strm, _out);\n          //--- LOAD() ---\n          put = strm.next_out;\n          output = strm.output;\n          left = strm.avail_out;\n          next = strm.next_in;\n          input = strm.input;\n          have = strm.avail_in;\n          hold = state.hold;\n          bits = state.bits;\n          //---\n\n          if (state.mode === TYPE) {\n            state.back = -1;\n          }\n          break;\n        }\n        state.back = 0;\n        for (;;) {\n          here = state.lencode[hold & ((1 << state.lenbits) - 1)];  /*BITS(state.lenbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if (here_bits <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if (here_op && (here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.lencode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        state.length = here_val;\n        if (here_op === 0) {\n          //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n          //        \"inflate:         literal '%c'\\n\" :\n          //        \"inflate:         literal 0x%02x\\n\", here.val));\n          state.mode = LIT;\n          break;\n        }\n        if (here_op & 32) {\n          //Tracevv((stderr, \"inflate:         end of block\\n\"));\n          state.back = -1;\n          state.mode = TYPE;\n          break;\n        }\n        if (here_op & 64) {\n          strm.msg = 'invalid literal/length code';\n          state.mode = BAD;\n          break;\n        }\n        state.extra = here_op & 15;\n        state.mode = LENEXT;\n        /* falls through */\n      case LENEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", state.length));\n        state.was = state.length;\n        state.mode = DIST;\n        /* falls through */\n      case DIST:\n        for (;;) {\n          here = state.distcode[hold & ((1 << state.distbits) - 1)];/*BITS(state.distbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if ((here_bits) <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if ((here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.distcode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        if (here_op & 64) {\n          strm.msg = 'invalid distance code';\n          state.mode = BAD;\n          break;\n        }\n        state.offset = here_val;\n        state.extra = (here_op) & 15;\n        state.mode = DISTEXT;\n        /* falls through */\n      case DISTEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.offset += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n//#ifdef INFLATE_STRICT\n        if (state.offset > state.dmax) {\n          strm.msg = 'invalid distance too far back';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracevv((stderr, \"inflate:         distance %u\\n\", state.offset));\n        state.mode = MATCH;\n        /* falls through */\n      case MATCH:\n        if (left === 0) { break inf_leave; }\n        copy = _out - left;\n        if (state.offset > copy) {         /* copy from window */\n          copy = state.offset - copy;\n          if (copy > state.whave) {\n            if (state.sane) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break;\n            }\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//          Trace((stderr, \"inflate.c too far\\n\"));\n//          copy -= state.whave;\n//          if (copy > state.length) { copy = state.length; }\n//          if (copy > left) { copy = left; }\n//          left -= copy;\n//          state.length -= copy;\n//          do {\n//            output[put++] = 0;\n//          } while (--copy);\n//          if (state.length === 0) { state.mode = LEN; }\n//          break;\n//#endif\n          }\n          if (copy > state.wnext) {\n            copy -= state.wnext;\n            from = state.wsize - copy;\n          }\n          else {\n            from = state.wnext - copy;\n          }\n          if (copy > state.length) { copy = state.length; }\n          from_source = state.window;\n        }\n        else {                              /* copy from output */\n          from_source = output;\n          from = put - state.offset;\n          copy = state.length;\n        }\n        if (copy > left) { copy = left; }\n        left -= copy;\n        state.length -= copy;\n        do {\n          output[put++] = from_source[from++];\n        } while (--copy);\n        if (state.length === 0) { state.mode = LEN; }\n        break;\n      case LIT:\n        if (left === 0) { break inf_leave; }\n        output[put++] = state.length;\n        left--;\n        state.mode = LEN;\n        break;\n      case CHECK:\n        if (state.wrap) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            // Use '|' instead of '+' to make sure that result is signed\n            hold |= input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          _out -= left;\n          strm.total_out += _out;\n          state.total += _out;\n          if (_out) {\n            strm.adler = state.check =\n                /*UPDATE(state.check, put - _out, _out);*/\n                (state.flags ? crc32(state.check, output, _out, put - _out) : adler32(state.check, output, _out, put - _out));\n\n          }\n          _out = left;\n          // NB: crc32 stored as signed 32-bit int, zswap32 returns signed too\n          if ((state.flags ? hold : zswap32(hold)) !== state.check) {\n            strm.msg = 'incorrect data check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   check matches trailer\\n\"));\n        }\n        state.mode = LENGTH;\n        /* falls through */\n      case LENGTH:\n        if (state.wrap && state.flags) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if (hold !== (state.total & 0xffffffff)) {\n            strm.msg = 'incorrect length check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   length matches trailer\\n\"));\n        }\n        state.mode = DONE;\n        /* falls through */\n      case DONE:\n        ret = Z_STREAM_END;\n        break inf_leave;\n      case BAD:\n        ret = Z_DATA_ERROR;\n        break inf_leave;\n      case MEM:\n        return Z_MEM_ERROR;\n      case SYNC:\n        /* falls through */\n      default:\n        return Z_STREAM_ERROR;\n    }\n  }\n\n  // inf_leave <- here is real place for \"goto inf_leave\", emulated via \"break inf_leave\"\n\n  /*\n     Return from inflate(), updating the total counts and the check value.\n     If there was no progress during the inflate() call, return a buffer\n     error.  Call updatewindow() to create and/or update the window state.\n     Note: a memory error from inflate() is non-recoverable.\n   */\n\n  //--- RESTORE() ---\n  strm.next_out = put;\n  strm.avail_out = left;\n  strm.next_in = next;\n  strm.avail_in = have;\n  state.hold = hold;\n  state.bits = bits;\n  //---\n\n  if (state.wsize || (_out !== strm.avail_out && state.mode < BAD &&\n                      (state.mode < CHECK || flush !== Z_FINISH))) {\n    if (updatewindow(strm, strm.output, strm.next_out, _out - strm.avail_out)) {\n      state.mode = MEM;\n      return Z_MEM_ERROR;\n    }\n  }\n  _in -= strm.avail_in;\n  _out -= strm.avail_out;\n  strm.total_in += _in;\n  strm.total_out += _out;\n  state.total += _out;\n  if (state.wrap && _out) {\n    strm.adler = state.check = /*UPDATE(state.check, strm.next_out - _out, _out);*/\n      (state.flags ? crc32(state.check, output, _out, strm.next_out - _out) : adler32(state.check, output, _out, strm.next_out - _out));\n  }\n  strm.data_type = state.bits + (state.last ? 64 : 0) +\n                    (state.mode === TYPE ? 128 : 0) +\n                    (state.mode === LEN_ || state.mode === COPY_ ? 256 : 0);\n  if (((_in === 0 && _out === 0) || flush === Z_FINISH) && ret === Z_OK) {\n    ret = Z_BUF_ERROR;\n  }\n  return ret;\n}\n\nfunction inflateEnd(strm) {\n\n  if (!strm || !strm.state /*|| strm->zfree == (free_func)0*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  var state = strm.state;\n  if (state.window) {\n    state.window = null;\n  }\n  strm.state = null;\n  return Z_OK;\n}\n\nfunction inflateGetHeader(strm, head) {\n  var state;\n\n  /* check state */\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  if ((state.wrap & 2) === 0) { return Z_STREAM_ERROR; }\n\n  /* save header structure */\n  state.head = head;\n  head.done = false;\n  return Z_OK;\n}\n\nfunction inflateSetDictionary(strm, dictionary) {\n  var dictLength = dictionary.length;\n\n  var state;\n  var dictid;\n  var ret;\n\n  /* check state */\n  if (!strm /* == Z_NULL */ || !strm.state /* == Z_NULL */) { return Z_STREAM_ERROR; }\n  state = strm.state;\n\n  if (state.wrap !== 0 && state.mode !== DICT) {\n    return Z_STREAM_ERROR;\n  }\n\n  /* check for correct dictionary identifier */\n  if (state.mode === DICT) {\n    dictid = 1; /* adler32(0, null, 0)*/\n    /* dictid = adler32(dictid, dictionary, dictLength); */\n    dictid = adler32(dictid, dictionary, dictLength, 0);\n    if (dictid !== state.check) {\n      return Z_DATA_ERROR;\n    }\n  }\n  /* copy dictionary to window using updatewindow(), which will amend the\n   existing dictionary if appropriate */\n  ret = updatewindow(strm, dictionary, dictLength, dictLength);\n  if (ret) {\n    state.mode = MEM;\n    return Z_MEM_ERROR;\n  }\n  state.havedict = 1;\n  // Tracev((stderr, \"inflate:   dictionary set\\n\"));\n  return Z_OK;\n}\n\nexports.inflateReset = inflateReset;\nexports.inflateReset2 = inflateReset2;\nexports.inflateResetKeep = inflateResetKeep;\nexports.inflateInit = inflateInit;\nexports.inflateInit2 = inflateInit2;\nexports.inflate = inflate;\nexports.inflateEnd = inflateEnd;\nexports.inflateGetHeader = inflateGetHeader;\nexports.inflateSetDictionary = inflateSetDictionary;\nexports.inflateInfo = 'pako inflate (from Nodeca project)';\n\n/* Not implemented\nexports.inflateCopy = inflateCopy;\nexports.inflateGetDictionary = inflateGetDictionary;\nexports.inflateMark = inflateMark;\nexports.inflatePrime = inflatePrime;\nexports.inflateSync = inflateSync;\nexports.inflateSyncPoint = inflateSyncPoint;\nexports.inflateUndermine = inflateUndermine;\n*/\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/inflate.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/inftrees.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/zlib/inftrees.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\n\nvar MAXBITS = 15;\nvar ENOUGH_LENS = 852;\nvar ENOUGH_DISTS = 592;\n//var ENOUGH = (ENOUGH_LENS+ENOUGH_DISTS);\n\nvar CODES = 0;\nvar LENS = 1;\nvar DISTS = 2;\n\nvar lbase = [ /* Length codes 257..285 base */\n  3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,\n  35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0\n];\n\nvar lext = [ /* Length codes 257..285 extra */\n  16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,\n  19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 72, 78\n];\n\nvar dbase = [ /* Distance codes 0..29 base */\n  1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,\n  257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,\n  8193, 12289, 16385, 24577, 0, 0\n];\n\nvar dext = [ /* Distance codes 0..29 extra */\n  16, 16, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,\n  23, 23, 24, 24, 25, 25, 26, 26, 27, 27,\n  28, 28, 29, 29, 64, 64\n];\n\nmodule.exports = function inflate_table(type, lens, lens_index, codes, table, table_index, work, opts)\n{\n  var bits = opts.bits;\n      //here = opts.here; /* table entry for duplication */\n\n  var len = 0;               /* a code's length in bits */\n  var sym = 0;               /* index of code symbols */\n  var min = 0, max = 0;          /* minimum and maximum code lengths */\n  var root = 0;              /* number of index bits for root table */\n  var curr = 0;              /* number of index bits for current table */\n  var drop = 0;              /* code bits to drop for sub-table */\n  var left = 0;                   /* number of prefix codes available */\n  var used = 0;              /* code entries in table used */\n  var huff = 0;              /* Huffman code */\n  var incr;              /* for incrementing code, index */\n  var fill;              /* index for replicating entries */\n  var low;               /* low bits for current root entry */\n  var mask;              /* mask for low root bits */\n  var next;             /* next available space in table */\n  var base = null;     /* base value table to use */\n  var base_index = 0;\n//  var shoextra;    /* extra bits table to use */\n  var end;                    /* use base and extra for symbol > end */\n  var count = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];    /* number of codes of each length */\n  var offs = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];     /* offsets in table for each length */\n  var extra = null;\n  var extra_index = 0;\n\n  var here_bits, here_op, here_val;\n\n  /*\n   Process a set of code lengths to create a canonical Huffman code.  The\n   code lengths are lens[0..codes-1].  Each length corresponds to the\n   symbols 0..codes-1.  The Huffman code is generated by first sorting the\n   symbols by length from short to long, and retaining the symbol order\n   for codes with equal lengths.  Then the code starts with all zero bits\n   for the first code of the shortest length, and the codes are integer\n   increments for the same length, and zeros are appended as the length\n   increases.  For the deflate format, these bits are stored backwards\n   from their more natural integer increment ordering, and so when the\n   decoding tables are built in the large loop below, the integer codes\n   are incremented backwards.\n\n   This routine assumes, but does not check, that all of the entries in\n   lens[] are in the range 0..MAXBITS.  The caller must assure this.\n   1..MAXBITS is interpreted as that code length.  zero means that that\n   symbol does not occur in this code.\n\n   The codes are sorted by computing a count of codes for each length,\n   creating from that a table of starting indices for each length in the\n   sorted table, and then entering the symbols in order in the sorted\n   table.  The sorted table is work[], with that space being provided by\n   the caller.\n\n   The length counts are used for other purposes as well, i.e. finding\n   the minimum and maximum length codes, determining if there are any\n   codes at all, checking for a valid set of lengths, and looking ahead\n   at length counts to determine sub-table sizes when building the\n   decoding tables.\n   */\n\n  /* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */\n  for (len = 0; len <= MAXBITS; len++) {\n    count[len] = 0;\n  }\n  for (sym = 0; sym < codes; sym++) {\n    count[lens[lens_index + sym]]++;\n  }\n\n  /* bound code lengths, force root to be within code lengths */\n  root = bits;\n  for (max = MAXBITS; max >= 1; max--) {\n    if (count[max] !== 0) { break; }\n  }\n  if (root > max) {\n    root = max;\n  }\n  if (max === 0) {                     /* no symbols to code at all */\n    //table.op[opts.table_index] = 64;  //here.op = (var char)64;    /* invalid code marker */\n    //table.bits[opts.table_index] = 1;   //here.bits = (var char)1;\n    //table.val[opts.table_index++] = 0;   //here.val = (var short)0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n\n    //table.op[opts.table_index] = 64;\n    //table.bits[opts.table_index] = 1;\n    //table.val[opts.table_index++] = 0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n    opts.bits = 1;\n    return 0;     /* no symbols, but wait for decoding to report error */\n  }\n  for (min = 1; min < max; min++) {\n    if (count[min] !== 0) { break; }\n  }\n  if (root < min) {\n    root = min;\n  }\n\n  /* check for an over-subscribed or incomplete set of lengths */\n  left = 1;\n  for (len = 1; len <= MAXBITS; len++) {\n    left <<= 1;\n    left -= count[len];\n    if (left < 0) {\n      return -1;\n    }        /* over-subscribed */\n  }\n  if (left > 0 && (type === CODES || max !== 1)) {\n    return -1;                      /* incomplete set */\n  }\n\n  /* generate offsets into symbol table for each length for sorting */\n  offs[1] = 0;\n  for (len = 1; len < MAXBITS; len++) {\n    offs[len + 1] = offs[len] + count[len];\n  }\n\n  /* sort symbols by length, by symbol order within each length */\n  for (sym = 0; sym < codes; sym++) {\n    if (lens[lens_index + sym] !== 0) {\n      work[offs[lens[lens_index + sym]]++] = sym;\n    }\n  }\n\n  /*\n   Create and fill in decoding tables.  In this loop, the table being\n   filled is at next and has curr index bits.  The code being used is huff\n   with length len.  That code is converted to an index by dropping drop\n   bits off of the bottom.  For codes where len is less than drop + curr,\n   those top drop + curr - len bits are incremented through all values to\n   fill the table with replicated entries.\n\n   root is the number of index bits for the root table.  When len exceeds\n   root, sub-tables are created pointed to by the root entry with an index\n   of the low root bits of huff.  This is saved in low to check for when a\n   new sub-table should be started.  drop is zero when the root table is\n   being filled, and drop is root when sub-tables are being filled.\n\n   When a new sub-table is needed, it is necessary to look ahead in the\n   code lengths to determine what size sub-table is needed.  The length\n   counts are used for this, and so count[] is decremented as codes are\n   entered in the tables.\n\n   used keeps track of how many table entries have been allocated from the\n   provided *table space.  It is checked for LENS and DIST tables against\n   the constants ENOUGH_LENS and ENOUGH_DISTS to guard against changes in\n   the initial root table size constants.  See the comments in inftrees.h\n   for more information.\n\n   sym increments through all symbols, and the loop terminates when\n   all codes of length max, i.e. all codes, have been processed.  This\n   routine permits incomplete codes, so another loop after this one fills\n   in the rest of the decoding tables with invalid code markers.\n   */\n\n  /* set up for code type */\n  // poor man optimization - use if-else instead of switch,\n  // to avoid deopts in old v8\n  if (type === CODES) {\n    base = extra = work;    /* dummy value--not used */\n    end = 19;\n\n  } else if (type === LENS) {\n    base = lbase;\n    base_index -= 257;\n    extra = lext;\n    extra_index -= 257;\n    end = 256;\n\n  } else {                    /* DISTS */\n    base = dbase;\n    extra = dext;\n    end = -1;\n  }\n\n  /* initialize opts for loop */\n  huff = 0;                   /* starting code */\n  sym = 0;                    /* starting code symbol */\n  len = min;                  /* starting code length */\n  next = table_index;              /* current table to fill in */\n  curr = root;                /* current table index bits */\n  drop = 0;                   /* current bits to drop from code for index */\n  low = -1;                   /* trigger new sub-table when len > root */\n  used = 1 << root;          /* use root table entries */\n  mask = used - 1;            /* mask for comparing low */\n\n  /* check available table space */\n  if ((type === LENS && used > ENOUGH_LENS) ||\n    (type === DISTS && used > ENOUGH_DISTS)) {\n    return 1;\n  }\n\n  /* process all codes and make table entries */\n  for (;;) {\n    /* create table entry */\n    here_bits = len - drop;\n    if (work[sym] < end) {\n      here_op = 0;\n      here_val = work[sym];\n    }\n    else if (work[sym] > end) {\n      here_op = extra[extra_index + work[sym]];\n      here_val = base[base_index + work[sym]];\n    }\n    else {\n      here_op = 32 + 64;         /* end of block */\n      here_val = 0;\n    }\n\n    /* replicate for those indices with low len bits equal to huff */\n    incr = 1 << (len - drop);\n    fill = 1 << curr;\n    min = fill;                 /* save offset to next table */\n    do {\n      fill -= incr;\n      table[next + (huff >> drop) + fill] = (here_bits << 24) | (here_op << 16) | here_val |0;\n    } while (fill !== 0);\n\n    /* backwards increment the len-bit code huff */\n    incr = 1 << (len - 1);\n    while (huff & incr) {\n      incr >>= 1;\n    }\n    if (incr !== 0) {\n      huff &= incr - 1;\n      huff += incr;\n    } else {\n      huff = 0;\n    }\n\n    /* go to next symbol, update count, len */\n    sym++;\n    if (--count[len] === 0) {\n      if (len === max) { break; }\n      len = lens[lens_index + work[sym]];\n    }\n\n    /* create new sub-table if needed */\n    if (len > root && (huff & mask) !== low) {\n      /* if first time, transition to sub-tables */\n      if (drop === 0) {\n        drop = root;\n      }\n\n      /* increment past last table */\n      next += min;            /* here min is 1 << curr */\n\n      /* determine length of next table */\n      curr = len - drop;\n      left = 1 << curr;\n      while (curr + drop < max) {\n        left -= count[curr + drop];\n        if (left <= 0) { break; }\n        curr++;\n        left <<= 1;\n      }\n\n      /* check for enough space */\n      used += 1 << curr;\n      if ((type === LENS && used > ENOUGH_LENS) ||\n        (type === DISTS && used > ENOUGH_DISTS)) {\n        return 1;\n      }\n\n      /* point entry in root table to sub-table */\n      low = huff & mask;\n      /*table.op[low] = curr;\n      table.bits[low] = root;\n      table.val[low] = next - opts.table_index;*/\n      table[low] = (root << 24) | (curr << 16) | (next - table_index) |0;\n    }\n  }\n\n  /* fill in remaining table entry if code is incomplete (guaranteed to have\n   at most one remaining entry, since if the code is incomplete, the\n   maximum code length that was allowed to get this far is one bit) */\n  if (huff !== 0) {\n    //table.op[next + huff] = 64;            /* invalid code marker */\n    //table.bits[next + huff] = len - drop;\n    //table.val[next + huff] = 0;\n    table[next + huff] = ((len - drop) << 24) | (64 << 16) |0;\n  }\n\n  /* set return parameters */\n  //opts.table_index += used;\n  opts.bits = root;\n  return 0;\n};\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/inftrees.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/messages.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/zlib/messages.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n  2:      'need dictionary',     /* Z_NEED_DICT       2  */\n  1:      'stream end',          /* Z_STREAM_END      1  */\n  0:      '',                    /* Z_OK              0  */\n  '-1':   'file error',          /* Z_ERRNO         (-1) */\n  '-2':   'stream error',        /* Z_STREAM_ERROR  (-2) */\n  '-3':   'data error',          /* Z_DATA_ERROR    (-3) */\n  '-4':   'insufficient memory', /* Z_MEM_ERROR     (-4) */\n  '-5':   'buffer error',        /* Z_BUF_ERROR     (-5) */\n  '-6':   'incompatible version' /* Z_VERSION_ERROR (-6) */\n};\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/messages.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/trees.js":
/*!*********************************************!*\
  !*** ./node_modules/pako/lib/zlib/trees.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n/* eslint-disable space-unary-ops */\n\nvar utils = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n//var Z_FILTERED          = 1;\n//var Z_HUFFMAN_ONLY      = 2;\n//var Z_RLE               = 3;\nvar Z_FIXED               = 4;\n//var Z_DEFAULT_STRATEGY  = 0;\n\n/* Possible values of the data_type field (though see inflate()) */\nvar Z_BINARY              = 0;\nvar Z_TEXT                = 1;\n//var Z_ASCII             = 1; // = Z_TEXT\nvar Z_UNKNOWN             = 2;\n\n/*============================================================================*/\n\n\nfunction zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }\n\n// From zutil.h\n\nvar STORED_BLOCK = 0;\nvar STATIC_TREES = 1;\nvar DYN_TREES    = 2;\n/* The three kinds of block type */\n\nvar MIN_MATCH    = 3;\nvar MAX_MATCH    = 258;\n/* The minimum and maximum match lengths */\n\n// From deflate.h\n/* ===========================================================================\n * Internal compression state.\n */\n\nvar LENGTH_CODES  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\n\nvar LITERALS      = 256;\n/* number of literal bytes 0..255 */\n\nvar L_CODES       = LITERALS + 1 + LENGTH_CODES;\n/* number of Literal or Length codes, including the END_BLOCK code */\n\nvar D_CODES       = 30;\n/* number of distance codes */\n\nvar BL_CODES      = 19;\n/* number of codes used to transfer the bit lengths */\n\nvar HEAP_SIZE     = 2 * L_CODES + 1;\n/* maximum heap size */\n\nvar MAX_BITS      = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nvar Buf_size      = 16;\n/* size of bit buffer in bi_buf */\n\n\n/* ===========================================================================\n * Constants\n */\n\nvar MAX_BL_BITS = 7;\n/* Bit length codes must not exceed MAX_BL_BITS bits */\n\nvar END_BLOCK   = 256;\n/* end of block literal code */\n\nvar REP_3_6     = 16;\n/* repeat previous bit length 3-6 times (2 bits of repeat count) */\n\nvar REPZ_3_10   = 17;\n/* repeat a zero length 3-10 times  (3 bits of repeat count) */\n\nvar REPZ_11_138 = 18;\n/* repeat a zero length 11-138 times  (7 bits of repeat count) */\n\n/* eslint-disable comma-spacing,array-bracket-spacing */\nvar extra_lbits =   /* extra bits for each length code */\n  [0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0];\n\nvar extra_dbits =   /* extra bits for each distance code */\n  [0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13];\n\nvar extra_blbits =  /* extra bits for each bit length code */\n  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,7];\n\nvar bl_order =\n  [16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15];\n/* eslint-enable comma-spacing,array-bracket-spacing */\n\n/* The lengths of the bit length codes are sent in order of decreasing\n * probability, to avoid transmitting the lengths for unused bit length codes.\n */\n\n/* ===========================================================================\n * Local data. These are initialized only once.\n */\n\n// We pre-fill arrays with 0 to avoid uninitialized gaps\n\nvar DIST_CODE_LEN = 512; /* see definition of array dist_code below */\n\n// !!!! Use flat array instead of structure, Freq = i*2, Len = i*2+1\nvar static_ltree  = new Array((L_CODES + 2) * 2);\nzero(static_ltree);\n/* The static literal tree. Since the bit lengths are imposed, there is no\n * need for the L_CODES extra codes used during heap construction. However\n * The codes 286 and 287 are needed to build a canonical tree (see _tr_init\n * below).\n */\n\nvar static_dtree  = new Array(D_CODES * 2);\nzero(static_dtree);\n/* The static distance tree. (Actually a trivial tree since all codes use\n * 5 bits.)\n */\n\nvar _dist_code    = new Array(DIST_CODE_LEN);\nzero(_dist_code);\n/* Distance codes. The first 256 values correspond to the distances\n * 3 .. 258, the last 256 values correspond to the top 8 bits of\n * the 15 bit distances.\n */\n\nvar _length_code  = new Array(MAX_MATCH - MIN_MATCH + 1);\nzero(_length_code);\n/* length code for each normalized match length (0 == MIN_MATCH) */\n\nvar base_length   = new Array(LENGTH_CODES);\nzero(base_length);\n/* First normalized length for each code (0 = MIN_MATCH) */\n\nvar base_dist     = new Array(D_CODES);\nzero(base_dist);\n/* First normalized distance for each code (0 = distance of 1) */\n\n\nfunction StaticTreeDesc(static_tree, extra_bits, extra_base, elems, max_length) {\n\n  this.static_tree  = static_tree;  /* static tree or NULL */\n  this.extra_bits   = extra_bits;   /* extra bits for each code or NULL */\n  this.extra_base   = extra_base;   /* base index for extra_bits */\n  this.elems        = elems;        /* max number of elements in the tree */\n  this.max_length   = max_length;   /* max bit length for the codes */\n\n  // show if `static_tree` has data or dummy - needed for monomorphic objects\n  this.has_stree    = static_tree && static_tree.length;\n}\n\n\nvar static_l_desc;\nvar static_d_desc;\nvar static_bl_desc;\n\n\nfunction TreeDesc(dyn_tree, stat_desc) {\n  this.dyn_tree = dyn_tree;     /* the dynamic tree */\n  this.max_code = 0;            /* largest code with non zero frequency */\n  this.stat_desc = stat_desc;   /* the corresponding static tree */\n}\n\n\n\nfunction d_code(dist) {\n  return dist < 256 ? _dist_code[dist] : _dist_code[256 + (dist >>> 7)];\n}\n\n\n/* ===========================================================================\n * Output a short LSB first on the stream.\n * IN assertion: there is enough room in pendingBuf.\n */\nfunction put_short(s, w) {\n//    put_byte(s, (uch)((w) & 0xff));\n//    put_byte(s, (uch)((ush)(w) >> 8));\n  s.pending_buf[s.pending++] = (w) & 0xff;\n  s.pending_buf[s.pending++] = (w >>> 8) & 0xff;\n}\n\n\n/* ===========================================================================\n * Send a value on a given number of bits.\n * IN assertion: length <= 16 and value fits in length bits.\n */\nfunction send_bits(s, value, length) {\n  if (s.bi_valid > (Buf_size - length)) {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    put_short(s, s.bi_buf);\n    s.bi_buf = value >> (Buf_size - s.bi_valid);\n    s.bi_valid += length - Buf_size;\n  } else {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    s.bi_valid += length;\n  }\n}\n\n\nfunction send_code(s, c, tree) {\n  send_bits(s, tree[c * 2]/*.Code*/, tree[c * 2 + 1]/*.Len*/);\n}\n\n\n/* ===========================================================================\n * Reverse the first len bits of a code, using straightforward code (a faster\n * method would use a table)\n * IN assertion: 1 <= len <= 15\n */\nfunction bi_reverse(code, len) {\n  var res = 0;\n  do {\n    res |= code & 1;\n    code >>>= 1;\n    res <<= 1;\n  } while (--len > 0);\n  return res >>> 1;\n}\n\n\n/* ===========================================================================\n * Flush the bit buffer, keeping at most 7 bits in it.\n */\nfunction bi_flush(s) {\n  if (s.bi_valid === 16) {\n    put_short(s, s.bi_buf);\n    s.bi_buf = 0;\n    s.bi_valid = 0;\n\n  } else if (s.bi_valid >= 8) {\n    s.pending_buf[s.pending++] = s.bi_buf & 0xff;\n    s.bi_buf >>= 8;\n    s.bi_valid -= 8;\n  }\n}\n\n\n/* ===========================================================================\n * Compute the optimal bit lengths for a tree and update the total bit length\n * for the current block.\n * IN assertion: the fields freq and dad are set, heap[heap_max] and\n *    above are the tree nodes sorted by increasing frequency.\n * OUT assertions: the field len is set to the optimal bit length, the\n *     array bl_count contains the frequencies for each bit length.\n *     The length opt_len is updated; static_len is also updated if stree is\n *     not null.\n */\nfunction gen_bitlen(s, desc)\n//    deflate_state *s;\n//    tree_desc *desc;    /* the tree descriptor */\n{\n  var tree            = desc.dyn_tree;\n  var max_code        = desc.max_code;\n  var stree           = desc.stat_desc.static_tree;\n  var has_stree       = desc.stat_desc.has_stree;\n  var extra           = desc.stat_desc.extra_bits;\n  var base            = desc.stat_desc.extra_base;\n  var max_length      = desc.stat_desc.max_length;\n  var h;              /* heap index */\n  var n, m;           /* iterate over the tree elements */\n  var bits;           /* bit length */\n  var xbits;          /* extra bits */\n  var f;              /* frequency */\n  var overflow = 0;   /* number of elements with bit length too large */\n\n  for (bits = 0; bits <= MAX_BITS; bits++) {\n    s.bl_count[bits] = 0;\n  }\n\n  /* In a first pass, compute the optimal bit lengths (which may\n   * overflow in the case of the bit length tree).\n   */\n  tree[s.heap[s.heap_max] * 2 + 1]/*.Len*/ = 0; /* root of the heap */\n\n  for (h = s.heap_max + 1; h < HEAP_SIZE; h++) {\n    n = s.heap[h];\n    bits = tree[tree[n * 2 + 1]/*.Dad*/ * 2 + 1]/*.Len*/ + 1;\n    if (bits > max_length) {\n      bits = max_length;\n      overflow++;\n    }\n    tree[n * 2 + 1]/*.Len*/ = bits;\n    /* We overwrite tree[n].Dad which is no longer needed */\n\n    if (n > max_code) { continue; } /* not a leaf node */\n\n    s.bl_count[bits]++;\n    xbits = 0;\n    if (n >= base) {\n      xbits = extra[n - base];\n    }\n    f = tree[n * 2]/*.Freq*/;\n    s.opt_len += f * (bits + xbits);\n    if (has_stree) {\n      s.static_len += f * (stree[n * 2 + 1]/*.Len*/ + xbits);\n    }\n  }\n  if (overflow === 0) { return; }\n\n  // Trace((stderr,\"\\nbit length overflow\\n\"));\n  /* This happens for example on obj2 and pic of the Calgary corpus */\n\n  /* Find the first bit length which could increase: */\n  do {\n    bits = max_length - 1;\n    while (s.bl_count[bits] === 0) { bits--; }\n    s.bl_count[bits]--;      /* move one leaf down the tree */\n    s.bl_count[bits + 1] += 2; /* move one overflow item as its brother */\n    s.bl_count[max_length]--;\n    /* The brother of the overflow item also moves one step up,\n     * but this does not affect bl_count[max_length]\n     */\n    overflow -= 2;\n  } while (overflow > 0);\n\n  /* Now recompute all bit lengths, scanning in increasing frequency.\n   * h is still equal to HEAP_SIZE. (It is simpler to reconstruct all\n   * lengths instead of fixing only the wrong ones. This idea is taken\n   * from 'ar' written by Haruhiko Okumura.)\n   */\n  for (bits = max_length; bits !== 0; bits--) {\n    n = s.bl_count[bits];\n    while (n !== 0) {\n      m = s.heap[--h];\n      if (m > max_code) { continue; }\n      if (tree[m * 2 + 1]/*.Len*/ !== bits) {\n        // Trace((stderr,\"code %d bits %d->%d\\n\", m, tree[m].Len, bits));\n        s.opt_len += (bits - tree[m * 2 + 1]/*.Len*/) * tree[m * 2]/*.Freq*/;\n        tree[m * 2 + 1]/*.Len*/ = bits;\n      }\n      n--;\n    }\n  }\n}\n\n\n/* ===========================================================================\n * Generate the codes for a given tree and bit counts (which need not be\n * optimal).\n * IN assertion: the array bl_count contains the bit length statistics for\n * the given tree and the field len is set for all tree elements.\n * OUT assertion: the field code is set for all tree elements of non\n *     zero code length.\n */\nfunction gen_codes(tree, max_code, bl_count)\n//    ct_data *tree;             /* the tree to decorate */\n//    int max_code;              /* largest code with non zero frequency */\n//    ushf *bl_count;            /* number of codes at each bit length */\n{\n  var next_code = new Array(MAX_BITS + 1); /* next code value for each bit length */\n  var code = 0;              /* running code value */\n  var bits;                  /* bit index */\n  var n;                     /* code index */\n\n  /* The distribution counts are first used to generate the code values\n   * without bit reversal.\n   */\n  for (bits = 1; bits <= MAX_BITS; bits++) {\n    next_code[bits] = code = (code + bl_count[bits - 1]) << 1;\n  }\n  /* Check that the bit counts in bl_count are consistent. The last code\n   * must be all ones.\n   */\n  //Assert (code + bl_count[MAX_BITS]-1 == (1<<MAX_BITS)-1,\n  //        \"inconsistent bit counts\");\n  //Tracev((stderr,\"\\ngen_codes: max_code %d \", max_code));\n\n  for (n = 0;  n <= max_code; n++) {\n    var len = tree[n * 2 + 1]/*.Len*/;\n    if (len === 0) { continue; }\n    /* Now reverse the bits */\n    tree[n * 2]/*.Code*/ = bi_reverse(next_code[len]++, len);\n\n    //Tracecv(tree != static_ltree, (stderr,\"\\nn %3d %c l %2d c %4x (%x) \",\n    //     n, (isgraph(n) ? n : ' '), len, tree[n].Code, next_code[len]-1));\n  }\n}\n\n\n/* ===========================================================================\n * Initialize the various 'constant' tables.\n */\nfunction tr_static_init() {\n  var n;        /* iterates over tree elements */\n  var bits;     /* bit counter */\n  var length;   /* length value */\n  var code;     /* code value */\n  var dist;     /* distance index */\n  var bl_count = new Array(MAX_BITS + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  // do check in _tr_init()\n  //if (static_init_done) return;\n\n  /* For some embedded targets, global variables are not initialized: */\n/*#ifdef NO_INIT_GLOBAL_POINTERS\n  static_l_desc.static_tree = static_ltree;\n  static_l_desc.extra_bits = extra_lbits;\n  static_d_desc.static_tree = static_dtree;\n  static_d_desc.extra_bits = extra_dbits;\n  static_bl_desc.extra_bits = extra_blbits;\n#endif*/\n\n  /* Initialize the mapping length (0..255) -> length code (0..28) */\n  length = 0;\n  for (code = 0; code < LENGTH_CODES - 1; code++) {\n    base_length[code] = length;\n    for (n = 0; n < (1 << extra_lbits[code]); n++) {\n      _length_code[length++] = code;\n    }\n  }\n  //Assert (length == 256, \"tr_static_init: length != 256\");\n  /* Note that the length 255 (match length 258) can be represented\n   * in two different ways: code 284 + 5 bits or code 285, so we\n   * overwrite length_code[255] to use the best encoding:\n   */\n  _length_code[length - 1] = code;\n\n  /* Initialize the mapping dist (0..32K) -> dist code (0..29) */\n  dist = 0;\n  for (code = 0; code < 16; code++) {\n    base_dist[code] = dist;\n    for (n = 0; n < (1 << extra_dbits[code]); n++) {\n      _dist_code[dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: dist != 256\");\n  dist >>= 7; /* from now on, all distances are divided by 128 */\n  for (; code < D_CODES; code++) {\n    base_dist[code] = dist << 7;\n    for (n = 0; n < (1 << (extra_dbits[code] - 7)); n++) {\n      _dist_code[256 + dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: 256+dist != 512\");\n\n  /* Construct the codes of the static literal tree */\n  for (bits = 0; bits <= MAX_BITS; bits++) {\n    bl_count[bits] = 0;\n  }\n\n  n = 0;\n  while (n <= 143) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  while (n <= 255) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 9;\n    n++;\n    bl_count[9]++;\n  }\n  while (n <= 279) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 7;\n    n++;\n    bl_count[7]++;\n  }\n  while (n <= 287) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  /* Codes 286 and 287 do not exist, but we must include them in the\n   * tree construction to get a canonical Huffman tree (longest code\n   * all ones)\n   */\n  gen_codes(static_ltree, L_CODES + 1, bl_count);\n\n  /* The static distance tree is trivial: */\n  for (n = 0; n < D_CODES; n++) {\n    static_dtree[n * 2 + 1]/*.Len*/ = 5;\n    static_dtree[n * 2]/*.Code*/ = bi_reverse(n, 5);\n  }\n\n  // Now data ready and we can init static trees\n  static_l_desc = new StaticTreeDesc(static_ltree, extra_lbits, LITERALS + 1, L_CODES, MAX_BITS);\n  static_d_desc = new StaticTreeDesc(static_dtree, extra_dbits, 0,          D_CODES, MAX_BITS);\n  static_bl_desc = new StaticTreeDesc(new Array(0), extra_blbits, 0,         BL_CODES, MAX_BL_BITS);\n\n  //static_init_done = true;\n}\n\n\n/* ===========================================================================\n * Initialize a new block.\n */\nfunction init_block(s) {\n  var n; /* iterates over tree elements */\n\n  /* Initialize the trees. */\n  for (n = 0; n < L_CODES;  n++) { s.dyn_ltree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < D_CODES;  n++) { s.dyn_dtree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < BL_CODES; n++) { s.bl_tree[n * 2]/*.Freq*/ = 0; }\n\n  s.dyn_ltree[END_BLOCK * 2]/*.Freq*/ = 1;\n  s.opt_len = s.static_len = 0;\n  s.last_lit = s.matches = 0;\n}\n\n\n/* ===========================================================================\n * Flush the bit buffer and align the output on a byte boundary\n */\nfunction bi_windup(s)\n{\n  if (s.bi_valid > 8) {\n    put_short(s, s.bi_buf);\n  } else if (s.bi_valid > 0) {\n    //put_byte(s, (Byte)s->bi_buf);\n    s.pending_buf[s.pending++] = s.bi_buf;\n  }\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n}\n\n/* ===========================================================================\n * Copy a stored block, storing first the length and its\n * one's complement if requested.\n */\nfunction copy_block(s, buf, len, header)\n//DeflateState *s;\n//charf    *buf;    /* the input data */\n//unsigned len;     /* its length */\n//int      header;  /* true if block header must be written */\n{\n  bi_windup(s);        /* align on byte boundary */\n\n  if (header) {\n    put_short(s, len);\n    put_short(s, ~len);\n  }\n//  while (len--) {\n//    put_byte(s, *buf++);\n//  }\n  utils.arraySet(s.pending_buf, s.window, buf, len, s.pending);\n  s.pending += len;\n}\n\n/* ===========================================================================\n * Compares to subtrees, using the tree depth as tie breaker when\n * the subtrees have equal frequency. This minimizes the worst case length.\n */\nfunction smaller(tree, n, m, depth) {\n  var _n2 = n * 2;\n  var _m2 = m * 2;\n  return (tree[_n2]/*.Freq*/ < tree[_m2]/*.Freq*/ ||\n         (tree[_n2]/*.Freq*/ === tree[_m2]/*.Freq*/ && depth[n] <= depth[m]));\n}\n\n/* ===========================================================================\n * Restore the heap property by moving down the tree starting at node k,\n * exchanging a node with the smallest of its two sons if necessary, stopping\n * when the heap property is re-established (each father smaller than its\n * two sons).\n */\nfunction pqdownheap(s, tree, k)\n//    deflate_state *s;\n//    ct_data *tree;  /* the tree to restore */\n//    int k;               /* node to move down */\n{\n  var v = s.heap[k];\n  var j = k << 1;  /* left son of k */\n  while (j <= s.heap_len) {\n    /* Set j to the smallest of the two sons: */\n    if (j < s.heap_len &&\n      smaller(tree, s.heap[j + 1], s.heap[j], s.depth)) {\n      j++;\n    }\n    /* Exit if v is smaller than both sons */\n    if (smaller(tree, v, s.heap[j], s.depth)) { break; }\n\n    /* Exchange v with the smallest son */\n    s.heap[k] = s.heap[j];\n    k = j;\n\n    /* And continue down the tree, setting j to the left son of k */\n    j <<= 1;\n  }\n  s.heap[k] = v;\n}\n\n\n// inlined manually\n// var SMALLEST = 1;\n\n/* ===========================================================================\n * Send the block data compressed using the given Huffman trees\n */\nfunction compress_block(s, ltree, dtree)\n//    deflate_state *s;\n//    const ct_data *ltree; /* literal tree */\n//    const ct_data *dtree; /* distance tree */\n{\n  var dist;           /* distance of matched string */\n  var lc;             /* match length or unmatched char (if dist == 0) */\n  var lx = 0;         /* running index in l_buf */\n  var code;           /* the code to send */\n  var extra;          /* number of extra bits to send */\n\n  if (s.last_lit !== 0) {\n    do {\n      dist = (s.pending_buf[s.d_buf + lx * 2] << 8) | (s.pending_buf[s.d_buf + lx * 2 + 1]);\n      lc = s.pending_buf[s.l_buf + lx];\n      lx++;\n\n      if (dist === 0) {\n        send_code(s, lc, ltree); /* send a literal byte */\n        //Tracecv(isgraph(lc), (stderr,\" '%c' \", lc));\n      } else {\n        /* Here, lc is the match length - MIN_MATCH */\n        code = _length_code[lc];\n        send_code(s, code + LITERALS + 1, ltree); /* send the length code */\n        extra = extra_lbits[code];\n        if (extra !== 0) {\n          lc -= base_length[code];\n          send_bits(s, lc, extra);       /* send the extra length bits */\n        }\n        dist--; /* dist is now the match distance - 1 */\n        code = d_code(dist);\n        //Assert (code < D_CODES, \"bad d_code\");\n\n        send_code(s, code, dtree);       /* send the distance code */\n        extra = extra_dbits[code];\n        if (extra !== 0) {\n          dist -= base_dist[code];\n          send_bits(s, dist, extra);   /* send the extra distance bits */\n        }\n      } /* literal or match pair ? */\n\n      /* Check that the overlay between pending_buf and d_buf+l_buf is ok: */\n      //Assert((uInt)(s->pending) < s->lit_bufsize + 2*lx,\n      //       \"pendingBuf overflow\");\n\n    } while (lx < s.last_lit);\n  }\n\n  send_code(s, END_BLOCK, ltree);\n}\n\n\n/* ===========================================================================\n * Construct one Huffman tree and assigns the code bit strings and lengths.\n * Update the total bit length for the current block.\n * IN assertion: the field freq is set for all tree elements.\n * OUT assertions: the fields len and code are set to the optimal bit length\n *     and corresponding code. The length opt_len is updated; static_len is\n *     also updated if stree is not null. The field max_code is set.\n */\nfunction build_tree(s, desc)\n//    deflate_state *s;\n//    tree_desc *desc; /* the tree descriptor */\n{\n  var tree     = desc.dyn_tree;\n  var stree    = desc.stat_desc.static_tree;\n  var has_stree = desc.stat_desc.has_stree;\n  var elems    = desc.stat_desc.elems;\n  var n, m;          /* iterate over heap elements */\n  var max_code = -1; /* largest code with non zero frequency */\n  var node;          /* new node being created */\n\n  /* Construct the initial heap, with least frequent element in\n   * heap[SMALLEST]. The sons of heap[n] are heap[2*n] and heap[2*n+1].\n   * heap[0] is not used.\n   */\n  s.heap_len = 0;\n  s.heap_max = HEAP_SIZE;\n\n  for (n = 0; n < elems; n++) {\n    if (tree[n * 2]/*.Freq*/ !== 0) {\n      s.heap[++s.heap_len] = max_code = n;\n      s.depth[n] = 0;\n\n    } else {\n      tree[n * 2 + 1]/*.Len*/ = 0;\n    }\n  }\n\n  /* The pkzip format requires that at least one distance code exists,\n   * and that at least one bit should be sent even if there is only one\n   * possible code. So to avoid special checks later on we force at least\n   * two codes of non zero frequency.\n   */\n  while (s.heap_len < 2) {\n    node = s.heap[++s.heap_len] = (max_code < 2 ? ++max_code : 0);\n    tree[node * 2]/*.Freq*/ = 1;\n    s.depth[node] = 0;\n    s.opt_len--;\n\n    if (has_stree) {\n      s.static_len -= stree[node * 2 + 1]/*.Len*/;\n    }\n    /* node is 0 or 1 so it does not have extra bits */\n  }\n  desc.max_code = max_code;\n\n  /* The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree,\n   * establish sub-heaps of increasing lengths:\n   */\n  for (n = (s.heap_len >> 1/*int /2*/); n >= 1; n--) { pqdownheap(s, tree, n); }\n\n  /* Construct the Huffman tree by repeatedly combining the least two\n   * frequent nodes.\n   */\n  node = elems;              /* next internal node of the tree */\n  do {\n    //pqremove(s, tree, n);  /* n = node of least frequency */\n    /*** pqremove ***/\n    n = s.heap[1/*SMALLEST*/];\n    s.heap[1/*SMALLEST*/] = s.heap[s.heap_len--];\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n    /***/\n\n    m = s.heap[1/*SMALLEST*/]; /* m = node of next least frequency */\n\n    s.heap[--s.heap_max] = n; /* keep the nodes sorted by frequency */\n    s.heap[--s.heap_max] = m;\n\n    /* Create a new node father of n and m */\n    tree[node * 2]/*.Freq*/ = tree[n * 2]/*.Freq*/ + tree[m * 2]/*.Freq*/;\n    s.depth[node] = (s.depth[n] >= s.depth[m] ? s.depth[n] : s.depth[m]) + 1;\n    tree[n * 2 + 1]/*.Dad*/ = tree[m * 2 + 1]/*.Dad*/ = node;\n\n    /* and insert the new node in the heap */\n    s.heap[1/*SMALLEST*/] = node++;\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n\n  } while (s.heap_len >= 2);\n\n  s.heap[--s.heap_max] = s.heap[1/*SMALLEST*/];\n\n  /* At this point, the fields freq and dad are set. We can now\n   * generate the bit lengths.\n   */\n  gen_bitlen(s, desc);\n\n  /* The field len is now set, we can generate the bit codes */\n  gen_codes(tree, max_code, s.bl_count);\n}\n\n\n/* ===========================================================================\n * Scan a literal or distance tree to determine the frequencies of the codes\n * in the bit length tree.\n */\nfunction scan_tree(s, tree, max_code)\n//    deflate_state *s;\n//    ct_data *tree;   /* the tree to be scanned */\n//    int max_code;    /* and its largest code of non zero frequency */\n{\n  var n;                     /* iterates over all tree elements */\n  var prevlen = -1;          /* last emitted length */\n  var curlen;                /* length of current code */\n\n  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  var count = 0;             /* repeat count of the current code */\n  var max_count = 7;         /* max repeat count */\n  var min_count = 4;         /* min repeat count */\n\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n  tree[(max_code + 1) * 2 + 1]/*.Len*/ = 0xffff; /* guard */\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      s.bl_tree[curlen * 2]/*.Freq*/ += count;\n\n    } else if (curlen !== 0) {\n\n      if (curlen !== prevlen) { s.bl_tree[curlen * 2]/*.Freq*/++; }\n      s.bl_tree[REP_3_6 * 2]/*.Freq*/++;\n\n    } else if (count <= 10) {\n      s.bl_tree[REPZ_3_10 * 2]/*.Freq*/++;\n\n    } else {\n      s.bl_tree[REPZ_11_138 * 2]/*.Freq*/++;\n    }\n\n    count = 0;\n    prevlen = curlen;\n\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n}\n\n\n/* ===========================================================================\n * Send a literal or distance tree in compressed form, using the codes in\n * bl_tree.\n */\nfunction send_tree(s, tree, max_code)\n//    deflate_state *s;\n//    ct_data *tree; /* the tree to be scanned */\n//    int max_code;       /* and its largest code of non zero frequency */\n{\n  var n;                     /* iterates over all tree elements */\n  var prevlen = -1;          /* last emitted length */\n  var curlen;                /* length of current code */\n\n  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  var count = 0;             /* repeat count of the current code */\n  var max_count = 7;         /* max repeat count */\n  var min_count = 4;         /* min repeat count */\n\n  /* tree[max_code+1].Len = -1; */  /* guard already set */\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      do { send_code(s, curlen, s.bl_tree); } while (--count !== 0);\n\n    } else if (curlen !== 0) {\n      if (curlen !== prevlen) {\n        send_code(s, curlen, s.bl_tree);\n        count--;\n      }\n      //Assert(count >= 3 && count <= 6, \" 3_6?\");\n      send_code(s, REP_3_6, s.bl_tree);\n      send_bits(s, count - 3, 2);\n\n    } else if (count <= 10) {\n      send_code(s, REPZ_3_10, s.bl_tree);\n      send_bits(s, count - 3, 3);\n\n    } else {\n      send_code(s, REPZ_11_138, s.bl_tree);\n      send_bits(s, count - 11, 7);\n    }\n\n    count = 0;\n    prevlen = curlen;\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n}\n\n\n/* ===========================================================================\n * Construct the Huffman tree for the bit lengths and return the index in\n * bl_order of the last bit length code to send.\n */\nfunction build_bl_tree(s) {\n  var max_blindex;  /* index of last bit length code of non zero freq */\n\n  /* Determine the bit length frequencies for literal and distance trees */\n  scan_tree(s, s.dyn_ltree, s.l_desc.max_code);\n  scan_tree(s, s.dyn_dtree, s.d_desc.max_code);\n\n  /* Build the bit length tree: */\n  build_tree(s, s.bl_desc);\n  /* opt_len now includes the length of the tree representations, except\n   * the lengths of the bit lengths codes and the 5+5+4 bits for the counts.\n   */\n\n  /* Determine the number of bit length codes to send. The pkzip format\n   * requires that at least 4 bit length codes be sent. (appnote.txt says\n   * 3 but the actual value used is 4.)\n   */\n  for (max_blindex = BL_CODES - 1; max_blindex >= 3; max_blindex--) {\n    if (s.bl_tree[bl_order[max_blindex] * 2 + 1]/*.Len*/ !== 0) {\n      break;\n    }\n  }\n  /* Update opt_len to include the bit length tree and counts */\n  s.opt_len += 3 * (max_blindex + 1) + 5 + 5 + 4;\n  //Tracev((stderr, \"\\ndyn trees: dyn %ld, stat %ld\",\n  //        s->opt_len, s->static_len));\n\n  return max_blindex;\n}\n\n\n/* ===========================================================================\n * Send the header for a block using dynamic Huffman trees: the counts, the\n * lengths of the bit length codes, the literal tree and the distance tree.\n * IN assertion: lcodes >= 257, dcodes >= 1, blcodes >= 4.\n */\nfunction send_all_trees(s, lcodes, dcodes, blcodes)\n//    deflate_state *s;\n//    int lcodes, dcodes, blcodes; /* number of codes for each tree */\n{\n  var rank;                    /* index in bl_order */\n\n  //Assert (lcodes >= 257 && dcodes >= 1 && blcodes >= 4, \"not enough codes\");\n  //Assert (lcodes <= L_CODES && dcodes <= D_CODES && blcodes <= BL_CODES,\n  //        \"too many codes\");\n  //Tracev((stderr, \"\\nbl counts: \"));\n  send_bits(s, lcodes - 257, 5); /* not +255 as stated in appnote.txt */\n  send_bits(s, dcodes - 1,   5);\n  send_bits(s, blcodes - 4,  4); /* not -3 as stated in appnote.txt */\n  for (rank = 0; rank < blcodes; rank++) {\n    //Tracev((stderr, \"\\nbl code %2d \", bl_order[rank]));\n    send_bits(s, s.bl_tree[bl_order[rank] * 2 + 1]/*.Len*/, 3);\n  }\n  //Tracev((stderr, \"\\nbl tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_ltree, lcodes - 1); /* literal tree */\n  //Tracev((stderr, \"\\nlit tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_dtree, dcodes - 1); /* distance tree */\n  //Tracev((stderr, \"\\ndist tree: sent %ld\", s->bits_sent));\n}\n\n\n/* ===========================================================================\n * Check if the data type is TEXT or BINARY, using the following algorithm:\n * - TEXT if the two conditions below are satisfied:\n *    a) There are no non-portable control characters belonging to the\n *       \"black list\" (0..6, 14..25, 28..31).\n *    b) There is at least one printable character belonging to the\n *       \"white list\" (9 {TAB}, 10 {LF}, 13 {CR}, 32..255).\n * - BINARY otherwise.\n * - The following partially-portable control characters form a\n *   \"gray list\" that is ignored in this detection algorithm:\n *   (7 {BEL}, 8 {BS}, 11 {VT}, 12 {FF}, 26 {SUB}, 27 {ESC}).\n * IN assertion: the fields Freq of dyn_ltree are set.\n */\nfunction detect_data_type(s) {\n  /* black_mask is the bit mask of black-listed bytes\n   * set bits 0..6, 14..25, and 28..31\n   * 0xf3ffc07f = binary 11110011111111111100000001111111\n   */\n  var black_mask = 0xf3ffc07f;\n  var n;\n\n  /* Check for non-textual (\"black-listed\") bytes. */\n  for (n = 0; n <= 31; n++, black_mask >>>= 1) {\n    if ((black_mask & 1) && (s.dyn_ltree[n * 2]/*.Freq*/ !== 0)) {\n      return Z_BINARY;\n    }\n  }\n\n  /* Check for textual (\"white-listed\") bytes. */\n  if (s.dyn_ltree[9 * 2]/*.Freq*/ !== 0 || s.dyn_ltree[10 * 2]/*.Freq*/ !== 0 ||\n      s.dyn_ltree[13 * 2]/*.Freq*/ !== 0) {\n    return Z_TEXT;\n  }\n  for (n = 32; n < LITERALS; n++) {\n    if (s.dyn_ltree[n * 2]/*.Freq*/ !== 0) {\n      return Z_TEXT;\n    }\n  }\n\n  /* There are no \"black-listed\" or \"white-listed\" bytes:\n   * this stream either is empty or has tolerated (\"gray-listed\") bytes only.\n   */\n  return Z_BINARY;\n}\n\n\nvar static_init_done = false;\n\n/* ===========================================================================\n * Initialize the tree data structures for a new zlib stream.\n */\nfunction _tr_init(s)\n{\n\n  if (!static_init_done) {\n    tr_static_init();\n    static_init_done = true;\n  }\n\n  s.l_desc  = new TreeDesc(s.dyn_ltree, static_l_desc);\n  s.d_desc  = new TreeDesc(s.dyn_dtree, static_d_desc);\n  s.bl_desc = new TreeDesc(s.bl_tree, static_bl_desc);\n\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n\n  /* Initialize the first block of the first file: */\n  init_block(s);\n}\n\n\n/* ===========================================================================\n * Send a stored block\n */\nfunction _tr_stored_block(s, buf, stored_len, last)\n//DeflateState *s;\n//charf *buf;       /* input block */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n{\n  send_bits(s, (STORED_BLOCK << 1) + (last ? 1 : 0), 3);    /* send block type */\n  copy_block(s, buf, stored_len, true); /* with header */\n}\n\n\n/* ===========================================================================\n * Send one empty static block to give enough lookahead for inflate.\n * This takes 10 bits, of which 7 may remain in the bit buffer.\n */\nfunction _tr_align(s) {\n  send_bits(s, STATIC_TREES << 1, 3);\n  send_code(s, END_BLOCK, static_ltree);\n  bi_flush(s);\n}\n\n\n/* ===========================================================================\n * Determine the best encoding for the current block: dynamic trees, static\n * trees or store, and output the encoded block to the zip file.\n */\nfunction _tr_flush_block(s, buf, stored_len, last)\n//DeflateState *s;\n//charf *buf;       /* input block, or NULL if too old */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n{\n  var opt_lenb, static_lenb;  /* opt_len and static_len in bytes */\n  var max_blindex = 0;        /* index of last bit length code of non zero freq */\n\n  /* Build the Huffman trees unless a stored block is forced */\n  if (s.level > 0) {\n\n    /* Check if the file is binary or text */\n    if (s.strm.data_type === Z_UNKNOWN) {\n      s.strm.data_type = detect_data_type(s);\n    }\n\n    /* Construct the literal and distance trees */\n    build_tree(s, s.l_desc);\n    // Tracev((stderr, \"\\nlit data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n\n    build_tree(s, s.d_desc);\n    // Tracev((stderr, \"\\ndist data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n    /* At this point, opt_len and static_len are the total bit lengths of\n     * the compressed block data, excluding the tree representations.\n     */\n\n    /* Build the bit length tree for the above two trees, and get the index\n     * in bl_order of the last bit length code to send.\n     */\n    max_blindex = build_bl_tree(s);\n\n    /* Determine the best encoding. Compute the block lengths in bytes. */\n    opt_lenb = (s.opt_len + 3 + 7) >>> 3;\n    static_lenb = (s.static_len + 3 + 7) >>> 3;\n\n    // Tracev((stderr, \"\\nopt %lu(%lu) stat %lu(%lu) stored %lu lit %u \",\n    //        opt_lenb, s->opt_len, static_lenb, s->static_len, stored_len,\n    //        s->last_lit));\n\n    if (static_lenb <= opt_lenb) { opt_lenb = static_lenb; }\n\n  } else {\n    // Assert(buf != (char*)0, \"lost buf\");\n    opt_lenb = static_lenb = stored_len + 5; /* force a stored block */\n  }\n\n  if ((stored_len + 4 <= opt_lenb) && (buf !== -1)) {\n    /* 4: two words for the lengths */\n\n    /* The test buf != NULL is only necessary if LIT_BUFSIZE > WSIZE.\n     * Otherwise we can't have processed more than WSIZE input bytes since\n     * the last block flush, because compression would have been\n     * successful. If LIT_BUFSIZE <= WSIZE, it is never too late to\n     * transform a block into a stored block.\n     */\n    _tr_stored_block(s, buf, stored_len, last);\n\n  } else if (s.strategy === Z_FIXED || static_lenb === opt_lenb) {\n\n    send_bits(s, (STATIC_TREES << 1) + (last ? 1 : 0), 3);\n    compress_block(s, static_ltree, static_dtree);\n\n  } else {\n    send_bits(s, (DYN_TREES << 1) + (last ? 1 : 0), 3);\n    send_all_trees(s, s.l_desc.max_code + 1, s.d_desc.max_code + 1, max_blindex + 1);\n    compress_block(s, s.dyn_ltree, s.dyn_dtree);\n  }\n  // Assert (s->compressed_len == s->bits_sent, \"bad compressed size\");\n  /* The above check is made mod 2^32, for files larger than 512 MB\n   * and uLong implemented on 32 bits.\n   */\n  init_block(s);\n\n  if (last) {\n    bi_windup(s);\n  }\n  // Tracev((stderr,\"\\ncomprlen %lu(%lu) \", s->compressed_len>>3,\n  //       s->compressed_len-7*last));\n}\n\n/* ===========================================================================\n * Save the match info and tally the frequency counts. Return true if\n * the current block must be flushed.\n */\nfunction _tr_tally(s, dist, lc)\n//    deflate_state *s;\n//    unsigned dist;  /* distance of matched string */\n//    unsigned lc;    /* match length-MIN_MATCH or unmatched char (if dist==0) */\n{\n  //var out_length, in_length, dcode;\n\n  s.pending_buf[s.d_buf + s.last_lit * 2]     = (dist >>> 8) & 0xff;\n  s.pending_buf[s.d_buf + s.last_lit * 2 + 1] = dist & 0xff;\n\n  s.pending_buf[s.l_buf + s.last_lit] = lc & 0xff;\n  s.last_lit++;\n\n  if (dist === 0) {\n    /* lc is the unmatched char */\n    s.dyn_ltree[lc * 2]/*.Freq*/++;\n  } else {\n    s.matches++;\n    /* Here, lc is the match length - MIN_MATCH */\n    dist--;             /* dist = match distance - 1 */\n    //Assert((ush)dist < (ush)MAX_DIST(s) &&\n    //       (ush)lc <= (ush)(MAX_MATCH-MIN_MATCH) &&\n    //       (ush)d_code(dist) < (ush)D_CODES,  \"_tr_tally: bad match\");\n\n    s.dyn_ltree[(_length_code[lc] + LITERALS + 1) * 2]/*.Freq*/++;\n    s.dyn_dtree[d_code(dist) * 2]/*.Freq*/++;\n  }\n\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n\n//#ifdef TRUNCATE_BLOCK\n//  /* Try to guess if it is profitable to stop the current block here */\n//  if ((s.last_lit & 0x1fff) === 0 && s.level > 2) {\n//    /* Compute an upper bound for the compressed length */\n//    out_length = s.last_lit*8;\n//    in_length = s.strstart - s.block_start;\n//\n//    for (dcode = 0; dcode < D_CODES; dcode++) {\n//      out_length += s.dyn_dtree[dcode*2]/*.Freq*/ * (5 + extra_dbits[dcode]);\n//    }\n//    out_length >>>= 3;\n//    //Tracev((stderr,\"\\nlast_lit %u, in %ld, out ~%ld(%ld%%) \",\n//    //       s->last_lit, in_length, out_length,\n//    //       100L - out_length*100L/in_length));\n//    if (s.matches < (s.last_lit>>1)/*int /2*/ && out_length < (in_length>>1)/*int /2*/) {\n//      return true;\n//    }\n//  }\n//#endif\n\n  return (s.last_lit === s.lit_bufsize - 1);\n  /* We avoid equality with lit_bufsize because of wraparound at 64K\n   * on 16 bit machines and because stored blocks are restricted to\n   * 64K-1 bytes.\n   */\n}\n\nexports._tr_init  = _tr_init;\nexports._tr_stored_block = _tr_stored_block;\nexports._tr_flush_block  = _tr_flush_block;\nexports._tr_tally = _tr_tally;\nexports._tr_align = _tr_align;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/trees.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/zstream.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/zstream.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction ZStream() {\n  /* next input byte */\n  this.input = null; // JS specific, because we have no pointers\n  this.next_in = 0;\n  /* number of bytes available at input */\n  this.avail_in = 0;\n  /* total number of input bytes read so far */\n  this.total_in = 0;\n  /* next output byte should be put there */\n  this.output = null; // JS specific, because we have no pointers\n  this.next_out = 0;\n  /* remaining free space at output */\n  this.avail_out = 0;\n  /* total number of bytes output so far */\n  this.total_out = 0;\n  /* last error message, NULL if no error */\n  this.msg = ''/*Z_NULL*/;\n  /* not visible by applications */\n  this.state = null;\n  /* best guess about the data type: binary or text */\n  this.data_type = 2/*Z_UNKNOWN*/;\n  /* adler32 value of the uncompressed data */\n  this.adler = 0;\n}\n\nmodule.exports = ZStream;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/zstream.js?");

/***/ }),

/***/ "./node_modules/path-is-absolute/index.js":
/*!************************************************!*\
  !*** ./node_modules/path-is-absolute/index.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nfunction posix(path) {\n\treturn path.charAt(0) === '/';\n}\n\nfunction win32(path) {\n\t// https://github.com/nodejs/node/blob/b3fcc245fb25539909ef1d5eaa01dbf92e168633/lib/path.js#L56\n\tvar splitDeviceRe = /^([a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/]+)?([\\\\\\/])?([\\s\\S]*?)$/;\n\tvar result = splitDeviceRe.exec(path);\n\tvar device = result[1] || '';\n\tvar isUnc = Boolean(device && device.charAt(1) !== ':');\n\n\t// UNC paths are always absolute\n\treturn Boolean(result[2] || isUnc);\n}\n\nmodule.exports = process.platform === 'win32' ? win32 : posix;\nmodule.exports.posix = posix;\nmodule.exports.win32 = win32;\n\n\n//# sourceURL=webpack:///./node_modules/path-is-absolute/index.js?");

/***/ }),

/***/ "./node_modules/process-nextick-args/index.js":
/*!****************************************************!*\
  !*** ./node_modules/process-nextick-args/index.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nif (typeof process === 'undefined' ||\n    !process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = { nextTick: nextTick };\n} else {\n  module.exports = process\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n\n\n\n//# sourceURL=webpack:///./node_modules/process-nextick-args/index.js?");

/***/ }),

/***/ "./node_modules/q/q.js":
/*!*****************************!*\
  !*** ./node_modules/q/q.js ***!
  \*****************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// vim:ts=4:sts=4:sw=4:\n/*!\n *\n * Copyright 2009-2017 Kris Kowal under the terms of the MIT\n * license found at https://github.com/kriskowal/q/blob/v1/LICENSE\n *\n * With parts by Tyler Close\n * Copyright 2007-2009 Tyler Close under the terms of the MIT X license found\n * at http://www.opensource.org/licenses/mit-license.html\n * Forked at ref_send.js version: 2009-05-11\n *\n * With parts by Mark Miller\n * Copyright (C) 2011 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n */\n\n(function (definition) {\n    \"use strict\";\n\n    // This file will function properly as a <script> tag, or a module\n    // using CommonJS and NodeJS or RequireJS module formats.  In\n    // Common/Node/RequireJS, the module exports the Q API and when\n    // executed as a simple <script>, it creates a Q global instead.\n\n    // Montage Require\n    if (typeof bootstrap === \"function\") {\n        bootstrap(\"promise\", definition);\n\n    // CommonJS\n    } else if (true) {\n        module.exports = definition();\n\n    // RequireJS\n    } else { var previousQ, global; }\n\n})(function () {\n\"use strict\";\n\nvar hasStacks = false;\ntry {\n    throw new Error();\n} catch (e) {\n    hasStacks = !!e.stack;\n}\n\n// All code after this point will be filtered from stack traces reported\n// by Q.\nvar qStartingLine = captureLine();\nvar qFileName;\n\n// shims\n\n// used for fallback in \"allResolved\"\nvar noop = function () {};\n\n// Use the fastest possible means to execute a task in a future turn\n// of the event loop.\nvar nextTick =(function () {\n    // linked list of tasks (single, with head node)\n    var head = {task: void 0, next: null};\n    var tail = head;\n    var flushing = false;\n    var requestTick = void 0;\n    var isNodeJS = false;\n    // queue for late tasks, used by unhandled rejection tracking\n    var laterQueue = [];\n\n    function flush() {\n        /* jshint loopfunc: true */\n        var task, domain;\n\n        while (head.next) {\n            head = head.next;\n            task = head.task;\n            head.task = void 0;\n            domain = head.domain;\n\n            if (domain) {\n                head.domain = void 0;\n                domain.enter();\n            }\n            runSingle(task, domain);\n\n        }\n        while (laterQueue.length) {\n            task = laterQueue.pop();\n            runSingle(task);\n        }\n        flushing = false;\n    }\n    // runs a single function in the async queue\n    function runSingle(task, domain) {\n        try {\n            task();\n\n        } catch (e) {\n            if (isNodeJS) {\n                // In node, uncaught exceptions are considered fatal errors.\n                // Re-throw them synchronously to interrupt flushing!\n\n                // Ensure continuation if the uncaught exception is suppressed\n                // listening \"uncaughtException\" events (as domains does).\n                // Continue in next event to avoid tick recursion.\n                if (domain) {\n                    domain.exit();\n                }\n                setTimeout(flush, 0);\n                if (domain) {\n                    domain.enter();\n                }\n\n                throw e;\n\n            } else {\n                // In browsers, uncaught exceptions are not fatal.\n                // Re-throw them asynchronously to avoid slow-downs.\n                setTimeout(function () {\n                    throw e;\n                }, 0);\n            }\n        }\n\n        if (domain) {\n            domain.exit();\n        }\n    }\n\n    nextTick = function (task) {\n        tail = tail.next = {\n            task: task,\n            domain: isNodeJS && process.domain,\n            next: null\n        };\n\n        if (!flushing) {\n            flushing = true;\n            requestTick();\n        }\n    };\n\n    if (typeof process === \"object\" &&\n        process.toString() === \"[object process]\" && process.nextTick) {\n        // Ensure Q is in a real Node environment, with a `process.nextTick`.\n        // To see through fake Node environments:\n        // * Mocha test runner - exposes a `process` global without a `nextTick`\n        // * Browserify - exposes a `process.nexTick` function that uses\n        //   `setTimeout`. In this case `setImmediate` is preferred because\n        //    it is faster. Browserify's `process.toString()` yields\n        //   \"[object Object]\", while in a real Node environment\n        //   `process.toString()` yields \"[object process]\".\n        isNodeJS = true;\n\n        requestTick = function () {\n            process.nextTick(flush);\n        };\n\n    } else if (typeof setImmediate === \"function\") {\n        // In IE10, Node.js 0.9+, or https://github.com/NobleJS/setImmediate\n        if (typeof window !== \"undefined\") {\n            requestTick = setImmediate.bind(window, flush);\n        } else {\n            requestTick = function () {\n                setImmediate(flush);\n            };\n        }\n\n    } else if (typeof MessageChannel !== \"undefined\") {\n        // modern browsers\n        // http://www.nonblocking.io/2011/06/windownexttick.html\n        var channel = new MessageChannel();\n        // At least Safari Version 6.0.5 (8536.30.1) intermittently cannot create\n        // working message ports the first time a page loads.\n        channel.port1.onmessage = function () {\n            requestTick = requestPortTick;\n            channel.port1.onmessage = flush;\n            flush();\n        };\n        var requestPortTick = function () {\n            // Opera requires us to provide a message payload, regardless of\n            // whether we use it.\n            channel.port2.postMessage(0);\n        };\n        requestTick = function () {\n            setTimeout(flush, 0);\n            requestPortTick();\n        };\n\n    } else {\n        // old browsers\n        requestTick = function () {\n            setTimeout(flush, 0);\n        };\n    }\n    // runs a task after all other tasks have been run\n    // this is useful for unhandled rejection tracking that needs to happen\n    // after all `then`d tasks have been run.\n    nextTick.runAfter = function (task) {\n        laterQueue.push(task);\n        if (!flushing) {\n            flushing = true;\n            requestTick();\n        }\n    };\n    return nextTick;\n})();\n\n// Attempt to make generics safe in the face of downstream\n// modifications.\n// There is no situation where this is necessary.\n// If you need a security guarantee, these primordials need to be\n// deeply frozen anyway, and if you dont need a security guarantee,\n// this is just plain paranoid.\n// However, this **might** have the nice side-effect of reducing the size of\n// the minified code by reducing x.call() to merely x()\n// See Mark Millers explanation of what this does.\n// http://wiki.ecmascript.org/doku.php?id=conventions:safe_meta_programming\nvar call = Function.call;\nfunction uncurryThis(f) {\n    return function () {\n        return call.apply(f, arguments);\n    };\n}\n// This is equivalent, but slower:\n// uncurryThis = Function_bind.bind(Function_bind.call);\n// http://jsperf.com/uncurrythis\n\nvar array_slice = uncurryThis(Array.prototype.slice);\n\nvar array_reduce = uncurryThis(\n    Array.prototype.reduce || function (callback, basis) {\n        var index = 0,\n            length = this.length;\n        // concerning the initial value, if one is not provided\n        if (arguments.length === 1) {\n            // seek to the first value in the array, accounting\n            // for the possibility that is is a sparse array\n            do {\n                if (index in this) {\n                    basis = this[index++];\n                    break;\n                }\n                if (++index >= length) {\n                    throw new TypeError();\n                }\n            } while (1);\n        }\n        // reduce\n        for (; index < length; index++) {\n            // account for the possibility that the array is sparse\n            if (index in this) {\n                basis = callback(basis, this[index], index);\n            }\n        }\n        return basis;\n    }\n);\n\nvar array_indexOf = uncurryThis(\n    Array.prototype.indexOf || function (value) {\n        // not a very good shim, but good enough for our one use of it\n        for (var i = 0; i < this.length; i++) {\n            if (this[i] === value) {\n                return i;\n            }\n        }\n        return -1;\n    }\n);\n\nvar array_map = uncurryThis(\n    Array.prototype.map || function (callback, thisp) {\n        var self = this;\n        var collect = [];\n        array_reduce(self, function (undefined, value, index) {\n            collect.push(callback.call(thisp, value, index, self));\n        }, void 0);\n        return collect;\n    }\n);\n\nvar object_create = Object.create || function (prototype) {\n    function Type() { }\n    Type.prototype = prototype;\n    return new Type();\n};\n\nvar object_defineProperty = Object.defineProperty || function (obj, prop, descriptor) {\n    obj[prop] = descriptor.value;\n    return obj;\n};\n\nvar object_hasOwnProperty = uncurryThis(Object.prototype.hasOwnProperty);\n\nvar object_keys = Object.keys || function (object) {\n    var keys = [];\n    for (var key in object) {\n        if (object_hasOwnProperty(object, key)) {\n            keys.push(key);\n        }\n    }\n    return keys;\n};\n\nvar object_toString = uncurryThis(Object.prototype.toString);\n\nfunction isObject(value) {\n    return value === Object(value);\n}\n\n// generator related shims\n\n// FIXME: Remove this function once ES6 generators are in SpiderMonkey.\nfunction isStopIteration(exception) {\n    return (\n        object_toString(exception) === \"[object StopIteration]\" ||\n        exception instanceof QReturnValue\n    );\n}\n\n// FIXME: Remove this helper and Q.return once ES6 generators are in\n// SpiderMonkey.\nvar QReturnValue;\nif (typeof ReturnValue !== \"undefined\") {\n    QReturnValue = ReturnValue;\n} else {\n    QReturnValue = function (value) {\n        this.value = value;\n    };\n}\n\n// long stack traces\n\nvar STACK_JUMP_SEPARATOR = \"From previous event:\";\n\nfunction makeStackTraceLong(error, promise) {\n    // If possible, transform the error stack trace by removing Node and Q\n    // cruft, then concatenating with the stack trace of `promise`. See #57.\n    if (hasStacks &&\n        promise.stack &&\n        typeof error === \"object\" &&\n        error !== null &&\n        error.stack\n    ) {\n        var stacks = [];\n        for (var p = promise; !!p; p = p.source) {\n            if (p.stack && (!error.__minimumStackCounter__ || error.__minimumStackCounter__ > p.stackCounter)) {\n                object_defineProperty(error, \"__minimumStackCounter__\", {value: p.stackCounter, configurable: true});\n                stacks.unshift(p.stack);\n            }\n        }\n        stacks.unshift(error.stack);\n\n        var concatedStacks = stacks.join(\"\\n\" + STACK_JUMP_SEPARATOR + \"\\n\");\n        var stack = filterStackString(concatedStacks);\n        object_defineProperty(error, \"stack\", {value: stack, configurable: true});\n    }\n}\n\nfunction filterStackString(stackString) {\n    var lines = stackString.split(\"\\n\");\n    var desiredLines = [];\n    for (var i = 0; i < lines.length; ++i) {\n        var line = lines[i];\n\n        if (!isInternalFrame(line) && !isNodeFrame(line) && line) {\n            desiredLines.push(line);\n        }\n    }\n    return desiredLines.join(\"\\n\");\n}\n\nfunction isNodeFrame(stackLine) {\n    return stackLine.indexOf(\"(module.js:\") !== -1 ||\n           stackLine.indexOf(\"(node.js:\") !== -1;\n}\n\nfunction getFileNameAndLineNumber(stackLine) {\n    // Named functions: \"at functionName (filename:lineNumber:columnNumber)\"\n    // In IE10 function name can have spaces (\"Anonymous function\") O_o\n    var attempt1 = /at .+ \\((.+):(\\d+):(?:\\d+)\\)$/.exec(stackLine);\n    if (attempt1) {\n        return [attempt1[1], Number(attempt1[2])];\n    }\n\n    // Anonymous functions: \"at filename:lineNumber:columnNumber\"\n    var attempt2 = /at ([^ ]+):(\\d+):(?:\\d+)$/.exec(stackLine);\n    if (attempt2) {\n        return [attempt2[1], Number(attempt2[2])];\n    }\n\n    // Firefox style: \"function@filename:lineNumber or @filename:lineNumber\"\n    var attempt3 = /.*@(.+):(\\d+)$/.exec(stackLine);\n    if (attempt3) {\n        return [attempt3[1], Number(attempt3[2])];\n    }\n}\n\nfunction isInternalFrame(stackLine) {\n    var fileNameAndLineNumber = getFileNameAndLineNumber(stackLine);\n\n    if (!fileNameAndLineNumber) {\n        return false;\n    }\n\n    var fileName = fileNameAndLineNumber[0];\n    var lineNumber = fileNameAndLineNumber[1];\n\n    return fileName === qFileName &&\n        lineNumber >= qStartingLine &&\n        lineNumber <= qEndingLine;\n}\n\n// discover own file name and line number range for filtering stack\n// traces\nfunction captureLine() {\n    if (!hasStacks) {\n        return;\n    }\n\n    try {\n        throw new Error();\n    } catch (e) {\n        var lines = e.stack.split(\"\\n\");\n        var firstLine = lines[0].indexOf(\"@\") > 0 ? lines[1] : lines[2];\n        var fileNameAndLineNumber = getFileNameAndLineNumber(firstLine);\n        if (!fileNameAndLineNumber) {\n            return;\n        }\n\n        qFileName = fileNameAndLineNumber[0];\n        return fileNameAndLineNumber[1];\n    }\n}\n\nfunction deprecate(callback, name, alternative) {\n    return function () {\n        if (typeof console !== \"undefined\" &&\n            typeof console.warn === \"function\") {\n            console.warn(name + \" is deprecated, use \" + alternative +\n                         \" instead.\", new Error(\"\").stack);\n        }\n        return callback.apply(callback, arguments);\n    };\n}\n\n// end of shims\n// beginning of real work\n\n/**\n * Constructs a promise for an immediate reference, passes promises through, or\n * coerces promises from different systems.\n * @param value immediate reference or promise\n */\nfunction Q(value) {\n    // If the object is already a Promise, return it directly.  This enables\n    // the resolve function to both be used to created references from objects,\n    // but to tolerably coerce non-promises to promises.\n    if (value instanceof Promise) {\n        return value;\n    }\n\n    // assimilate thenables\n    if (isPromiseAlike(value)) {\n        return coerce(value);\n    } else {\n        return fulfill(value);\n    }\n}\nQ.resolve = Q;\n\n/**\n * Performs a task in a future turn of the event loop.\n * @param {Function} task\n */\nQ.nextTick = nextTick;\n\n/**\n * Controls whether or not long stack traces will be on\n */\nQ.longStackSupport = false;\n\n/**\n * The counter is used to determine the stopping point for building\n * long stack traces. In makeStackTraceLong we walk backwards through\n * the linked list of promises, only stacks which were created before\n * the rejection are concatenated.\n */\nvar longStackCounter = 1;\n\n// enable long stacks if Q_DEBUG is set\nif (typeof process === \"object\" && process && process.env && process.env.Q_DEBUG) {\n    Q.longStackSupport = true;\n}\n\n/**\n * Constructs a {promise, resolve, reject} object.\n *\n * `resolve` is a callback to invoke with a more resolved value for the\n * promise. To fulfill the promise, invoke `resolve` with any value that is\n * not a thenable. To reject the promise, invoke `resolve` with a rejected\n * thenable, or invoke `reject` with the reason directly. To resolve the\n * promise to another thenable, thus putting it in the same state, invoke\n * `resolve` with that other thenable.\n */\nQ.defer = defer;\nfunction defer() {\n    // if \"messages\" is an \"Array\", that indicates that the promise has not yet\n    // been resolved.  If it is \"undefined\", it has been resolved.  Each\n    // element of the messages array is itself an array of complete arguments to\n    // forward to the resolved promise.  We coerce the resolution value to a\n    // promise using the `resolve` function because it handles both fully\n    // non-thenable values and other thenables gracefully.\n    var messages = [], progressListeners = [], resolvedPromise;\n\n    var deferred = object_create(defer.prototype);\n    var promise = object_create(Promise.prototype);\n\n    promise.promiseDispatch = function (resolve, op, operands) {\n        var args = array_slice(arguments);\n        if (messages) {\n            messages.push(args);\n            if (op === \"when\" && operands[1]) { // progress operand\n                progressListeners.push(operands[1]);\n            }\n        } else {\n            Q.nextTick(function () {\n                resolvedPromise.promiseDispatch.apply(resolvedPromise, args);\n            });\n        }\n    };\n\n    // XXX deprecated\n    promise.valueOf = function () {\n        if (messages) {\n            return promise;\n        }\n        var nearerValue = nearer(resolvedPromise);\n        if (isPromise(nearerValue)) {\n            resolvedPromise = nearerValue; // shorten chain\n        }\n        return nearerValue;\n    };\n\n    promise.inspect = function () {\n        if (!resolvedPromise) {\n            return { state: \"pending\" };\n        }\n        return resolvedPromise.inspect();\n    };\n\n    if (Q.longStackSupport && hasStacks) {\n        try {\n            throw new Error();\n        } catch (e) {\n            // NOTE: don't try to use `Error.captureStackTrace` or transfer the\n            // accessor around; that causes memory leaks as per GH-111. Just\n            // reify the stack trace as a string ASAP.\n            //\n            // At the same time, cut off the first line; it's always just\n            // \"[object Promise]\\n\", as per the `toString`.\n            promise.stack = e.stack.substring(e.stack.indexOf(\"\\n\") + 1);\n            promise.stackCounter = longStackCounter++;\n        }\n    }\n\n    // NOTE: we do the checks for `resolvedPromise` in each method, instead of\n    // consolidating them into `become`, since otherwise we'd create new\n    // promises with the lines `become(whatever(value))`. See e.g. GH-252.\n\n    function become(newPromise) {\n        resolvedPromise = newPromise;\n\n        if (Q.longStackSupport && hasStacks) {\n            // Only hold a reference to the new promise if long stacks\n            // are enabled to reduce memory usage\n            promise.source = newPromise;\n        }\n\n        array_reduce(messages, function (undefined, message) {\n            Q.nextTick(function () {\n                newPromise.promiseDispatch.apply(newPromise, message);\n            });\n        }, void 0);\n\n        messages = void 0;\n        progressListeners = void 0;\n    }\n\n    deferred.promise = promise;\n    deferred.resolve = function (value) {\n        if (resolvedPromise) {\n            return;\n        }\n\n        become(Q(value));\n    };\n\n    deferred.fulfill = function (value) {\n        if (resolvedPromise) {\n            return;\n        }\n\n        become(fulfill(value));\n    };\n    deferred.reject = function (reason) {\n        if (resolvedPromise) {\n            return;\n        }\n\n        become(reject(reason));\n    };\n    deferred.notify = function (progress) {\n        if (resolvedPromise) {\n            return;\n        }\n\n        array_reduce(progressListeners, function (undefined, progressListener) {\n            Q.nextTick(function () {\n                progressListener(progress);\n            });\n        }, void 0);\n    };\n\n    return deferred;\n}\n\n/**\n * Creates a Node-style callback that will resolve or reject the deferred\n * promise.\n * @returns a nodeback\n */\ndefer.prototype.makeNodeResolver = function () {\n    var self = this;\n    return function (error, value) {\n        if (error) {\n            self.reject(error);\n        } else if (arguments.length > 2) {\n            self.resolve(array_slice(arguments, 1));\n        } else {\n            self.resolve(value);\n        }\n    };\n};\n\n/**\n * @param resolver {Function} a function that returns nothing and accepts\n * the resolve, reject, and notify functions for a deferred.\n * @returns a promise that may be resolved with the given resolve and reject\n * functions, or rejected by a thrown exception in resolver\n */\nQ.Promise = promise; // ES6\nQ.promise = promise;\nfunction promise(resolver) {\n    if (typeof resolver !== \"function\") {\n        throw new TypeError(\"resolver must be a function.\");\n    }\n    var deferred = defer();\n    try {\n        resolver(deferred.resolve, deferred.reject, deferred.notify);\n    } catch (reason) {\n        deferred.reject(reason);\n    }\n    return deferred.promise;\n}\n\npromise.race = race; // ES6\npromise.all = all; // ES6\npromise.reject = reject; // ES6\npromise.resolve = Q; // ES6\n\n// XXX experimental.  This method is a way to denote that a local value is\n// serializable and should be immediately dispatched to a remote upon request,\n// instead of passing a reference.\nQ.passByCopy = function (object) {\n    //freeze(object);\n    //passByCopies.set(object, true);\n    return object;\n};\n\nPromise.prototype.passByCopy = function () {\n    //freeze(object);\n    //passByCopies.set(object, true);\n    return this;\n};\n\n/**\n * If two promises eventually fulfill to the same value, promises that value,\n * but otherwise rejects.\n * @param x {Any*}\n * @param y {Any*}\n * @returns {Any*} a promise for x and y if they are the same, but a rejection\n * otherwise.\n *\n */\nQ.join = function (x, y) {\n    return Q(x).join(y);\n};\n\nPromise.prototype.join = function (that) {\n    return Q([this, that]).spread(function (x, y) {\n        if (x === y) {\n            // TODO: \"===\" should be Object.is or equiv\n            return x;\n        } else {\n            throw new Error(\"Q can't join: not the same: \" + x + \" \" + y);\n        }\n    });\n};\n\n/**\n * Returns a promise for the first of an array of promises to become settled.\n * @param answers {Array[Any*]} promises to race\n * @returns {Any*} the first promise to be settled\n */\nQ.race = race;\nfunction race(answerPs) {\n    return promise(function (resolve, reject) {\n        // Switch to this once we can assume at least ES5\n        // answerPs.forEach(function (answerP) {\n        //     Q(answerP).then(resolve, reject);\n        // });\n        // Use this in the meantime\n        for (var i = 0, len = answerPs.length; i < len; i++) {\n            Q(answerPs[i]).then(resolve, reject);\n        }\n    });\n}\n\nPromise.prototype.race = function () {\n    return this.then(Q.race);\n};\n\n/**\n * Constructs a Promise with a promise descriptor object and optional fallback\n * function.  The descriptor contains methods like when(rejected), get(name),\n * set(name, value), post(name, args), and delete(name), which all\n * return either a value, a promise for a value, or a rejection.  The fallback\n * accepts the operation name, a resolver, and any further arguments that would\n * have been forwarded to the appropriate method above had a method been\n * provided with the proper name.  The API makes no guarantees about the nature\n * of the returned object, apart from that it is usable whereever promises are\n * bought and sold.\n */\nQ.makePromise = Promise;\nfunction Promise(descriptor, fallback, inspect) {\n    if (fallback === void 0) {\n        fallback = function (op) {\n            return reject(new Error(\n                \"Promise does not support operation: \" + op\n            ));\n        };\n    }\n    if (inspect === void 0) {\n        inspect = function () {\n            return {state: \"unknown\"};\n        };\n    }\n\n    var promise = object_create(Promise.prototype);\n\n    promise.promiseDispatch = function (resolve, op, args) {\n        var result;\n        try {\n            if (descriptor[op]) {\n                result = descriptor[op].apply(promise, args);\n            } else {\n                result = fallback.call(promise, op, args);\n            }\n        } catch (exception) {\n            result = reject(exception);\n        }\n        if (resolve) {\n            resolve(result);\n        }\n    };\n\n    promise.inspect = inspect;\n\n    // XXX deprecated `valueOf` and `exception` support\n    if (inspect) {\n        var inspected = inspect();\n        if (inspected.state === \"rejected\") {\n            promise.exception = inspected.reason;\n        }\n\n        promise.valueOf = function () {\n            var inspected = inspect();\n            if (inspected.state === \"pending\" ||\n                inspected.state === \"rejected\") {\n                return promise;\n            }\n            return inspected.value;\n        };\n    }\n\n    return promise;\n}\n\nPromise.prototype.toString = function () {\n    return \"[object Promise]\";\n};\n\nPromise.prototype.then = function (fulfilled, rejected, progressed) {\n    var self = this;\n    var deferred = defer();\n    var done = false;   // ensure the untrusted promise makes at most a\n                        // single call to one of the callbacks\n\n    function _fulfilled(value) {\n        try {\n            return typeof fulfilled === \"function\" ? fulfilled(value) : value;\n        } catch (exception) {\n            return reject(exception);\n        }\n    }\n\n    function _rejected(exception) {\n        if (typeof rejected === \"function\") {\n            makeStackTraceLong(exception, self);\n            try {\n                return rejected(exception);\n            } catch (newException) {\n                return reject(newException);\n            }\n        }\n        return reject(exception);\n    }\n\n    function _progressed(value) {\n        return typeof progressed === \"function\" ? progressed(value) : value;\n    }\n\n    Q.nextTick(function () {\n        self.promiseDispatch(function (value) {\n            if (done) {\n                return;\n            }\n            done = true;\n\n            deferred.resolve(_fulfilled(value));\n        }, \"when\", [function (exception) {\n            if (done) {\n                return;\n            }\n            done = true;\n\n            deferred.resolve(_rejected(exception));\n        }]);\n    });\n\n    // Progress propagator need to be attached in the current tick.\n    self.promiseDispatch(void 0, \"when\", [void 0, function (value) {\n        var newValue;\n        var threw = false;\n        try {\n            newValue = _progressed(value);\n        } catch (e) {\n            threw = true;\n            if (Q.onerror) {\n                Q.onerror(e);\n            } else {\n                throw e;\n            }\n        }\n\n        if (!threw) {\n            deferred.notify(newValue);\n        }\n    }]);\n\n    return deferred.promise;\n};\n\nQ.tap = function (promise, callback) {\n    return Q(promise).tap(callback);\n};\n\n/**\n * Works almost like \"finally\", but not called for rejections.\n * Original resolution value is passed through callback unaffected.\n * Callback may return a promise that will be awaited for.\n * @param {Function} callback\n * @returns {Q.Promise}\n * @example\n * doSomething()\n *   .then(...)\n *   .tap(console.log)\n *   .then(...);\n */\nPromise.prototype.tap = function (callback) {\n    callback = Q(callback);\n\n    return this.then(function (value) {\n        return callback.fcall(value).thenResolve(value);\n    });\n};\n\n/**\n * Registers an observer on a promise.\n *\n * Guarantees:\n *\n * 1. that fulfilled and rejected will be called only once.\n * 2. that either the fulfilled callback or the rejected callback will be\n *    called, but not both.\n * 3. that fulfilled and rejected will not be called in this turn.\n *\n * @param value      promise or immediate reference to observe\n * @param fulfilled  function to be called with the fulfilled value\n * @param rejected   function to be called with the rejection exception\n * @param progressed function to be called on any progress notifications\n * @return promise for the return value from the invoked callback\n */\nQ.when = when;\nfunction when(value, fulfilled, rejected, progressed) {\n    return Q(value).then(fulfilled, rejected, progressed);\n}\n\nPromise.prototype.thenResolve = function (value) {\n    return this.then(function () { return value; });\n};\n\nQ.thenResolve = function (promise, value) {\n    return Q(promise).thenResolve(value);\n};\n\nPromise.prototype.thenReject = function (reason) {\n    return this.then(function () { throw reason; });\n};\n\nQ.thenReject = function (promise, reason) {\n    return Q(promise).thenReject(reason);\n};\n\n/**\n * If an object is not a promise, it is as \"near\" as possible.\n * If a promise is rejected, it is as \"near\" as possible too.\n * If its a fulfilled promise, the fulfillment value is nearer.\n * If its a deferred promise and the deferred has been resolved, the\n * resolution is \"nearer\".\n * @param object\n * @returns most resolved (nearest) form of the object\n */\n\n// XXX should we re-do this?\nQ.nearer = nearer;\nfunction nearer(value) {\n    if (isPromise(value)) {\n        var inspected = value.inspect();\n        if (inspected.state === \"fulfilled\") {\n            return inspected.value;\n        }\n    }\n    return value;\n}\n\n/**\n * @returns whether the given object is a promise.\n * Otherwise it is a fulfilled value.\n */\nQ.isPromise = isPromise;\nfunction isPromise(object) {\n    return object instanceof Promise;\n}\n\nQ.isPromiseAlike = isPromiseAlike;\nfunction isPromiseAlike(object) {\n    return isObject(object) && typeof object.then === \"function\";\n}\n\n/**\n * @returns whether the given object is a pending promise, meaning not\n * fulfilled or rejected.\n */\nQ.isPending = isPending;\nfunction isPending(object) {\n    return isPromise(object) && object.inspect().state === \"pending\";\n}\n\nPromise.prototype.isPending = function () {\n    return this.inspect().state === \"pending\";\n};\n\n/**\n * @returns whether the given object is a value or fulfilled\n * promise.\n */\nQ.isFulfilled = isFulfilled;\nfunction isFulfilled(object) {\n    return !isPromise(object) || object.inspect().state === \"fulfilled\";\n}\n\nPromise.prototype.isFulfilled = function () {\n    return this.inspect().state === \"fulfilled\";\n};\n\n/**\n * @returns whether the given object is a rejected promise.\n */\nQ.isRejected = isRejected;\nfunction isRejected(object) {\n    return isPromise(object) && object.inspect().state === \"rejected\";\n}\n\nPromise.prototype.isRejected = function () {\n    return this.inspect().state === \"rejected\";\n};\n\n//// BEGIN UNHANDLED REJECTION TRACKING\n\n// This promise library consumes exceptions thrown in handlers so they can be\n// handled by a subsequent promise.  The exceptions get added to this array when\n// they are created, and removed when they are handled.  Note that in ES6 or\n// shimmed environments, this would naturally be a `Set`.\nvar unhandledReasons = [];\nvar unhandledRejections = [];\nvar reportedUnhandledRejections = [];\nvar trackUnhandledRejections = true;\n\nfunction resetUnhandledRejections() {\n    unhandledReasons.length = 0;\n    unhandledRejections.length = 0;\n\n    if (!trackUnhandledRejections) {\n        trackUnhandledRejections = true;\n    }\n}\n\nfunction trackRejection(promise, reason) {\n    if (!trackUnhandledRejections) {\n        return;\n    }\n    if (typeof process === \"object\" && typeof process.emit === \"function\") {\n        Q.nextTick.runAfter(function () {\n            if (array_indexOf(unhandledRejections, promise) !== -1) {\n                process.emit(\"unhandledRejection\", reason, promise);\n                reportedUnhandledRejections.push(promise);\n            }\n        });\n    }\n\n    unhandledRejections.push(promise);\n    if (reason && typeof reason.stack !== \"undefined\") {\n        unhandledReasons.push(reason.stack);\n    } else {\n        unhandledReasons.push(\"(no stack) \" + reason);\n    }\n}\n\nfunction untrackRejection(promise) {\n    if (!trackUnhandledRejections) {\n        return;\n    }\n\n    var at = array_indexOf(unhandledRejections, promise);\n    if (at !== -1) {\n        if (typeof process === \"object\" && typeof process.emit === \"function\") {\n            Q.nextTick.runAfter(function () {\n                var atReport = array_indexOf(reportedUnhandledRejections, promise);\n                if (atReport !== -1) {\n                    process.emit(\"rejectionHandled\", unhandledReasons[at], promise);\n                    reportedUnhandledRejections.splice(atReport, 1);\n                }\n            });\n        }\n        unhandledRejections.splice(at, 1);\n        unhandledReasons.splice(at, 1);\n    }\n}\n\nQ.resetUnhandledRejections = resetUnhandledRejections;\n\nQ.getUnhandledReasons = function () {\n    // Make a copy so that consumers can't interfere with our internal state.\n    return unhandledReasons.slice();\n};\n\nQ.stopUnhandledRejectionTracking = function () {\n    resetUnhandledRejections();\n    trackUnhandledRejections = false;\n};\n\nresetUnhandledRejections();\n\n//// END UNHANDLED REJECTION TRACKING\n\n/**\n * Constructs a rejected promise.\n * @param reason value describing the failure\n */\nQ.reject = reject;\nfunction reject(reason) {\n    var rejection = Promise({\n        \"when\": function (rejected) {\n            // note that the error has been handled\n            if (rejected) {\n                untrackRejection(this);\n            }\n            return rejected ? rejected(reason) : this;\n        }\n    }, function fallback() {\n        return this;\n    }, function inspect() {\n        return { state: \"rejected\", reason: reason };\n    });\n\n    // Note that the reason has not been handled.\n    trackRejection(rejection, reason);\n\n    return rejection;\n}\n\n/**\n * Constructs a fulfilled promise for an immediate reference.\n * @param value immediate reference\n */\nQ.fulfill = fulfill;\nfunction fulfill(value) {\n    return Promise({\n        \"when\": function () {\n            return value;\n        },\n        \"get\": function (name) {\n            return value[name];\n        },\n        \"set\": function (name, rhs) {\n            value[name] = rhs;\n        },\n        \"delete\": function (name) {\n            delete value[name];\n        },\n        \"post\": function (name, args) {\n            // Mark Miller proposes that post with no name should apply a\n            // promised function.\n            if (name === null || name === void 0) {\n                return value.apply(void 0, args);\n            } else {\n                return value[name].apply(value, args);\n            }\n        },\n        \"apply\": function (thisp, args) {\n            return value.apply(thisp, args);\n        },\n        \"keys\": function () {\n            return object_keys(value);\n        }\n    }, void 0, function inspect() {\n        return { state: \"fulfilled\", value: value };\n    });\n}\n\n/**\n * Converts thenables to Q promises.\n * @param promise thenable promise\n * @returns a Q promise\n */\nfunction coerce(promise) {\n    var deferred = defer();\n    Q.nextTick(function () {\n        try {\n            promise.then(deferred.resolve, deferred.reject, deferred.notify);\n        } catch (exception) {\n            deferred.reject(exception);\n        }\n    });\n    return deferred.promise;\n}\n\n/**\n * Annotates an object such that it will never be\n * transferred away from this process over any promise\n * communication channel.\n * @param object\n * @returns promise a wrapping of that object that\n * additionally responds to the \"isDef\" message\n * without a rejection.\n */\nQ.master = master;\nfunction master(object) {\n    return Promise({\n        \"isDef\": function () {}\n    }, function fallback(op, args) {\n        return dispatch(object, op, args);\n    }, function () {\n        return Q(object).inspect();\n    });\n}\n\n/**\n * Spreads the values of a promised array of arguments into the\n * fulfillment callback.\n * @param fulfilled callback that receives variadic arguments from the\n * promised array\n * @param rejected callback that receives the exception if the promise\n * is rejected.\n * @returns a promise for the return value or thrown exception of\n * either callback.\n */\nQ.spread = spread;\nfunction spread(value, fulfilled, rejected) {\n    return Q(value).spread(fulfilled, rejected);\n}\n\nPromise.prototype.spread = function (fulfilled, rejected) {\n    return this.all().then(function (array) {\n        return fulfilled.apply(void 0, array);\n    }, rejected);\n};\n\n/**\n * The async function is a decorator for generator functions, turning\n * them into asynchronous generators.  Although generators are only part\n * of the newest ECMAScript 6 drafts, this code does not cause syntax\n * errors in older engines.  This code should continue to work and will\n * in fact improve over time as the language improves.\n *\n * ES6 generators are currently part of V8 version 3.19 with the\n * --harmony-generators runtime flag enabled.  SpiderMonkey has had them\n * for longer, but under an older Python-inspired form.  This function\n * works on both kinds of generators.\n *\n * Decorates a generator function such that:\n *  - it may yield promises\n *  - execution will continue when that promise is fulfilled\n *  - the value of the yield expression will be the fulfilled value\n *  - it returns a promise for the return value (when the generator\n *    stops iterating)\n *  - the decorated function returns a promise for the return value\n *    of the generator or the first rejected promise among those\n *    yielded.\n *  - if an error is thrown in the generator, it propagates through\n *    every following yield until it is caught, or until it escapes\n *    the generator function altogether, and is translated into a\n *    rejection for the promise returned by the decorated generator.\n */\nQ.async = async;\nfunction async(makeGenerator) {\n    return function () {\n        // when verb is \"send\", arg is a value\n        // when verb is \"throw\", arg is an exception\n        function continuer(verb, arg) {\n            var result;\n\n            // Until V8 3.19 / Chromium 29 is released, SpiderMonkey is the only\n            // engine that has a deployed base of browsers that support generators.\n            // However, SM's generators use the Python-inspired semantics of\n            // outdated ES6 drafts.  We would like to support ES6, but we'd also\n            // like to make it possible to use generators in deployed browsers, so\n            // we also support Python-style generators.  At some point we can remove\n            // this block.\n\n            if (typeof StopIteration === \"undefined\") {\n                // ES6 Generators\n                try {\n                    result = generator[verb](arg);\n                } catch (exception) {\n                    return reject(exception);\n                }\n                if (result.done) {\n                    return Q(result.value);\n                } else {\n                    return when(result.value, callback, errback);\n                }\n            } else {\n                // SpiderMonkey Generators\n                // FIXME: Remove this case when SM does ES6 generators.\n                try {\n                    result = generator[verb](arg);\n                } catch (exception) {\n                    if (isStopIteration(exception)) {\n                        return Q(exception.value);\n                    } else {\n                        return reject(exception);\n                    }\n                }\n                return when(result, callback, errback);\n            }\n        }\n        var generator = makeGenerator.apply(this, arguments);\n        var callback = continuer.bind(continuer, \"next\");\n        var errback = continuer.bind(continuer, \"throw\");\n        return callback();\n    };\n}\n\n/**\n * The spawn function is a small wrapper around async that immediately\n * calls the generator and also ends the promise chain, so that any\n * unhandled errors are thrown instead of forwarded to the error\n * handler. This is useful because it's extremely common to run\n * generators at the top-level to work with libraries.\n */\nQ.spawn = spawn;\nfunction spawn(makeGenerator) {\n    Q.done(Q.async(makeGenerator)());\n}\n\n// FIXME: Remove this interface once ES6 generators are in SpiderMonkey.\n/**\n * Throws a ReturnValue exception to stop an asynchronous generator.\n *\n * This interface is a stop-gap measure to support generator return\n * values in older Firefox/SpiderMonkey.  In browsers that support ES6\n * generators like Chromium 29, just use \"return\" in your generator\n * functions.\n *\n * @param value the return value for the surrounding generator\n * @throws ReturnValue exception with the value.\n * @example\n * // ES6 style\n * Q.async(function* () {\n *      var foo = yield getFooPromise();\n *      var bar = yield getBarPromise();\n *      return foo + bar;\n * })\n * // Older SpiderMonkey style\n * Q.async(function () {\n *      var foo = yield getFooPromise();\n *      var bar = yield getBarPromise();\n *      Q.return(foo + bar);\n * })\n */\nQ[\"return\"] = _return;\nfunction _return(value) {\n    throw new QReturnValue(value);\n}\n\n/**\n * The promised function decorator ensures that any promise arguments\n * are settled and passed as values (`this` is also settled and passed\n * as a value).  It will also ensure that the result of a function is\n * always a promise.\n *\n * @example\n * var add = Q.promised(function (a, b) {\n *     return a + b;\n * });\n * add(Q(a), Q(B));\n *\n * @param {function} callback The function to decorate\n * @returns {function} a function that has been decorated.\n */\nQ.promised = promised;\nfunction promised(callback) {\n    return function () {\n        return spread([this, all(arguments)], function (self, args) {\n            return callback.apply(self, args);\n        });\n    };\n}\n\n/**\n * sends a message to a value in a future turn\n * @param object* the recipient\n * @param op the name of the message operation, e.g., \"when\",\n * @param args further arguments to be forwarded to the operation\n * @returns result {Promise} a promise for the result of the operation\n */\nQ.dispatch = dispatch;\nfunction dispatch(object, op, args) {\n    return Q(object).dispatch(op, args);\n}\n\nPromise.prototype.dispatch = function (op, args) {\n    var self = this;\n    var deferred = defer();\n    Q.nextTick(function () {\n        self.promiseDispatch(deferred.resolve, op, args);\n    });\n    return deferred.promise;\n};\n\n/**\n * Gets the value of a property in a future turn.\n * @param object    promise or immediate reference for target object\n * @param name      name of property to get\n * @return promise for the property value\n */\nQ.get = function (object, key) {\n    return Q(object).dispatch(\"get\", [key]);\n};\n\nPromise.prototype.get = function (key) {\n    return this.dispatch(\"get\", [key]);\n};\n\n/**\n * Sets the value of a property in a future turn.\n * @param object    promise or immediate reference for object object\n * @param name      name of property to set\n * @param value     new value of property\n * @return promise for the return value\n */\nQ.set = function (object, key, value) {\n    return Q(object).dispatch(\"set\", [key, value]);\n};\n\nPromise.prototype.set = function (key, value) {\n    return this.dispatch(\"set\", [key, value]);\n};\n\n/**\n * Deletes a property in a future turn.\n * @param object    promise or immediate reference for target object\n * @param name      name of property to delete\n * @return promise for the return value\n */\nQ.del = // XXX legacy\nQ[\"delete\"] = function (object, key) {\n    return Q(object).dispatch(\"delete\", [key]);\n};\n\nPromise.prototype.del = // XXX legacy\nPromise.prototype[\"delete\"] = function (key) {\n    return this.dispatch(\"delete\", [key]);\n};\n\n/**\n * Invokes a method in a future turn.\n * @param object    promise or immediate reference for target object\n * @param name      name of method to invoke\n * @param value     a value to post, typically an array of\n *                  invocation arguments for promises that\n *                  are ultimately backed with `resolve` values,\n *                  as opposed to those backed with URLs\n *                  wherein the posted value can be any\n *                  JSON serializable object.\n * @return promise for the return value\n */\n// bound locally because it is used by other methods\nQ.mapply = // XXX As proposed by \"Redsandro\"\nQ.post = function (object, name, args) {\n    return Q(object).dispatch(\"post\", [name, args]);\n};\n\nPromise.prototype.mapply = // XXX As proposed by \"Redsandro\"\nPromise.prototype.post = function (name, args) {\n    return this.dispatch(\"post\", [name, args]);\n};\n\n/**\n * Invokes a method in a future turn.\n * @param object    promise or immediate reference for target object\n * @param name      name of method to invoke\n * @param ...args   array of invocation arguments\n * @return promise for the return value\n */\nQ.send = // XXX Mark Miller's proposed parlance\nQ.mcall = // XXX As proposed by \"Redsandro\"\nQ.invoke = function (object, name /*...args*/) {\n    return Q(object).dispatch(\"post\", [name, array_slice(arguments, 2)]);\n};\n\nPromise.prototype.send = // XXX Mark Miller's proposed parlance\nPromise.prototype.mcall = // XXX As proposed by \"Redsandro\"\nPromise.prototype.invoke = function (name /*...args*/) {\n    return this.dispatch(\"post\", [name, array_slice(arguments, 1)]);\n};\n\n/**\n * Applies the promised function in a future turn.\n * @param object    promise or immediate reference for target function\n * @param args      array of application arguments\n */\nQ.fapply = function (object, args) {\n    return Q(object).dispatch(\"apply\", [void 0, args]);\n};\n\nPromise.prototype.fapply = function (args) {\n    return this.dispatch(\"apply\", [void 0, args]);\n};\n\n/**\n * Calls the promised function in a future turn.\n * @param object    promise or immediate reference for target function\n * @param ...args   array of application arguments\n */\nQ[\"try\"] =\nQ.fcall = function (object /* ...args*/) {\n    return Q(object).dispatch(\"apply\", [void 0, array_slice(arguments, 1)]);\n};\n\nPromise.prototype.fcall = function (/*...args*/) {\n    return this.dispatch(\"apply\", [void 0, array_slice(arguments)]);\n};\n\n/**\n * Binds the promised function, transforming return values into a fulfilled\n * promise and thrown errors into a rejected one.\n * @param object    promise or immediate reference for target function\n * @param ...args   array of application arguments\n */\nQ.fbind = function (object /*...args*/) {\n    var promise = Q(object);\n    var args = array_slice(arguments, 1);\n    return function fbound() {\n        return promise.dispatch(\"apply\", [\n            this,\n            args.concat(array_slice(arguments))\n        ]);\n    };\n};\nPromise.prototype.fbind = function (/*...args*/) {\n    var promise = this;\n    var args = array_slice(arguments);\n    return function fbound() {\n        return promise.dispatch(\"apply\", [\n            this,\n            args.concat(array_slice(arguments))\n        ]);\n    };\n};\n\n/**\n * Requests the names of the owned properties of a promised\n * object in a future turn.\n * @param object    promise or immediate reference for target object\n * @return promise for the keys of the eventually settled object\n */\nQ.keys = function (object) {\n    return Q(object).dispatch(\"keys\", []);\n};\n\nPromise.prototype.keys = function () {\n    return this.dispatch(\"keys\", []);\n};\n\n/**\n * Turns an array of promises into a promise for an array.  If any of\n * the promises gets rejected, the whole array is rejected immediately.\n * @param {Array*} an array (or promise for an array) of values (or\n * promises for values)\n * @returns a promise for an array of the corresponding values\n */\n// By Mark Miller\n// http://wiki.ecmascript.org/doku.php?id=strawman:concurrency&rev=1308776521#allfulfilled\nQ.all = all;\nfunction all(promises) {\n    return when(promises, function (promises) {\n        var pendingCount = 0;\n        var deferred = defer();\n        array_reduce(promises, function (undefined, promise, index) {\n            var snapshot;\n            if (\n                isPromise(promise) &&\n                (snapshot = promise.inspect()).state === \"fulfilled\"\n            ) {\n                promises[index] = snapshot.value;\n            } else {\n                ++pendingCount;\n                when(\n                    promise,\n                    function (value) {\n                        promises[index] = value;\n                        if (--pendingCount === 0) {\n                            deferred.resolve(promises);\n                        }\n                    },\n                    deferred.reject,\n                    function (progress) {\n                        deferred.notify({ index: index, value: progress });\n                    }\n                );\n            }\n        }, void 0);\n        if (pendingCount === 0) {\n            deferred.resolve(promises);\n        }\n        return deferred.promise;\n    });\n}\n\nPromise.prototype.all = function () {\n    return all(this);\n};\n\n/**\n * Returns the first resolved promise of an array. Prior rejected promises are\n * ignored.  Rejects only if all promises are rejected.\n * @param {Array*} an array containing values or promises for values\n * @returns a promise fulfilled with the value of the first resolved promise,\n * or a rejected promise if all promises are rejected.\n */\nQ.any = any;\n\nfunction any(promises) {\n    if (promises.length === 0) {\n        return Q.resolve();\n    }\n\n    var deferred = Q.defer();\n    var pendingCount = 0;\n    array_reduce(promises, function (prev, current, index) {\n        var promise = promises[index];\n\n        pendingCount++;\n\n        when(promise, onFulfilled, onRejected, onProgress);\n        function onFulfilled(result) {\n            deferred.resolve(result);\n        }\n        function onRejected(err) {\n            pendingCount--;\n            if (pendingCount === 0) {\n                var rejection = err || new Error(\"\" + err);\n\n                rejection.message = (\"Q can't get fulfillment value from any promise, all \" +\n                    \"promises were rejected. Last error message: \" + rejection.message);\n\n                deferred.reject(rejection);\n            }\n        }\n        function onProgress(progress) {\n            deferred.notify({\n                index: index,\n                value: progress\n            });\n        }\n    }, undefined);\n\n    return deferred.promise;\n}\n\nPromise.prototype.any = function () {\n    return any(this);\n};\n\n/**\n * Waits for all promises to be settled, either fulfilled or\n * rejected.  This is distinct from `all` since that would stop\n * waiting at the first rejection.  The promise returned by\n * `allResolved` will never be rejected.\n * @param promises a promise for an array (or an array) of promises\n * (or values)\n * @return a promise for an array of promises\n */\nQ.allResolved = deprecate(allResolved, \"allResolved\", \"allSettled\");\nfunction allResolved(promises) {\n    return when(promises, function (promises) {\n        promises = array_map(promises, Q);\n        return when(all(array_map(promises, function (promise) {\n            return when(promise, noop, noop);\n        })), function () {\n            return promises;\n        });\n    });\n}\n\nPromise.prototype.allResolved = function () {\n    return allResolved(this);\n};\n\n/**\n * @see Promise#allSettled\n */\nQ.allSettled = allSettled;\nfunction allSettled(promises) {\n    return Q(promises).allSettled();\n}\n\n/**\n * Turns an array of promises into a promise for an array of their states (as\n * returned by `inspect`) when they have all settled.\n * @param {Array[Any*]} values an array (or promise for an array) of values (or\n * promises for values)\n * @returns {Array[State]} an array of states for the respective values.\n */\nPromise.prototype.allSettled = function () {\n    return this.then(function (promises) {\n        return all(array_map(promises, function (promise) {\n            promise = Q(promise);\n            function regardless() {\n                return promise.inspect();\n            }\n            return promise.then(regardless, regardless);\n        }));\n    });\n};\n\n/**\n * Captures the failure of a promise, giving an oportunity to recover\n * with a callback.  If the given promise is fulfilled, the returned\n * promise is fulfilled.\n * @param {Any*} promise for something\n * @param {Function} callback to fulfill the returned promise if the\n * given promise is rejected\n * @returns a promise for the return value of the callback\n */\nQ.fail = // XXX legacy\nQ[\"catch\"] = function (object, rejected) {\n    return Q(object).then(void 0, rejected);\n};\n\nPromise.prototype.fail = // XXX legacy\nPromise.prototype[\"catch\"] = function (rejected) {\n    return this.then(void 0, rejected);\n};\n\n/**\n * Attaches a listener that can respond to progress notifications from a\n * promise's originating deferred. This listener receives the exact arguments\n * passed to ``deferred.notify``.\n * @param {Any*} promise for something\n * @param {Function} callback to receive any progress notifications\n * @returns the given promise, unchanged\n */\nQ.progress = progress;\nfunction progress(object, progressed) {\n    return Q(object).then(void 0, void 0, progressed);\n}\n\nPromise.prototype.progress = function (progressed) {\n    return this.then(void 0, void 0, progressed);\n};\n\n/**\n * Provides an opportunity to observe the settling of a promise,\n * regardless of whether the promise is fulfilled or rejected.  Forwards\n * the resolution to the returned promise when the callback is done.\n * The callback can return a promise to defer completion.\n * @param {Any*} promise\n * @param {Function} callback to observe the resolution of the given\n * promise, takes no arguments.\n * @returns a promise for the resolution of the given promise when\n * ``fin`` is done.\n */\nQ.fin = // XXX legacy\nQ[\"finally\"] = function (object, callback) {\n    return Q(object)[\"finally\"](callback);\n};\n\nPromise.prototype.fin = // XXX legacy\nPromise.prototype[\"finally\"] = function (callback) {\n    if (!callback || typeof callback.apply !== \"function\") {\n        throw new Error(\"Q can't apply finally callback\");\n    }\n    callback = Q(callback);\n    return this.then(function (value) {\n        return callback.fcall().then(function () {\n            return value;\n        });\n    }, function (reason) {\n        // TODO attempt to recycle the rejection with \"this\".\n        return callback.fcall().then(function () {\n            throw reason;\n        });\n    });\n};\n\n/**\n * Terminates a chain of promises, forcing rejections to be\n * thrown as exceptions.\n * @param {Any*} promise at the end of a chain of promises\n * @returns nothing\n */\nQ.done = function (object, fulfilled, rejected, progress) {\n    return Q(object).done(fulfilled, rejected, progress);\n};\n\nPromise.prototype.done = function (fulfilled, rejected, progress) {\n    var onUnhandledError = function (error) {\n        // forward to a future turn so that ``when``\n        // does not catch it and turn it into a rejection.\n        Q.nextTick(function () {\n            makeStackTraceLong(error, promise);\n            if (Q.onerror) {\n                Q.onerror(error);\n            } else {\n                throw error;\n            }\n        });\n    };\n\n    // Avoid unnecessary `nextTick`ing via an unnecessary `when`.\n    var promise = fulfilled || rejected || progress ?\n        this.then(fulfilled, rejected, progress) :\n        this;\n\n    if (typeof process === \"object\" && process && process.domain) {\n        onUnhandledError = process.domain.bind(onUnhandledError);\n    }\n\n    promise.then(void 0, onUnhandledError);\n};\n\n/**\n * Causes a promise to be rejected if it does not get fulfilled before\n * some milliseconds time out.\n * @param {Any*} promise\n * @param {Number} milliseconds timeout\n * @param {Any*} custom error message or Error object (optional)\n * @returns a promise for the resolution of the given promise if it is\n * fulfilled before the timeout, otherwise rejected.\n */\nQ.timeout = function (object, ms, error) {\n    return Q(object).timeout(ms, error);\n};\n\nPromise.prototype.timeout = function (ms, error) {\n    var deferred = defer();\n    var timeoutId = setTimeout(function () {\n        if (!error || \"string\" === typeof error) {\n            error = new Error(error || \"Timed out after \" + ms + \" ms\");\n            error.code = \"ETIMEDOUT\";\n        }\n        deferred.reject(error);\n    }, ms);\n\n    this.then(function (value) {\n        clearTimeout(timeoutId);\n        deferred.resolve(value);\n    }, function (exception) {\n        clearTimeout(timeoutId);\n        deferred.reject(exception);\n    }, deferred.notify);\n\n    return deferred.promise;\n};\n\n/**\n * Returns a promise for the given value (or promised value), some\n * milliseconds after it resolved. Passes rejections immediately.\n * @param {Any*} promise\n * @param {Number} milliseconds\n * @returns a promise for the resolution of the given promise after milliseconds\n * time has elapsed since the resolution of the given promise.\n * If the given promise rejects, that is passed immediately.\n */\nQ.delay = function (object, timeout) {\n    if (timeout === void 0) {\n        timeout = object;\n        object = void 0;\n    }\n    return Q(object).delay(timeout);\n};\n\nPromise.prototype.delay = function (timeout) {\n    return this.then(function (value) {\n        var deferred = defer();\n        setTimeout(function () {\n            deferred.resolve(value);\n        }, timeout);\n        return deferred.promise;\n    });\n};\n\n/**\n * Passes a continuation to a Node function, which is called with the given\n * arguments provided as an array, and returns a promise.\n *\n *      Q.nfapply(FS.readFile, [__filename])\n *      .then(function (content) {\n *      })\n *\n */\nQ.nfapply = function (callback, args) {\n    return Q(callback).nfapply(args);\n};\n\nPromise.prototype.nfapply = function (args) {\n    var deferred = defer();\n    var nodeArgs = array_slice(args);\n    nodeArgs.push(deferred.makeNodeResolver());\n    this.fapply(nodeArgs).fail(deferred.reject);\n    return deferred.promise;\n};\n\n/**\n * Passes a continuation to a Node function, which is called with the given\n * arguments provided individually, and returns a promise.\n * @example\n * Q.nfcall(FS.readFile, __filename)\n * .then(function (content) {\n * })\n *\n */\nQ.nfcall = function (callback /*...args*/) {\n    var args = array_slice(arguments, 1);\n    return Q(callback).nfapply(args);\n};\n\nPromise.prototype.nfcall = function (/*...args*/) {\n    var nodeArgs = array_slice(arguments);\n    var deferred = defer();\n    nodeArgs.push(deferred.makeNodeResolver());\n    this.fapply(nodeArgs).fail(deferred.reject);\n    return deferred.promise;\n};\n\n/**\n * Wraps a NodeJS continuation passing function and returns an equivalent\n * version that returns a promise.\n * @example\n * Q.nfbind(FS.readFile, __filename)(\"utf-8\")\n * .then(console.log)\n * .done()\n */\nQ.nfbind =\nQ.denodeify = function (callback /*...args*/) {\n    if (callback === undefined) {\n        throw new Error(\"Q can't wrap an undefined function\");\n    }\n    var baseArgs = array_slice(arguments, 1);\n    return function () {\n        var nodeArgs = baseArgs.concat(array_slice(arguments));\n        var deferred = defer();\n        nodeArgs.push(deferred.makeNodeResolver());\n        Q(callback).fapply(nodeArgs).fail(deferred.reject);\n        return deferred.promise;\n    };\n};\n\nPromise.prototype.nfbind =\nPromise.prototype.denodeify = function (/*...args*/) {\n    var args = array_slice(arguments);\n    args.unshift(this);\n    return Q.denodeify.apply(void 0, args);\n};\n\nQ.nbind = function (callback, thisp /*...args*/) {\n    var baseArgs = array_slice(arguments, 2);\n    return function () {\n        var nodeArgs = baseArgs.concat(array_slice(arguments));\n        var deferred = defer();\n        nodeArgs.push(deferred.makeNodeResolver());\n        function bound() {\n            return callback.apply(thisp, arguments);\n        }\n        Q(bound).fapply(nodeArgs).fail(deferred.reject);\n        return deferred.promise;\n    };\n};\n\nPromise.prototype.nbind = function (/*thisp, ...args*/) {\n    var args = array_slice(arguments, 0);\n    args.unshift(this);\n    return Q.nbind.apply(void 0, args);\n};\n\n/**\n * Calls a method of a Node-style object that accepts a Node-style\n * callback with a given array of arguments, plus a provided callback.\n * @param object an object that has the named method\n * @param {String} name name of the method of object\n * @param {Array} args arguments to pass to the method; the callback\n * will be provided by Q and appended to these arguments.\n * @returns a promise for the value or error\n */\nQ.nmapply = // XXX As proposed by \"Redsandro\"\nQ.npost = function (object, name, args) {\n    return Q(object).npost(name, args);\n};\n\nPromise.prototype.nmapply = // XXX As proposed by \"Redsandro\"\nPromise.prototype.npost = function (name, args) {\n    var nodeArgs = array_slice(args || []);\n    var deferred = defer();\n    nodeArgs.push(deferred.makeNodeResolver());\n    this.dispatch(\"post\", [name, nodeArgs]).fail(deferred.reject);\n    return deferred.promise;\n};\n\n/**\n * Calls a method of a Node-style object that accepts a Node-style\n * callback, forwarding the given variadic arguments, plus a provided\n * callback argument.\n * @param object an object that has the named method\n * @param {String} name name of the method of object\n * @param ...args arguments to pass to the method; the callback will\n * be provided by Q and appended to these arguments.\n * @returns a promise for the value or error\n */\nQ.nsend = // XXX Based on Mark Miller's proposed \"send\"\nQ.nmcall = // XXX Based on \"Redsandro's\" proposal\nQ.ninvoke = function (object, name /*...args*/) {\n    var nodeArgs = array_slice(arguments, 2);\n    var deferred = defer();\n    nodeArgs.push(deferred.makeNodeResolver());\n    Q(object).dispatch(\"post\", [name, nodeArgs]).fail(deferred.reject);\n    return deferred.promise;\n};\n\nPromise.prototype.nsend = // XXX Based on Mark Miller's proposed \"send\"\nPromise.prototype.nmcall = // XXX Based on \"Redsandro's\" proposal\nPromise.prototype.ninvoke = function (name /*...args*/) {\n    var nodeArgs = array_slice(arguments, 1);\n    var deferred = defer();\n    nodeArgs.push(deferred.makeNodeResolver());\n    this.dispatch(\"post\", [name, nodeArgs]).fail(deferred.reject);\n    return deferred.promise;\n};\n\n/**\n * If a function would like to support both Node continuation-passing-style and\n * promise-returning-style, it can end its internal promise chain with\n * `nodeify(nodeback)`, forwarding the optional nodeback argument.  If the user\n * elects to use a nodeback, the result will be sent there.  If they do not\n * pass a nodeback, they will receive the result promise.\n * @param object a result (or a promise for a result)\n * @param {Function} nodeback a Node.js-style callback\n * @returns either the promise or nothing\n */\nQ.nodeify = nodeify;\nfunction nodeify(object, nodeback) {\n    return Q(object).nodeify(nodeback);\n}\n\nPromise.prototype.nodeify = function (nodeback) {\n    if (nodeback) {\n        this.then(function (value) {\n            Q.nextTick(function () {\n                nodeback(null, value);\n            });\n        }, function (error) {\n            Q.nextTick(function () {\n                nodeback(error);\n            });\n        });\n    } else {\n        return this;\n    }\n};\n\nQ.noConflict = function() {\n    throw new Error(\"Q.noConflict only works when Q is used as a global\");\n};\n\n// All code before this point will be filtered from stack traces.\nvar qEndingLine = captureLine();\n\nreturn Q;\n\n});\n\n\n//# sourceURL=webpack:///./node_modules/q/q.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_duplex.js":
/*!************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_duplex.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = __webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\");\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\nvar Readable = __webpack_require__(/*! ./_stream_readable */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\nvar Writable = __webpack_require__(/*! ./_stream_writable */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_duplex.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_passthrough.js":
/*!*****************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_passthrough.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(/*! ./_stream_transform */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\n\n/*<replacement>*/\nvar util = __webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\");\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_passthrough.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_readable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_readable.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = __webpack_require__(/*! isarray */ \"./node_modules/isarray/index.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = __webpack_require__(/*! events */ \"events\").EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream.js\");\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(/*! safe-buffer */ \"./node_modules/readable-stream/node_modules/safe-buffer/index.js\").Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = __webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\");\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = __webpack_require__(/*! util */ \"util\");\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = __webpack_require__(/*! ./internal/streams/BufferList */ \"./node_modules/readable-stream/lib/internal/streams/BufferList.js\");\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = __webpack_require__(/*! string_decoder/ */ \"./node_modules/readable-stream/node_modules/string_decoder/lib/string_decoder.js\").StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = __webpack_require__(/*! string_decoder/ */ \"./node_modules/readable-stream/node_modules/string_decoder/lib/string_decoder.js\").StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_readable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_transform.js":
/*!***************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_transform.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\n\nmodule.exports = Transform;\n\nvar Duplex = __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n/*<replacement>*/\nvar util = __webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\");\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_transform.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_writable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_writable.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = __webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\");\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: __webpack_require__(/*! util-deprecate */ \"./node_modules/util-deprecate/node.js\")\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream.js\");\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(/*! safe-buffer */ \"./node_modules/readable-stream/node_modules/safe-buffer/index.js\").Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_writable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/BufferList.js":
/*!*************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/BufferList.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = __webpack_require__(/*! safe-buffer */ \"./node_modules/readable-stream/node_modules/safe-buffer/index.js\").Buffer;\nvar util = __webpack_require__(/*! util */ \"util\");\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/internal/streams/BufferList.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!**********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/internal/streams/destroy.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/stream.js":
/*!*********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/stream.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = __webpack_require__(/*! stream */ \"stream\");\n\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/internal/streams/stream.js?");

/***/ }),

/***/ "./node_modules/readable-stream/node_modules/safe-buffer/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/readable-stream/node_modules/safe-buffer/index.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* eslint-disable node/no-deprecated-api */\nvar buffer = __webpack_require__(/*! buffer */ \"buffer\")\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n\n\n//# sourceURL=webpack:///./node_modules/readable-stream/node_modules/safe-buffer/index.js?");

/***/ }),

/***/ "./node_modules/readable-stream/node_modules/string_decoder/lib/string_decoder.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/readable-stream/node_modules/string_decoder/lib/string_decoder.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(/*! safe-buffer */ \"./node_modules/readable-stream/node_modules/safe-buffer/index.js\").Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}\n\n//# sourceURL=webpack:///./node_modules/readable-stream/node_modules/string_decoder/lib/string_decoder.js?");

/***/ }),

/***/ "./node_modules/readable-stream/readable.js":
/*!**************************************************!*\
  !*** ./node_modules/readable-stream/readable.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var Stream = __webpack_require__(/*! stream */ \"stream\");\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = __webpack_require__(/*! ./lib/_stream_readable.js */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = __webpack_require__(/*! ./lib/_stream_writable.js */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\n  exports.Duplex = __webpack_require__(/*! ./lib/_stream_duplex.js */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  exports.Transform = __webpack_require__(/*! ./lib/_stream_transform.js */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\n  exports.PassThrough = __webpack_require__(/*! ./lib/_stream_passthrough.js */ \"./node_modules/readable-stream/lib/_stream_passthrough.js\");\n}\n\n\n//# sourceURL=webpack:///./node_modules/readable-stream/readable.js?");

/***/ }),

/***/ "./node_modules/rimraf/rimraf.js":
/*!***************************************!*\
  !*** ./node_modules/rimraf/rimraf.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = rimraf\nrimraf.sync = rimrafSync\n\nvar assert = __webpack_require__(/*! assert */ \"assert\")\nvar path = __webpack_require__(/*! path */ \"path\")\nvar fs = __webpack_require__(/*! fs */ \"fs\")\nvar glob = undefined\ntry {\n  glob = __webpack_require__(/*! glob */ \"./node_modules/glob/glob.js\")\n} catch (_err) {\n  // treat glob as optional.\n}\nvar _0666 = parseInt('666', 8)\n\nvar defaultGlobOpts = {\n  nosort: true,\n  silent: true\n}\n\n// for EMFILE handling\nvar timeout = 0\n\nvar isWindows = (process.platform === \"win32\")\n\nfunction defaults (options) {\n  var methods = [\n    'unlink',\n    'chmod',\n    'stat',\n    'lstat',\n    'rmdir',\n    'readdir'\n  ]\n  methods.forEach(function(m) {\n    options[m] = options[m] || fs[m]\n    m = m + 'Sync'\n    options[m] = options[m] || fs[m]\n  })\n\n  options.maxBusyTries = options.maxBusyTries || 3\n  options.emfileWait = options.emfileWait || 1000\n  if (options.glob === false) {\n    options.disableGlob = true\n  }\n  if (options.disableGlob !== true && glob === undefined) {\n    throw Error('glob dependency not found, set `options.disableGlob = true` if intentional')\n  }\n  options.disableGlob = options.disableGlob || false\n  options.glob = options.glob || defaultGlobOpts\n}\n\nfunction rimraf (p, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = {}\n  }\n\n  assert(p, 'rimraf: missing path')\n  assert.equal(typeof p, 'string', 'rimraf: path should be a string')\n  assert.equal(typeof cb, 'function', 'rimraf: callback function required')\n  assert(options, 'rimraf: invalid options argument provided')\n  assert.equal(typeof options, 'object', 'rimraf: options should be object')\n\n  defaults(options)\n\n  var busyTries = 0\n  var errState = null\n  var n = 0\n\n  if (options.disableGlob || !glob.hasMagic(p))\n    return afterGlob(null, [p])\n\n  options.lstat(p, function (er, stat) {\n    if (!er)\n      return afterGlob(null, [p])\n\n    glob(p, options.glob, afterGlob)\n  })\n\n  function next (er) {\n    errState = errState || er\n    if (--n === 0)\n      cb(errState)\n  }\n\n  function afterGlob (er, results) {\n    if (er)\n      return cb(er)\n\n    n = results.length\n    if (n === 0)\n      return cb()\n\n    results.forEach(function (p) {\n      rimraf_(p, options, function CB (er) {\n        if (er) {\n          if ((er.code === \"EBUSY\" || er.code === \"ENOTEMPTY\" || er.code === \"EPERM\") &&\n              busyTries < options.maxBusyTries) {\n            busyTries ++\n            var time = busyTries * 100\n            // try again, with the same exact callback as this one.\n            return setTimeout(function () {\n              rimraf_(p, options, CB)\n            }, time)\n          }\n\n          // this one won't happen if graceful-fs is used.\n          if (er.code === \"EMFILE\" && timeout < options.emfileWait) {\n            return setTimeout(function () {\n              rimraf_(p, options, CB)\n            }, timeout ++)\n          }\n\n          // already gone\n          if (er.code === \"ENOENT\") er = null\n        }\n\n        timeout = 0\n        next(er)\n      })\n    })\n  }\n}\n\n// Two possible strategies.\n// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR\n// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR\n//\n// Both result in an extra syscall when you guess wrong.  However, there\n// are likely far more normal files in the world than directories.  This\n// is based on the assumption that a the average number of files per\n// directory is >= 1.\n//\n// If anyone ever complains about this, then I guess the strategy could\n// be made configurable somehow.  But until then, YAGNI.\nfunction rimraf_ (p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // sunos lets the root user unlink directories, which is... weird.\n  // so we have to lstat here and make sure it's not a dir.\n  options.lstat(p, function (er, st) {\n    if (er && er.code === \"ENOENT\")\n      return cb(null)\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er && er.code === \"EPERM\" && isWindows)\n      fixWinEPERM(p, options, er, cb)\n\n    if (st && st.isDirectory())\n      return rmdir(p, options, er, cb)\n\n    options.unlink(p, function (er) {\n      if (er) {\n        if (er.code === \"ENOENT\")\n          return cb(null)\n        if (er.code === \"EPERM\")\n          return (isWindows)\n            ? fixWinEPERM(p, options, er, cb)\n            : rmdir(p, options, er, cb)\n        if (er.code === \"EISDIR\")\n          return rmdir(p, options, er, cb)\n      }\n      return cb(er)\n    })\n  })\n}\n\nfunction fixWinEPERM (p, options, er, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n  if (er)\n    assert(er instanceof Error)\n\n  options.chmod(p, _0666, function (er2) {\n    if (er2)\n      cb(er2.code === \"ENOENT\" ? null : er)\n    else\n      options.stat(p, function(er3, stats) {\n        if (er3)\n          cb(er3.code === \"ENOENT\" ? null : er)\n        else if (stats.isDirectory())\n          rmdir(p, options, er, cb)\n        else\n          options.unlink(p, cb)\n      })\n  })\n}\n\nfunction fixWinEPERMSync (p, options, er) {\n  assert(p)\n  assert(options)\n  if (er)\n    assert(er instanceof Error)\n\n  try {\n    options.chmodSync(p, _0666)\n  } catch (er2) {\n    if (er2.code === \"ENOENT\")\n      return\n    else\n      throw er\n  }\n\n  try {\n    var stats = options.statSync(p)\n  } catch (er3) {\n    if (er3.code === \"ENOENT\")\n      return\n    else\n      throw er\n  }\n\n  if (stats.isDirectory())\n    rmdirSync(p, options, er)\n  else\n    options.unlinkSync(p)\n}\n\nfunction rmdir (p, options, originalEr, cb) {\n  assert(p)\n  assert(options)\n  if (originalEr)\n    assert(originalEr instanceof Error)\n  assert(typeof cb === 'function')\n\n  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)\n  // if we guessed wrong, and it's not a directory, then\n  // raise the original error.\n  options.rmdir(p, function (er) {\n    if (er && (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\" || er.code === \"EPERM\"))\n      rmkids(p, options, cb)\n    else if (er && er.code === \"ENOTDIR\")\n      cb(originalEr)\n    else\n      cb(er)\n  })\n}\n\nfunction rmkids(p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.readdir(p, function (er, files) {\n    if (er)\n      return cb(er)\n    var n = files.length\n    if (n === 0)\n      return options.rmdir(p, cb)\n    var errState\n    files.forEach(function (f) {\n      rimraf(path.join(p, f), options, function (er) {\n        if (errState)\n          return\n        if (er)\n          return cb(errState = er)\n        if (--n === 0)\n          options.rmdir(p, cb)\n      })\n    })\n  })\n}\n\n// this looks simpler, and is strictly *faster*, but will\n// tie up the JavaScript thread and fail on excessively\n// deep directory trees.\nfunction rimrafSync (p, options) {\n  options = options || {}\n  defaults(options)\n\n  assert(p, 'rimraf: missing path')\n  assert.equal(typeof p, 'string', 'rimraf: path should be a string')\n  assert(options, 'rimraf: missing options')\n  assert.equal(typeof options, 'object', 'rimraf: options should be object')\n\n  var results\n\n  if (options.disableGlob || !glob.hasMagic(p)) {\n    results = [p]\n  } else {\n    try {\n      options.lstatSync(p)\n      results = [p]\n    } catch (er) {\n      results = glob.sync(p, options.glob)\n    }\n  }\n\n  if (!results.length)\n    return\n\n  for (var i = 0; i < results.length; i++) {\n    var p = results[i]\n\n    try {\n      var st = options.lstatSync(p)\n    } catch (er) {\n      if (er.code === \"ENOENT\")\n        return\n\n      // Windows can EPERM on stat.  Life is suffering.\n      if (er.code === \"EPERM\" && isWindows)\n        fixWinEPERMSync(p, options, er)\n    }\n\n    try {\n      // sunos lets the root user unlink directories, which is... weird.\n      if (st && st.isDirectory())\n        rmdirSync(p, options, null)\n      else\n        options.unlinkSync(p)\n    } catch (er) {\n      if (er.code === \"ENOENT\")\n        return\n      if (er.code === \"EPERM\")\n        return isWindows ? fixWinEPERMSync(p, options, er) : rmdirSync(p, options, er)\n      if (er.code !== \"EISDIR\")\n        throw er\n\n      rmdirSync(p, options, er)\n    }\n  }\n}\n\nfunction rmdirSync (p, options, originalEr) {\n  assert(p)\n  assert(options)\n  if (originalEr)\n    assert(originalEr instanceof Error)\n\n  try {\n    options.rmdirSync(p)\n  } catch (er) {\n    if (er.code === \"ENOENT\")\n      return\n    if (er.code === \"ENOTDIR\")\n      throw originalEr\n    if (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\" || er.code === \"EPERM\")\n      rmkidsSync(p, options)\n  }\n}\n\nfunction rmkidsSync (p, options) {\n  assert(p)\n  assert(options)\n  options.readdirSync(p).forEach(function (f) {\n    rimrafSync(path.join(p, f), options)\n  })\n\n  // We only end up here once we got ENOTEMPTY at least once, and\n  // at this point, we are guaranteed to have removed all the kids.\n  // So, we know that it won't be ENOENT or ENOTDIR or anything else.\n  // try really hard to delete stuff on windows, because it has a\n  // PROFOUNDLY annoying habit of not closing handles promptly when\n  // files are deleted, resulting in spurious ENOTEMPTY errors.\n  var retries = isWindows ? 100 : 1\n  var i = 0\n  do {\n    var threw = true\n    try {\n      var ret = options.rmdirSync(p, options)\n      threw = false\n      return ret\n    } finally {\n      if (++i < retries && threw)\n        continue\n    }\n  } while (true)\n}\n\n\n//# sourceURL=webpack:///./node_modules/rimraf/rimraf.js?");

/***/ }),

/***/ "./node_modules/safer-buffer/safer.js":
/*!********************************************!*\
  !*** ./node_modules/safer-buffer/safer.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* eslint-disable node/no-deprecated-api */\n\n\n\nvar buffer = __webpack_require__(/*! buffer */ \"buffer\")\nvar Buffer = buffer.Buffer\n\nvar safer = {}\n\nvar key\n\nfor (key in buffer) {\n  if (!buffer.hasOwnProperty(key)) continue\n  if (key === 'SlowBuffer' || key === 'Buffer') continue\n  safer[key] = buffer[key]\n}\n\nvar Safer = safer.Buffer = {}\nfor (key in Buffer) {\n  if (!Buffer.hasOwnProperty(key)) continue\n  if (key === 'allocUnsafe' || key === 'allocUnsafeSlow') continue\n  Safer[key] = Buffer[key]\n}\n\nsafer.Buffer.prototype = Buffer.prototype\n\nif (!Safer.from || Safer.from === Uint8Array.from) {\n  Safer.from = function (value, encodingOrOffset, length) {\n    if (typeof value === 'number') {\n      throw new TypeError('The \"value\" argument must not be of type number. Received type ' + typeof value)\n    }\n    if (value && typeof value.length === 'undefined') {\n      throw new TypeError('The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type ' + typeof value)\n    }\n    return Buffer(value, encodingOrOffset, length)\n  }\n}\n\nif (!Safer.alloc) {\n  Safer.alloc = function (size, fill, encoding) {\n    if (typeof size !== 'number') {\n      throw new TypeError('The \"size\" argument must be of type number. Received type ' + typeof size)\n    }\n    if (size < 0 || size >= 2 * (1 << 30)) {\n      throw new RangeError('The value \"' + size + '\" is invalid for option \"size\"')\n    }\n    var buf = Buffer(size)\n    if (!fill || fill.length === 0) {\n      buf.fill(0)\n    } else if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n    return buf\n  }\n}\n\nif (!safer.kStringMaxLength) {\n  try {\n    safer.kStringMaxLength = process.binding('buffer').kStringMaxLength\n  } catch (e) {\n    // we can't determine kStringMaxLength in environments where process.binding\n    // is unsupported, so let's not set it\n  }\n}\n\nif (!safer.constants) {\n  safer.constants = {\n    MAX_LENGTH: safer.kMaxLength\n  }\n  if (safer.kStringMaxLength) {\n    safer.constants.MAX_STRING_LENGTH = safer.kStringMaxLength\n  }\n}\n\nmodule.exports = safer\n\n\n//# sourceURL=webpack:///./node_modules/safer-buffer/safer.js?");

/***/ }),

/***/ "./node_modules/sb-promisify/lib/index.js":
/*!************************************************!*\
  !*** ./node_modules/sb-promisify/lib/index.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nfunction promisify(callback) {\n  var throwError = arguments.length <= 1 || arguments[1] === undefined ? true : arguments[1];\n\n  return function promisified() {\n    var _this = this;\n\n    for (var _len = arguments.length, parameters = Array(_len), _key = 0; _key < _len; _key++) {\n      parameters[_key] = arguments[_key];\n    }\n\n    var promise = new Promise(function (resolve, reject) {\n      parameters.push(function (error, data) {\n        if (error) {\n          reject(error);\n        } else resolve(data);\n      });\n      callback.apply(_this, parameters);\n    });\n    if (!throwError) {\n      promise = promise.then(function (result) {\n        return typeof result === 'undefined' ? true : result;\n      }).catch(function () {\n        return false;\n      });\n    }\n    return promise;\n  };\n}\n\nfunction promisifyAll(object) {\n  var throwError = arguments.length <= 1 || arguments[1] === undefined ? true : arguments[1];\n\n  var duplicate = Object.assign({}, object);\n  for (var item in duplicate) {\n    if (!{}.hasOwnProperty.call(duplicate, item) || typeof duplicate[item] !== 'function') {\n      continue;\n    }\n    duplicate[item + 'Async'] = promisify(duplicate[item], throwError);\n  }\n  return duplicate;\n}\n\nexports.default = promisify;\nexports.promisify = promisify;\nexports.promisifyAll = promisifyAll;\n\n//# sourceURL=webpack:///./node_modules/sb-promisify/lib/index.js?");

/***/ }),

/***/ "./node_modules/sb-scandir/lib/index.js":
/*!**********************************************!*\
  !*** ./node_modules/sb-scandir/lib/index.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar scanDirectoryInternal = function () {\n  var _ref = _asyncToGenerator(function* (path, recursive, validate, result) {\n    var itemStat = yield stat(path);\n    if (itemStat.isFile()) {\n      result.files.push(path);\n    } else if (itemStat.isDirectory() && recursive !== 0) {\n      result.directories.push(path);\n    }\n    if (!itemStat.isDirectory() || recursive === 0) {\n      return;\n    }\n    var contents = yield readdir(path);\n    yield (0, _pMap2.default)(contents, function () {\n      var _ref2 = _asyncToGenerator(function* (item) {\n        var itemPath = _path2.default.join(path, item);\n        if (validate(itemPath)) {\n          yield scanDirectoryInternal(itemPath, recursive === 1 ? 0 : 2, validate, result);\n        }\n      });\n\n      return function (_x5) {\n        return _ref2.apply(this, arguments);\n      };\n    }());\n  });\n\n  return function scanDirectoryInternal(_x, _x2, _x3, _x4) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nvar scanDirectory = function () {\n  var _ref3 = _asyncToGenerator(function* (path) {\n    var givenRecursive = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n    var givenValidate = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n\n    (0, _assert2.default)(path && typeof path === 'string', 'path must be a valid string');\n    (0, _assert2.default)(!givenValidate || typeof givenValidate === 'function', 'validate must be a valid function');\n\n    var recursive = !!givenRecursive;\n    var validate = givenValidate || function (itemPath) {\n      return _path2.default.basename(itemPath).substr(0, 1) !== '.';\n    };\n\n    var result = { files: [], directories: [] };\n    yield scanDirectoryInternal(path, recursive ? 2 : 1, validate, result);\n    return result;\n  });\n\n  return function scanDirectory(_x6) {\n    return _ref3.apply(this, arguments);\n  };\n}();\n\nvar _fs = __webpack_require__(/*! fs */ \"fs\");\n\nvar _fs2 = _interopRequireDefault(_fs);\n\nvar _path = __webpack_require__(/*! path */ \"path\");\n\nvar _path2 = _interopRequireDefault(_path);\n\nvar _pMap = __webpack_require__(/*! p-map */ \"./node_modules/sb-scandir/node_modules/p-map/index.js\");\n\nvar _pMap2 = _interopRequireDefault(_pMap);\n\nvar _assert = __webpack_require__(/*! assert */ \"assert\");\n\nvar _assert2 = _interopRequireDefault(_assert);\n\nvar _sbPromisify = __webpack_require__(/*! sb-promisify */ \"./node_modules/sb-promisify/lib/index.js\");\n\nvar _sbPromisify2 = _interopRequireDefault(_sbPromisify);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _asyncToGenerator(fn) { return function () { var gen = fn.apply(this, arguments); return new Promise(function (resolve, reject) { function step(key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { return Promise.resolve(value).then(function (value) { step(\"next\", value); }, function (err) { step(\"throw\", err); }); } } return step(\"next\"); }); }; }\n\nvar stat = (0, _sbPromisify2.default)(_fs2.default.stat);\nvar readdir = (0, _sbPromisify2.default)(_fs2.default.readdir);\n\nexports.default = scanDirectory;\n\n//# sourceURL=webpack:///./node_modules/sb-scandir/lib/index.js?");

/***/ }),

/***/ "./node_modules/sb-scandir/node_modules/p-map/index.js":
/*!*************************************************************!*\
  !*** ./node_modules/sb-scandir/node_modules/p-map/index.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nmodule.exports = (iterable, mapper, opts) => new Promise((resolve, reject) => {\n\topts = Object.assign({\n\t\tconcurrency: Infinity\n\t}, opts);\n\n\tif (typeof mapper !== 'function') {\n\t\tthrow new TypeError('Mapper function is required');\n\t}\n\n\tconst concurrency = opts.concurrency;\n\n\tif (!(typeof concurrency === 'number' && concurrency >= 1)) {\n\t\tthrow new TypeError(`Expected \\`concurrency\\` to be a number from 1 and up, got \\`${concurrency}\\` (${typeof concurrency})`);\n\t}\n\n\tconst ret = [];\n\tconst iterator = iterable[Symbol.iterator]();\n\tlet isRejected = false;\n\tlet iterableDone = false;\n\tlet resolvingCount = 0;\n\tlet currentIdx = 0;\n\n\tconst next = () => {\n\t\tif (isRejected) {\n\t\t\treturn;\n\t\t}\n\n\t\tconst nextItem = iterator.next();\n\t\tconst i = currentIdx;\n\t\tcurrentIdx++;\n\n\t\tif (nextItem.done) {\n\t\t\titerableDone = true;\n\n\t\t\tif (resolvingCount === 0) {\n\t\t\t\tresolve(ret);\n\t\t\t}\n\n\t\t\treturn;\n\t\t}\n\n\t\tresolvingCount++;\n\n\t\tPromise.resolve(nextItem.value)\n\t\t\t.then(el => mapper(el, i))\n\t\t\t.then(\n\t\t\t\tval => {\n\t\t\t\t\tret[i] = val;\n\t\t\t\t\tresolvingCount--;\n\t\t\t\t\tnext();\n\t\t\t\t},\n\t\t\t\terr => {\n\t\t\t\t\tisRejected = true;\n\t\t\t\t\treject(err);\n\t\t\t\t}\n\t\t\t);\n\t};\n\n\tfor (let i = 0; i < concurrency; i++) {\n\t\tnext();\n\n\t\tif (iterableDone) {\n\t\t\tbreak;\n\t\t}\n\t}\n});\n\n\n//# sourceURL=webpack:///./node_modules/sb-scandir/node_modules/p-map/index.js?");

/***/ }),

/***/ "./node_modules/set-immediate-shim/index.js":
/*!**************************************************!*\
  !*** ./node_modules/set-immediate-shim/index.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nmodule.exports = typeof setImmediate === 'function' ? setImmediate :\n\tfunction setImmediate() {\n\t\tvar args = [].slice.apply(arguments);\n\t\targs.splice(1, 0, 0);\n\t\tsetTimeout.apply(null, args);\n\t};\n\n\n//# sourceURL=webpack:///./node_modules/set-immediate-shim/index.js?");

/***/ }),

/***/ "./node_modules/shell-escape/shell-escape.js":
/*!***************************************************!*\
  !*** ./node_modules/shell-escape/shell-escape.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = shellescape;\n\n// return a shell compatible format\nfunction shellescape(a) {\n  var ret = [];\n\n  a.forEach(function(s) {\n    if (!/^[A-Za-z0-9_\\/-]+$/.test(s)) {\n      s = \"'\"+s.replace(/'/g,\"'\\\\''\")+\"'\";\n      s = s.replace(/^(?:'')+/g, '') // unduplicate single-quote at the beginning\n        .replace(/\\\\'''/g, \"\\\\'\" ); // remove non-escaped single-quote if there are enclosed between 2 escaped\n    }\n    ret.push(s);\n  });\n\n  return ret.join(' ');\n}\n\n\n//# sourceURL=webpack:///./node_modules/shell-escape/shell-escape.js?");

/***/ }),

/***/ "./node_modules/shelljs/commands.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/commands.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = [\n  'cat',\n  'cd',\n  'chmod',\n  'cp',\n  'dirs',\n  'echo',\n  'exec',\n  'find',\n  'grep',\n  'head',\n  'ln',\n  'ls',\n  'mkdir',\n  'mv',\n  'pwd',\n  'rm',\n  'sed',\n  'set',\n  'sort',\n  'tail',\n  'tempdir',\n  'test',\n  'to',\n  'toEnd',\n  'touch',\n  'uniq',\n  'which',\n];\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/commands.js?");

/***/ }),

/***/ "./node_modules/shelljs/shell.js":
/*!***************************************!*\
  !*** ./node_modules/shelljs/shell.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n// ShellJS\n// Unix shell commands on top of Node's API\n//\n// Copyright (c) 2012 Artur Adib\n// http://github.com/shelljs/shelljs\n//\n\nvar common = __webpack_require__(/*! ./src/common */ \"./node_modules/shelljs/src/common.js\");\n\n//@\n//@ All commands run synchronously, unless otherwise stated.\n//@ All commands accept standard bash globbing characters (`*`, `?`, etc.),\n//@ compatible with the [node `glob` module](https://github.com/isaacs/node-glob).\n//@\n//@ For less-commonly used commands and features, please check out our [wiki\n//@ page](https://github.com/shelljs/shelljs/wiki).\n//@\n\n// Include the docs for all the default commands\n//@commands\n\n// Load all default commands\n__webpack_require__(/*! ./commands */ \"./node_modules/shelljs/commands.js\").forEach(function (command) {\n  __webpack_require__(\"./node_modules/shelljs/src sync recursive ^\\\\.\\\\/.*$\")(\"./\" + command);\n});\n\n//@\n//@ ### exit(code)\n//@\n//@ Exits the current process with the given exit `code`.\nexports.exit = process.exit;\n\n//@include ./src/error\nexports.error = __webpack_require__(/*! ./src/error */ \"./node_modules/shelljs/src/error.js\");\n\n//@include ./src/common\nexports.ShellString = common.ShellString;\n\n//@\n//@ ### env['VAR_NAME']\n//@\n//@ Object containing environment variables (both getter and setter). Shortcut\n//@ to `process.env`.\nexports.env = process.env;\n\n//@\n//@ ### Pipes\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ grep('foo', 'file1.txt', 'file2.txt').sed(/o/g, 'a').to('output.txt');\n//@ echo('files with o\\'s in the name:\\n' + ls().grep('o'));\n//@ cat('test.js').exec('node'); // pipe to exec() call\n//@ ```\n//@\n//@ Commands can send their output to another command in a pipe-like fashion.\n//@ `sed`, `grep`, `cat`, `exec`, `to`, and `toEnd` can appear on the right-hand\n//@ side of a pipe. Pipes can be chained.\n\n//@\n//@ ## Configuration\n//@\n\nexports.config = common.config;\n\n//@\n//@ ### config.silent\n//@\n//@ Example:\n//@\n//@ ```javascript\n//@ var sh = require('shelljs');\n//@ var silentState = sh.config.silent; // save old silent state\n//@ sh.config.silent = true;\n//@ /* ... */\n//@ sh.config.silent = silentState; // restore old silent state\n//@ ```\n//@\n//@ Suppresses all command output if `true`, except for `echo()` calls.\n//@ Default is `false`.\n\n//@\n//@ ### config.fatal\n//@\n//@ Example:\n//@\n//@ ```javascript\n//@ require('shelljs/global');\n//@ config.fatal = true; // or set('-e');\n//@ cp('this_file_does_not_exist', '/dev/null'); // throws Error here\n//@ /* more commands... */\n//@ ```\n//@\n//@ If `true`, the script will throw a Javascript error when any shell.js\n//@ command encounters an error. Default is `false`. This is analogous to\n//@ Bash's `set -e`.\n\n//@\n//@ ### config.verbose\n//@\n//@ Example:\n//@\n//@ ```javascript\n//@ config.verbose = true; // or set('-v');\n//@ cd('dir/');\n//@ rm('-rf', 'foo.txt', 'bar.txt');\n//@ exec('echo hello');\n//@ ```\n//@\n//@ Will print each command as follows:\n//@\n//@ ```\n//@ cd dir/\n//@ rm -rf foo.txt bar.txt\n//@ exec echo hello\n//@ ```\n\n//@\n//@ ### config.globOptions\n//@\n//@ Example:\n//@\n//@ ```javascript\n//@ config.globOptions = {nodir: true};\n//@ ```\n//@\n//@ Use this value for calls to `glob.sync()` instead of the default options.\n\n//@\n//@ ### config.reset()\n//@\n//@ Example:\n//@\n//@ ```javascript\n//@ var shell = require('shelljs');\n//@ // Make changes to shell.config, and do stuff...\n//@ /* ... */\n//@ shell.config.reset(); // reset to original state\n//@ // Do more stuff, but with original settings\n//@ /* ... */\n//@ ```\n//@\n//@ Reset `shell.config` to the defaults:\n//@\n//@ ```javascript\n//@ {\n//@   fatal: false,\n//@   globOptions: {},\n//@   maxdepth: 255,\n//@   noglob: false,\n//@   silent: false,\n//@   verbose: false,\n//@ }\n//@ ```\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/shell.js?");

/***/ }),

/***/ "./node_modules/shelljs/src sync recursive ^\\.\\/.*$":
/*!************************************************!*\
  !*** ./node_modules/shelljs/src sync ^\.\/.*$ ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var map = {\n\t\"./cat\": \"./node_modules/shelljs/src/cat.js\",\n\t\"./cat.js\": \"./node_modules/shelljs/src/cat.js\",\n\t\"./cd\": \"./node_modules/shelljs/src/cd.js\",\n\t\"./cd.js\": \"./node_modules/shelljs/src/cd.js\",\n\t\"./chmod\": \"./node_modules/shelljs/src/chmod.js\",\n\t\"./chmod.js\": \"./node_modules/shelljs/src/chmod.js\",\n\t\"./common\": \"./node_modules/shelljs/src/common.js\",\n\t\"./common.js\": \"./node_modules/shelljs/src/common.js\",\n\t\"./cp\": \"./node_modules/shelljs/src/cp.js\",\n\t\"./cp.js\": \"./node_modules/shelljs/src/cp.js\",\n\t\"./dirs\": \"./node_modules/shelljs/src/dirs.js\",\n\t\"./dirs.js\": \"./node_modules/shelljs/src/dirs.js\",\n\t\"./echo\": \"./node_modules/shelljs/src/echo.js\",\n\t\"./echo.js\": \"./node_modules/shelljs/src/echo.js\",\n\t\"./error\": \"./node_modules/shelljs/src/error.js\",\n\t\"./error.js\": \"./node_modules/shelljs/src/error.js\",\n\t\"./exec\": \"./node_modules/shelljs/src/exec.js\",\n\t\"./exec-child\": \"./node_modules/shelljs/src/exec-child.js\",\n\t\"./exec-child.js\": \"./node_modules/shelljs/src/exec-child.js\",\n\t\"./exec.js\": \"./node_modules/shelljs/src/exec.js\",\n\t\"./find\": \"./node_modules/shelljs/src/find.js\",\n\t\"./find.js\": \"./node_modules/shelljs/src/find.js\",\n\t\"./grep\": \"./node_modules/shelljs/src/grep.js\",\n\t\"./grep.js\": \"./node_modules/shelljs/src/grep.js\",\n\t\"./head\": \"./node_modules/shelljs/src/head.js\",\n\t\"./head.js\": \"./node_modules/shelljs/src/head.js\",\n\t\"./ln\": \"./node_modules/shelljs/src/ln.js\",\n\t\"./ln.js\": \"./node_modules/shelljs/src/ln.js\",\n\t\"./ls\": \"./node_modules/shelljs/src/ls.js\",\n\t\"./ls.js\": \"./node_modules/shelljs/src/ls.js\",\n\t\"./mkdir\": \"./node_modules/shelljs/src/mkdir.js\",\n\t\"./mkdir.js\": \"./node_modules/shelljs/src/mkdir.js\",\n\t\"./mv\": \"./node_modules/shelljs/src/mv.js\",\n\t\"./mv.js\": \"./node_modules/shelljs/src/mv.js\",\n\t\"./popd\": \"./node_modules/shelljs/src/popd.js\",\n\t\"./popd.js\": \"./node_modules/shelljs/src/popd.js\",\n\t\"./pushd\": \"./node_modules/shelljs/src/pushd.js\",\n\t\"./pushd.js\": \"./node_modules/shelljs/src/pushd.js\",\n\t\"./pwd\": \"./node_modules/shelljs/src/pwd.js\",\n\t\"./pwd.js\": \"./node_modules/shelljs/src/pwd.js\",\n\t\"./rm\": \"./node_modules/shelljs/src/rm.js\",\n\t\"./rm.js\": \"./node_modules/shelljs/src/rm.js\",\n\t\"./sed\": \"./node_modules/shelljs/src/sed.js\",\n\t\"./sed.js\": \"./node_modules/shelljs/src/sed.js\",\n\t\"./set\": \"./node_modules/shelljs/src/set.js\",\n\t\"./set.js\": \"./node_modules/shelljs/src/set.js\",\n\t\"./sort\": \"./node_modules/shelljs/src/sort.js\",\n\t\"./sort.js\": \"./node_modules/shelljs/src/sort.js\",\n\t\"./tail\": \"./node_modules/shelljs/src/tail.js\",\n\t\"./tail.js\": \"./node_modules/shelljs/src/tail.js\",\n\t\"./tempdir\": \"./node_modules/shelljs/src/tempdir.js\",\n\t\"./tempdir.js\": \"./node_modules/shelljs/src/tempdir.js\",\n\t\"./test\": \"./node_modules/shelljs/src/test.js\",\n\t\"./test.js\": \"./node_modules/shelljs/src/test.js\",\n\t\"./to\": \"./node_modules/shelljs/src/to.js\",\n\t\"./to.js\": \"./node_modules/shelljs/src/to.js\",\n\t\"./toEnd\": \"./node_modules/shelljs/src/toEnd.js\",\n\t\"./toEnd.js\": \"./node_modules/shelljs/src/toEnd.js\",\n\t\"./touch\": \"./node_modules/shelljs/src/touch.js\",\n\t\"./touch.js\": \"./node_modules/shelljs/src/touch.js\",\n\t\"./uniq\": \"./node_modules/shelljs/src/uniq.js\",\n\t\"./uniq.js\": \"./node_modules/shelljs/src/uniq.js\",\n\t\"./which\": \"./node_modules/shelljs/src/which.js\",\n\t\"./which.js\": \"./node_modules/shelljs/src/which.js\"\n};\n\n\nfunction webpackContext(req) {\n\tvar id = webpackContextResolve(req);\n\treturn __webpack_require__(id);\n}\nfunction webpackContextResolve(req) {\n\tif(!__webpack_require__.o(map, req)) {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t}\n\treturn map[req];\n}\nwebpackContext.keys = function webpackContextKeys() {\n\treturn Object.keys(map);\n};\nwebpackContext.resolve = webpackContextResolve;\nmodule.exports = webpackContext;\nwebpackContext.id = \"./node_modules/shelljs/src sync recursive ^\\\\.\\\\/.*$\";\n\n//# sourceURL=webpack:///./node_modules/shelljs/src_sync_^\\.\\/.*$?");

/***/ }),

/***/ "./node_modules/shelljs/src/cat.js":
/*!*****************************************!*\
  !*** ./node_modules/shelljs/src/cat.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('cat', _cat, {\n  canReceivePipe: true,\n  cmdOptions: {\n    'n': 'number',\n  },\n});\n\n//@\n//@ ### cat([options,] file [, file ...])\n//@ ### cat([options,] file_array)\n//@\n//@ Available options:\n//@\n//@ + `-n`: number all output lines\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ var str = cat('file*.txt');\n//@ var str = cat('file1', 'file2');\n//@ var str = cat(['file1', 'file2']); // same as above\n//@ ```\n//@\n//@ Returns a string containing the given file, or a concatenated string\n//@ containing the files if more than one file is given (a new line character is\n//@ introduced between each file).\nfunction _cat(options, files) {\n  var cat = common.readFromPipe();\n\n  if (!files && !cat) common.error('no paths given');\n\n  files = [].slice.call(arguments, 1);\n\n  files.forEach(function (file) {\n    if (!fs.existsSync(file)) {\n      common.error('no such file or directory: ' + file);\n    } else if (common.statFollowLinks(file).isDirectory()) {\n      common.error(file + ': Is a directory');\n    }\n\n    cat += fs.readFileSync(file, 'utf8');\n  });\n\n  if (options.number) {\n    cat = addNumbers(cat);\n  }\n\n  return cat;\n}\nmodule.exports = _cat;\n\nfunction addNumbers(cat) {\n  var lines = cat.split('\\n');\n  var lastLine = lines.pop();\n\n  lines = lines.map(function (line, i) {\n    return numberedLine(i + 1, line);\n  });\n\n  if (lastLine.length) {\n    lastLine = numberedLine(lines.length + 1, lastLine);\n  }\n  lines.push(lastLine);\n\n  return lines.join('\\n');\n}\n\nfunction numberedLine(n, line) {\n  // GNU cat use six pad start number + tab. See http://lingrok.org/xref/coreutils/src/cat.c#57\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/padStart\n  var number = ('     ' + n).slice(-6) + '\\t';\n  return number + line;\n}\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/cat.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/cd.js":
/*!****************************************!*\
  !*** ./node_modules/shelljs/src/cd.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var os = __webpack_require__(/*! os */ \"os\");\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\n\ncommon.register('cd', _cd, {});\n\n//@\n//@ ### cd([dir])\n//@\n//@ Changes to directory `dir` for the duration of the script. Changes to home\n//@ directory if no argument is supplied.\nfunction _cd(options, dir) {\n  if (!dir) dir = os.homedir();\n\n  if (dir === '-') {\n    if (!process.env.OLDPWD) {\n      common.error('could not find previous directory');\n    } else {\n      dir = process.env.OLDPWD;\n    }\n  }\n\n  try {\n    var curDir = process.cwd();\n    process.chdir(dir);\n    process.env.OLDPWD = curDir;\n  } catch (e) {\n    // something went wrong, let's figure out the error\n    var err;\n    try {\n      common.statFollowLinks(dir); // if this succeeds, it must be some sort of file\n      err = 'not a directory: ' + dir;\n    } catch (e2) {\n      err = 'no such file or directory: ' + dir;\n    }\n    if (err) common.error(err);\n  }\n  return '';\n}\nmodule.exports = _cd;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/cd.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/chmod.js":
/*!*******************************************!*\
  !*** ./node_modules/shelljs/src/chmod.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\n\nvar PERMS = (function (base) {\n  return {\n    OTHER_EXEC: base.EXEC,\n    OTHER_WRITE: base.WRITE,\n    OTHER_READ: base.READ,\n\n    GROUP_EXEC: base.EXEC << 3,\n    GROUP_WRITE: base.WRITE << 3,\n    GROUP_READ: base.READ << 3,\n\n    OWNER_EXEC: base.EXEC << 6,\n    OWNER_WRITE: base.WRITE << 6,\n    OWNER_READ: base.READ << 6,\n\n    // Literal octal numbers are apparently not allowed in \"strict\" javascript.\n    STICKY: parseInt('01000', 8),\n    SETGID: parseInt('02000', 8),\n    SETUID: parseInt('04000', 8),\n\n    TYPE_MASK: parseInt('0770000', 8),\n  };\n}({\n  EXEC: 1,\n  WRITE: 2,\n  READ: 4,\n}));\n\ncommon.register('chmod', _chmod, {\n});\n\n//@\n//@ ### chmod([options,] octal_mode || octal_string, file)\n//@ ### chmod([options,] symbolic_mode, file)\n//@\n//@ Available options:\n//@\n//@ + `-v`: output a diagnostic for every file processed//@\n//@ + `-c`: like verbose, but report only when a change is made//@\n//@ + `-R`: change files and directories recursively//@\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ chmod(755, '/Users/brandon');\n//@ chmod('755', '/Users/brandon'); // same as above\n//@ chmod('u+x', '/Users/brandon');\n//@ chmod('-R', 'a-w', '/Users/brandon');\n//@ ```\n//@\n//@ Alters the permissions of a file or directory by either specifying the\n//@ absolute permissions in octal form or expressing the changes in symbols.\n//@ This command tries to mimic the POSIX behavior as much as possible.\n//@ Notable exceptions:\n//@\n//@ + In symbolic modes, `a-r` and `-r` are identical.  No consideration is\n//@   given to the `umask`.\n//@ + There is no \"quiet\" option, since default behavior is to run silent.\nfunction _chmod(options, mode, filePattern) {\n  if (!filePattern) {\n    if (options.length > 0 && options.charAt(0) === '-') {\n      // Special case where the specified file permissions started with - to subtract perms, which\n      // get picked up by the option parser as command flags.\n      // If we are down by one argument and options starts with -, shift everything over.\n      [].unshift.call(arguments, '');\n    } else {\n      common.error('You must specify a file.');\n    }\n  }\n\n  options = common.parseOptions(options, {\n    'R': 'recursive',\n    'c': 'changes',\n    'v': 'verbose',\n  });\n\n  filePattern = [].slice.call(arguments, 2);\n\n  var files;\n\n  // TODO: replace this with a call to common.expand()\n  if (options.recursive) {\n    files = [];\n    filePattern.forEach(function addFile(expandedFile) {\n      var stat = common.statNoFollowLinks(expandedFile);\n\n      if (!stat.isSymbolicLink()) {\n        files.push(expandedFile);\n\n        if (stat.isDirectory()) {  // intentionally does not follow symlinks.\n          fs.readdirSync(expandedFile).forEach(function (child) {\n            addFile(expandedFile + '/' + child);\n          });\n        }\n      }\n    });\n  } else {\n    files = filePattern;\n  }\n\n  files.forEach(function innerChmod(file) {\n    file = path.resolve(file);\n    if (!fs.existsSync(file)) {\n      common.error('File not found: ' + file);\n    }\n\n    // When recursing, don't follow symlinks.\n    if (options.recursive && common.statNoFollowLinks(file).isSymbolicLink()) {\n      return;\n    }\n\n    var stat = common.statFollowLinks(file);\n    var isDir = stat.isDirectory();\n    var perms = stat.mode;\n    var type = perms & PERMS.TYPE_MASK;\n\n    var newPerms = perms;\n\n    if (isNaN(parseInt(mode, 8))) {\n      // parse options\n      mode.split(',').forEach(function (symbolicMode) {\n        var pattern = /([ugoa]*)([=\\+-])([rwxXst]*)/i;\n        var matches = pattern.exec(symbolicMode);\n\n        if (matches) {\n          var applyTo = matches[1];\n          var operator = matches[2];\n          var change = matches[3];\n\n          var changeOwner = applyTo.indexOf('u') !== -1 || applyTo === 'a' || applyTo === '';\n          var changeGroup = applyTo.indexOf('g') !== -1 || applyTo === 'a' || applyTo === '';\n          var changeOther = applyTo.indexOf('o') !== -1 || applyTo === 'a' || applyTo === '';\n\n          var changeRead = change.indexOf('r') !== -1;\n          var changeWrite = change.indexOf('w') !== -1;\n          var changeExec = change.indexOf('x') !== -1;\n          var changeExecDir = change.indexOf('X') !== -1;\n          var changeSticky = change.indexOf('t') !== -1;\n          var changeSetuid = change.indexOf('s') !== -1;\n\n          if (changeExecDir && isDir) {\n            changeExec = true;\n          }\n\n          var mask = 0;\n          if (changeOwner) {\n            mask |= (changeRead ? PERMS.OWNER_READ : 0) + (changeWrite ? PERMS.OWNER_WRITE : 0) + (changeExec ? PERMS.OWNER_EXEC : 0) + (changeSetuid ? PERMS.SETUID : 0);\n          }\n          if (changeGroup) {\n            mask |= (changeRead ? PERMS.GROUP_READ : 0) + (changeWrite ? PERMS.GROUP_WRITE : 0) + (changeExec ? PERMS.GROUP_EXEC : 0) + (changeSetuid ? PERMS.SETGID : 0);\n          }\n          if (changeOther) {\n            mask |= (changeRead ? PERMS.OTHER_READ : 0) + (changeWrite ? PERMS.OTHER_WRITE : 0) + (changeExec ? PERMS.OTHER_EXEC : 0);\n          }\n\n          // Sticky bit is special - it's not tied to user, group or other.\n          if (changeSticky) {\n            mask |= PERMS.STICKY;\n          }\n\n          switch (operator) {\n            case '+':\n              newPerms |= mask;\n              break;\n\n            case '-':\n              newPerms &= ~mask;\n              break;\n\n            case '=':\n              newPerms = type + mask;\n\n              // According to POSIX, when using = to explicitly set the\n              // permissions, setuid and setgid can never be cleared.\n              if (common.statFollowLinks(file).isDirectory()) {\n                newPerms |= (PERMS.SETUID + PERMS.SETGID) & perms;\n              }\n              break;\n            default:\n              common.error('Could not recognize operator: `' + operator + '`');\n          }\n\n          if (options.verbose) {\n            console.log(file + ' -> ' + newPerms.toString(8));\n          }\n\n          if (perms !== newPerms) {\n            if (!options.verbose && options.changes) {\n              console.log(file + ' -> ' + newPerms.toString(8));\n            }\n            fs.chmodSync(file, newPerms);\n            perms = newPerms; // for the next round of changes!\n          }\n        } else {\n          common.error('Invalid symbolic mode change: ' + symbolicMode);\n        }\n      });\n    } else {\n      // they gave us a full number\n      newPerms = type + parseInt(mode, 8);\n\n      // POSIX rules are that setuid and setgid can only be added using numeric\n      // form, but not cleared.\n      if (common.statFollowLinks(file).isDirectory()) {\n        newPerms |= (PERMS.SETUID + PERMS.SETGID) & perms;\n      }\n\n      fs.chmodSync(file, newPerms);\n    }\n  });\n  return '';\n}\nmodule.exports = _chmod;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/chmod.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/common.js":
/*!********************************************!*\
  !*** ./node_modules/shelljs/src/common.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Ignore warning about 'new String()'\n/* eslint no-new-wrappers: 0 */\n\n\nvar os = __webpack_require__(/*! os */ \"os\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar glob = __webpack_require__(/*! glob */ \"./node_modules/glob/glob.js\");\nvar shell = __webpack_require__(/*! .. */ \"./node_modules/shelljs/shell.js\");\n\nvar shellMethods = Object.create(shell);\n\nexports.extend = Object.assign;\n\n// Check if we're running under electron\nvar isElectron = Boolean(process.versions.electron);\n\n// Module globals (assume no execPath by default)\nvar DEFAULT_CONFIG = {\n  fatal: false,\n  globOptions: {},\n  maxdepth: 255,\n  noglob: false,\n  silent: false,\n  verbose: false,\n  execPath: null,\n  bufLength: 64 * 1024, // 64KB\n};\n\nvar config = {\n  reset: function () {\n    Object.assign(this, DEFAULT_CONFIG);\n    if (!isElectron) {\n      this.execPath = process.execPath;\n    }\n  },\n  resetForTesting: function () {\n    this.reset();\n    this.silent = true;\n  },\n};\n\nconfig.reset();\nexports.config = config;\n\n// Note: commands should generally consider these as read-only values.\nvar state = {\n  error: null,\n  errorCode: 0,\n  currentCmd: 'shell.js',\n};\nexports.state = state;\n\ndelete process.env.OLDPWD; // initially, there's no previous directory\n\n// Reliably test if something is any sort of javascript object\nfunction isObject(a) {\n  return typeof a === 'object' && a !== null;\n}\nexports.isObject = isObject;\n\nfunction log() {\n  /* istanbul ignore next */\n  if (!config.silent) {\n    console.error.apply(console, arguments);\n  }\n}\nexports.log = log;\n\n// Converts strings to be equivalent across all platforms. Primarily responsible\n// for making sure we use '/' instead of '\\' as path separators, but this may be\n// expanded in the future if necessary\nfunction convertErrorOutput(msg) {\n  if (typeof msg !== 'string') {\n    throw new TypeError('input must be a string');\n  }\n  return msg.replace(/\\\\/g, '/');\n}\nexports.convertErrorOutput = convertErrorOutput;\n\n// Shows error message. Throws if config.fatal is true\nfunction error(msg, _code, options) {\n  // Validate input\n  if (typeof msg !== 'string') throw new Error('msg must be a string');\n\n  var DEFAULT_OPTIONS = {\n    continue: false,\n    code: 1,\n    prefix: state.currentCmd + ': ',\n    silent: false,\n  };\n\n  if (typeof _code === 'number' && isObject(options)) {\n    options.code = _code;\n  } else if (isObject(_code)) { // no 'code'\n    options = _code;\n  } else if (typeof _code === 'number') { // no 'options'\n    options = { code: _code };\n  } else if (typeof _code !== 'number') { // only 'msg'\n    options = {};\n  }\n  options = Object.assign({}, DEFAULT_OPTIONS, options);\n\n  if (!state.errorCode) state.errorCode = options.code;\n\n  var logEntry = convertErrorOutput(options.prefix + msg);\n  state.error = state.error ? state.error + '\\n' : '';\n  state.error += logEntry;\n\n  // Throw an error, or log the entry\n  if (config.fatal) throw new Error(logEntry);\n  if (msg.length > 0 && !options.silent) log(logEntry);\n\n  if (!options.continue) {\n    throw {\n      msg: 'earlyExit',\n      retValue: (new ShellString('', state.error, state.errorCode)),\n    };\n  }\n}\nexports.error = error;\n\n//@\n//@ ### ShellString(str)\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ var foo = ShellString('hello world');\n//@ ```\n//@\n//@ Turns a regular string into a string-like object similar to what each\n//@ command returns. This has special methods, like `.to()` and `.toEnd()`.\nfunction ShellString(stdout, stderr, code) {\n  var that;\n  if (stdout instanceof Array) {\n    that = stdout;\n    that.stdout = stdout.join('\\n');\n    if (stdout.length > 0) that.stdout += '\\n';\n  } else {\n    that = new String(stdout);\n    that.stdout = stdout;\n  }\n  that.stderr = stderr;\n  that.code = code;\n  // A list of all commands that can appear on the right-hand side of a pipe\n  // (populated by calls to common.wrap())\n  pipeMethods.forEach(function (cmd) {\n    that[cmd] = shellMethods[cmd].bind(that);\n  });\n  return that;\n}\n\nexports.ShellString = ShellString;\n\n// Returns {'alice': true, 'bob': false} when passed a string and dictionary as follows:\n//   parseOptions('-a', {'a':'alice', 'b':'bob'});\n// Returns {'reference': 'string-value', 'bob': false} when passed two dictionaries of the form:\n//   parseOptions({'-r': 'string-value'}, {'r':'reference', 'b':'bob'});\n// Throws an error when passed a string that does not start with '-':\n//   parseOptions('a', {'a':'alice'}); // throws\nfunction parseOptions(opt, map, errorOptions) {\n  // Validate input\n  if (typeof opt !== 'string' && !isObject(opt)) {\n    throw new Error('options must be strings or key-value pairs');\n  } else if (!isObject(map)) {\n    throw new Error('parseOptions() internal error: map must be an object');\n  } else if (errorOptions && !isObject(errorOptions)) {\n    throw new Error('parseOptions() internal error: errorOptions must be object');\n  }\n\n  if (opt === '--') {\n    // This means there are no options.\n    return {};\n  }\n\n  // All options are false by default\n  var options = {};\n  Object.keys(map).forEach(function (letter) {\n    var optName = map[letter];\n    if (optName[0] !== '!') {\n      options[optName] = false;\n    }\n  });\n\n  if (opt === '') return options; // defaults\n\n  if (typeof opt === 'string') {\n    if (opt[0] !== '-') {\n      throw new Error(\"Options string must start with a '-'\");\n    }\n\n    // e.g. chars = ['R', 'f']\n    var chars = opt.slice(1).split('');\n\n    chars.forEach(function (c) {\n      if (c in map) {\n        var optionName = map[c];\n        if (optionName[0] === '!') {\n          options[optionName.slice(1)] = false;\n        } else {\n          options[optionName] = true;\n        }\n      } else {\n        error('option not recognized: ' + c, errorOptions || {});\n      }\n    });\n  } else { // opt is an Object\n    Object.keys(opt).forEach(function (key) {\n      // key is a string of the form '-r', '-d', etc.\n      var c = key[1];\n      if (c in map) {\n        var optionName = map[c];\n        options[optionName] = opt[key]; // assign the given value\n      } else {\n        error('option not recognized: ' + c, errorOptions || {});\n      }\n    });\n  }\n  return options;\n}\nexports.parseOptions = parseOptions;\n\n// Expands wildcards with matching (ie. existing) file names.\n// For example:\n//   expand(['file*.js']) = ['file1.js', 'file2.js', ...]\n//   (if the files 'file1.js', 'file2.js', etc, exist in the current dir)\nfunction expand(list) {\n  if (!Array.isArray(list)) {\n    throw new TypeError('must be an array');\n  }\n  var expanded = [];\n  list.forEach(function (listEl) {\n    // Don't expand non-strings\n    if (typeof listEl !== 'string') {\n      expanded.push(listEl);\n    } else {\n      var ret;\n      try {\n        ret = glob.sync(listEl, config.globOptions);\n        // if nothing matched, interpret the string literally\n        ret = ret.length > 0 ? ret : [listEl];\n      } catch (e) {\n        // if glob fails, interpret the string literally\n        ret = [listEl];\n      }\n      expanded = expanded.concat(ret);\n    }\n  });\n  return expanded;\n}\nexports.expand = expand;\n\n// Normalizes Buffer creation, using Buffer.alloc if possible.\n// Also provides a good default buffer length for most use cases.\nvar buffer = typeof Buffer.alloc === 'function' ?\n  function (len) {\n    return Buffer.alloc(len || config.bufLength);\n  } :\n  function (len) {\n    return new Buffer(len || config.bufLength);\n  };\nexports.buffer = buffer;\n\n// Normalizes _unlinkSync() across platforms to match Unix behavior, i.e.\n// file can be unlinked even if it's read-only, see https://github.com/joyent/node/issues/3006\nfunction unlinkSync(file) {\n  try {\n    fs.unlinkSync(file);\n  } catch (e) {\n    // Try to override file permission\n    /* istanbul ignore next */\n    if (e.code === 'EPERM') {\n      fs.chmodSync(file, '0666');\n      fs.unlinkSync(file);\n    } else {\n      throw e;\n    }\n  }\n}\nexports.unlinkSync = unlinkSync;\n\n// wrappers around common.statFollowLinks and common.statNoFollowLinks that clarify intent\n// and improve readability\nfunction statFollowLinks() {\n  return fs.statSync.apply(fs, arguments);\n}\nexports.statFollowLinks = statFollowLinks;\n\nfunction statNoFollowLinks() {\n  return fs.lstatSync.apply(fs, arguments);\n}\nexports.statNoFollowLinks = statNoFollowLinks;\n\n// e.g. 'shelljs_a5f185d0443ca...'\nfunction randomFileName() {\n  function randomHash(count) {\n    if (count === 1) {\n      return parseInt(16 * Math.random(), 10).toString(16);\n    }\n    var hash = '';\n    for (var i = 0; i < count; i++) {\n      hash += randomHash(1);\n    }\n    return hash;\n  }\n\n  return 'shelljs_' + randomHash(20);\n}\nexports.randomFileName = randomFileName;\n\n// Common wrapper for all Unix-like commands that performs glob expansion,\n// command-logging, and other nice things\nfunction wrap(cmd, fn, options) {\n  options = options || {};\n  return function () {\n    var retValue = null;\n\n    state.currentCmd = cmd;\n    state.error = null;\n    state.errorCode = 0;\n\n    try {\n      var args = [].slice.call(arguments, 0);\n\n      // Log the command to stderr, if appropriate\n      if (config.verbose) {\n        console.error.apply(console, [cmd].concat(args));\n      }\n\n      // If this is coming from a pipe, let's set the pipedValue (otherwise, set\n      // it to the empty string)\n      state.pipedValue = (this && typeof this.stdout === 'string') ? this.stdout : '';\n\n      if (options.unix === false) { // this branch is for exec()\n        retValue = fn.apply(this, args);\n      } else { // and this branch is for everything else\n        if (isObject(args[0]) && args[0].constructor.name === 'Object') {\n          // a no-op, allowing the syntax `touch({'-r': file}, ...)`\n        } else if (args.length === 0 || typeof args[0] !== 'string' || args[0].length <= 1 || args[0][0] !== '-') {\n          args.unshift(''); // only add dummy option if '-option' not already present\n        }\n\n        // flatten out arrays that are arguments, to make the syntax:\n        //    `cp([file1, file2, file3], dest);`\n        // equivalent to:\n        //    `cp(file1, file2, file3, dest);`\n        args = args.reduce(function (accum, cur) {\n          if (Array.isArray(cur)) {\n            return accum.concat(cur);\n          }\n          accum.push(cur);\n          return accum;\n        }, []);\n\n        // Convert ShellStrings (basically just String objects) to regular strings\n        args = args.map(function (arg) {\n          if (isObject(arg) && arg.constructor.name === 'String') {\n            return arg.toString();\n          }\n          return arg;\n        });\n\n        // Expand the '~' if appropriate\n        var homeDir = os.homedir();\n        args = args.map(function (arg) {\n          if (typeof arg === 'string' && arg.slice(0, 2) === '~/' || arg === '~') {\n            return arg.replace(/^~/, homeDir);\n          }\n          return arg;\n        });\n\n        // Perform glob-expansion on all arguments after globStart, but preserve\n        // the arguments before it (like regexes for sed and grep)\n        if (!config.noglob && options.allowGlobbing === true) {\n          args = args.slice(0, options.globStart).concat(expand(args.slice(options.globStart)));\n        }\n\n        try {\n          // parse options if options are provided\n          if (isObject(options.cmdOptions)) {\n            args[0] = parseOptions(args[0], options.cmdOptions);\n          }\n\n          retValue = fn.apply(this, args);\n        } catch (e) {\n          /* istanbul ignore else */\n          if (e.msg === 'earlyExit') {\n            retValue = e.retValue;\n          } else {\n            throw e; // this is probably a bug that should be thrown up the call stack\n          }\n        }\n      }\n    } catch (e) {\n      /* istanbul ignore next */\n      if (!state.error) {\n        // If state.error hasn't been set it's an error thrown by Node, not us - probably a bug...\n        e.name = 'ShellJSInternalError';\n        throw e;\n      }\n      if (config.fatal) throw e;\n    }\n\n    if (options.wrapOutput &&\n        (typeof retValue === 'string' || Array.isArray(retValue))) {\n      retValue = new ShellString(retValue, state.error, state.errorCode);\n    }\n\n    state.currentCmd = 'shell.js';\n    return retValue;\n  };\n} // wrap\nexports.wrap = wrap;\n\n// This returns all the input that is piped into the current command (or the\n// empty string, if this isn't on the right-hand side of a pipe\nfunction _readFromPipe() {\n  return state.pipedValue;\n}\nexports.readFromPipe = _readFromPipe;\n\nvar DEFAULT_WRAP_OPTIONS = {\n  allowGlobbing: true,\n  canReceivePipe: false,\n  cmdOptions: null,\n  globStart: 1,\n  pipeOnly: false,\n  wrapOutput: true,\n  unix: true,\n};\n\n// This is populated during plugin registration\nvar pipeMethods = [];\n\n// Register a new ShellJS command\nfunction _register(name, implementation, wrapOptions) {\n  wrapOptions = wrapOptions || {};\n\n  // Validate options\n  Object.keys(wrapOptions).forEach(function (option) {\n    if (!DEFAULT_WRAP_OPTIONS.hasOwnProperty(option)) {\n      throw new Error(\"Unknown option '\" + option + \"'\");\n    }\n    if (typeof wrapOptions[option] !== typeof DEFAULT_WRAP_OPTIONS[option]) {\n      throw new TypeError(\"Unsupported type '\" + typeof wrapOptions[option] +\n        \"' for option '\" + option + \"'\");\n    }\n  });\n\n  // If an option isn't specified, use the default\n  wrapOptions = Object.assign({}, DEFAULT_WRAP_OPTIONS, wrapOptions);\n\n  if (shell[name]) {\n    throw new Error('Command `' + name + '` already exists');\n  }\n\n  if (wrapOptions.pipeOnly) {\n    wrapOptions.canReceivePipe = true;\n    shellMethods[name] = wrap(name, implementation, wrapOptions);\n  } else {\n    shell[name] = wrap(name, implementation, wrapOptions);\n  }\n\n  if (wrapOptions.canReceivePipe) {\n    pipeMethods.push(name);\n  }\n}\nexports.register = _register;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/common.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/cp.js":
/*!****************************************!*\
  !*** ./node_modules/shelljs/src/cp.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\n\ncommon.register('cp', _cp, {\n  cmdOptions: {\n    'f': '!no_force',\n    'n': 'no_force',\n    'u': 'update',\n    'R': 'recursive',\n    'r': 'recursive',\n    'L': 'followsymlink',\n    'P': 'noFollowsymlink',\n  },\n  wrapOutput: false,\n});\n\n// Buffered file copy, synchronous\n// (Using readFileSync() + writeFileSync() could easily cause a memory overflow\n//  with large files)\nfunction copyFileSync(srcFile, destFile, options) {\n  if (!fs.existsSync(srcFile)) {\n    common.error('copyFileSync: no such file or directory: ' + srcFile);\n  }\n\n  var isWindows = process.platform === 'win32';\n\n  // Check the mtimes of the files if the '-u' flag is provided\n  try {\n    if (options.update && common.statFollowLinks(srcFile).mtime < fs.statSync(destFile).mtime) {\n      return;\n    }\n  } catch (e) {\n    // If we're here, destFile probably doesn't exist, so just do a normal copy\n  }\n\n  if (common.statNoFollowLinks(srcFile).isSymbolicLink() && !options.followsymlink) {\n    try {\n      common.statNoFollowLinks(destFile);\n      common.unlinkSync(destFile); // re-link it\n    } catch (e) {\n      // it doesn't exist, so no work needs to be done\n    }\n\n    var symlinkFull = fs.readlinkSync(srcFile);\n    fs.symlinkSync(symlinkFull, destFile, isWindows ? 'junction' : null);\n  } else {\n    var buf = common.buffer();\n    var bufLength = buf.length;\n    var bytesRead = bufLength;\n    var pos = 0;\n    var fdr = null;\n    var fdw = null;\n\n    try {\n      fdr = fs.openSync(srcFile, 'r');\n    } catch (e) {\n      /* istanbul ignore next */\n      common.error('copyFileSync: could not read src file (' + srcFile + ')');\n    }\n\n    try {\n      fdw = fs.openSync(destFile, 'w');\n    } catch (e) {\n      /* istanbul ignore next */\n      common.error('copyFileSync: could not write to dest file (code=' + e.code + '):' + destFile);\n    }\n\n    while (bytesRead === bufLength) {\n      bytesRead = fs.readSync(fdr, buf, 0, bufLength, pos);\n      fs.writeSync(fdw, buf, 0, bytesRead);\n      pos += bytesRead;\n    }\n\n    fs.closeSync(fdr);\n    fs.closeSync(fdw);\n\n    fs.chmodSync(destFile, common.statFollowLinks(srcFile).mode);\n  }\n}\n\n// Recursively copies 'sourceDir' into 'destDir'\n// Adapted from https://github.com/ryanmcgrath/wrench-js\n//\n// Copyright (c) 2010 Ryan McGrath\n// Copyright (c) 2012 Artur Adib\n//\n// Licensed under the MIT License\n// http://www.opensource.org/licenses/mit-license.php\nfunction cpdirSyncRecursive(sourceDir, destDir, currentDepth, opts) {\n  if (!opts) opts = {};\n\n  // Ensure there is not a run away recursive copy\n  if (currentDepth >= common.config.maxdepth) return;\n  currentDepth++;\n\n  var isWindows = process.platform === 'win32';\n\n  // Create the directory where all our junk is moving to; read the mode of the\n  // source directory and mirror it\n  try {\n    fs.mkdirSync(destDir);\n  } catch (e) {\n    // if the directory already exists, that's okay\n    if (e.code !== 'EEXIST') throw e;\n  }\n\n  var files = fs.readdirSync(sourceDir);\n\n  for (var i = 0; i < files.length; i++) {\n    var srcFile = sourceDir + '/' + files[i];\n    var destFile = destDir + '/' + files[i];\n    var srcFileStat = common.statNoFollowLinks(srcFile);\n\n    var symlinkFull;\n    if (opts.followsymlink) {\n      if (cpcheckcycle(sourceDir, srcFile)) {\n        // Cycle link found.\n        console.error('Cycle link found.');\n        symlinkFull = fs.readlinkSync(srcFile);\n        fs.symlinkSync(symlinkFull, destFile, isWindows ? 'junction' : null);\n        continue;\n      }\n    }\n    if (srcFileStat.isDirectory()) {\n      /* recursion this thing right on back. */\n      cpdirSyncRecursive(srcFile, destFile, currentDepth, opts);\n    } else if (srcFileStat.isSymbolicLink() && !opts.followsymlink) {\n      symlinkFull = fs.readlinkSync(srcFile);\n      try {\n        common.statNoFollowLinks(destFile);\n        common.unlinkSync(destFile); // re-link it\n      } catch (e) {\n        // it doesn't exist, so no work needs to be done\n      }\n      fs.symlinkSync(symlinkFull, destFile, isWindows ? 'junction' : null);\n    } else if (srcFileStat.isSymbolicLink() && opts.followsymlink) {\n      srcFileStat = common.statFollowLinks(srcFile);\n      if (srcFileStat.isDirectory()) {\n        cpdirSyncRecursive(srcFile, destFile, currentDepth, opts);\n      } else {\n        copyFileSync(srcFile, destFile, opts);\n      }\n    } else {\n      /* At this point, we've hit a file actually worth copying... so copy it on over. */\n      if (fs.existsSync(destFile) && opts.no_force) {\n        common.log('skipping existing file: ' + files[i]);\n      } else {\n        copyFileSync(srcFile, destFile, opts);\n      }\n    }\n  } // for files\n\n  // finally change the mode for the newly created directory (otherwise, we\n  // couldn't add files to a read-only directory).\n  var checkDir = common.statFollowLinks(sourceDir);\n  fs.chmodSync(destDir, checkDir.mode);\n} // cpdirSyncRecursive\n\n// Checks if cureent file was created recently\nfunction checkRecentCreated(sources, index) {\n  var lookedSource = sources[index];\n  return sources.slice(0, index).some(function (src) {\n    return path.basename(src) === path.basename(lookedSource);\n  });\n}\n\nfunction cpcheckcycle(sourceDir, srcFile) {\n  var srcFileStat = common.statNoFollowLinks(srcFile);\n  if (srcFileStat.isSymbolicLink()) {\n    // Do cycle check. For example:\n    //   $ mkdir -p 1/2/3/4\n    //   $ cd  1/2/3/4\n    //   $ ln -s ../../3 link\n    //   $ cd ../../../..\n    //   $ cp -RL 1 copy\n    var cyclecheck = common.statFollowLinks(srcFile);\n    if (cyclecheck.isDirectory()) {\n      var sourcerealpath = fs.realpathSync(sourceDir);\n      var symlinkrealpath = fs.realpathSync(srcFile);\n      var re = new RegExp(symlinkrealpath);\n      if (re.test(sourcerealpath)) {\n        return true;\n      }\n    }\n  }\n  return false;\n}\n\n//@\n//@ ### cp([options,] source [, source ...], dest)\n//@ ### cp([options,] source_array, dest)\n//@\n//@ Available options:\n//@\n//@ + `-f`: force (default behavior)\n//@ + `-n`: no-clobber\n//@ + `-u`: only copy if `source` is newer than `dest`\n//@ + `-r`, `-R`: recursive\n//@ + `-L`: follow symlinks\n//@ + `-P`: don't follow symlinks\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ cp('file1', 'dir1');\n//@ cp('-R', 'path/to/dir/', '~/newCopy/');\n//@ cp('-Rf', '/tmp/*', '/usr/local/*', '/home/tmp');\n//@ cp('-Rf', ['/tmp/*', '/usr/local/*'], '/home/tmp'); // same as above\n//@ ```\n//@\n//@ Copies files.\nfunction _cp(options, sources, dest) {\n  // If we're missing -R, it actually implies -L (unless -P is explicit)\n  if (options.followsymlink) {\n    options.noFollowsymlink = false;\n  }\n  if (!options.recursive && !options.noFollowsymlink) {\n    options.followsymlink = true;\n  }\n\n  // Get sources, dest\n  if (arguments.length < 3) {\n    common.error('missing <source> and/or <dest>');\n  } else {\n    sources = [].slice.call(arguments, 1, arguments.length - 1);\n    dest = arguments[arguments.length - 1];\n  }\n\n  var destExists = fs.existsSync(dest);\n  var destStat = destExists && common.statFollowLinks(dest);\n\n  // Dest is not existing dir, but multiple sources given\n  if ((!destExists || !destStat.isDirectory()) && sources.length > 1) {\n    common.error('dest is not a directory (too many sources)');\n  }\n\n  // Dest is an existing file, but -n is given\n  if (destExists && destStat.isFile() && options.no_force) {\n    return new common.ShellString('', '', 0);\n  }\n\n  sources.forEach(function (src, srcIndex) {\n    if (!fs.existsSync(src)) {\n      if (src === '') src = \"''\"; // if src was empty string, display empty string\n      common.error('no such file or directory: ' + src, { continue: true });\n      return; // skip file\n    }\n    var srcStat = common.statFollowLinks(src);\n    if (!options.noFollowsymlink && srcStat.isDirectory()) {\n      if (!options.recursive) {\n        // Non-Recursive\n        common.error(\"omitting directory '\" + src + \"'\", { continue: true });\n      } else {\n        // Recursive\n        // 'cp /a/source dest' should create 'source' in 'dest'\n        var newDest = (destStat && destStat.isDirectory()) ?\n            path.join(dest, path.basename(src)) :\n            dest;\n\n        try {\n          common.statFollowLinks(path.dirname(dest));\n          cpdirSyncRecursive(src, newDest, 0, { no_force: options.no_force, followsymlink: options.followsymlink });\n        } catch (e) {\n          /* istanbul ignore next */\n          common.error(\"cannot create directory '\" + dest + \"': No such file or directory\");\n        }\n      }\n    } else {\n      // If here, src is a file\n\n      // When copying to '/path/dir':\n      //    thisDest = '/path/dir/file1'\n      var thisDest = dest;\n      if (destStat && destStat.isDirectory()) {\n        thisDest = path.normalize(dest + '/' + path.basename(src));\n      }\n\n      var thisDestExists = fs.existsSync(thisDest);\n      if (thisDestExists && checkRecentCreated(sources, srcIndex)) {\n        // cannot overwrite file created recently in current execution, but we want to continue copying other files\n        if (!options.no_force) {\n          common.error(\"will not overwrite just-created '\" + thisDest + \"' with '\" + src + \"'\", { continue: true });\n        }\n        return;\n      }\n\n      if (thisDestExists && options.no_force) {\n        return; // skip file\n      }\n\n      if (path.relative(src, thisDest) === '') {\n        // a file cannot be copied to itself, but we want to continue copying other files\n        common.error(\"'\" + thisDest + \"' and '\" + src + \"' are the same file\", { continue: true });\n        return;\n      }\n\n      copyFileSync(src, thisDest, options);\n    }\n  }); // forEach(src)\n\n  return new common.ShellString('', common.state.error, common.state.errorCode);\n}\nmodule.exports = _cp;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/cp.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/dirs.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/dirs.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar _cd = __webpack_require__(/*! ./cd */ \"./node_modules/shelljs/src/cd.js\");\nvar path = __webpack_require__(/*! path */ \"path\");\n\ncommon.register('dirs', _dirs, {\n  wrapOutput: false,\n});\ncommon.register('pushd', _pushd, {\n  wrapOutput: false,\n});\ncommon.register('popd', _popd, {\n  wrapOutput: false,\n});\n\n// Pushd/popd/dirs internals\nvar _dirStack = [];\n\nfunction _isStackIndex(index) {\n  return (/^[\\-+]\\d+$/).test(index);\n}\n\nfunction _parseStackIndex(index) {\n  if (_isStackIndex(index)) {\n    if (Math.abs(index) < _dirStack.length + 1) { // +1 for pwd\n      return (/^-/).test(index) ? Number(index) - 1 : Number(index);\n    }\n    common.error(index + ': directory stack index out of range');\n  } else {\n    common.error(index + ': invalid number');\n  }\n}\n\nfunction _actualDirStack() {\n  return [process.cwd()].concat(_dirStack);\n}\n\n//@\n//@ ### pushd([options,] [dir | '-N' | '+N'])\n//@\n//@ Available options:\n//@\n//@ + `-n`: Suppresses the normal change of directory when adding directories to the stack, so that only the stack is manipulated.\n//@ + `-q`: Supresses output to the console.\n//@\n//@ Arguments:\n//@\n//@ + `dir`: Sets the current working directory to the top of the stack, then executes the equivalent of `cd dir`.\n//@ + `+N`: Brings the Nth directory (counting from the left of the list printed by dirs, starting with zero) to the top of the list by rotating the stack.\n//@ + `-N`: Brings the Nth directory (counting from the right of the list printed by dirs, starting with zero) to the top of the list by rotating the stack.\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ // process.cwd() === '/usr'\n//@ pushd('/etc'); // Returns /etc /usr\n//@ pushd('+1');   // Returns /usr /etc\n//@ ```\n//@\n//@ Save the current directory on the top of the directory stack and then `cd` to `dir`. With no arguments, `pushd` exchanges the top two directories. Returns an array of paths in the stack.\nfunction _pushd(options, dir) {\n  if (_isStackIndex(options)) {\n    dir = options;\n    options = '';\n  }\n\n  options = common.parseOptions(options, {\n    'n': 'no-cd',\n    'q': 'quiet',\n  });\n\n  var dirs = _actualDirStack();\n\n  if (dir === '+0') {\n    return dirs; // +0 is a noop\n  } else if (!dir) {\n    if (dirs.length > 1) {\n      dirs = dirs.splice(1, 1).concat(dirs);\n    } else {\n      return common.error('no other directory');\n    }\n  } else if (_isStackIndex(dir)) {\n    var n = _parseStackIndex(dir);\n    dirs = dirs.slice(n).concat(dirs.slice(0, n));\n  } else {\n    if (options['no-cd']) {\n      dirs.splice(1, 0, dir);\n    } else {\n      dirs.unshift(dir);\n    }\n  }\n\n  if (options['no-cd']) {\n    dirs = dirs.slice(1);\n  } else {\n    dir = path.resolve(dirs.shift());\n    _cd('', dir);\n  }\n\n  _dirStack = dirs;\n  return _dirs(options.quiet ? '-q' : '');\n}\nexports.pushd = _pushd;\n\n//@\n//@\n//@ ### popd([options,] ['-N' | '+N'])\n//@\n//@ Available options:\n//@\n//@ + `-n`: Suppress the normal directory change when removing directories from the stack, so that only the stack is manipulated.\n//@ + `-q`: Supresses output to the console.\n//@\n//@ Arguments:\n//@\n//@ + `+N`: Removes the Nth directory (counting from the left of the list printed by dirs), starting with zero.\n//@ + `-N`: Removes the Nth directory (counting from the right of the list printed by dirs), starting with zero.\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ echo(process.cwd()); // '/usr'\n//@ pushd('/etc');       // '/etc /usr'\n//@ echo(process.cwd()); // '/etc'\n//@ popd();              // '/usr'\n//@ echo(process.cwd()); // '/usr'\n//@ ```\n//@\n//@ When no arguments are given, `popd` removes the top directory from the stack and performs a `cd` to the new top directory. The elements are numbered from 0, starting at the first directory listed with dirs (i.e., `popd` is equivalent to `popd +0`). Returns an array of paths in the stack.\nfunction _popd(options, index) {\n  if (_isStackIndex(options)) {\n    index = options;\n    options = '';\n  }\n\n  options = common.parseOptions(options, {\n    'n': 'no-cd',\n    'q': 'quiet',\n  });\n\n  if (!_dirStack.length) {\n    return common.error('directory stack empty');\n  }\n\n  index = _parseStackIndex(index || '+0');\n\n  if (options['no-cd'] || index > 0 || _dirStack.length + index === 0) {\n    index = index > 0 ? index - 1 : index;\n    _dirStack.splice(index, 1);\n  } else {\n    var dir = path.resolve(_dirStack.shift());\n    _cd('', dir);\n  }\n\n  return _dirs(options.quiet ? '-q' : '');\n}\nexports.popd = _popd;\n\n//@\n//@\n//@ ### dirs([options | '+N' | '-N'])\n//@\n//@ Available options:\n//@\n//@ + `-c`: Clears the directory stack by deleting all of the elements.\n//@ + `-q`: Supresses output to the console.\n//@\n//@ Arguments:\n//@\n//@ + `+N`: Displays the Nth directory (counting from the left of the list printed by dirs when invoked without options), starting with zero.\n//@ + `-N`: Displays the Nth directory (counting from the right of the list printed by dirs when invoked without options), starting with zero.\n//@\n//@ Display the list of currently remembered directories. Returns an array of paths in the stack, or a single path if `+N` or `-N` was specified.\n//@\n//@ See also: `pushd`, `popd`\nfunction _dirs(options, index) {\n  if (_isStackIndex(options)) {\n    index = options;\n    options = '';\n  }\n\n  options = common.parseOptions(options, {\n    'c': 'clear',\n    'q': 'quiet',\n  });\n\n  if (options.clear) {\n    _dirStack = [];\n    return _dirStack;\n  }\n\n  var stack = _actualDirStack();\n\n  if (index) {\n    index = _parseStackIndex(index);\n\n    if (index < 0) {\n      index = stack.length + index;\n    }\n\n    if (!options.quiet) {\n      common.log(stack[index]);\n    }\n    return stack[index];\n  }\n\n  if (!options.quiet) {\n    common.log(stack.join(' '));\n  }\n\n  return stack;\n}\nexports.dirs = _dirs;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/dirs.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/echo.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/echo.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var format = __webpack_require__(/*! util */ \"util\").format;\n\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\n\ncommon.register('echo', _echo, {\n  allowGlobbing: false,\n});\n\n//@\n//@ ### echo([options,] string [, string ...])\n//@\n//@ Available options:\n//@\n//@ + `-e`: interpret backslash escapes (default)\n//@ + `-n`: remove trailing newline from output\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ echo('hello world');\n//@ var str = echo('hello world');\n//@ echo('-n', 'no newline at end');\n//@ ```\n//@\n//@ Prints `string` to stdout, and returns string with additional utility methods\n//@ like `.to()`.\nfunction _echo(opts) {\n  // allow strings starting with '-', see issue #20\n  var messages = [].slice.call(arguments, opts ? 0 : 1);\n  var options = {};\n\n  // If the first argument starts with '-', parse it as options string.\n  // If parseOptions throws, it wasn't an options string.\n  try {\n    options = common.parseOptions(messages[0], {\n      'e': 'escapes',\n      'n': 'no_newline',\n    }, {\n      silent: true,\n    });\n\n    // Allow null to be echoed\n    if (messages[0]) {\n      messages.shift();\n    }\n  } catch (_) {\n    // Clear out error if an error occurred\n    common.state.error = null;\n  }\n\n  var output = format.apply(null, messages);\n\n  // Add newline if -n is not passed.\n  if (!options.no_newline) {\n    output += '\\n';\n  }\n\n  process.stdout.write(output);\n\n  return output;\n}\n\nmodule.exports = _echo;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/echo.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/error.js":
/*!*******************************************!*\
  !*** ./node_modules/shelljs/src/error.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\n\n//@\n//@ ### error()\n//@\n//@ Tests if error occurred in the last command. Returns a truthy value if an\n//@ error returned, or a falsy value otherwise.\n//@\n//@ **Note**: do not rely on the\n//@ return value to be an error message. If you need the last error message, use\n//@ the `.stderr` attribute from the last command's return value instead.\nfunction error() {\n  return common.state.error;\n}\nmodule.exports = error;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/error.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/exec-child.js":
/*!************************************************!*\
  !*** ./node_modules/shelljs/src/exec-child.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(module) {if (__webpack_require__.c[__webpack_require__.s] !== module) {\n  throw new Error('This file should not be required');\n}\n\nvar childProcess = __webpack_require__(/*! child_process */ \"child_process\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\nvar paramFilePath = process.argv[2];\n\nvar serializedParams = fs.readFileSync(paramFilePath, 'utf8');\nvar params = JSON.parse(serializedParams);\n\nvar cmd = params.command;\nvar execOptions = params.execOptions;\nvar pipe = params.pipe;\nvar stdoutFile = params.stdoutFile;\nvar stderrFile = params.stderrFile;\n\nvar c = childProcess.exec(cmd, execOptions, function (err) {\n  if (!err) {\n    process.exitCode = 0;\n  } else if (err.code === undefined) {\n    process.exitCode = 1;\n  } else {\n    process.exitCode = err.code;\n  }\n});\n\nvar stdoutStream = fs.createWriteStream(stdoutFile);\nvar stderrStream = fs.createWriteStream(stderrFile);\n\nc.stdout.pipe(stdoutStream);\nc.stderr.pipe(stderrStream);\nc.stdout.pipe(process.stdout);\nc.stderr.pipe(process.stderr);\n\nif (pipe) {\n  c.stdin.end(pipe);\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/module.js */ \"./node_modules/webpack/buildin/module.js\")(module)))\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/exec-child.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/exec.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/exec.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar _tempDir = __webpack_require__(/*! ./tempdir */ \"./node_modules/shelljs/src/tempdir.js\").tempDir;\nvar _pwd = __webpack_require__(/*! ./pwd */ \"./node_modules/shelljs/src/pwd.js\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar child = __webpack_require__(/*! child_process */ \"child_process\");\n\nvar DEFAULT_MAXBUFFER_SIZE = 20 * 1024 * 1024;\nvar DEFAULT_ERROR_CODE = 1;\n\ncommon.register('exec', _exec, {\n  unix: false,\n  canReceivePipe: true,\n  wrapOutput: false,\n});\n\n// We use this function to run `exec` synchronously while also providing realtime\n// output.\nfunction execSync(cmd, opts, pipe) {\n  if (!common.config.execPath) {\n    common.error('Unable to find a path to the node binary. Please manually set config.execPath');\n  }\n\n  var tempDir = _tempDir();\n  var paramsFile = path.resolve(tempDir + '/' + common.randomFileName());\n  var stderrFile = path.resolve(tempDir + '/' + common.randomFileName());\n  var stdoutFile = path.resolve(tempDir + '/' + common.randomFileName());\n\n  opts = common.extend({\n    silent: common.config.silent,\n    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  if (fs.existsSync(paramsFile)) common.unlinkSync(paramsFile);\n  if (fs.existsSync(stderrFile)) common.unlinkSync(stderrFile);\n  if (fs.existsSync(stdoutFile)) common.unlinkSync(stdoutFile);\n\n  opts.cwd = path.resolve(opts.cwd);\n\n  var paramsToSerialize = {\n    command: cmd,\n    execOptions: opts,\n    pipe: pipe,\n    stdoutFile: stdoutFile,\n    stderrFile: stderrFile,\n  };\n\n  fs.writeFileSync(paramsFile, JSON.stringify(paramsToSerialize), 'utf8');\n\n  var execArgs = [\n    path.join(__dirname, 'exec-child.js'),\n    paramsFile,\n  ];\n\n  /* istanbul ignore else */\n  if (opts.silent) {\n    opts.stdio = 'ignore';\n  } else {\n    opts.stdio = [0, 1, 2];\n  }\n\n  var code = 0;\n\n  // Welcome to the future\n  try {\n    // Bad things if we pass in a `shell` option to child_process.execFileSync,\n    // so we need to explicitly remove it here.\n    delete opts.shell;\n\n    child.execFileSync(common.config.execPath, execArgs, opts);\n  } catch (e) {\n    // Commands with non-zero exit code raise an exception.\n    code = e.status || DEFAULT_ERROR_CODE;\n  }\n\n  // fs.readFileSync uses buffer encoding by default, so call\n  // it without the encoding option if the encoding is 'buffer'.\n  // Also, if the exec timeout is too short for node to start up,\n  // the files will not be created, so these calls will throw.\n  var stdout = '';\n  var stderr = '';\n  if (opts.encoding === 'buffer') {\n    stdout = fs.readFileSync(stdoutFile);\n    stderr = fs.readFileSync(stderrFile);\n  } else {\n    stdout = fs.readFileSync(stdoutFile, opts.encoding);\n    stderr = fs.readFileSync(stderrFile, opts.encoding);\n  }\n\n  // No biggie if we can't erase the files now -- they're in a temp dir anyway\n  try { common.unlinkSync(paramsFile); } catch (e) {}\n  try { common.unlinkSync(stderrFile); } catch (e) {}\n  try { common.unlinkSync(stdoutFile); } catch (e) {}\n\n  if (code !== 0) {\n    // Note: `silent` should be unconditionally true to avoid double-printing\n    // the command's stderr, and to avoid printing any stderr when the user has\n    // set `shell.config.silent`.\n    common.error(stderr, code, { continue: true, silent: true });\n  }\n  var obj = common.ShellString(stdout, stderr, code);\n  return obj;\n} // execSync()\n\n// Wrapper around exec() to enable echoing output to console in real time\nfunction execAsync(cmd, opts, pipe, callback) {\n  opts = common.extend({\n    silent: common.config.silent,\n    cwd: _pwd().toString(),\n    env: process.env,\n    maxBuffer: DEFAULT_MAXBUFFER_SIZE,\n    encoding: 'utf8',\n  }, opts);\n\n  var c = child.exec(cmd, opts, function (err, stdout, stderr) {\n    if (callback) {\n      if (!err) {\n        callback(0, stdout, stderr);\n      } else if (err.code === undefined) {\n        // See issue #536\n        /* istanbul ignore next */\n        callback(1, stdout, stderr);\n      } else {\n        callback(err.code, stdout, stderr);\n      }\n    }\n  });\n\n  if (pipe) c.stdin.end(pipe);\n\n  if (!opts.silent) {\n    c.stdout.pipe(process.stdout);\n    c.stderr.pipe(process.stderr);\n  }\n\n  return c;\n}\n\n//@\n//@ ### exec(command [, options] [, callback])\n//@\n//@ Available options:\n//@\n//@ + `async`: Asynchronous execution. If a callback is provided, it will be set to\n//@   `true`, regardless of the passed value (default: `false`).\n//@ + `silent`: Do not echo program output to console (default: `false`).\n//@ + `encoding`: Character encoding to use. Affects the values returned to stdout and stderr, and\n//@   what is written to stdout and stderr when not in silent mode (default: `'utf8'`).\n//@ + and any option available to Node.js's\n//@   [`child_process.exec()`](https://nodejs.org/api/child_process.html#child_process_child_process_exec_command_options_callback)\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ var version = exec('node --version', {silent:true}).stdout;\n//@\n//@ var child = exec('some_long_running_process', {async:true});\n//@ child.stdout.on('data', function(data) {\n//@   /* ... do something with data ... */\n//@ });\n//@\n//@ exec('some_long_running_process', function(code, stdout, stderr) {\n//@   console.log('Exit code:', code);\n//@   console.log('Program output:', stdout);\n//@   console.log('Program stderr:', stderr);\n//@ });\n//@ ```\n//@\n//@ Executes the given `command` _synchronously_, unless otherwise specified.  When in synchronous\n//@ mode, this returns a `ShellString` (compatible with ShellJS v0.6.x, which returns an object\n//@ of the form `{ code:..., stdout:... , stderr:... }`). Otherwise, this returns the child process\n//@ object, and the `callback` receives the arguments `(code, stdout, stderr)`.\n//@\n//@ Not seeing the behavior you want? `exec()` runs everything through `sh`\n//@ by default (or `cmd.exe` on Windows), which differs from `bash`. If you\n//@ need bash-specific behavior, try out the `{shell: 'path/to/bash'}` option.\nfunction _exec(command, options, callback) {\n  options = options || {};\n  if (!command) common.error('must specify command');\n\n  var pipe = common.readFromPipe();\n\n  // Callback is defined instead of options.\n  if (typeof options === 'function') {\n    callback = options;\n    options = { async: true };\n  }\n\n  // Callback is defined with options.\n  if (typeof options === 'object' && typeof callback === 'function') {\n    options.async = true;\n  }\n\n  options = common.extend({\n    silent: common.config.silent,\n    async: false,\n  }, options);\n\n  if (options.async) {\n    return execAsync(command, options, pipe, callback);\n  } else {\n    return execSync(command, options, pipe);\n  }\n}\nmodule.exports = _exec;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/exec.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/find.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/find.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var path = __webpack_require__(/*! path */ \"path\");\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar _ls = __webpack_require__(/*! ./ls */ \"./node_modules/shelljs/src/ls.js\");\n\ncommon.register('find', _find, {});\n\n//@\n//@ ### find(path [, path ...])\n//@ ### find(path_array)\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ find('src', 'lib');\n//@ find(['src', 'lib']); // same as above\n//@ find('.').filter(function(file) { return file.match(/\\.js$/); });\n//@ ```\n//@\n//@ Returns array of all files (however deep) in the given paths.\n//@\n//@ The main difference from `ls('-R', path)` is that the resulting file names\n//@ include the base directories (e.g., `lib/resources/file1` instead of just `file1`).\nfunction _find(options, paths) {\n  if (!paths) {\n    common.error('no path specified');\n  } else if (typeof paths === 'string') {\n    paths = [].slice.call(arguments, 1);\n  }\n\n  var list = [];\n\n  function pushFile(file) {\n    if (process.platform === 'win32') {\n      file = file.replace(/\\\\/g, '/');\n    }\n    list.push(file);\n  }\n\n  // why not simply do `ls('-R', paths)`? because the output wouldn't give the base dirs\n  // to get the base dir in the output, we need instead `ls('-R', 'dir/*')` for every directory\n\n  paths.forEach(function (file) {\n    var stat;\n    try {\n      stat = common.statFollowLinks(file);\n    } catch (e) {\n      common.error('no such file or directory: ' + file);\n    }\n\n    pushFile(file);\n\n    if (stat.isDirectory()) {\n      _ls({ recursive: true, all: true }, file).forEach(function (subfile) {\n        pushFile(path.join(file, subfile));\n      });\n    }\n  });\n\n  return list;\n}\nmodule.exports = _find;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/find.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/grep.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/grep.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('grep', _grep, {\n  globStart: 2, // don't glob-expand the regex\n  canReceivePipe: true,\n  cmdOptions: {\n    'v': 'inverse',\n    'l': 'nameOnly',\n    'i': 'ignoreCase',\n  },\n});\n\n//@\n//@ ### grep([options,] regex_filter, file [, file ...])\n//@ ### grep([options,] regex_filter, file_array)\n//@\n//@ Available options:\n//@\n//@ + `-v`: Invert `regex_filter` (only print non-matching lines).\n//@ + `-l`: Print only filenames of matching files.\n//@ + `-i`: Ignore case.\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ grep('-v', 'GLOBAL_VARIABLE', '*.js');\n//@ grep('GLOBAL_VARIABLE', '*.js');\n//@ ```\n//@\n//@ Reads input string from given files and returns a string containing all lines of the\n//@ file that match the given `regex_filter`.\nfunction _grep(options, regex, files) {\n  // Check if this is coming from a pipe\n  var pipe = common.readFromPipe();\n\n  if (!files && !pipe) common.error('no paths given', 2);\n\n  files = [].slice.call(arguments, 2);\n\n  if (pipe) {\n    files.unshift('-');\n  }\n\n  var grep = [];\n  if (options.ignoreCase) {\n    regex = new RegExp(regex, 'i');\n  }\n  files.forEach(function (file) {\n    if (!fs.existsSync(file) && file !== '-') {\n      common.error('no such file or directory: ' + file, 2, { continue: true });\n      return;\n    }\n\n    var contents = file === '-' ? pipe : fs.readFileSync(file, 'utf8');\n    if (options.nameOnly) {\n      if (contents.match(regex)) {\n        grep.push(file);\n      }\n    } else {\n      var lines = contents.split('\\n');\n      lines.forEach(function (line) {\n        var matched = line.match(regex);\n        if ((options.inverse && !matched) || (!options.inverse && matched)) {\n          grep.push(line);\n        }\n      });\n    }\n  });\n\n  return grep.join('\\n') + '\\n';\n}\nmodule.exports = _grep;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/grep.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/head.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/head.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('head', _head, {\n  canReceivePipe: true,\n  cmdOptions: {\n    'n': 'numLines',\n  },\n});\n\n// Reads |numLines| lines or the entire file, whichever is less.\nfunction readSomeLines(file, numLines) {\n  var buf = common.buffer();\n  var bufLength = buf.length;\n  var bytesRead = bufLength;\n  var pos = 0;\n\n  var fdr = fs.openSync(file, 'r');\n  var numLinesRead = 0;\n  var ret = '';\n  while (bytesRead === bufLength && numLinesRead < numLines) {\n    bytesRead = fs.readSync(fdr, buf, 0, bufLength, pos);\n    var bufStr = buf.toString('utf8', 0, bytesRead);\n    numLinesRead += bufStr.split('\\n').length - 1;\n    ret += bufStr;\n    pos += bytesRead;\n  }\n\n  fs.closeSync(fdr);\n  return ret;\n}\n\n//@\n//@ ### head([{'-n': \\<num\\>},] file [, file ...])\n//@ ### head([{'-n': \\<num\\>},] file_array)\n//@\n//@ Available options:\n//@\n//@ + `-n <num>`: Show the first `<num>` lines of the files\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ var str = head({'-n': 1}, 'file*.txt');\n//@ var str = head('file1', 'file2');\n//@ var str = head(['file1', 'file2']); // same as above\n//@ ```\n//@\n//@ Read the start of a file.\nfunction _head(options, files) {\n  var head = [];\n  var pipe = common.readFromPipe();\n\n  if (!files && !pipe) common.error('no paths given');\n\n  var idx = 1;\n  if (options.numLines === true) {\n    idx = 2;\n    options.numLines = Number(arguments[1]);\n  } else if (options.numLines === false) {\n    options.numLines = 10;\n  }\n  files = [].slice.call(arguments, idx);\n\n  if (pipe) {\n    files.unshift('-');\n  }\n\n  var shouldAppendNewline = false;\n  files.forEach(function (file) {\n    if (file !== '-') {\n      if (!fs.existsSync(file)) {\n        common.error('no such file or directory: ' + file, { continue: true });\n        return;\n      } else if (common.statFollowLinks(file).isDirectory()) {\n        common.error(\"error reading '\" + file + \"': Is a directory\", {\n          continue: true,\n        });\n        return;\n      }\n    }\n\n    var contents;\n    if (file === '-') {\n      contents = pipe;\n    } else if (options.numLines < 0) {\n      contents = fs.readFileSync(file, 'utf8');\n    } else {\n      contents = readSomeLines(file, options.numLines);\n    }\n\n    var lines = contents.split('\\n');\n    var hasTrailingNewline = (lines[lines.length - 1] === '');\n    if (hasTrailingNewline) {\n      lines.pop();\n    }\n    shouldAppendNewline = (hasTrailingNewline || options.numLines < lines.length);\n\n    head = head.concat(lines.slice(0, options.numLines));\n  });\n\n  if (shouldAppendNewline) {\n    head.push(''); // to add a trailing newline once we join\n  }\n  return head.join('\\n');\n}\nmodule.exports = _head;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/head.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/ln.js":
/*!****************************************!*\
  !*** ./node_modules/shelljs/src/ln.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\n\ncommon.register('ln', _ln, {\n  cmdOptions: {\n    's': 'symlink',\n    'f': 'force',\n  },\n});\n\n//@\n//@ ### ln([options,] source, dest)\n//@\n//@ Available options:\n//@\n//@ + `-s`: symlink\n//@ + `-f`: force\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ ln('file', 'newlink');\n//@ ln('-sf', 'file', 'existing');\n//@ ```\n//@\n//@ Links `source` to `dest`. Use `-f` to force the link, should `dest` already exist.\nfunction _ln(options, source, dest) {\n  if (!source || !dest) {\n    common.error('Missing <source> and/or <dest>');\n  }\n\n  source = String(source);\n  var sourcePath = path.normalize(source).replace(RegExp(path.sep + '$'), '');\n  var isAbsolute = (path.resolve(source) === sourcePath);\n  dest = path.resolve(process.cwd(), String(dest));\n\n  if (fs.existsSync(dest)) {\n    if (!options.force) {\n      common.error('Destination file exists', { continue: true });\n    }\n\n    fs.unlinkSync(dest);\n  }\n\n  if (options.symlink) {\n    var isWindows = process.platform === 'win32';\n    var linkType = isWindows ? 'file' : null;\n    var resolvedSourcePath = isAbsolute ? sourcePath : path.resolve(process.cwd(), path.dirname(dest), source);\n    if (!fs.existsSync(resolvedSourcePath)) {\n      common.error('Source file does not exist', { continue: true });\n    } else if (isWindows && common.statFollowLinks(resolvedSourcePath).isDirectory()) {\n      linkType = 'junction';\n    }\n\n    try {\n      fs.symlinkSync(linkType === 'junction' ? resolvedSourcePath : source, dest, linkType);\n    } catch (err) {\n      common.error(err.message);\n    }\n  } else {\n    if (!fs.existsSync(source)) {\n      common.error('Source file does not exist', { continue: true });\n    }\n    try {\n      fs.linkSync(source, dest);\n    } catch (err) {\n      common.error(err.message);\n    }\n  }\n  return '';\n}\nmodule.exports = _ln;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/ln.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/ls.js":
/*!****************************************!*\
  !*** ./node_modules/shelljs/src/ls.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var path = __webpack_require__(/*! path */ \"path\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar glob = __webpack_require__(/*! glob */ \"./node_modules/glob/glob.js\");\n\nvar globPatternRecursive = path.sep + '**';\n\ncommon.register('ls', _ls, {\n  cmdOptions: {\n    'R': 'recursive',\n    'A': 'all',\n    'L': 'link',\n    'a': 'all_deprecated',\n    'd': 'directory',\n    'l': 'long',\n  },\n});\n\n//@\n//@ ### ls([options,] [path, ...])\n//@ ### ls([options,] path_array)\n//@\n//@ Available options:\n//@\n//@ + `-R`: recursive\n//@ + `-A`: all files (include files beginning with `.`, except for `.` and `..`)\n//@ + `-L`: follow symlinks\n//@ + `-d`: list directories themselves, not their contents\n//@ + `-l`: list objects representing each file, each with fields containing `ls\n//@         -l` output fields. See\n//@         [`fs.Stats`](https://nodejs.org/api/fs.html#fs_class_fs_stats)\n//@         for more info\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ ls('projs/*.js');\n//@ ls('-R', '/users/me', '/tmp');\n//@ ls('-R', ['/users/me', '/tmp']); // same as above\n//@ ls('-l', 'file.txt'); // { name: 'file.txt', mode: 33188, nlink: 1, ...}\n//@ ```\n//@\n//@ Returns array of files in the given `path`, or files in\n//@ the current directory if no `path` is  provided.\nfunction _ls(options, paths) {\n  if (options.all_deprecated) {\n    // We won't support the -a option as it's hard to image why it's useful\n    // (it includes '.' and '..' in addition to '.*' files)\n    // For backwards compatibility we'll dump a deprecated message and proceed as before\n    common.log('ls: Option -a is deprecated. Use -A instead');\n    options.all = true;\n  }\n\n  if (!paths) {\n    paths = ['.'];\n  } else {\n    paths = [].slice.call(arguments, 1);\n  }\n\n  var list = [];\n\n  function pushFile(abs, relName, stat) {\n    if (process.platform === 'win32') {\n      relName = relName.replace(/\\\\/g, '/');\n    }\n    if (options.long) {\n      stat = stat || (options.link ? common.statFollowLinks(abs) : common.statNoFollowLinks(abs));\n      list.push(addLsAttributes(relName, stat));\n    } else {\n      // list.push(path.relative(rel || '.', file));\n      list.push(relName);\n    }\n  }\n\n  paths.forEach(function (p) {\n    var stat;\n\n    try {\n      stat = options.link ? common.statFollowLinks(p) : common.statNoFollowLinks(p);\n      // follow links to directories by default\n      if (stat.isSymbolicLink()) {\n        /* istanbul ignore next */\n        // workaround for https://github.com/shelljs/shelljs/issues/795\n        // codecov seems to have a bug that miscalculate this block as uncovered.\n        // but according to nyc report this block does get covered.\n        try {\n          var _stat = common.statFollowLinks(p);\n          if (_stat.isDirectory()) {\n            stat = _stat;\n          }\n        } catch (_) {} // bad symlink, treat it like a file\n      }\n    } catch (e) {\n      common.error('no such file or directory: ' + p, 2, { continue: true });\n      return;\n    }\n\n    // If the stat succeeded\n    if (stat.isDirectory() && !options.directory) {\n      if (options.recursive) {\n        // use glob, because it's simple\n        glob.sync(p + globPatternRecursive, { dot: options.all, follow: options.link })\n          .forEach(function (item) {\n            // Glob pattern returns the directory itself and needs to be filtered out.\n            if (path.relative(p, item)) {\n              pushFile(item, path.relative(p, item));\n            }\n          });\n      } else if (options.all) {\n        // use fs.readdirSync, because it's fast\n        fs.readdirSync(p).forEach(function (item) {\n          pushFile(path.join(p, item), item);\n        });\n      } else {\n        // use fs.readdirSync and then filter out secret files\n        fs.readdirSync(p).forEach(function (item) {\n          if (item[0] !== '.') {\n            pushFile(path.join(p, item), item);\n          }\n        });\n      }\n    } else {\n      pushFile(p, p, stat);\n    }\n  });\n\n  // Add methods, to make this more compatible with ShellStrings\n  return list;\n}\n\nfunction addLsAttributes(pathName, stats) {\n  // Note: this object will contain more information than .toString() returns\n  stats.name = pathName;\n  stats.toString = function () {\n    // Return a string resembling unix's `ls -l` format\n    return [this.mode, this.nlink, this.uid, this.gid, this.size, this.mtime, this.name].join(' ');\n  };\n  return stats;\n}\n\nmodule.exports = _ls;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/ls.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/mkdir.js":
/*!*******************************************!*\
  !*** ./node_modules/shelljs/src/mkdir.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\n\ncommon.register('mkdir', _mkdir, {\n  cmdOptions: {\n    'p': 'fullpath',\n  },\n});\n\n// Recursively creates `dir`\nfunction mkdirSyncRecursive(dir) {\n  var baseDir = path.dirname(dir);\n\n  // Prevents some potential problems arising from malformed UNCs or\n  // insufficient permissions.\n  /* istanbul ignore next */\n  if (baseDir === dir) {\n    common.error('dirname() failed: [' + dir + ']');\n  }\n\n  // Base dir exists, no recursion necessary\n  if (fs.existsSync(baseDir)) {\n    fs.mkdirSync(dir, parseInt('0777', 8));\n    return;\n  }\n\n  // Base dir does not exist, go recursive\n  mkdirSyncRecursive(baseDir);\n\n  // Base dir created, can create dir\n  fs.mkdirSync(dir, parseInt('0777', 8));\n}\n\n//@\n//@ ### mkdir([options,] dir [, dir ...])\n//@ ### mkdir([options,] dir_array)\n//@\n//@ Available options:\n//@\n//@ + `-p`: full path (and create intermediate directories, if necessary)\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ mkdir('-p', '/tmp/a/b/c/d', '/tmp/e/f/g');\n//@ mkdir('-p', ['/tmp/a/b/c/d', '/tmp/e/f/g']); // same as above\n//@ ```\n//@\n//@ Creates directories.\nfunction _mkdir(options, dirs) {\n  if (!dirs) common.error('no paths given');\n\n  if (typeof dirs === 'string') {\n    dirs = [].slice.call(arguments, 1);\n  }\n  // if it's array leave it as it is\n\n  dirs.forEach(function (dir) {\n    try {\n      var stat = common.statNoFollowLinks(dir);\n      if (!options.fullpath) {\n        common.error('path already exists: ' + dir, { continue: true });\n      } else if (stat.isFile()) {\n        common.error('cannot create directory ' + dir + ': File exists', { continue: true });\n      }\n      return; // skip dir\n    } catch (e) {\n      // do nothing\n    }\n\n    // Base dir does not exist, and no -p option given\n    var baseDir = path.dirname(dir);\n    if (!fs.existsSync(baseDir) && !options.fullpath) {\n      common.error('no such file or directory: ' + baseDir, { continue: true });\n      return; // skip dir\n    }\n\n    try {\n      if (options.fullpath) {\n        mkdirSyncRecursive(path.resolve(dir));\n      } else {\n        fs.mkdirSync(dir, parseInt('0777', 8));\n      }\n    } catch (e) {\n      var reason;\n      if (e.code === 'EACCES') {\n        reason = 'Permission denied';\n      } else if (e.code === 'ENOTDIR' || e.code === 'ENOENT') {\n        reason = 'Not a directory';\n      } else {\n        /* istanbul ignore next */\n        throw e;\n      }\n      common.error('cannot create directory ' + dir + ': ' + reason, { continue: true });\n    }\n  });\n  return '';\n} // mkdir\nmodule.exports = _mkdir;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/mkdir.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/mv.js":
/*!****************************************!*\
  !*** ./node_modules/shelljs/src/mv.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar cp = __webpack_require__(/*! ./cp */ \"./node_modules/shelljs/src/cp.js\");\nvar rm = __webpack_require__(/*! ./rm */ \"./node_modules/shelljs/src/rm.js\");\n\ncommon.register('mv', _mv, {\n  cmdOptions: {\n    'f': '!no_force',\n    'n': 'no_force',\n  },\n});\n\n// Checks if cureent file was created recently\nfunction checkRecentCreated(sources, index) {\n  var lookedSource = sources[index];\n  return sources.slice(0, index).some(function (src) {\n    return path.basename(src) === path.basename(lookedSource);\n  });\n}\n\n//@\n//@ ### mv([options ,] source [, source ...], dest')\n//@ ### mv([options ,] source_array, dest')\n//@\n//@ Available options:\n//@\n//@ + `-f`: force (default behavior)\n//@ + `-n`: no-clobber\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ mv('-n', 'file', 'dir/');\n//@ mv('file1', 'file2', 'dir/');\n//@ mv(['file1', 'file2'], 'dir/'); // same as above\n//@ ```\n//@\n//@ Moves `source` file(s) to `dest`.\nfunction _mv(options, sources, dest) {\n  // Get sources, dest\n  if (arguments.length < 3) {\n    common.error('missing <source> and/or <dest>');\n  } else if (arguments.length > 3) {\n    sources = [].slice.call(arguments, 1, arguments.length - 1);\n    dest = arguments[arguments.length - 1];\n  } else if (typeof sources === 'string') {\n    sources = [sources];\n  } else {\n    // TODO(nate): figure out if we actually need this line\n    common.error('invalid arguments');\n  }\n\n  var exists = fs.existsSync(dest);\n  var stats = exists && common.statFollowLinks(dest);\n\n  // Dest is not existing dir, but multiple sources given\n  if ((!exists || !stats.isDirectory()) && sources.length > 1) {\n    common.error('dest is not a directory (too many sources)');\n  }\n\n  // Dest is an existing file, but no -f given\n  if (exists && stats.isFile() && options.no_force) {\n    common.error('dest file already exists: ' + dest);\n  }\n\n  sources.forEach(function (src, srcIndex) {\n    if (!fs.existsSync(src)) {\n      common.error('no such file or directory: ' + src, { continue: true });\n      return; // skip file\n    }\n\n    // If here, src exists\n\n    // When copying to '/path/dir':\n    //    thisDest = '/path/dir/file1'\n    var thisDest = dest;\n    if (fs.existsSync(dest) && common.statFollowLinks(dest).isDirectory()) {\n      thisDest = path.normalize(dest + '/' + path.basename(src));\n    }\n\n    var thisDestExists = fs.existsSync(thisDest);\n\n    if (thisDestExists && checkRecentCreated(sources, srcIndex)) {\n      // cannot overwrite file created recently in current execution, but we want to continue copying other files\n      if (!options.no_force) {\n        common.error(\"will not overwrite just-created '\" + thisDest + \"' with '\" + src + \"'\", { continue: true });\n      }\n      return;\n    }\n\n    if (fs.existsSync(thisDest) && options.no_force) {\n      common.error('dest file already exists: ' + thisDest, { continue: true });\n      return; // skip file\n    }\n\n    if (path.resolve(src) === path.dirname(path.resolve(thisDest))) {\n      common.error('cannot move to self: ' + src, { continue: true });\n      return; // skip file\n    }\n\n    try {\n      fs.renameSync(src, thisDest);\n    } catch (e) {\n      /* istanbul ignore next */\n      if (e.code === 'EXDEV') {\n        // If we're trying to `mv` to an external partition, we'll actually need\n        // to perform a copy and then clean up the original file. If either the\n        // copy or the rm fails with an exception, we should allow this\n        // exception to pass up to the top level.\n        cp('-r', src, thisDest);\n        rm('-rf', src);\n      }\n    }\n  }); // forEach(src)\n  return '';\n} // mv\nmodule.exports = _mv;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/mv.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/popd.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/popd.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// see dirs.js\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/popd.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/pushd.js":
/*!*******************************************!*\
  !*** ./node_modules/shelljs/src/pushd.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// see dirs.js\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/pushd.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/pwd.js":
/*!*****************************************!*\
  !*** ./node_modules/shelljs/src/pwd.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var path = __webpack_require__(/*! path */ \"path\");\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\n\ncommon.register('pwd', _pwd, {\n  allowGlobbing: false,\n});\n\n//@\n//@ ### pwd()\n//@\n//@ Returns the current directory.\nfunction _pwd() {\n  var pwd = path.resolve(process.cwd());\n  return pwd;\n}\nmodule.exports = _pwd;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/pwd.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/rm.js":
/*!****************************************!*\
  !*** ./node_modules/shelljs/src/rm.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('rm', _rm, {\n  cmdOptions: {\n    'f': 'force',\n    'r': 'recursive',\n    'R': 'recursive',\n  },\n});\n\n// Recursively removes 'dir'\n// Adapted from https://github.com/ryanmcgrath/wrench-js\n//\n// Copyright (c) 2010 Ryan McGrath\n// Copyright (c) 2012 Artur Adib\n//\n// Licensed under the MIT License\n// http://www.opensource.org/licenses/mit-license.php\nfunction rmdirSyncRecursive(dir, force, fromSymlink) {\n  var files;\n\n  files = fs.readdirSync(dir);\n\n  // Loop through and delete everything in the sub-tree after checking it\n  for (var i = 0; i < files.length; i++) {\n    var file = dir + '/' + files[i];\n    var currFile = common.statNoFollowLinks(file);\n\n    if (currFile.isDirectory()) { // Recursive function back to the beginning\n      rmdirSyncRecursive(file, force);\n    } else { // Assume it's a file - perhaps a try/catch belongs here?\n      if (force || isWriteable(file)) {\n        try {\n          common.unlinkSync(file);\n        } catch (e) {\n          /* istanbul ignore next */\n          common.error('could not remove file (code ' + e.code + '): ' + file, {\n            continue: true,\n          });\n        }\n      }\n    }\n  }\n\n  // if was directory was referenced through a symbolic link,\n  // the contents should be removed, but not the directory itself\n  if (fromSymlink) return;\n\n  // Now that we know everything in the sub-tree has been deleted, we can delete the main directory.\n  // Huzzah for the shopkeep.\n\n  var result;\n  try {\n    // Retry on windows, sometimes it takes a little time before all the files in the directory are gone\n    var start = Date.now();\n\n    // TODO: replace this with a finite loop\n    for (;;) {\n      try {\n        result = fs.rmdirSync(dir);\n        if (fs.existsSync(dir)) throw { code: 'EAGAIN' };\n        break;\n      } catch (er) {\n        /* istanbul ignore next */\n        // In addition to error codes, also check if the directory still exists and loop again if true\n        if (process.platform === 'win32' && (er.code === 'ENOTEMPTY' || er.code === 'EBUSY' || er.code === 'EPERM' || er.code === 'EAGAIN')) {\n          if (Date.now() - start > 1000) throw er;\n        } else if (er.code === 'ENOENT') {\n          // Directory did not exist, deletion was successful\n          break;\n        } else {\n          throw er;\n        }\n      }\n    }\n  } catch (e) {\n    common.error('could not remove directory (code ' + e.code + '): ' + dir, { continue: true });\n  }\n\n  return result;\n} // rmdirSyncRecursive\n\n// Hack to determine if file has write permissions for current user\n// Avoids having to check user, group, etc, but it's probably slow\nfunction isWriteable(file) {\n  var writePermission = true;\n  try {\n    var __fd = fs.openSync(file, 'a');\n    fs.closeSync(__fd);\n  } catch (e) {\n    writePermission = false;\n  }\n\n  return writePermission;\n}\n\nfunction handleFile(file, options) {\n  if (options.force || isWriteable(file)) {\n    // -f was passed, or file is writable, so it can be removed\n    common.unlinkSync(file);\n  } else {\n    common.error('permission denied: ' + file, { continue: true });\n  }\n}\n\nfunction handleDirectory(file, options) {\n  if (options.recursive) {\n    // -r was passed, so directory can be removed\n    rmdirSyncRecursive(file, options.force);\n  } else {\n    common.error('path is a directory', { continue: true });\n  }\n}\n\nfunction handleSymbolicLink(file, options) {\n  var stats;\n  try {\n    stats = common.statFollowLinks(file);\n  } catch (e) {\n    // symlink is broken, so remove the symlink itself\n    common.unlinkSync(file);\n    return;\n  }\n\n  if (stats.isFile()) {\n    common.unlinkSync(file);\n  } else if (stats.isDirectory()) {\n    if (file[file.length - 1] === '/') {\n      // trailing separator, so remove the contents, not the link\n      if (options.recursive) {\n        // -r was passed, so directory can be removed\n        var fromSymlink = true;\n        rmdirSyncRecursive(file, options.force, fromSymlink);\n      } else {\n        common.error('path is a directory', { continue: true });\n      }\n    } else {\n      // no trailing separator, so remove the link\n      common.unlinkSync(file);\n    }\n  }\n}\n\nfunction handleFIFO(file) {\n  common.unlinkSync(file);\n}\n\n//@\n//@ ### rm([options,] file [, file ...])\n//@ ### rm([options,] file_array)\n//@\n//@ Available options:\n//@\n//@ + `-f`: force\n//@ + `-r, -R`: recursive\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ rm('-rf', '/tmp/*');\n//@ rm('some_file.txt', 'another_file.txt');\n//@ rm(['some_file.txt', 'another_file.txt']); // same as above\n//@ ```\n//@\n//@ Removes files.\nfunction _rm(options, files) {\n  if (!files) common.error('no paths given');\n\n  // Convert to array\n  files = [].slice.call(arguments, 1);\n\n  files.forEach(function (file) {\n    var lstats;\n    try {\n      var filepath = (file[file.length - 1] === '/')\n        ? file.slice(0, -1) // remove the '/' so lstatSync can detect symlinks\n        : file;\n      lstats = common.statNoFollowLinks(filepath); // test for existence\n    } catch (e) {\n      // Path does not exist, no force flag given\n      if (!options.force) {\n        common.error('no such file or directory: ' + file, { continue: true });\n      }\n      return; // skip file\n    }\n\n    // If here, path exists\n    if (lstats.isFile()) {\n      handleFile(file, options);\n    } else if (lstats.isDirectory()) {\n      handleDirectory(file, options);\n    } else if (lstats.isSymbolicLink()) {\n      handleSymbolicLink(file, options);\n    } else if (lstats.isFIFO()) {\n      handleFIFO(file);\n    }\n  }); // forEach(file)\n  return '';\n} // rm\nmodule.exports = _rm;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/rm.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/sed.js":
/*!*****************************************!*\
  !*** ./node_modules/shelljs/src/sed.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('sed', _sed, {\n  globStart: 3, // don't glob-expand regexes\n  canReceivePipe: true,\n  cmdOptions: {\n    'i': 'inplace',\n  },\n});\n\n//@\n//@ ### sed([options,] search_regex, replacement, file [, file ...])\n//@ ### sed([options,] search_regex, replacement, file_array)\n//@\n//@ Available options:\n//@\n//@ + `-i`: Replace contents of `file` in-place. _Note that no backups will be created!_\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ sed('-i', 'PROGRAM_VERSION', 'v0.1.3', 'source.js');\n//@ sed(/.*DELETE_THIS_LINE.*\\n/, '', 'source.js');\n//@ ```\n//@\n//@ Reads an input string from `file`s, and performs a JavaScript `replace()` on the input\n//@ using the given `search_regex` and `replacement` string or function. Returns the new string after replacement.\n//@\n//@ Note:\n//@\n//@ Like unix `sed`, ShellJS `sed` supports capture groups. Capture groups are specified\n//@ using the `$n` syntax:\n//@\n//@ ```javascript\n//@ sed(/(\\w+)\\s(\\w+)/, '$2, $1', 'file.txt');\n//@ ```\nfunction _sed(options, regex, replacement, files) {\n  // Check if this is coming from a pipe\n  var pipe = common.readFromPipe();\n\n  if (typeof replacement !== 'string' && typeof replacement !== 'function') {\n    if (typeof replacement === 'number') {\n      replacement = replacement.toString(); // fallback\n    } else {\n      common.error('invalid replacement string');\n    }\n  }\n\n  // Convert all search strings to RegExp\n  if (typeof regex === 'string') {\n    regex = RegExp(regex);\n  }\n\n  if (!files && !pipe) {\n    common.error('no files given');\n  }\n\n  files = [].slice.call(arguments, 3);\n\n  if (pipe) {\n    files.unshift('-');\n  }\n\n  var sed = [];\n  files.forEach(function (file) {\n    if (!fs.existsSync(file) && file !== '-') {\n      common.error('no such file or directory: ' + file, 2, { continue: true });\n      return;\n    }\n\n    var contents = file === '-' ? pipe : fs.readFileSync(file, 'utf8');\n    var lines = contents.split('\\n');\n    var result = lines.map(function (line) {\n      return line.replace(regex, replacement);\n    }).join('\\n');\n\n    sed.push(result);\n\n    if (options.inplace) {\n      fs.writeFileSync(file, result, 'utf8');\n    }\n  });\n\n  return sed.join('\\n');\n}\nmodule.exports = _sed;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/sed.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/set.js":
/*!*****************************************!*\
  !*** ./node_modules/shelljs/src/set.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\n\ncommon.register('set', _set, {\n  allowGlobbing: false,\n  wrapOutput: false,\n});\n\n//@\n//@ ### set(options)\n//@\n//@ Available options:\n//@\n//@ + `+/-e`: exit upon error (`config.fatal`)\n//@ + `+/-v`: verbose: show all commands (`config.verbose`)\n//@ + `+/-f`: disable filename expansion (globbing)\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ set('-e'); // exit upon first error\n//@ set('+e'); // this undoes a \"set('-e')\"\n//@ ```\n//@\n//@ Sets global configuration variables.\nfunction _set(options) {\n  if (!options) {\n    var args = [].slice.call(arguments, 0);\n    if (args.length < 2) common.error('must provide an argument');\n    options = args[1];\n  }\n  var negate = (options[0] === '+');\n  if (negate) {\n    options = '-' + options.slice(1); // parseOptions needs a '-' prefix\n  }\n  options = common.parseOptions(options, {\n    'e': 'fatal',\n    'v': 'verbose',\n    'f': 'noglob',\n  });\n\n  if (negate) {\n    Object.keys(options).forEach(function (key) {\n      options[key] = !options[key];\n    });\n  }\n\n  Object.keys(options).forEach(function (key) {\n    // Only change the global config if `negate` is false and the option is true\n    // or if `negate` is true and the option is false (aka negate !== option)\n    if (negate !== options[key]) {\n      common.config[key] = options[key];\n    }\n  });\n  return;\n}\nmodule.exports = _set;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/set.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/sort.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/sort.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('sort', _sort, {\n  canReceivePipe: true,\n  cmdOptions: {\n    'r': 'reverse',\n    'n': 'numerical',\n  },\n});\n\n// parse out the number prefix of a line\nfunction parseNumber(str) {\n  var match = str.match(/^\\s*(\\d*)\\s*(.*)$/);\n  return { num: Number(match[1]), value: match[2] };\n}\n\n// compare two strings case-insensitively, but examine case for strings that are\n// case-insensitive equivalent\nfunction unixCmp(a, b) {\n  var aLower = a.toLowerCase();\n  var bLower = b.toLowerCase();\n  return (aLower === bLower ?\n      -1 * a.localeCompare(b) : // unix sort treats case opposite how javascript does\n      aLower.localeCompare(bLower));\n}\n\n// compare two strings in the fashion that unix sort's -n option works\nfunction numericalCmp(a, b) {\n  var objA = parseNumber(a);\n  var objB = parseNumber(b);\n  if (objA.hasOwnProperty('num') && objB.hasOwnProperty('num')) {\n    return ((objA.num !== objB.num) ?\n        (objA.num - objB.num) :\n        unixCmp(objA.value, objB.value));\n  } else {\n    return unixCmp(objA.value, objB.value);\n  }\n}\n\n//@\n//@ ### sort([options,] file [, file ...])\n//@ ### sort([options,] file_array)\n//@\n//@ Available options:\n//@\n//@ + `-r`: Reverse the results\n//@ + `-n`: Compare according to numerical value\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ sort('foo.txt', 'bar.txt');\n//@ sort('-r', 'foo.txt');\n//@ ```\n//@\n//@ Return the contents of the `file`s, sorted line-by-line. Sorting multiple\n//@ files mixes their content (just as unix `sort` does).\nfunction _sort(options, files) {\n  // Check if this is coming from a pipe\n  var pipe = common.readFromPipe();\n\n  if (!files && !pipe) common.error('no files given');\n\n  files = [].slice.call(arguments, 1);\n\n  if (pipe) {\n    files.unshift('-');\n  }\n\n  var lines = files.reduce(function (accum, file) {\n    if (file !== '-') {\n      if (!fs.existsSync(file)) {\n        common.error('no such file or directory: ' + file, { continue: true });\n        return accum;\n      } else if (common.statFollowLinks(file).isDirectory()) {\n        common.error('read failed: ' + file + ': Is a directory', {\n          continue: true,\n        });\n        return accum;\n      }\n    }\n\n    var contents = file === '-' ? pipe : fs.readFileSync(file, 'utf8');\n    return accum.concat(contents.trimRight().split('\\n'));\n  }, []);\n\n  var sorted = lines.sort(options.numerical ? numericalCmp : unixCmp);\n\n  if (options.reverse) {\n    sorted = sorted.reverse();\n  }\n\n  return sorted.join('\\n') + '\\n';\n}\n\nmodule.exports = _sort;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/sort.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/tail.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/tail.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('tail', _tail, {\n  canReceivePipe: true,\n  cmdOptions: {\n    'n': 'numLines',\n  },\n});\n\n//@\n//@ ### tail([{'-n': \\<num\\>},] file [, file ...])\n//@ ### tail([{'-n': \\<num\\>},] file_array)\n//@\n//@ Available options:\n//@\n//@ + `-n <num>`: Show the last `<num>` lines of `file`s\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ var str = tail({'-n': 1}, 'file*.txt');\n//@ var str = tail('file1', 'file2');\n//@ var str = tail(['file1', 'file2']); // same as above\n//@ ```\n//@\n//@ Read the end of a `file`.\nfunction _tail(options, files) {\n  var tail = [];\n  var pipe = common.readFromPipe();\n\n  if (!files && !pipe) common.error('no paths given');\n\n  var idx = 1;\n  if (options.numLines === true) {\n    idx = 2;\n    options.numLines = Number(arguments[1]);\n  } else if (options.numLines === false) {\n    options.numLines = 10;\n  }\n  options.numLines = -1 * Math.abs(options.numLines);\n  files = [].slice.call(arguments, idx);\n\n  if (pipe) {\n    files.unshift('-');\n  }\n\n  var shouldAppendNewline = false;\n  files.forEach(function (file) {\n    if (file !== '-') {\n      if (!fs.existsSync(file)) {\n        common.error('no such file or directory: ' + file, { continue: true });\n        return;\n      } else if (common.statFollowLinks(file).isDirectory()) {\n        common.error(\"error reading '\" + file + \"': Is a directory\", {\n          continue: true,\n        });\n        return;\n      }\n    }\n\n    var contents = file === '-' ? pipe : fs.readFileSync(file, 'utf8');\n\n    var lines = contents.split('\\n');\n    if (lines[lines.length - 1] === '') {\n      lines.pop();\n      shouldAppendNewline = true;\n    } else {\n      shouldAppendNewline = false;\n    }\n\n    tail = tail.concat(lines.slice(options.numLines));\n  });\n\n  if (shouldAppendNewline) {\n    tail.push(''); // to add a trailing newline once we join\n  }\n  return tail.join('\\n');\n}\nmodule.exports = _tail;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/tail.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/tempdir.js":
/*!*********************************************!*\
  !*** ./node_modules/shelljs/src/tempdir.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar os = __webpack_require__(/*! os */ \"os\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('tempdir', _tempDir, {\n  allowGlobbing: false,\n  wrapOutput: false,\n});\n\n// Returns false if 'dir' is not a writeable directory, 'dir' otherwise\nfunction writeableDir(dir) {\n  if (!dir || !fs.existsSync(dir)) return false;\n\n  if (!common.statFollowLinks(dir).isDirectory()) return false;\n\n  var testFile = dir + '/' + common.randomFileName();\n  try {\n    fs.writeFileSync(testFile, ' ');\n    common.unlinkSync(testFile);\n    return dir;\n  } catch (e) {\n    /* istanbul ignore next */\n    return false;\n  }\n}\n\n// Variable to cache the tempdir value for successive lookups.\nvar cachedTempDir;\n\n//@\n//@ ### tempdir()\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ var tmp = tempdir(); // \"/tmp\" for most *nix platforms\n//@ ```\n//@\n//@ Searches and returns string containing a writeable, platform-dependent temporary directory.\n//@ Follows Python's [tempfile algorithm](http://docs.python.org/library/tempfile.html#tempfile.tempdir).\nfunction _tempDir() {\n  if (cachedTempDir) return cachedTempDir;\n\n  cachedTempDir = writeableDir(os.tmpdir()) ||\n                  writeableDir(process.env.TMPDIR) ||\n                  writeableDir(process.env.TEMP) ||\n                  writeableDir(process.env.TMP) ||\n                  writeableDir(process.env.Wimp$ScrapDir) || // RiscOS\n                  writeableDir('C:\\\\TEMP') || // Windows\n                  writeableDir('C:\\\\TMP') || // Windows\n                  writeableDir('\\\\TEMP') || // Windows\n                  writeableDir('\\\\TMP') || // Windows\n                  writeableDir('/tmp') ||\n                  writeableDir('/var/tmp') ||\n                  writeableDir('/usr/tmp') ||\n                  writeableDir('.'); // last resort\n\n  return cachedTempDir;\n}\n\n// Indicates if the tempdir value is currently cached. This is exposed for tests\n// only. The return value should only be tested for truthiness.\nfunction isCached() {\n  return cachedTempDir;\n}\n\n// Clears the cached tempDir value, if one is cached. This is exposed for tests\n// only.\nfunction clearCache() {\n  cachedTempDir = undefined;\n}\n\nmodule.exports.tempDir = _tempDir;\nmodule.exports.isCached = isCached;\nmodule.exports.clearCache = clearCache;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/tempdir.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/test.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/test.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('test', _test, {\n  cmdOptions: {\n    'b': 'block',\n    'c': 'character',\n    'd': 'directory',\n    'e': 'exists',\n    'f': 'file',\n    'L': 'link',\n    'p': 'pipe',\n    'S': 'socket',\n  },\n  wrapOutput: false,\n  allowGlobbing: false,\n});\n\n\n//@\n//@ ### test(expression)\n//@\n//@ Available expression primaries:\n//@\n//@ + `'-b', 'path'`: true if path is a block device\n//@ + `'-c', 'path'`: true if path is a character device\n//@ + `'-d', 'path'`: true if path is a directory\n//@ + `'-e', 'path'`: true if path exists\n//@ + `'-f', 'path'`: true if path is a regular file\n//@ + `'-L', 'path'`: true if path is a symbolic link\n//@ + `'-p', 'path'`: true if path is a pipe (FIFO)\n//@ + `'-S', 'path'`: true if path is a socket\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ if (test('-d', path)) { /* do something with dir */ };\n//@ if (!test('-f', path)) continue; // skip if it's a regular file\n//@ ```\n//@\n//@ Evaluates `expression` using the available primaries and returns corresponding value.\nfunction _test(options, path) {\n  if (!path) common.error('no path given');\n\n  var canInterpret = false;\n  Object.keys(options).forEach(function (key) {\n    if (options[key] === true) {\n      canInterpret = true;\n    }\n  });\n\n  if (!canInterpret) common.error('could not interpret expression');\n\n  if (options.link) {\n    try {\n      return common.statNoFollowLinks(path).isSymbolicLink();\n    } catch (e) {\n      return false;\n    }\n  }\n\n  if (!fs.existsSync(path)) return false;\n\n  if (options.exists) return true;\n\n  var stats = common.statFollowLinks(path);\n\n  if (options.block) return stats.isBlockDevice();\n\n  if (options.character) return stats.isCharacterDevice();\n\n  if (options.directory) return stats.isDirectory();\n\n  if (options.file) return stats.isFile();\n\n  /* istanbul ignore next */\n  if (options.pipe) return stats.isFIFO();\n\n  /* istanbul ignore next */\n  if (options.socket) return stats.isSocket();\n\n  /* istanbul ignore next */\n  return false; // fallback\n} // test\nmodule.exports = _test;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/test.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/to.js":
/*!****************************************!*\
  !*** ./node_modules/shelljs/src/to.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\n\ncommon.register('to', _to, {\n  pipeOnly: true,\n  wrapOutput: false,\n});\n\n//@\n//@ ### ShellString.prototype.to(file)\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ cat('input.txt').to('output.txt');\n//@ ```\n//@\n//@ Analogous to the redirection operator `>` in Unix, but works with\n//@ `ShellStrings` (such as those returned by `cat`, `grep`, etc.). _Like Unix\n//@ redirections, `to()` will overwrite any existing file!_\nfunction _to(options, file) {\n  if (!file) common.error('wrong arguments');\n\n  if (!fs.existsSync(path.dirname(file))) {\n    common.error('no such file or directory: ' + path.dirname(file));\n  }\n\n  try {\n    fs.writeFileSync(file, this.stdout || this.toString(), 'utf8');\n    return this;\n  } catch (e) {\n    /* istanbul ignore next */\n    common.error('could not write to file (code ' + e.code + '): ' + file, { continue: true });\n  }\n}\nmodule.exports = _to;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/to.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/toEnd.js":
/*!*******************************************!*\
  !*** ./node_modules/shelljs/src/toEnd.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\n\ncommon.register('toEnd', _toEnd, {\n  pipeOnly: true,\n  wrapOutput: false,\n});\n\n//@\n//@ ### ShellString.prototype.toEnd(file)\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ cat('input.txt').toEnd('output.txt');\n//@ ```\n//@\n//@ Analogous to the redirect-and-append operator `>>` in Unix, but works with\n//@ `ShellStrings` (such as those returned by `cat`, `grep`, etc.).\nfunction _toEnd(options, file) {\n  if (!file) common.error('wrong arguments');\n\n  if (!fs.existsSync(path.dirname(file))) {\n    common.error('no such file or directory: ' + path.dirname(file));\n  }\n\n  try {\n    fs.appendFileSync(file, this.stdout || this.toString(), 'utf8');\n    return this;\n  } catch (e) {\n    /* istanbul ignore next */\n    common.error('could not append to file (code ' + e.code + '): ' + file, { continue: true });\n  }\n}\nmodule.exports = _toEnd;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/toEnd.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/touch.js":
/*!*******************************************!*\
  !*** ./node_modules/shelljs/src/touch.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\ncommon.register('touch', _touch, {\n  cmdOptions: {\n    'a': 'atime_only',\n    'c': 'no_create',\n    'd': 'date',\n    'm': 'mtime_only',\n    'r': 'reference',\n  },\n});\n\n//@\n//@ ### touch([options,] file [, file ...])\n//@ ### touch([options,] file_array)\n//@\n//@ Available options:\n//@\n//@ + `-a`: Change only the access time\n//@ + `-c`: Do not create any files\n//@ + `-m`: Change only the modification time\n//@ + `-d DATE`: Parse `DATE` and use it instead of current time\n//@ + `-r FILE`: Use `FILE`'s times instead of current time\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ touch('source.js');\n//@ touch('-c', '/path/to/some/dir/source.js');\n//@ touch({ '-r': FILE }, '/path/to/some/dir/source.js');\n//@ ```\n//@\n//@ Update the access and modification times of each `FILE` to the current time.\n//@ A `FILE` argument that does not exist is created empty, unless `-c` is supplied.\n//@ This is a partial implementation of [`touch(1)`](http://linux.die.net/man/1/touch).\nfunction _touch(opts, files) {\n  if (!files) {\n    common.error('no files given');\n  } else if (typeof files === 'string') {\n    files = [].slice.call(arguments, 1);\n  } else {\n    common.error('file arg should be a string file path or an Array of string file paths');\n  }\n\n  files.forEach(function (f) {\n    touchFile(opts, f);\n  });\n  return '';\n}\n\nfunction touchFile(opts, file) {\n  var stat = tryStatFile(file);\n\n  if (stat && stat.isDirectory()) {\n    // don't error just exit\n    return;\n  }\n\n  // if the file doesn't already exist and the user has specified --no-create then\n  // this script is finished\n  if (!stat && opts.no_create) {\n    return;\n  }\n\n  // open the file and then close it. this will create it if it doesn't exist but will\n  // not truncate the file\n  fs.closeSync(fs.openSync(file, 'a'));\n\n  //\n  // Set timestamps\n  //\n\n  // setup some defaults\n  var now = new Date();\n  var mtime = opts.date || now;\n  var atime = opts.date || now;\n\n  // use reference file\n  if (opts.reference) {\n    var refStat = tryStatFile(opts.reference);\n    if (!refStat) {\n      common.error('failed to get attributess of ' + opts.reference);\n    }\n    mtime = refStat.mtime;\n    atime = refStat.atime;\n  } else if (opts.date) {\n    mtime = opts.date;\n    atime = opts.date;\n  }\n\n  if (opts.atime_only && opts.mtime_only) {\n    // keep the new values of mtime and atime like GNU\n  } else if (opts.atime_only) {\n    mtime = stat.mtime;\n  } else if (opts.mtime_only) {\n    atime = stat.atime;\n  }\n\n  fs.utimesSync(file, atime, mtime);\n}\n\nmodule.exports = _touch;\n\nfunction tryStatFile(filePath) {\n  try {\n    return common.statFollowLinks(filePath);\n  } catch (e) {\n    return null;\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/touch.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/uniq.js":
/*!******************************************!*\
  !*** ./node_modules/shelljs/src/uniq.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\n// add c spaces to the left of str\nfunction lpad(c, str) {\n  var res = '' + str;\n  if (res.length < c) {\n    res = Array((c - res.length) + 1).join(' ') + res;\n  }\n  return res;\n}\n\ncommon.register('uniq', _uniq, {\n  canReceivePipe: true,\n  cmdOptions: {\n    'i': 'ignoreCase',\n    'c': 'count',\n    'd': 'duplicates',\n  },\n});\n\n//@\n//@ ### uniq([options,] [input, [output]])\n//@\n//@ Available options:\n//@\n//@ + `-i`: Ignore case while comparing\n//@ + `-c`: Prefix lines by the number of occurrences\n//@ + `-d`: Only print duplicate lines, one for each group of identical lines\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ uniq('foo.txt');\n//@ uniq('-i', 'foo.txt');\n//@ uniq('-cd', 'foo.txt', 'bar.txt');\n//@ ```\n//@\n//@ Filter adjacent matching lines from `input`.\nfunction _uniq(options, input, output) {\n  // Check if this is coming from a pipe\n  var pipe = common.readFromPipe();\n\n  if (!pipe) {\n    if (!input) common.error('no input given');\n\n    if (!fs.existsSync(input)) {\n      common.error(input + ': No such file or directory');\n    } else if (common.statFollowLinks(input).isDirectory()) {\n      common.error(\"error reading '\" + input + \"'\");\n    }\n  }\n  if (output && fs.existsSync(output) && common.statFollowLinks(output).isDirectory()) {\n    common.error(output + ': Is a directory');\n  }\n\n  var lines = (input ? fs.readFileSync(input, 'utf8') : pipe).\n              trimRight().\n              split('\\n');\n\n  var compare = function (a, b) {\n    return options.ignoreCase ?\n           a.toLocaleLowerCase().localeCompare(b.toLocaleLowerCase()) :\n           a.localeCompare(b);\n  };\n  var uniqed = lines.reduceRight(function (res, e) {\n    // Perform uniq -c on the input\n    if (res.length === 0) {\n      return [{ count: 1, ln: e }];\n    } else if (compare(res[0].ln, e) === 0) {\n      return [{ count: res[0].count + 1, ln: e }].concat(res.slice(1));\n    } else {\n      return [{ count: 1, ln: e }].concat(res);\n    }\n  }, []).filter(function (obj) {\n                 // Do we want only duplicated objects?\n    return options.duplicates ? obj.count > 1 : true;\n  }).map(function (obj) {\n                 // Are we tracking the counts of each line?\n    return (options.count ? (lpad(7, obj.count) + ' ') : '') + obj.ln;\n  }).join('\\n') + '\\n';\n\n  if (output) {\n    (new common.ShellString(uniqed)).to(output);\n    // if uniq writes to output, nothing is passed to the next command in the pipeline (if any)\n    return '';\n  } else {\n    return uniqed;\n  }\n}\n\nmodule.exports = _uniq;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/uniq.js?");

/***/ }),

/***/ "./node_modules/shelljs/src/which.js":
/*!*******************************************!*\
  !*** ./node_modules/shelljs/src/which.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var common = __webpack_require__(/*! ./common */ \"./node_modules/shelljs/src/common.js\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\n\ncommon.register('which', _which, {\n  allowGlobbing: false,\n  cmdOptions: {\n    'a': 'all',\n  },\n});\n\n// XP's system default value for `PATHEXT` system variable, just in case it's not\n// set on Windows.\nvar XP_DEFAULT_PATHEXT = '.com;.exe;.bat;.cmd;.vbs;.vbe;.js;.jse;.wsf;.wsh';\n\n// For earlier versions of NodeJS that doesn't have a list of constants (< v6)\nvar FILE_EXECUTABLE_MODE = 1;\n\nfunction isWindowsPlatform() {\n  return process.platform === 'win32';\n}\n\n// Cross-platform method for splitting environment `PATH` variables\nfunction splitPath(p) {\n  return p ? p.split(path.delimiter) : [];\n}\n\n// Tests are running all cases for this func but it stays uncovered by codecov due to unknown reason\n/* istanbul ignore next */\nfunction isExecutable(pathName) {\n  try {\n    // TODO(node-support): replace with fs.constants.X_OK once remove support for node < v6\n    fs.accessSync(pathName, FILE_EXECUTABLE_MODE);\n  } catch (err) {\n    return false;\n  }\n  return true;\n}\n\nfunction checkPath(pathName) {\n  return fs.existsSync(pathName) && !common.statFollowLinks(pathName).isDirectory()\n    && (isWindowsPlatform() || isExecutable(pathName));\n}\n\n//@\n//@ ### which(command)\n//@\n//@ Examples:\n//@\n//@ ```javascript\n//@ var nodeExec = which('node');\n//@ ```\n//@\n//@ Searches for `command` in the system's `PATH`. On Windows, this uses the\n//@ `PATHEXT` variable to append the extension if it's not already executable.\n//@ Returns string containing the absolute path to `command`.\nfunction _which(options, cmd) {\n  if (!cmd) common.error('must specify command');\n\n  var isWindows = isWindowsPlatform();\n  var pathArray = splitPath(process.env.PATH);\n\n  var queryMatches = [];\n\n  // No relative/absolute paths provided?\n  if (cmd.indexOf('/') === -1) {\n    // Assume that there are no extensions to append to queries (this is the\n    // case for unix)\n    var pathExtArray = [''];\n    if (isWindows) {\n      // In case the PATHEXT variable is somehow not set (e.g.\n      // child_process.spawn with an empty environment), use the XP default.\n      var pathExtEnv = process.env.PATHEXT || XP_DEFAULT_PATHEXT;\n      pathExtArray = splitPath(pathExtEnv.toUpperCase());\n    }\n\n    // Search for command in PATH\n    for (var k = 0; k < pathArray.length; k++) {\n      // already found it\n      if (queryMatches.length > 0 && !options.all) break;\n\n      var attempt = path.resolve(pathArray[k], cmd);\n\n      if (isWindows) {\n        attempt = attempt.toUpperCase();\n      }\n\n      var match = attempt.match(/\\.[^<>:\"/\\|?*.]+$/);\n      if (match && pathExtArray.indexOf(match[0]) >= 0) { // this is Windows-only\n        // The user typed a query with the file extension, like\n        // `which('node.exe')`\n        if (checkPath(attempt)) {\n          queryMatches.push(attempt);\n          break;\n        }\n      } else { // All-platforms\n        // Cycle through the PATHEXT array, and check each extension\n        // Note: the array is always [''] on Unix\n        for (var i = 0; i < pathExtArray.length; i++) {\n          var ext = pathExtArray[i];\n          var newAttempt = attempt + ext;\n          if (checkPath(newAttempt)) {\n            queryMatches.push(newAttempt);\n            break;\n          }\n        }\n      }\n    }\n  } else if (checkPath(cmd)) { // a valid absolute or relative path\n    queryMatches.push(path.resolve(cmd));\n  }\n\n  if (queryMatches.length > 0) {\n    return options.all ? queryMatches : queryMatches[0];\n  }\n  return options.all ? [] : null;\n}\nmodule.exports = _which;\n\n\n//# sourceURL=webpack:///./node_modules/shelljs/src/which.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/index.js":
/*!********************************************!*\
  !*** ./node_modules/ssh2-streams/index.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = {\n  SFTPStream: __webpack_require__(/*! ./lib/sftp */ \"./node_modules/ssh2-streams/lib/sftp.js\"),\n  SSH2Stream: __webpack_require__(/*! ./lib/ssh */ \"./node_modules/ssh2-streams/lib/ssh.js\"),\n  utils: __webpack_require__(/*! ./lib/utils */ \"./node_modules/ssh2-streams/lib/utils.js\"),\n  constants: __webpack_require__(/*! ./lib/constants */ \"./node_modules/ssh2-streams/lib/constants.js\")\n};\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/index.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/lib/buffer-helpers.js":
/*!*********************************************************!*\
  !*** ./node_modules/ssh2-streams/lib/buffer-helpers.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = {\n  readUInt32BE: function readUInt32BE(buf, offset) {\n    return buf[offset++] * 16777216\n           + buf[offset++] * 65536\n           + buf[offset++] * 256\n           + buf[offset];\n  },\n  writeUInt32BE: function writeUInt32BE(buf, value, offset) {\n    buf[offset++] = (value >>> 24);\n    buf[offset++] = (value >>> 16);\n    buf[offset++] = (value >>> 8);\n    buf[offset++] = value;\n    return offset;\n  },\n  writeUInt32LE: function writeUInt32LE(buf, value, offset) {\n    buf[offset++] = value;\n    buf[offset++] = (value >>> 8);\n    buf[offset++] = (value >>> 16);\n    buf[offset++] = (value >>> 24);\n    return offset;\n  }\n};\n\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/lib/buffer-helpers.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/lib/constants.js":
/*!****************************************************!*\
  !*** ./node_modules/ssh2-streams/lib/constants.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var i;\nvar keys;\nvar len;\n\nvar eddsaSupported = (function() {\n  var crypto = __webpack_require__(/*! crypto */ \"crypto\");\n  if (typeof crypto.sign === 'function'\n      && typeof crypto.verify === 'function') {\n    var key = '-----BEGIN PRIVATE KEY-----\\r\\nMC4CAQAwBQYDK2VwBCIEIHKj+sVa9WcD'\n              + '/q2DJUJaf43Kptc8xYuUQA4bOFj9vC8T\\r\\n-----END PRIVATE KEY-----';\n    var data = Buffer.from('a');\n    var sig;\n    var verified;\n    try {\n      sig = crypto.sign(null, data, key);\n      verified = crypto.verify(null, data, key, sig);\n    } catch (ex) {}\n    return (Buffer.isBuffer(sig) && sig.length === 64 && verified === true);\n  }\n\n  return false;\n})();\n\nvar MESSAGE = exports.MESSAGE = {\n  // Transport layer protocol -- generic (1-19)\n  DISCONNECT: 1,\n  IGNORE: 2,\n  UNIMPLEMENTED: 3,\n  DEBUG: 4,\n  SERVICE_REQUEST: 5,\n  SERVICE_ACCEPT: 6,\n\n  // Transport layer protocol -- algorithm negotiation (20-29)\n  KEXINIT: 20,\n  NEWKEYS: 21,\n\n  // Transport layer protocol -- key exchange method-specific (30-49)\n\n  // User auth protocol -- generic (50-59)\n  USERAUTH_REQUEST: 50,\n  USERAUTH_FAILURE: 51,\n  USERAUTH_SUCCESS: 52,\n  USERAUTH_BANNER: 53,\n\n  // User auth protocol -- user auth method-specific (60-79)\n\n  // Connection protocol -- generic (80-89)\n  GLOBAL_REQUEST: 80,\n  REQUEST_SUCCESS: 81,\n  REQUEST_FAILURE: 82,\n\n  // Connection protocol -- channel-related (90-127)\n  CHANNEL_OPEN: 90,\n  CHANNEL_OPEN_CONFIRMATION: 91,\n  CHANNEL_OPEN_FAILURE: 92,\n  CHANNEL_WINDOW_ADJUST: 93,\n  CHANNEL_DATA: 94,\n  CHANNEL_EXTENDED_DATA: 95,\n  CHANNEL_EOF: 96,\n  CHANNEL_CLOSE: 97,\n  CHANNEL_REQUEST: 98,\n  CHANNEL_SUCCESS: 99,\n  CHANNEL_FAILURE: 100\n\n  // Reserved for client protocols (128-191)\n\n  // Local extensions (192-155)\n};\nfor (i = 0, keys = Object.keys(MESSAGE), len = keys.length; i < len; ++i)\n  MESSAGE[MESSAGE[keys[i]]] = keys[i];\n// context-specific message codes:\nMESSAGE.KEXDH_INIT = 30;\nMESSAGE.KEXDH_REPLY = 31;\nMESSAGE.KEXDH_GEX_REQUEST = 34;\nMESSAGE.KEXDH_GEX_GROUP = 31;\nMESSAGE.KEXDH_GEX_INIT = 32;\nMESSAGE.KEXDH_GEX_REPLY = 33;\nMESSAGE.KEXECDH_INIT = 30; // included here for completeness\nMESSAGE.KEXECDH_REPLY = 31; // included here for completeness\nMESSAGE.USERAUTH_PASSWD_CHANGEREQ = 60;\nMESSAGE.USERAUTH_PK_OK = 60;\nMESSAGE.USERAUTH_INFO_REQUEST = 60;\nMESSAGE.USERAUTH_INFO_RESPONSE = 61;\n\nvar DYNAMIC_KEXDH_MESSAGE = exports.DYNAMIC_KEXDH_MESSAGE = {};\nDYNAMIC_KEXDH_MESSAGE[MESSAGE.KEXDH_GEX_GROUP] = 'KEXDH_GEX_GROUP';\nDYNAMIC_KEXDH_MESSAGE[MESSAGE.KEXDH_GEX_REPLY] = 'KEXDH_GEX_REPLY';\n\nvar KEXDH_MESSAGE = exports.KEXDH_MESSAGE = {};\nKEXDH_MESSAGE[MESSAGE.KEXDH_INIT] = 'KEXDH_INIT';\nKEXDH_MESSAGE[MESSAGE.KEXDH_REPLY] = 'KEXDH_REPLY';\n\nvar DISCONNECT_REASON = exports.DISCONNECT_REASON = {\n  HOST_NOT_ALLOWED_TO_CONNECT: 1,\n  PROTOCOL_ERROR: 2,\n  KEY_EXCHANGE_FAILED: 3,\n  RESERVED: 4,\n  MAC_ERROR: 5,\n  COMPRESSION_ERROR: 6,\n  SERVICE_NOT_AVAILABLE: 7,\n  PROTOCOL_VERSION_NOT_SUPPORTED: 8,\n  HOST_KEY_NOT_VERIFIABLE: 9,\n  CONNECTION_LOST: 10,\n  BY_APPLICATION: 11,\n  TOO_MANY_CONNECTIONS: 12,\n  AUTH_CANCELED_BY_USER: 13,\n  NO_MORE_AUTH_METHODS_AVAILABLE: 14,\n  ILLEGAL_USER_NAME: 15\n};\nfor (i = 0, keys = Object.keys(DISCONNECT_REASON), len = keys.length;\n     i < len;\n     ++i) {\n  DISCONNECT_REASON[DISCONNECT_REASON[keys[i]]] = keys[i];\n}\n\nvar CHANNEL_OPEN_FAILURE = exports.CHANNEL_OPEN_FAILURE = {\n  ADMINISTRATIVELY_PROHIBITED: 1,\n  CONNECT_FAILED: 2,\n  UNKNOWN_CHANNEL_TYPE: 3,\n  RESOURCE_SHORTAGE: 4\n};\nfor (i = 0, keys = Object.keys(CHANNEL_OPEN_FAILURE), len = keys.length;\n     i < len;\n     ++i) {\n  CHANNEL_OPEN_FAILURE[CHANNEL_OPEN_FAILURE[keys[i]]] = keys[i];\n}\n\nvar TERMINAL_MODE = exports.TERMINAL_MODE = {\n  TTY_OP_END: 0,        // Indicates end of options.\n  VINTR: 1,             // Interrupt character; 255 if none. Similarly for the\n                        //  other characters.  Not all of these characters are\n                        //  supported on all systems.\n  VQUIT: 2,             // The quit character (sends SIGQUIT signal on POSIX\n                        //  systems).\n  VERASE: 3,            // Erase the character to left of the cursor.\n  VKILL: 4,             // Kill the current input line.\n  VEOF: 5,              // End-of-file character (sends EOF from the terminal).\n  VEOL: 6,              // End-of-line character in addition to carriage return\n                        //  and/or linefeed.\n  VEOL2: 7,             // Additional end-of-line character.\n  VSTART: 8,            // Continues paused output (normally control-Q).\n  VSTOP: 9,             // Pauses output (normally control-S).\n  VSUSP: 10,            // Suspends the current program.\n  VDSUSP: 11,           // Another suspend character.\n  VREPRINT: 12,         // Reprints the current input line.\n  VWERASE: 13,          // Erases a word left of cursor.\n  VLNEXT: 14,           // Enter the next character typed literally, even if it\n                        //  is a special character\n  VFLUSH: 15,           // Character to flush output.\n  VSWTCH: 16,           // Switch to a different shell layer.\n  VSTATUS: 17,          // Prints system status line (load, command, pid, etc).\n  VDISCARD: 18,         // Toggles the flushing of terminal output.\n  IGNPAR: 30,           // The ignore parity flag.  The parameter SHOULD be 0\n                        //  if this flag is FALSE, and 1 if it is TRUE.\n  PARMRK: 31,           // Mark parity and framing errors.\n  INPCK: 32,            // Enable checking of parity errors.\n  ISTRIP: 33,           // Strip 8th bit off characters.\n  INLCR: 34,            // Map NL into CR on input.\n  IGNCR: 35,            // Ignore CR on input.\n  ICRNL: 36,            // Map CR to NL on input.\n  IUCLC: 37,            // Translate uppercase characters to lowercase.\n  IXON: 38,             // Enable output flow control.\n  IXANY: 39,            // Any char will restart after stop.\n  IXOFF: 40,            // Enable input flow control.\n  IMAXBEL: 41,          // Ring bell on input queue full.\n  ISIG: 50,             // Enable signals INTR, QUIT, [D]SUSP.\n  ICANON: 51,           // Canonicalize input lines.\n  XCASE: 52,            // Enable input and output of uppercase characters by\n                        //  preceding their lowercase equivalents with \"\\\".\n  ECHO: 53,             // Enable echoing.\n  ECHOE: 54,            // Visually erase chars.\n  ECHOK: 55,            // Kill character discards current line.\n  ECHONL: 56,           // Echo NL even if ECHO is off.\n  NOFLSH: 57,           // Don't flush after interrupt.\n  TOSTOP: 58,           // Stop background jobs from output.\n  IEXTEN: 59,           // Enable extensions.\n  ECHOCTL: 60,          // Echo control characters as ^(Char).\n  ECHOKE: 61,           // Visual erase for line kill.\n  PENDIN: 62,           // Retype pending input.\n  OPOST: 70,            // Enable output processing.\n  OLCUC: 71,            // Convert lowercase to uppercase.\n  ONLCR: 72,            // Map NL to CR-NL.\n  OCRNL: 73,            // Translate carriage return to newline (output).\n  ONOCR: 74,            // Translate newline to carriage return-newline\n                        // (output).\n  ONLRET: 75,           // Newline performs a carriage return (output).\n  CS7: 90,              // 7 bit mode.\n  CS8: 91,              // 8 bit mode.\n  PARENB: 92,           // Parity enable.\n  PARODD: 93,           // Odd parity, else even.\n  TTY_OP_ISPEED: 128,   // Specifies the input baud rate in bits per second.\n  TTY_OP_OSPEED: 129    // Specifies the output baud rate in bits per second.\n};\nfor (i = 0, keys = Object.keys(TERMINAL_MODE), len = keys.length; i < len; ++i)\n  TERMINAL_MODE[TERMINAL_MODE[keys[i]]] = keys[i];\n\nvar CHANNEL_EXTENDED_DATATYPE = exports.CHANNEL_EXTENDED_DATATYPE = {\n  STDERR: 1\n};\nfor (i = 0, keys = Object.keys(CHANNEL_EXTENDED_DATATYPE), len = keys.length;\n     i < len;\n     ++i) {\n  CHANNEL_EXTENDED_DATATYPE[CHANNEL_EXTENDED_DATATYPE[keys[i]]] = keys[i];\n}\n\nexports.SIGNALS = ['ABRT', 'ALRM', 'FPE', 'HUP', 'ILL', 'INT',\n                   'QUIT', 'SEGV', 'TERM', 'USR1', 'USR2', 'KILL',\n                   'PIPE'];\n\nvar DEFAULT_KEX = [\n  // https://tools.ietf.org/html/rfc5656#section-10.1\n  'ecdh-sha2-nistp256',\n  'ecdh-sha2-nistp384',\n  'ecdh-sha2-nistp521',\n\n  // https://tools.ietf.org/html/rfc4419#section-4\n  'diffie-hellman-group-exchange-sha256',\n\n  'diffie-hellman-group14-sha1' // REQUIRED\n];\nvar SUPPORTED_KEX = [\n  // https://tools.ietf.org/html/rfc4419#section-4\n  'diffie-hellman-group-exchange-sha1',\n\n  'diffie-hellman-group1-sha1'  // REQUIRED\n];\nvar KEX_BUF = Buffer.from(DEFAULT_KEX.join(','), 'ascii');\nSUPPORTED_KEX = DEFAULT_KEX.concat(SUPPORTED_KEX);\n\nvar DEFAULT_SERVER_HOST_KEY = [\n  'ssh-rsa',\n  'ecdsa-sha2-nistp256',\n  'ecdsa-sha2-nistp384',\n  'ecdsa-sha2-nistp521'\n];\nif (eddsaSupported)\n  DEFAULT_SERVER_HOST_KEY.unshift('ssh-ed25519');\nvar SUPPORTED_SERVER_HOST_KEY = [\n  'ssh-dss'\n];\nvar SERVER_HOST_KEY_BUF = Buffer.from(DEFAULT_SERVER_HOST_KEY.join(','),\n                                      'ascii');\nSUPPORTED_SERVER_HOST_KEY = DEFAULT_SERVER_HOST_KEY.concat(\n  SUPPORTED_SERVER_HOST_KEY\n);\n\nvar DEFAULT_CIPHER = [\n  // http://tools.ietf.org/html/rfc4344#section-4\n  'aes128-ctr',\n  'aes192-ctr',\n  'aes256-ctr',\n\n  // http://tools.ietf.org/html/rfc5647\n  'aes128-gcm',\n  'aes128-gcm@openssh.com',\n  'aes256-gcm',\n  'aes256-gcm@openssh.com'\n];\nvar SUPPORTED_CIPHER = [\n  'aes256-cbc',\n  'aes192-cbc',\n  'aes128-cbc',\n  'blowfish-cbc',\n  '3des-cbc',\n\n  // http://tools.ietf.org/html/rfc4345#section-4:\n  'arcfour256',\n  'arcfour128',\n\n  'cast128-cbc',\n  'arcfour'\n];\nvar CIPHER_BUF = Buffer.from(DEFAULT_CIPHER.join(','), 'ascii');\nSUPPORTED_CIPHER = DEFAULT_CIPHER.concat(SUPPORTED_CIPHER);\n\nvar DEFAULT_HMAC = [\n  'hmac-sha2-256',\n  'hmac-sha2-512',\n  'hmac-sha1',\n];\nvar SUPPORTED_HMAC = [\n  'hmac-md5',\n  'hmac-sha2-256-96', // first 96 bits of HMAC-SHA256\n  'hmac-sha2-512-96', // first 96 bits of HMAC-SHA512\n  'hmac-ripemd160',\n  'hmac-sha1-96',     // first 96 bits of HMAC-SHA1\n  'hmac-md5-96'       // first 96 bits of HMAC-MD5\n];\nvar HMAC_BUF = Buffer.from(DEFAULT_HMAC.join(','), 'ascii');\nSUPPORTED_HMAC = DEFAULT_HMAC.concat(SUPPORTED_HMAC);\n\nvar DEFAULT_COMPRESS = [\n  'none',\n  'zlib@openssh.com', // ZLIB (LZ77) compression, except\n                      // compression/decompression does not start until after\n                      // successful user authentication\n  'zlib'              // ZLIB (LZ77) compression\n];\nvar SUPPORTED_COMPRESS = [];\nvar COMPRESS_BUF = Buffer.from(DEFAULT_COMPRESS.join(','), 'ascii');\nSUPPORTED_COMPRESS = DEFAULT_COMPRESS.concat(SUPPORTED_COMPRESS);\n\nfunction makeCipherInfo(blockLen, keyLen, ivLen, authLen, discardLen, stream) {\n  return {\n    blockLen: blockLen,\n    keyLen: keyLen,\n    ivLen: ivLen === 0 ? blockLen : ivLen,\n    authLen: authLen,\n    discardLen: discardLen,\n    stream: stream,\n  };\n}\nexports.CIPHER_INFO = {\n  'aes128-gcm': makeCipherInfo(16, 16, 12, 16, 0, false),\n  'aes256-gcm': makeCipherInfo(16, 32, 12, 16, 0, false),\n  'aes128-gcm@openssh.com': makeCipherInfo(16, 16, 12, 16, 0, false),\n  'aes256-gcm@openssh.com': makeCipherInfo(16, 32, 12, 16, 0, false),\n\n  'aes128-cbc': makeCipherInfo(16, 16, 0, 0, 0, false),\n  'aes192-cbc': makeCipherInfo(16, 24, 0, 0, 0, false),\n  'aes256-cbc': makeCipherInfo(16, 32, 0, 0, 0, false),\n  'rijndael-cbc@lysator.liu.se': makeCipherInfo(16, 32, 0, 0, 0, false),\n  '3des-cbc': makeCipherInfo(8, 24, 0, 0, 0, false),\n  'blowfish-cbc': makeCipherInfo(8, 16, 0, 0, 0, false),\n  'idea-cbc': makeCipherInfo(8, 16, 0, 0, 0, false),\n  'cast128-cbc': makeCipherInfo(8, 16, 0, 0, 0, false),\n  'camellia128-cbc': makeCipherInfo(16, 16, 0, 0, 0, false),\n  'camellia192-cbc': makeCipherInfo(16, 24, 0, 0, 0, false),\n  'camellia256-cbc': makeCipherInfo(16, 32, 0, 0, 0, false),\n  'camellia128-cbc@openssh.com': makeCipherInfo(16, 16, 0, 0, 0, false),\n  'camellia192-cbc@openssh.com': makeCipherInfo(16, 24, 0, 0, 0, false),\n  'camellia256-cbc@openssh.com': makeCipherInfo(16, 32, 0, 0, 0, false),\n\n  'aes128-ctr': makeCipherInfo(16, 16, 0, 0, 0, false),\n  'aes192-ctr': makeCipherInfo(16, 24, 0, 0, 0, false),\n  'aes256-ctr': makeCipherInfo(16, 32, 0, 0, 0, false),\n  '3des-ctr': makeCipherInfo(8, 24, 0, 0, 0, false),\n  'blowfish-ctr': makeCipherInfo(8, 16, 0, 0, 0, false),\n  'cast128-ctr': makeCipherInfo(8, 16, 0, 0, 0, false),\n  'camellia128-ctr': makeCipherInfo(16, 16, 0, 0, 0, false),\n  'camellia192-ctr': makeCipherInfo(16, 24, 0, 0, 0, false),\n  'camellia256-ctr': makeCipherInfo(16, 32, 0, 0, 0, false),\n  'camellia128-ctr@openssh.com': makeCipherInfo(16, 16, 0, 0, 0, false),\n  'camellia192-ctr@openssh.com': makeCipherInfo(16, 24, 0, 0, 0, false),\n  'camellia256-ctr@openssh.com': makeCipherInfo(16, 32, 0, 0, 0, false),\n\n  /* The \"arcfour128\" algorithm is the RC4 cipher, as described in\n     [SCHNEIER], using a 128-bit key.  The first 1536 bytes of keystream\n     generated by the cipher MUST be discarded, and the first byte of the\n     first encrypted packet MUST be encrypted using the 1537th byte of\n     keystream.\n\n     -- http://tools.ietf.org/html/rfc4345#section-4 */\n  'arcfour': makeCipherInfo(8, 16, 0, 0, 1536, true),\n  'arcfour128': makeCipherInfo(8, 16, 0, 0, 1536, true),\n  'arcfour256': makeCipherInfo(8, 32, 0, 0, 1536, true),\n  'arcfour512': makeCipherInfo(8, 64, 0, 0, 1536, true),\n};\n\nfunction makeHMACInfo(len, actualLen) {\n  return { len: len, actualLen: actualLen };\n}\nexports.HMAC_INFO = {\n  'hmac-md5': makeHMACInfo(16, 16),\n  'hmac-md5-96': makeHMACInfo(16, 12),\n  'hmac-ripemd160': makeHMACInfo(20, 20),\n  'hmac-sha1': makeHMACInfo(20, 20),\n  'hmac-sha1-96': makeHMACInfo(20, 12),\n  'hmac-sha2-256': makeHMACInfo(32, 32),\n  'hmac-sha2-256-96': makeHMACInfo(32, 12),\n  'hmac-sha2-512': makeHMACInfo(64, 64),\n  'hmac-sha2-512-96': makeHMACInfo(64, 12),\n};\n\nexports.ALGORITHMS = {\n  KEX: DEFAULT_KEX,\n  KEX_BUF: KEX_BUF,\n  SUPPORTED_KEX: SUPPORTED_KEX,\n\n  SERVER_HOST_KEY: DEFAULT_SERVER_HOST_KEY,\n  SERVER_HOST_KEY_BUF: SERVER_HOST_KEY_BUF,\n  SUPPORTED_SERVER_HOST_KEY: SUPPORTED_SERVER_HOST_KEY,\n\n  CIPHER: DEFAULT_CIPHER,\n  CIPHER_BUF: CIPHER_BUF,\n  SUPPORTED_CIPHER: SUPPORTED_CIPHER,\n\n  HMAC: DEFAULT_HMAC,\n  HMAC_BUF: HMAC_BUF,\n  SUPPORTED_HMAC: SUPPORTED_HMAC,\n\n  COMPRESS: DEFAULT_COMPRESS,\n  COMPRESS_BUF: COMPRESS_BUF,\n  SUPPORTED_COMPRESS: SUPPORTED_COMPRESS\n};\nexports.SSH_TO_OPENSSL = {\n  // ECDH key exchange\n  'ecdh-sha2-nistp256': 'prime256v1', // OpenSSL's name for 'secp256r1'\n  'ecdh-sha2-nistp384': 'secp384r1',\n  'ecdh-sha2-nistp521': 'secp521r1',\n  // Ciphers\n  'aes128-gcm': 'aes-128-gcm',\n  'aes256-gcm': 'aes-256-gcm',\n  'aes128-gcm@openssh.com': 'aes-128-gcm',\n  'aes256-gcm@openssh.com': 'aes-256-gcm',\n  '3des-cbc': 'des-ede3-cbc',\n  'blowfish-cbc': 'bf-cbc',\n  'aes256-cbc': 'aes-256-cbc',\n  'aes192-cbc': 'aes-192-cbc',\n  'aes128-cbc': 'aes-128-cbc',\n  'idea-cbc': 'idea-cbc',\n  'cast128-cbc': 'cast-cbc',\n  'rijndael-cbc@lysator.liu.se': 'aes-256-cbc',\n  'arcfour128': 'rc4',\n  'arcfour256': 'rc4',\n  'arcfour512': 'rc4',\n  'arcfour': 'rc4',\n  'camellia128-cbc': 'camellia-128-cbc',\n  'camellia192-cbc': 'camellia-192-cbc',\n  'camellia256-cbc': 'camellia-256-cbc',\n  'camellia128-cbc@openssh.com': 'camellia-128-cbc',\n  'camellia192-cbc@openssh.com': 'camellia-192-cbc',\n  'camellia256-cbc@openssh.com': 'camellia-256-cbc',\n  '3des-ctr': 'des-ede3',\n  'blowfish-ctr': 'bf-ecb',\n  'aes256-ctr': 'aes-256-ctr',\n  'aes192-ctr': 'aes-192-ctr',\n  'aes128-ctr': 'aes-128-ctr',\n  'cast128-ctr': 'cast5-ecb',\n  'camellia128-ctr': 'camellia-128-ecb',\n  'camellia192-ctr': 'camellia-192-ecb',\n  'camellia256-ctr': 'camellia-256-ecb',\n  'camellia128-ctr@openssh.com': 'camellia-128-ecb',\n  'camellia192-ctr@openssh.com': 'camellia-192-ecb',\n  'camellia256-ctr@openssh.com': 'camellia-256-ecb',\n  // HMAC\n  'hmac-sha1-96': 'sha1',\n  'hmac-sha1': 'sha1',\n  'hmac-sha2-256': 'sha256',\n  'hmac-sha2-256-96': 'sha256',\n  'hmac-sha2-512': 'sha512',\n  'hmac-sha2-512-96': 'sha512',\n  'hmac-md5-96': 'md5',\n  'hmac-md5': 'md5',\n  'hmac-ripemd160': 'ripemd160'\n};\n\nvar BUGS = exports.BUGS = {\n  BAD_DHGEX: 1,\n  OLD_EXIT: 2,\n  DYN_RPORT_BUG: 4\n};\n\nexports.BUGGY_IMPLS = [\n  [ 'Cisco-1.25', BUGS.BAD_DHGEX ],\n  [ /^[0-9.]+$/, BUGS.OLD_EXIT ], // old SSH.com implementations\n  [ /^OpenSSH_5\\.\\d+/, BUGS.DYN_RPORT_BUG ]\n];\n\nexports.EDDSA_SUPPORTED = eddsaSupported;\n\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/lib/constants.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/lib/jsbn.js":
/*!***********************************************!*\
  !*** ./node_modules/ssh2-streams/lib/jsbn.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) 2005  Tom Wu\n// All Rights Reserved.\n// See \"LICENSE\" for details.\n\n// Basic JavaScript BN library - subset useful for RSA encryption.\n\n// Bits per digit\nvar dbits;\n\n// JavaScript engine analysis\nvar canary = 0xdeadbeefcafe;\nvar j_lm = ((canary&0xffffff)==0xefcafe);\n\n// (public) Constructor\nfunction BigInteger(a,b,c) {\n  if(a != null)\n    if(\"number\" == typeof a) this.fromNumber(a,b,c);\n    else if(b == null && \"string\" != typeof a) this.fromString(a,256);\n    else this.fromString(a,b);\n}\n\n// return new, unset BigInteger\nfunction nbi() { return new BigInteger(null); }\n\n// am: Compute w_j += (x*this_i), propagate carries,\n// c is initial carry, returns final carry.\n// c < 3*dvalue, x < 2*dvalue, this_i < dvalue\n// We need to select the fastest one that works in this environment.\n\n// Set max digit bits to 28 since some\n// browsers slow down when dealing with 32-bit numbers.\nfunction am3(i,x,w,j,c,n) {\n  var xl = x&0x3fff, xh = x>>14;\n  while(--n >= 0) {\n    var l = this[i]&0x3fff;\n    var h = this[i++]>>14;\n    var m = xh*l+h*xl;\n    l = xl*l+((m&0x3fff)<<14)+w[j]+c;\n    c = (l>>28)+(m>>14)+xh*h;\n    w[j++] = l&0xfffffff;\n  }\n  return c;\n}\nBigInteger.prototype.am = am3;\ndbits = 28;\n\nBigInteger.prototype.DB = dbits;\nBigInteger.prototype.DM = ((1<<dbits)-1);\nBigInteger.prototype.DV = (1<<dbits);\n\nvar BI_FP = 52;\nBigInteger.prototype.FV = Math.pow(2,BI_FP);\nBigInteger.prototype.F1 = BI_FP-dbits;\nBigInteger.prototype.F2 = 2*dbits-BI_FP;\n\n// Digit conversions\nvar BI_RM = \"0123456789abcdefghijklmnopqrstuvwxyz\";\nvar BI_RC = new Array();\nvar rr,vv;\nrr = \"0\".charCodeAt(0);\nfor(vv = 0; vv <= 9; ++vv) BI_RC[rr++] = vv;\nrr = \"a\".charCodeAt(0);\nfor(vv = 10; vv < 36; ++vv) BI_RC[rr++] = vv;\nrr = \"A\".charCodeAt(0);\nfor(vv = 10; vv < 36; ++vv) BI_RC[rr++] = vv;\n\nfunction int2char(n) { return BI_RM.charAt(n); }\nfunction intAt(s,i) {\n  var c = BI_RC[s.charCodeAt(i)];\n  return (c==null)?-1:c;\n}\n\n// (protected) copy this to r\nfunction bnpCopyTo(r) {\n  for(var i = this.t-1; i >= 0; --i) r[i] = this[i];\n  r.t = this.t;\n  r.s = this.s;\n}\n\n// (protected) set from integer value x, -DV <= x < DV\nfunction bnpFromInt(x) {\n  this.t = 1;\n  this.s = (x<0)?-1:0;\n  if(x > 0) this[0] = x;\n  else if(x < -1) this[0] = x+this.DV;\n  else this.t = 0;\n}\n\n// return bigint initialized to value\nfunction nbv(i) { var r = nbi(); r.fromInt(i); return r; }\n\n// (protected) set from string and radix\nfunction bnpFromString(s,b) {\n  var k;\n  if(b == 16) k = 4;\n  else if(b == 8) k = 3;\n  else if(b == 256) k = 8; // byte array\n  else if(b == 2) k = 1;\n  else if(b == 32) k = 5;\n  else if(b == 4) k = 2;\n  else { this.fromRadix(s,b); return; }\n  this.t = 0;\n  this.s = 0;\n  var i = s.length, mi = false, sh = 0;\n  while(--i >= 0) {\n    var x = (k==8)?s[i]&0xff:intAt(s,i);\n    if(x < 0) {\n      if(s.charAt(i) == \"-\") mi = true;\n      continue;\n    }\n    mi = false;\n    if(sh == 0)\n      this[this.t++] = x;\n    else if(sh+k > this.DB) {\n      this[this.t-1] |= (x&((1<<(this.DB-sh))-1))<<sh;\n      this[this.t++] = (x>>(this.DB-sh));\n    }\n    else\n      this[this.t-1] |= x<<sh;\n    sh += k;\n    if(sh >= this.DB) sh -= this.DB;\n  }\n  if(k == 8 && (s[0]&0x80) != 0) {\n    this.s = -1;\n    if(sh > 0) this[this.t-1] |= ((1<<(this.DB-sh))-1)<<sh;\n  }\n  this.clamp();\n  if(mi) BigInteger.ZERO.subTo(this,this);\n}\n\n// (protected) clamp off excess high words\nfunction bnpClamp() {\n  var c = this.s&this.DM;\n  while(this.t > 0 && this[this.t-1] == c) --this.t;\n}\n\n// (public) return string representation in given radix\nfunction bnToString(b) {\n  if(this.s < 0) return \"-\"+this.negate().toString(b);\n  var k;\n  if(b == 16) k = 4;\n  else if(b == 8) k = 3;\n  else if(b == 2) k = 1;\n  else if(b == 32) k = 5;\n  else if(b == 4) k = 2;\n  else return this.toRadix(b);\n  var km = (1<<k)-1, d, m = false, r = \"\", i = this.t;\n  var p = this.DB-(i*this.DB)%k;\n  if(i-- > 0) {\n    if(p < this.DB && (d = this[i]>>p) > 0) { m = true; r = int2char(d); }\n    while(i >= 0) {\n      if(p < k) {\n        d = (this[i]&((1<<p)-1))<<(k-p);\n        d |= this[--i]>>(p+=this.DB-k);\n      }\n      else {\n        d = (this[i]>>(p-=k))&km;\n        if(p <= 0) { p += this.DB; --i; }\n      }\n      if(d > 0) m = true;\n      if(m) r += int2char(d);\n    }\n  }\n  return m?r:\"0\";\n}\n\n// (public) -this\nfunction bnNegate() { var r = nbi(); BigInteger.ZERO.subTo(this,r); return r; }\n\n// (public) |this|\nfunction bnAbs() { return (this.s<0)?this.negate():this; }\n\n// (public) return + if this > a, - if this < a, 0 if equal\nfunction bnCompareTo(a) {\n  var r = this.s-a.s;\n  if(r != 0) return r;\n  var i = this.t;\n  r = i-a.t;\n  if(r != 0) return (this.s<0)?-r:r;\n  while(--i >= 0) if((r=this[i]-a[i]) != 0) return r;\n  return 0;\n}\n\n// returns bit length of the integer x\nfunction nbits(x) {\n  var r = 1, t;\n  if((t=x>>>16) != 0) { x = t; r += 16; }\n  if((t=x>>8) != 0) { x = t; r += 8; }\n  if((t=x>>4) != 0) { x = t; r += 4; }\n  if((t=x>>2) != 0) { x = t; r += 2; }\n  if((t=x>>1) != 0) { x = t; r += 1; }\n  return r;\n}\n\n// (public) return the number of bits in \"this\"\nfunction bnBitLength() {\n  if(this.t <= 0) return 0;\n  return this.DB*(this.t-1)+nbits(this[this.t-1]^(this.s&this.DM));\n}\n\n// (protected) r = this << n*DB\nfunction bnpDLShiftTo(n,r) {\n  var i;\n  for(i = this.t-1; i >= 0; --i) r[i+n] = this[i];\n  for(i = n-1; i >= 0; --i) r[i] = 0;\n  r.t = this.t+n;\n  r.s = this.s;\n}\n\n// (protected) r = this >> n*DB\nfunction bnpDRShiftTo(n,r) {\n  for(var i = n; i < this.t; ++i) r[i-n] = this[i];\n  r.t = Math.max(this.t-n,0);\n  r.s = this.s;\n}\n\n// (protected) r = this << n\nfunction bnpLShiftTo(n,r) {\n  var bs = n%this.DB;\n  var cbs = this.DB-bs;\n  var bm = (1<<cbs)-1;\n  var ds = Math.floor(n/this.DB), c = (this.s<<bs)&this.DM, i;\n  for(i = this.t-1; i >= 0; --i) {\n    r[i+ds+1] = (this[i]>>cbs)|c;\n    c = (this[i]&bm)<<bs;\n  }\n  for(i = ds-1; i >= 0; --i) r[i] = 0;\n  r[ds] = c;\n  r.t = this.t+ds+1;\n  r.s = this.s;\n  r.clamp();\n}\n\n// (protected) r = this >> n\nfunction bnpRShiftTo(n,r) {\n  r.s = this.s;\n  var ds = Math.floor(n/this.DB);\n  if(ds >= this.t) { r.t = 0; return; }\n  var bs = n%this.DB;\n  var cbs = this.DB-bs;\n  var bm = (1<<bs)-1;\n  r[0] = this[ds]>>bs;\n  for(var i = ds+1; i < this.t; ++i) {\n    r[i-ds-1] |= (this[i]&bm)<<cbs;\n    r[i-ds] = this[i]>>bs;\n  }\n  if(bs > 0) r[this.t-ds-1] |= (this.s&bm)<<cbs;\n  r.t = this.t-ds;\n  r.clamp();\n}\n\n// (protected) r = this - a\nfunction bnpSubTo(a,r) {\n  var i = 0, c = 0, m = Math.min(a.t,this.t);\n  while(i < m) {\n    c += this[i]-a[i];\n    r[i++] = c&this.DM;\n    c >>= this.DB;\n  }\n  if(a.t < this.t) {\n    c -= a.s;\n    while(i < this.t) {\n      c += this[i];\n      r[i++] = c&this.DM;\n      c >>= this.DB;\n    }\n    c += this.s;\n  }\n  else {\n    c += this.s;\n    while(i < a.t) {\n      c -= a[i];\n      r[i++] = c&this.DM;\n      c >>= this.DB;\n    }\n    c -= a.s;\n  }\n  r.s = (c<0)?-1:0;\n  if(c < -1) r[i++] = this.DV+c;\n  else if(c > 0) r[i++] = c;\n  r.t = i;\n  r.clamp();\n}\n\n// (protected) r = this * a, r != this,a (HAC 14.12)\n// \"this\" should be the larger one if appropriate.\nfunction bnpMultiplyTo(a,r) {\n  var x = this.abs(), y = a.abs();\n  var i = x.t;\n  r.t = i+y.t;\n  while(--i >= 0) r[i] = 0;\n  for(i = 0; i < y.t; ++i) r[i+x.t] = x.am(0,y[i],r,i,0,x.t);\n  r.s = 0;\n  r.clamp();\n  if(this.s != a.s) BigInteger.ZERO.subTo(r,r);\n}\n\n// (protected) r = this^2, r != this (HAC 14.16)\nfunction bnpSquareTo(r) {\n  var x = this.abs();\n  var i = r.t = 2*x.t;\n  while(--i >= 0) r[i] = 0;\n  for(i = 0; i < x.t-1; ++i) {\n    var c = x.am(i,x[i],r,2*i,0,1);\n    if((r[i+x.t]+=x.am(i+1,2*x[i],r,2*i+1,c,x.t-i-1)) >= x.DV) {\n      r[i+x.t] -= x.DV;\n      r[i+x.t+1] = 1;\n    }\n  }\n  if(r.t > 0) r[r.t-1] += x.am(i,x[i],r,2*i,0,1);\n  r.s = 0;\n  r.clamp();\n}\n\n// (protected) divide this by m, quotient and remainder to q, r (HAC 14.20)\n// r != q, this != m.  q or r may be null.\nfunction bnpDivRemTo(m,q,r) {\n  var pm = m.abs();\n  if(pm.t <= 0) return;\n  var pt = this.abs();\n  if(pt.t < pm.t) {\n    if(q != null) q.fromInt(0);\n    if(r != null) this.copyTo(r);\n    return;\n  }\n  if(r == null) r = nbi();\n  var y = nbi(), ts = this.s, ms = m.s;\n  var nsh = this.DB-nbits(pm[pm.t-1]);   // normalize modulus\n  if(nsh > 0) { pm.lShiftTo(nsh,y); pt.lShiftTo(nsh,r); }\n  else { pm.copyTo(y); pt.copyTo(r); }\n  var ys = y.t;\n  var y0 = y[ys-1];\n  if(y0 == 0) return;\n  var yt = y0*(1<<this.F1)+((ys>1)?y[ys-2]>>this.F2:0);\n  var d1 = this.FV/yt, d2 = (1<<this.F1)/yt, e = 1<<this.F2;\n  var i = r.t, j = i-ys, t = (q==null)?nbi():q;\n  y.dlShiftTo(j,t);\n  if(r.compareTo(t) >= 0) {\n    r[r.t++] = 1;\n    r.subTo(t,r);\n  }\n  BigInteger.ONE.dlShiftTo(ys,t);\n  t.subTo(y,y);  // \"negative\" y so we can replace sub with am later\n  while(y.t < ys) y[y.t++] = 0;\n  while(--j >= 0) {\n    // Estimate quotient digit\n    var qd = (r[--i]==y0)?this.DM:Math.floor(r[i]*d1+(r[i-1]+e)*d2);\n    if((r[i]+=y.am(0,qd,r,j,0,ys)) < qd) {   // Try it out\n      y.dlShiftTo(j,t);\n      r.subTo(t,r);\n      while(r[i] < --qd) r.subTo(t,r);\n    }\n  }\n  if(q != null) {\n    r.drShiftTo(ys,q);\n    if(ts != ms) BigInteger.ZERO.subTo(q,q);\n  }\n  r.t = ys;\n  r.clamp();\n  if(nsh > 0) r.rShiftTo(nsh,r); // Denormalize remainder\n  if(ts < 0) BigInteger.ZERO.subTo(r,r);\n}\n\n// (public) this mod a\nfunction bnMod(a) {\n  var r = nbi();\n  this.abs().divRemTo(a,null,r);\n  if(this.s < 0 && r.compareTo(BigInteger.ZERO) > 0) a.subTo(r,r);\n  return r;\n}\n\n// Modular reduction using \"classic\" algorithm\nfunction Classic(m) { this.m = m; }\nfunction cConvert(x) {\n  if(x.s < 0 || x.compareTo(this.m) >= 0) return x.mod(this.m);\n  else return x;\n}\nfunction cRevert(x) { return x; }\nfunction cReduce(x) { x.divRemTo(this.m,null,x); }\nfunction cMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }\nfunction cSqrTo(x,r) { x.squareTo(r); this.reduce(r); }\n\nClassic.prototype.convert = cConvert;\nClassic.prototype.revert = cRevert;\nClassic.prototype.reduce = cReduce;\nClassic.prototype.mulTo = cMulTo;\nClassic.prototype.sqrTo = cSqrTo;\n\n// (protected) return \"-1/this % 2^DB\"; useful for Mont. reduction\n// justification:\n//         xy == 1 (mod m)\n//         xy =  1+km\n//   xy(2-xy) = (1+km)(1-km)\n// x[y(2-xy)] = 1-k^2m^2\n// x[y(2-xy)] == 1 (mod m^2)\n// if y is 1/x mod m, then y(2-xy) is 1/x mod m^2\n// should reduce x and y(2-xy) by m^2 at each step to keep size bounded.\n// JS multiply \"overflows\" differently from C/C++, so care is needed here.\nfunction bnpInvDigit() {\n  if(this.t < 1) return 0;\n  var x = this[0];\n  if((x&1) == 0) return 0;\n  var y = x&3;       // y == 1/x mod 2^2\n  y = (y*(2-(x&0xf)*y))&0xf; // y == 1/x mod 2^4\n  y = (y*(2-(x&0xff)*y))&0xff;   // y == 1/x mod 2^8\n  y = (y*(2-(((x&0xffff)*y)&0xffff)))&0xffff;    // y == 1/x mod 2^16\n  // last step - calculate inverse mod DV directly;\n  // assumes 16 < DB <= 32 and assumes ability to handle 48-bit ints\n  y = (y*(2-x*y%this.DV))%this.DV;       // y == 1/x mod 2^dbits\n  // we really want the negative inverse, and -DV < y < DV\n  return (y>0)?this.DV-y:-y;\n}\n\n// Montgomery reduction\nfunction Montgomery(m) {\n  this.m = m;\n  this.mp = m.invDigit();\n  this.mpl = this.mp&0x7fff;\n  this.mph = this.mp>>15;\n  this.um = (1<<(m.DB-15))-1;\n  this.mt2 = 2*m.t;\n}\n\n// xR mod m\nfunction montConvert(x) {\n  var r = nbi();\n  x.abs().dlShiftTo(this.m.t,r);\n  r.divRemTo(this.m,null,r);\n  if(x.s < 0 && r.compareTo(BigInteger.ZERO) > 0) this.m.subTo(r,r);\n  return r;\n}\n\n// x/R mod m\nfunction montRevert(x) {\n  var r = nbi();\n  x.copyTo(r);\n  this.reduce(r);\n  return r;\n}\n\n// x = x/R mod m (HAC 14.32)\nfunction montReduce(x) {\n  while(x.t <= this.mt2) // pad x so am has enough room later\n    x[x.t++] = 0;\n  for(var i = 0; i < this.m.t; ++i) {\n    // faster way of calculating u0 = x[i]*mp mod DV\n    var j = x[i]&0x7fff;\n    var u0 = (j*this.mpl+(((j*this.mph+(x[i]>>15)*this.mpl)&this.um)<<15))&x.DM;\n    // use am to combine the multiply-shift-add into one call\n    j = i+this.m.t;\n    x[j] += this.m.am(0,u0,x,i,0,this.m.t);\n    // propagate carry\n    while(x[j] >= x.DV) { x[j] -= x.DV; x[++j]++; }\n  }\n  x.clamp();\n  x.drShiftTo(this.m.t,x);\n  if(x.compareTo(this.m) >= 0) x.subTo(this.m,x);\n}\n\n// r = \"x^2/R mod m\"; x != r\nfunction montSqrTo(x,r) { x.squareTo(r); this.reduce(r); }\n\n// r = \"xy/R mod m\"; x,y != r\nfunction montMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }\n\nMontgomery.prototype.convert = montConvert;\nMontgomery.prototype.revert = montRevert;\nMontgomery.prototype.reduce = montReduce;\nMontgomery.prototype.mulTo = montMulTo;\nMontgomery.prototype.sqrTo = montSqrTo;\n\n// (protected) true iff this is even\nfunction bnpIsEven() { return ((this.t>0)?(this[0]&1):this.s) == 0; }\n\n// (protected) this^e, e < 2^32, doing sqr and mul with \"r\" (HAC 14.79)\nfunction bnpExp(e,z) {\n  if(e > 0xffffffff || e < 1) return BigInteger.ONE;\n  var r = nbi(), r2 = nbi(), g = z.convert(this), i = nbits(e)-1;\n  g.copyTo(r);\n  while(--i >= 0) {\n    z.sqrTo(r,r2);\n    if((e&(1<<i)) > 0) z.mulTo(r2,g,r);\n    else { var t = r; r = r2; r2 = t; }\n  }\n  return z.revert(r);\n}\n\n// (public) this^e % m, 0 <= e < 2^32\nfunction bnModPowInt(e,m) {\n  var z;\n  if(e < 256 || m.isEven()) z = new Classic(m); else z = new Montgomery(m);\n  return this.exp(e,z);\n}\n\n// protected\nBigInteger.prototype.copyTo = bnpCopyTo;\nBigInteger.prototype.fromInt = bnpFromInt;\nBigInteger.prototype.fromString = bnpFromString;\nBigInteger.prototype.clamp = bnpClamp;\nBigInteger.prototype.dlShiftTo = bnpDLShiftTo;\nBigInteger.prototype.drShiftTo = bnpDRShiftTo;\nBigInteger.prototype.lShiftTo = bnpLShiftTo;\nBigInteger.prototype.rShiftTo = bnpRShiftTo;\nBigInteger.prototype.subTo = bnpSubTo;\nBigInteger.prototype.multiplyTo = bnpMultiplyTo;\nBigInteger.prototype.squareTo = bnpSquareTo;\nBigInteger.prototype.divRemTo = bnpDivRemTo;\nBigInteger.prototype.invDigit = bnpInvDigit;\nBigInteger.prototype.isEven = bnpIsEven;\nBigInteger.prototype.exp = bnpExp;\n\n// public\nBigInteger.prototype.toString = bnToString;\nBigInteger.prototype.negate = bnNegate;\nBigInteger.prototype.abs = bnAbs;\nBigInteger.prototype.compareTo = bnCompareTo;\nBigInteger.prototype.bitLength = bnBitLength;\nBigInteger.prototype.mod = bnMod;\nBigInteger.prototype.modPowInt = bnModPowInt;\n\n// \"constants\"\nBigInteger.ZERO = nbv(0);\nBigInteger.ONE = nbv(1);\n\n// Copyright (c) 2005-2009  Tom Wu\n// All Rights Reserved.\n// See \"LICENSE\" for details.\n\n// Extended JavaScript BN functions, required for RSA private ops.\n\n// Version 1.1: new BigInteger(\"0\", 10) returns \"proper\" zero\n// Version 1.2: square() API, isProbablePrime fix\n\n// (public)\nfunction bnClone() { var r = nbi(); this.copyTo(r); return r; }\n\n// (public) return value as integer\nfunction bnIntValue() {\n  if(this.s < 0) {\n    if(this.t == 1) return this[0]-this.DV;\n    else if(this.t == 0) return -1;\n  }\n  else if(this.t == 1) return this[0];\n  else if(this.t == 0) return 0;\n  // assumes 16 < DB < 32\n  return ((this[1]&((1<<(32-this.DB))-1))<<this.DB)|this[0];\n}\n\n// (public) return value as byte\nfunction bnByteValue() { return (this.t==0)?this.s:(this[0]<<24)>>24; }\n\n// (public) return value as short (assumes DB>=16)\nfunction bnShortValue() { return (this.t==0)?this.s:(this[0]<<16)>>16; }\n\n// (protected) return x s.t. r^x < DV\nfunction bnpChunkSize(r) { return Math.floor(Math.LN2*this.DB/Math.log(r)); }\n\n// (public) 0 if this == 0, 1 if this > 0\nfunction bnSigNum() {\n  if(this.s < 0) return -1;\n  else if(this.t <= 0 || (this.t == 1 && this[0] <= 0)) return 0;\n  else return 1;\n}\n\n// (protected) convert to radix string\nfunction bnpToRadix(b) {\n  if(b == null) b = 10;\n  if(this.signum() == 0 || b < 2 || b > 36) return \"0\";\n  var cs = this.chunkSize(b);\n  var a = Math.pow(b,cs);\n  var d = nbv(a), y = nbi(), z = nbi(), r = \"\";\n  this.divRemTo(d,y,z);\n  while(y.signum() > 0) {\n    r = (a+z.intValue()).toString(b).substr(1) + r;\n    y.divRemTo(d,y,z);\n  }\n  return z.intValue().toString(b) + r;\n}\n\n// (protected) convert from radix string\nfunction bnpFromRadix(s,b) {\n  this.fromInt(0);\n  if(b == null) b = 10;\n  var cs = this.chunkSize(b);\n  var d = Math.pow(b,cs), mi = false, j = 0, w = 0;\n  for(var i = 0; i < s.length; ++i) {\n    var x = intAt(s,i);\n    if(x < 0) {\n      if(s.charAt(i) == \"-\" && this.signum() == 0) mi = true;\n      continue;\n    }\n    w = b*w+x;\n    if(++j >= cs) {\n      this.dMultiply(d);\n      this.dAddOffset(w,0);\n      j = 0;\n      w = 0;\n    }\n  }\n  if(j > 0) {\n    this.dMultiply(Math.pow(b,j));\n    this.dAddOffset(w,0);\n  }\n  if(mi) BigInteger.ZERO.subTo(this,this);\n}\n\n// (protected) alternate constructor\nfunction bnpFromNumber(a,b,c) {\n  if(\"number\" == typeof b) {\n    // new BigInteger(int,int,RNG)\n    if(a < 2) this.fromInt(1);\n    else {\n      this.fromNumber(a,c);\n      if(!this.testBit(a-1))  // force MSB set\n        this.bitwiseTo(BigInteger.ONE.shiftLeft(a-1),op_or,this);\n      if(this.isEven()) this.dAddOffset(1,0); // force odd\n      while(!this.isProbablePrime(b)) {\n        this.dAddOffset(2,0);\n        if(this.bitLength() > a) this.subTo(BigInteger.ONE.shiftLeft(a-1),this);\n      }\n    }\n  }\n  else {\n    // new BigInteger(int,RNG)\n    var x = new Array(), t = a&7;\n    x.length = (a>>3)+1;\n    b.nextBytes(x);\n    if(t > 0) x[0] &= ((1<<t)-1); else x[0] = 0;\n    this.fromString(x,256);\n  }\n}\n\n// (public) convert to bigendian byte array\nfunction bnToByteArray() {\n  var i = this.t, r = new Array();\n  r[0] = this.s;\n  var p = this.DB-(i*this.DB)%8, d, k = 0;\n  if(i-- > 0) {\n    if(p < this.DB && (d = this[i]>>p) != (this.s&this.DM)>>p)\n      r[k++] = d|(this.s<<(this.DB-p));\n    while(i >= 0) {\n      if(p < 8) {\n        d = (this[i]&((1<<p)-1))<<(8-p);\n        d |= this[--i]>>(p+=this.DB-8);\n      }\n      else {\n        d = (this[i]>>(p-=8))&0xff;\n        if(p <= 0) { p += this.DB; --i; }\n      }\n      if((d&0x80) != 0) d |= -256;\n      if(k == 0 && (this.s&0x80) != (d&0x80)) ++k;\n      if(k > 0 || d != this.s) r[k++] = d;\n    }\n  }\n  return r;\n}\n\nfunction bnEquals(a) { return(this.compareTo(a)==0); }\nfunction bnMin(a) { return(this.compareTo(a)<0)?this:a; }\nfunction bnMax(a) { return(this.compareTo(a)>0)?this:a; }\n\n// (protected) r = this op a (bitwise)\nfunction bnpBitwiseTo(a,op,r) {\n  var i, f, m = Math.min(a.t,this.t);\n  for(i = 0; i < m; ++i) r[i] = op(this[i],a[i]);\n  if(a.t < this.t) {\n    f = a.s&this.DM;\n    for(i = m; i < this.t; ++i) r[i] = op(this[i],f);\n    r.t = this.t;\n  }\n  else {\n    f = this.s&this.DM;\n    for(i = m; i < a.t; ++i) r[i] = op(f,a[i]);\n    r.t = a.t;\n  }\n  r.s = op(this.s,a.s);\n  r.clamp();\n}\n\n// (public) this & a\nfunction op_and(x,y) { return x&y; }\nfunction bnAnd(a) { var r = nbi(); this.bitwiseTo(a,op_and,r); return r; }\n\n// (public) this | a\nfunction op_or(x,y) { return x|y; }\nfunction bnOr(a) { var r = nbi(); this.bitwiseTo(a,op_or,r); return r; }\n\n// (public) this ^ a\nfunction op_xor(x,y) { return x^y; }\nfunction bnXor(a) { var r = nbi(); this.bitwiseTo(a,op_xor,r); return r; }\n\n// (public) this & ~a\nfunction op_andnot(x,y) { return x&~y; }\nfunction bnAndNot(a) { var r = nbi(); this.bitwiseTo(a,op_andnot,r); return r; }\n\n// (public) ~this\nfunction bnNot() {\n  var r = nbi();\n  for(var i = 0; i < this.t; ++i) r[i] = this.DM&~this[i];\n  r.t = this.t;\n  r.s = ~this.s;\n  return r;\n}\n\n// (public) this << n\nfunction bnShiftLeft(n) {\n  var r = nbi();\n  if(n < 0) this.rShiftTo(-n,r); else this.lShiftTo(n,r);\n  return r;\n}\n\n// (public) this >> n\nfunction bnShiftRight(n) {\n  var r = nbi();\n  if(n < 0) this.lShiftTo(-n,r); else this.rShiftTo(n,r);\n  return r;\n}\n\n// return index of lowest 1-bit in x, x < 2^31\nfunction lbit(x) {\n  if(x == 0) return -1;\n  var r = 0;\n  if((x&0xffff) == 0) { x >>= 16; r += 16; }\n  if((x&0xff) == 0) { x >>= 8; r += 8; }\n  if((x&0xf) == 0) { x >>= 4; r += 4; }\n  if((x&3) == 0) { x >>= 2; r += 2; }\n  if((x&1) == 0) ++r;\n  return r;\n}\n\n// (public) returns index of lowest 1-bit (or -1 if none)\nfunction bnGetLowestSetBit() {\n  for(var i = 0; i < this.t; ++i)\n    if(this[i] != 0) return i*this.DB+lbit(this[i]);\n  if(this.s < 0) return this.t*this.DB;\n  return -1;\n}\n\n// return number of 1 bits in x\nfunction cbit(x) {\n  var r = 0;\n  while(x != 0) { x &= x-1; ++r; }\n  return r;\n}\n\n// (public) return number of set bits\nfunction bnBitCount() {\n  var r = 0, x = this.s&this.DM;\n  for(var i = 0; i < this.t; ++i) r += cbit(this[i]^x);\n  return r;\n}\n\n// (public) true iff nth bit is set\nfunction bnTestBit(n) {\n  var j = Math.floor(n/this.DB);\n  if(j >= this.t) return(this.s!=0);\n  return((this[j]&(1<<(n%this.DB)))!=0);\n}\n\n// (protected) this op (1<<n)\nfunction bnpChangeBit(n,op) {\n  var r = BigInteger.ONE.shiftLeft(n);\n  this.bitwiseTo(r,op,r);\n  return r;\n}\n\n// (public) this | (1<<n)\nfunction bnSetBit(n) { return this.changeBit(n,op_or); }\n\n// (public) this & ~(1<<n)\nfunction bnClearBit(n) { return this.changeBit(n,op_andnot); }\n\n// (public) this ^ (1<<n)\nfunction bnFlipBit(n) { return this.changeBit(n,op_xor); }\n\n// (protected) r = this + a\nfunction bnpAddTo(a,r) {\n  var i = 0, c = 0, m = Math.min(a.t,this.t);\n  while(i < m) {\n    c += this[i]+a[i];\n    r[i++] = c&this.DM;\n    c >>= this.DB;\n  }\n  if(a.t < this.t) {\n    c += a.s;\n    while(i < this.t) {\n      c += this[i];\n      r[i++] = c&this.DM;\n      c >>= this.DB;\n    }\n    c += this.s;\n  }\n  else {\n    c += this.s;\n    while(i < a.t) {\n      c += a[i];\n      r[i++] = c&this.DM;\n      c >>= this.DB;\n    }\n    c += a.s;\n  }\n  r.s = (c<0)?-1:0;\n  if(c > 0) r[i++] = c;\n  else if(c < -1) r[i++] = this.DV+c;\n  r.t = i;\n  r.clamp();\n}\n\n// (public) this + a\nfunction bnAdd(a) { var r = nbi(); this.addTo(a,r); return r; }\n\n// (public) this - a\nfunction bnSubtract(a) { var r = nbi(); this.subTo(a,r); return r; }\n\n// (public) this * a\nfunction bnMultiply(a) { var r = nbi(); this.multiplyTo(a,r); return r; }\n\n// (public) this^2\nfunction bnSquare() { var r = nbi(); this.squareTo(r); return r; }\n\n// (public) this / a\nfunction bnDivide(a) { var r = nbi(); this.divRemTo(a,r,null); return r; }\n\n// (public) this % a\nfunction bnRemainder(a) { var r = nbi(); this.divRemTo(a,null,r); return r; }\n\n// (public) [this/a,this%a]\nfunction bnDivideAndRemainder(a) {\n  var q = nbi(), r = nbi();\n  this.divRemTo(a,q,r);\n  return new Array(q,r);\n}\n\n// (protected) this *= n, this >= 0, 1 < n < DV\nfunction bnpDMultiply(n) {\n  this[this.t] = this.am(0,n-1,this,0,0,this.t);\n  ++this.t;\n  this.clamp();\n}\n\n// (protected) this += n << w words, this >= 0\nfunction bnpDAddOffset(n,w) {\n  if(n == 0) return;\n  while(this.t <= w) this[this.t++] = 0;\n  this[w] += n;\n  while(this[w] >= this.DV) {\n    this[w] -= this.DV;\n    if(++w >= this.t) this[this.t++] = 0;\n    ++this[w];\n  }\n}\n\n// A \"null\" reducer\nfunction NullExp() {}\nfunction nNop(x) { return x; }\nfunction nMulTo(x,y,r) { x.multiplyTo(y,r); }\nfunction nSqrTo(x,r) { x.squareTo(r); }\n\nNullExp.prototype.convert = nNop;\nNullExp.prototype.revert = nNop;\nNullExp.prototype.mulTo = nMulTo;\nNullExp.prototype.sqrTo = nSqrTo;\n\n// (public) this^e\nfunction bnPow(e) { return this.exp(e,new NullExp()); }\n\n// (protected) r = lower n words of \"this * a\", a.t <= n\n// \"this\" should be the larger one if appropriate.\nfunction bnpMultiplyLowerTo(a,n,r) {\n  var i = Math.min(this.t+a.t,n);\n  r.s = 0; // assumes a,this >= 0\n  r.t = i;\n  while(i > 0) r[--i] = 0;\n  var j;\n  for(j = r.t-this.t; i < j; ++i) r[i+this.t] = this.am(0,a[i],r,i,0,this.t);\n  for(j = Math.min(a.t,n); i < j; ++i) this.am(0,a[i],r,i,0,n-i);\n  r.clamp();\n}\n\n// (protected) r = \"this * a\" without lower n words, n > 0\n// \"this\" should be the larger one if appropriate.\nfunction bnpMultiplyUpperTo(a,n,r) {\n  --n;\n  var i = r.t = this.t+a.t-n;\n  r.s = 0; // assumes a,this >= 0\n  while(--i >= 0) r[i] = 0;\n  for(i = Math.max(n-this.t,0); i < a.t; ++i)\n    r[this.t+i-n] = this.am(n-i,a[i],r,0,0,this.t+i-n);\n  r.clamp();\n  r.drShiftTo(1,r);\n}\n\n// Barrett modular reduction\nfunction Barrett(m) {\n  // setup Barrett\n  this.r2 = nbi();\n  this.q3 = nbi();\n  BigInteger.ONE.dlShiftTo(2*m.t,this.r2);\n  this.mu = this.r2.divide(m);\n  this.m = m;\n}\n\nfunction barrettConvert(x) {\n  if(x.s < 0 || x.t > 2*this.m.t) return x.mod(this.m);\n  else if(x.compareTo(this.m) < 0) return x;\n  else { var r = nbi(); x.copyTo(r); this.reduce(r); return r; }\n}\n\nfunction barrettRevert(x) { return x; }\n\n// x = x mod m (HAC 14.42)\nfunction barrettReduce(x) {\n  x.drShiftTo(this.m.t-1,this.r2);\n  if(x.t > this.m.t+1) { x.t = this.m.t+1; x.clamp(); }\n  this.mu.multiplyUpperTo(this.r2,this.m.t+1,this.q3);\n  this.m.multiplyLowerTo(this.q3,this.m.t+1,this.r2);\n  while(x.compareTo(this.r2) < 0) x.dAddOffset(1,this.m.t+1);\n  x.subTo(this.r2,x);\n  while(x.compareTo(this.m) >= 0) x.subTo(this.m,x);\n}\n\n// r = x^2 mod m; x != r\nfunction barrettSqrTo(x,r) { x.squareTo(r); this.reduce(r); }\n\n// r = x*y mod m; x,y != r\nfunction barrettMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }\n\nBarrett.prototype.convert = barrettConvert;\nBarrett.prototype.revert = barrettRevert;\nBarrett.prototype.reduce = barrettReduce;\nBarrett.prototype.mulTo = barrettMulTo;\nBarrett.prototype.sqrTo = barrettSqrTo;\n\n// (public) this^e % m (HAC 14.85)\nfunction bnModPow(e,m) {\n  var i = e.bitLength(), k, r = nbv(1), z;\n  if(i <= 0) return r;\n  else if(i < 18) k = 1;\n  else if(i < 48) k = 3;\n  else if(i < 144) k = 4;\n  else if(i < 768) k = 5;\n  else k = 6;\n  if(i < 8)\n    z = new Classic(m);\n  else if(m.isEven())\n    z = new Barrett(m);\n  else\n    z = new Montgomery(m);\n\n  // precomputation\n  var g = new Array(), n = 3, k1 = k-1, km = (1<<k)-1;\n  g[1] = z.convert(this);\n  if(k > 1) {\n    var g2 = nbi();\n    z.sqrTo(g[1],g2);\n    while(n <= km) {\n      g[n] = nbi();\n      z.mulTo(g2,g[n-2],g[n]);\n      n += 2;\n    }\n  }\n\n  var j = e.t-1, w, is1 = true, r2 = nbi(), t;\n  i = nbits(e[j])-1;\n  while(j >= 0) {\n    if(i >= k1) w = (e[j]>>(i-k1))&km;\n    else {\n      w = (e[j]&((1<<(i+1))-1))<<(k1-i);\n      if(j > 0) w |= e[j-1]>>(this.DB+i-k1);\n    }\n\n    n = k;\n    while((w&1) == 0) { w >>= 1; --n; }\n    if((i -= n) < 0) { i += this.DB; --j; }\n    if(is1) {  // ret == 1, don't bother squaring or multiplying it\n      g[w].copyTo(r);\n      is1 = false;\n    }\n    else {\n      while(n > 1) { z.sqrTo(r,r2); z.sqrTo(r2,r); n -= 2; }\n      if(n > 0) z.sqrTo(r,r2); else { t = r; r = r2; r2 = t; }\n      z.mulTo(r2,g[w],r);\n    }\n\n    while(j >= 0 && (e[j]&(1<<i)) == 0) {\n      z.sqrTo(r,r2); t = r; r = r2; r2 = t;\n      if(--i < 0) { i = this.DB-1; --j; }\n    }\n  }\n  return z.revert(r);\n}\n\n// (public) gcd(this,a) (HAC 14.54)\nfunction bnGCD(a) {\n  var x = (this.s<0)?this.negate():this.clone();\n  var y = (a.s<0)?a.negate():a.clone();\n  if(x.compareTo(y) < 0) { var t = x; x = y; y = t; }\n  var i = x.getLowestSetBit(), g = y.getLowestSetBit();\n  if(g < 0) return x;\n  if(i < g) g = i;\n  if(g > 0) {\n    x.rShiftTo(g,x);\n    y.rShiftTo(g,y);\n  }\n  while(x.signum() > 0) {\n    if((i = x.getLowestSetBit()) > 0) x.rShiftTo(i,x);\n    if((i = y.getLowestSetBit()) > 0) y.rShiftTo(i,y);\n    if(x.compareTo(y) >= 0) {\n      x.subTo(y,x);\n      x.rShiftTo(1,x);\n    }\n    else {\n      y.subTo(x,y);\n      y.rShiftTo(1,y);\n    }\n  }\n  if(g > 0) y.lShiftTo(g,y);\n  return y;\n}\n\n// (protected) this % n, n < 2^26\nfunction bnpModInt(n) {\n  if(n <= 0) return 0;\n  var d = this.DV%n, r = (this.s<0)?n-1:0;\n  if(this.t > 0)\n    if(d == 0) r = this[0]%n;\n    else for(var i = this.t-1; i >= 0; --i) r = (d*r+this[i])%n;\n  return r;\n}\n\n// (public) 1/this % m (HAC 14.61)\nfunction bnModInverse(m) {\n  var ac = m.isEven();\n  if((this.isEven() && ac) || m.signum() == 0) return BigInteger.ZERO;\n  var u = m.clone(), v = this.clone();\n  var a = nbv(1), b = nbv(0), c = nbv(0), d = nbv(1);\n  while(u.signum() != 0) {\n    while(u.isEven()) {\n      u.rShiftTo(1,u);\n      if(ac) {\n        if(!a.isEven() || !b.isEven()) { a.addTo(this,a); b.subTo(m,b); }\n        a.rShiftTo(1,a);\n      }\n      else if(!b.isEven()) b.subTo(m,b);\n      b.rShiftTo(1,b);\n    }\n    while(v.isEven()) {\n      v.rShiftTo(1,v);\n      if(ac) {\n        if(!c.isEven() || !d.isEven()) { c.addTo(this,c); d.subTo(m,d); }\n        c.rShiftTo(1,c);\n      }\n      else if(!d.isEven()) d.subTo(m,d);\n      d.rShiftTo(1,d);\n    }\n    if(u.compareTo(v) >= 0) {\n      u.subTo(v,u);\n      if(ac) a.subTo(c,a);\n      b.subTo(d,b);\n    }\n    else {\n      v.subTo(u,v);\n      if(ac) c.subTo(a,c);\n      d.subTo(b,d);\n    }\n  }\n  if(v.compareTo(BigInteger.ONE) != 0) return BigInteger.ZERO;\n  if(d.compareTo(m) >= 0) return d.subtract(m);\n  if(d.signum() < 0) d.addTo(m,d); else return d;\n  if(d.signum() < 0) return d.add(m); else return d;\n}\n\nvar lowprimes = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,103,107,109,113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199,211,223,227,229,233,239,241,251,257,263,269,271,277,281,283,293,307,311,313,317,331,337,347,349,353,359,367,373,379,383,389,397,401,409,419,421,431,433,439,443,449,457,461,463,467,479,487,491,499,503,509,521,523,541,547,557,563,569,571,577,587,593,599,601,607,613,617,619,631,641,643,647,653,659,661,673,677,683,691,701,709,719,727,733,739,743,751,757,761,769,773,787,797,809,811,821,823,827,829,839,853,857,859,863,877,881,883,887,907,911,919,929,937,941,947,953,967,971,977,983,991,997];\nvar lplim = (1<<26)/lowprimes[lowprimes.length-1];\n\n// (public) test primality with certainty >= 1-.5^t\nfunction bnIsProbablePrime(t) {\n  var i, x = this.abs();\n  if(x.t == 1 && x[0] <= lowprimes[lowprimes.length-1]) {\n    for(i = 0; i < lowprimes.length; ++i)\n      if(x[0] == lowprimes[i]) return true;\n    return false;\n  }\n  if(x.isEven()) return false;\n  i = 1;\n  while(i < lowprimes.length) {\n    var m = lowprimes[i], j = i+1;\n    while(j < lowprimes.length && m < lplim) m *= lowprimes[j++];\n    m = x.modInt(m);\n    while(i < j) if(m%lowprimes[i++] == 0) return false;\n  }\n  return x.millerRabin(t);\n}\n\n// (protected) true if probably prime (HAC 4.24, Miller-Rabin)\nfunction bnpMillerRabin(t) {\n  var n1 = this.subtract(BigInteger.ONE);\n  var k = n1.getLowestSetBit();\n  if(k <= 0) return false;\n  var r = n1.shiftRight(k);\n  t = (t+1)>>1;\n  if(t > lowprimes.length) t = lowprimes.length;\n  var a = nbi();\n  for(var i = 0; i < t; ++i) {\n    //Pick bases at random, instead of starting at 2\n    a.fromInt(lowprimes[Math.floor(Math.random()*lowprimes.length)]);\n    var y = a.modPow(r,this);\n    if(y.compareTo(BigInteger.ONE) != 0 && y.compareTo(n1) != 0) {\n      var j = 1;\n      while(j++ < k && y.compareTo(n1) != 0) {\n        y = y.modPowInt(2,this);\n        if(y.compareTo(BigInteger.ONE) == 0) return false;\n      }\n      if(y.compareTo(n1) != 0) return false;\n    }\n  }\n  return true;\n}\n\n// protected\nBigInteger.prototype.chunkSize = bnpChunkSize;\nBigInteger.prototype.toRadix = bnpToRadix;\nBigInteger.prototype.fromRadix = bnpFromRadix;\nBigInteger.prototype.fromNumber = bnpFromNumber;\nBigInteger.prototype.bitwiseTo = bnpBitwiseTo;\nBigInteger.prototype.changeBit = bnpChangeBit;\nBigInteger.prototype.addTo = bnpAddTo;\nBigInteger.prototype.dMultiply = bnpDMultiply;\nBigInteger.prototype.dAddOffset = bnpDAddOffset;\nBigInteger.prototype.multiplyLowerTo = bnpMultiplyLowerTo;\nBigInteger.prototype.multiplyUpperTo = bnpMultiplyUpperTo;\nBigInteger.prototype.modInt = bnpModInt;\nBigInteger.prototype.millerRabin = bnpMillerRabin;\n\n// public\nBigInteger.prototype.clone = bnClone;\nBigInteger.prototype.intValue = bnIntValue;\nBigInteger.prototype.byteValue = bnByteValue;\nBigInteger.prototype.shortValue = bnShortValue;\nBigInteger.prototype.signum = bnSigNum;\nBigInteger.prototype.toByteArray = bnToByteArray;\nBigInteger.prototype.equals = bnEquals;\nBigInteger.prototype.min = bnMin;\nBigInteger.prototype.max = bnMax;\nBigInteger.prototype.and = bnAnd;\nBigInteger.prototype.or = bnOr;\nBigInteger.prototype.xor = bnXor;\nBigInteger.prototype.andNot = bnAndNot;\nBigInteger.prototype.not = bnNot;\nBigInteger.prototype.shiftLeft = bnShiftLeft;\nBigInteger.prototype.shiftRight = bnShiftRight;\nBigInteger.prototype.getLowestSetBit = bnGetLowestSetBit;\nBigInteger.prototype.bitCount = bnBitCount;\nBigInteger.prototype.testBit = bnTestBit;\nBigInteger.prototype.setBit = bnSetBit;\nBigInteger.prototype.clearBit = bnClearBit;\nBigInteger.prototype.flipBit = bnFlipBit;\nBigInteger.prototype.add = bnAdd;\nBigInteger.prototype.subtract = bnSubtract;\nBigInteger.prototype.multiply = bnMultiply;\nBigInteger.prototype.divide = bnDivide;\nBigInteger.prototype.remainder = bnRemainder;\nBigInteger.prototype.divideAndRemainder = bnDivideAndRemainder;\nBigInteger.prototype.modPow = bnModPow;\nBigInteger.prototype.modInverse = bnModInverse;\nBigInteger.prototype.pow = bnPow;\nBigInteger.prototype.gcd = bnGCD;\nBigInteger.prototype.isProbablePrime = bnIsProbablePrime;\n\n// JSBN-specific extension\nBigInteger.prototype.square = bnSquare;\n\n// Expose the Barrett function\nBigInteger.prototype.Barrett = Barrett\n\n// BigInteger interfaces not implemented in jsbn:\n\n// BigInteger(int signum, byte[] magnitude)\n// double doubleValue()\n// float floatValue()\n// int hashCode()\n// long longValue()\n// static BigInteger valueOf(long val)\n\nmodule.exports = BigInteger;\n\n\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/lib/jsbn.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/lib/keyParser.js":
/*!****************************************************!*\
  !*** ./node_modules/ssh2-streams/lib/keyParser.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// TODO:\n//    * utilize `crypto.create(Private|Public)Key()` and `keyObject.export()`\n//    * handle multi-line header values (OpenSSH)?\n//    * more thorough validation?\n\nvar crypto = __webpack_require__(/*! crypto */ \"crypto\");\nvar cryptoSign = crypto.sign;\nvar cryptoVerify = crypto.verify;\nvar createSign = crypto.createSign;\nvar createVerify = crypto.createVerify;\nvar createDecipheriv = crypto.createDecipheriv;\nvar createHash = crypto.createHash;\nvar createHmac = crypto.createHmac;\nvar supportedOpenSSLCiphers = crypto.getCiphers();\n\nvar utils;\nvar Ber = __webpack_require__(/*! asn1 */ \"./node_modules/asn1/lib/index.js\").Ber;\nvar bcrypt_pbkdf = __webpack_require__(/*! bcrypt-pbkdf */ \"./node_modules/bcrypt-pbkdf/index.js\").pbkdf;\n\nvar bufferHelpers = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2-streams/lib/buffer-helpers.js\");\nvar readUInt32BE = bufferHelpers.readUInt32BE;\nvar writeUInt32BE = bufferHelpers.writeUInt32BE;\nvar constants = __webpack_require__(/*! ./constants */ \"./node_modules/ssh2-streams/lib/constants.js\");\nvar SUPPORTED_CIPHER = constants.ALGORITHMS.SUPPORTED_CIPHER;\nvar CIPHER_INFO = constants.CIPHER_INFO;\nvar SSH_TO_OPENSSL = constants.SSH_TO_OPENSSL;\nvar EDDSA_SUPPORTED = constants.EDDSA_SUPPORTED;\n\nvar SYM_HASH_ALGO = Symbol('Hash Algorithm');\nvar SYM_PRIV_PEM = Symbol('Private key PEM');\nvar SYM_PUB_PEM = Symbol('Public key PEM');\nvar SYM_PUB_SSH = Symbol('Public key SSH');\nvar SYM_DECRYPTED = Symbol('Decrypted Key');\n\n// Create OpenSSL cipher name -> SSH cipher name conversion table\nvar CIPHER_INFO_OPENSSL = Object.create(null);\n(function() {\n  var keys = Object.keys(CIPHER_INFO);\n  for (var i = 0; i < keys.length; ++i) {\n    var cipherName = SSH_TO_OPENSSL[keys[i]];\n    if (!cipherName || CIPHER_INFO_OPENSSL[cipherName])\n      continue;\n    CIPHER_INFO_OPENSSL[cipherName] = CIPHER_INFO[keys[i]];\n  }\n})();\n\nvar trimStart = (function() {\n  if (typeof String.prototype.trimStart === 'function') {\n    return function trimStart(str) {\n      return str.trimStart();\n    };\n  }\n\n  return function trimStart(str) {\n    var start = 0;\n    for (var i = 0; i < str.length; ++i) {\n      switch (str.charCodeAt(i)) {\n        case 32: // ' '\n        case 9: // '\\t'\n        case 13: // '\\r'\n        case 10: // '\\n'\n        case 12: // '\\f'\n          ++start;\n          continue;\n      }\n      break;\n    }\n    if (start === 0)\n      return str;\n    return str.slice(start);\n  };\n})();\n\nfunction makePEM(type, data) {\n  data = data.toString('base64');\n  return '-----BEGIN ' + type + ' KEY-----\\n'\n         + data.replace(/.{64}/g, '$&\\n')\n         + (data.length % 64 ? '\\n' : '')\n         + '-----END ' + type + ' KEY-----';\n}\n\nfunction combineBuffers(buf1, buf2) {\n  var result = Buffer.allocUnsafe(buf1.length + buf2.length);\n  buf1.copy(result, 0);\n  buf2.copy(result, buf1.length);\n  return result;\n}\n\nfunction skipFields(buf, nfields) {\n  var bufLen = buf.length;\n  var pos = (buf._pos || 0);\n  for (var i = 0; i < nfields; ++i) {\n    var left = (bufLen - pos);\n    if (pos >= bufLen || left < 4)\n      return false;\n    var len = readUInt32BE(buf, pos);\n    if (left < 4 + len)\n      return false;\n    pos += 4 + len;\n  }\n  buf._pos = pos;\n  return true;\n}\n\nfunction genOpenSSLRSAPub(n, e) {\n  var asnWriter = new Ber.Writer();\n  asnWriter.startSequence();\n    // algorithm\n    asnWriter.startSequence();\n      asnWriter.writeOID('1.2.840.113549.1.1.1'); // rsaEncryption\n      // algorithm parameters (RSA has none)\n      asnWriter.writeNull();\n    asnWriter.endSequence();\n\n    // subjectPublicKey\n    asnWriter.startSequence(Ber.BitString);\n      asnWriter.writeByte(0x00);\n      asnWriter.startSequence();\n        asnWriter.writeBuffer(n, Ber.Integer);\n        asnWriter.writeBuffer(e, Ber.Integer);\n      asnWriter.endSequence();\n    asnWriter.endSequence();\n  asnWriter.endSequence();\n  return makePEM('PUBLIC', asnWriter.buffer);\n}\n\nfunction genOpenSSHRSAPub(n, e) {\n  var publicKey = Buffer.allocUnsafe(4 + 7 // \"ssh-rsa\"\n                                     + 4 + n.length\n                                     + 4 + e.length);\n\n  writeUInt32BE(publicKey, 7, 0);\n  publicKey.write('ssh-rsa', 4, 7, 'ascii');\n\n  var i = 4 + 7;\n  writeUInt32BE(publicKey, e.length, i);\n  e.copy(publicKey, i += 4);\n\n  writeUInt32BE(publicKey, n.length, i += e.length);\n  n.copy(publicKey, i + 4);\n\n  return publicKey;\n}\n\nvar genOpenSSLRSAPriv = (function() {\n  function genRSAASN1Buf(n, e, d, p, q, dmp1, dmq1, iqmp) {\n    var asnWriter = new Ber.Writer();\n    asnWriter.startSequence();\n      asnWriter.writeInt(0x00, Ber.Integer);\n      asnWriter.writeBuffer(n, Ber.Integer);\n      asnWriter.writeBuffer(e, Ber.Integer);\n      asnWriter.writeBuffer(d, Ber.Integer);\n      asnWriter.writeBuffer(p, Ber.Integer);\n      asnWriter.writeBuffer(q, Ber.Integer);\n      asnWriter.writeBuffer(dmp1, Ber.Integer);\n      asnWriter.writeBuffer(dmq1, Ber.Integer);\n      asnWriter.writeBuffer(iqmp, Ber.Integer);\n    asnWriter.endSequence();\n    return asnWriter.buffer;\n  }\n\n  function bigIntFromBuffer(buf) {\n    return BigInt('0x' + buf.toString('hex'));\n  }\n\n  function bigIntToBuffer(bn) {\n    var hex = bn.toString(16);\n    if ((hex.length & 1) !== 0) {\n      hex = '0' + hex;\n    } else {\n      var sigbit = hex.charCodeAt(0);\n      // BER/DER integers require leading zero byte to denote a positive value\n      // when first byte >= 0x80\n      if (sigbit === 56 || (sigbit >= 97 && sigbit <= 102))\n        hex = '00' + hex;\n    }\n    return Buffer.from(hex, 'hex');\n  }\n\n  // Feature detect native BigInt availability and use it when possible\n  try {\n    var code = [\n      'return function genOpenSSLRSAPriv(n, e, d, iqmp, p, q) {',\n      '  var bn_d = bigIntFromBuffer(d);',\n      '  var dmp1 = bigIntToBuffer(bn_d % (bigIntFromBuffer(p) - 1n));',\n      '  var dmq1 = bigIntToBuffer(bn_d % (bigIntFromBuffer(q) - 1n));',\n      '  return makePEM(\\'RSA PRIVATE\\', '\n        + 'genRSAASN1Buf(n, e, d, p, q, dmp1, dmq1, iqmp));',\n      '};'\n    ].join('\\n');\n    return new Function(\n      'bigIntFromBuffer, bigIntToBuffer, makePEM, genRSAASN1Buf',\n      code\n    )(bigIntFromBuffer, bigIntToBuffer, makePEM, genRSAASN1Buf);\n  } catch (ex) {\n    return (function() {\n      var BigInteger = __webpack_require__(/*! ./jsbn.js */ \"./node_modules/ssh2-streams/lib/jsbn.js\");\n      return function genOpenSSLRSAPriv(n, e, d, iqmp, p, q) {\n        var pbi = new BigInteger(p, 256);\n        var qbi = new BigInteger(q, 256);\n        var dbi = new BigInteger(d, 256);\n        var dmp1bi = dbi.mod(pbi.subtract(BigInteger.ONE));\n        var dmq1bi = dbi.mod(qbi.subtract(BigInteger.ONE));\n        var dmp1 = Buffer.from(dmp1bi.toByteArray());\n        var dmq1 = Buffer.from(dmq1bi.toByteArray());\n        return makePEM('RSA PRIVATE',\n                       genRSAASN1Buf(n, e, d, p, q, dmp1, dmq1, iqmp));\n      };\n    })();\n  }\n})();\n\nfunction genOpenSSLDSAPub(p, q, g, y) {\n  var asnWriter = new Ber.Writer();\n  asnWriter.startSequence();\n    // algorithm\n    asnWriter.startSequence();\n      asnWriter.writeOID('1.2.840.10040.4.1'); // id-dsa\n      // algorithm parameters\n      asnWriter.startSequence();\n        asnWriter.writeBuffer(p, Ber.Integer);\n        asnWriter.writeBuffer(q, Ber.Integer);\n        asnWriter.writeBuffer(g, Ber.Integer);\n      asnWriter.endSequence();\n    asnWriter.endSequence();\n\n    // subjectPublicKey\n    asnWriter.startSequence(Ber.BitString);\n      asnWriter.writeByte(0x00);\n      asnWriter.writeBuffer(y, Ber.Integer);\n    asnWriter.endSequence();\n  asnWriter.endSequence();\n  return makePEM('PUBLIC', asnWriter.buffer);\n}\n\nfunction genOpenSSHDSAPub(p, q, g, y) {\n  var publicKey = Buffer.allocUnsafe(4 + 7 // ssh-dss\n                                     + 4 + p.length\n                                     + 4 + q.length\n                                     + 4 + g.length\n                                     + 4 + y.length);\n\n  writeUInt32BE(publicKey, 7, 0);\n  publicKey.write('ssh-dss', 4, 7, 'ascii');\n\n  var i = 4 + 7;\n  writeUInt32BE(publicKey, p.length, i);\n  p.copy(publicKey, i += 4);\n\n  writeUInt32BE(publicKey, q.length, i += p.length);\n  q.copy(publicKey, i += 4);\n\n  writeUInt32BE(publicKey, g.length, i += q.length);\n  g.copy(publicKey, i += 4);\n\n  writeUInt32BE(publicKey, y.length, i += g.length);\n  y.copy(publicKey, i + 4);\n\n  return publicKey;\n}\n\nfunction genOpenSSLDSAPriv(p, q, g, y, x) {\n  var asnWriter = new Ber.Writer();\n  asnWriter.startSequence();\n    asnWriter.writeInt(0x00, Ber.Integer);\n    asnWriter.writeBuffer(p, Ber.Integer);\n    asnWriter.writeBuffer(q, Ber.Integer);\n    asnWriter.writeBuffer(g, Ber.Integer);\n    asnWriter.writeBuffer(y, Ber.Integer);\n    asnWriter.writeBuffer(x, Ber.Integer);\n  asnWriter.endSequence();\n  return makePEM('DSA PRIVATE', asnWriter.buffer);\n}\n\nfunction genOpenSSLEdPub(pub) {\n  var asnWriter = new Ber.Writer();\n  asnWriter.startSequence();\n    // algorithm\n    asnWriter.startSequence();\n      asnWriter.writeOID('1.3.101.112'); // id-Ed25519\n    asnWriter.endSequence();\n\n    // PublicKey\n    asnWriter.writeBuffer(pub, Ber.BitString);\n  asnWriter.endSequence();\n  return makePEM('PUBLIC', asnWriter.buffer);\n}\n\nfunction genOpenSSHEdPub(pub) {\n  var publicKey = Buffer.allocUnsafe(4 + 11 // ssh-ed25519\n                                     + 4 + pub.length);\n\n  writeUInt32BE(publicKey, 11, 0);\n  publicKey.write('ssh-ed25519', 4, 11, 'ascii');\n\n  writeUInt32BE(publicKey, pub.length, 15);\n  pub.copy(publicKey, 19);\n\n  return publicKey;\n}\n\nfunction genOpenSSLEdPriv(priv) {\n  var asnWriter = new Ber.Writer();\n  asnWriter.startSequence();\n    // version\n    asnWriter.writeInt(0x00, Ber.Integer);\n\n    // algorithm\n    asnWriter.startSequence();\n      asnWriter.writeOID('1.3.101.112'); // id-Ed25519\n    asnWriter.endSequence();\n\n    // PrivateKey\n    asnWriter.startSequence(Ber.OctetString);\n      asnWriter.writeBuffer(priv, Ber.OctetString);\n    asnWriter.endSequence();\n  asnWriter.endSequence();\n  return makePEM('PRIVATE', asnWriter.buffer);\n}\n\nfunction genOpenSSLECDSAPub(oid, Q) {\n  var asnWriter = new Ber.Writer();\n  asnWriter.startSequence();\n    // algorithm\n    asnWriter.startSequence();\n      asnWriter.writeOID('1.2.840.10045.2.1'); // id-ecPublicKey\n      // algorithm parameters (namedCurve)\n      asnWriter.writeOID(oid);\n    asnWriter.endSequence();\n\n    // subjectPublicKey\n    asnWriter.startSequence(Ber.BitString);\n      asnWriter.writeByte(0x00);\n      // XXX: hack to write a raw buffer without a tag -- yuck\n      asnWriter._ensure(Q.length);\n      Q.copy(asnWriter._buf, asnWriter._offset, 0, Q.length);\n      asnWriter._offset += Q.length;\n      // end hack\n    asnWriter.endSequence();\n  asnWriter.endSequence();\n  return makePEM('PUBLIC', asnWriter.buffer);\n}\n\nfunction genOpenSSHECDSAPub(oid, Q) {\n  var curveName;\n  switch (oid) {\n    case '1.2.840.10045.3.1.7':\n      // prime256v1/secp256r1\n      curveName = 'nistp256';\n      break;\n    case '1.3.132.0.34':\n      // secp384r1\n      curveName = 'nistp384';\n      break;\n    case '1.3.132.0.35':\n      // secp521r1\n      curveName = 'nistp521';\n      break;\n    default:\n      return;\n  }\n\n  var publicKey = Buffer.allocUnsafe(4 + 19 // ecdsa-sha2-<curve name>\n                                     + 4 + 8 // <curve name>\n                                     + 4 + Q.length);\n\n  writeUInt32BE(publicKey, 19, 0);\n  publicKey.write('ecdsa-sha2-' + curveName, 4, 19, 'ascii');\n\n  writeUInt32BE(publicKey, 8, 23);\n  publicKey.write(curveName, 27, 8, 'ascii');\n\n  writeUInt32BE(publicKey, Q.length, 35);\n  Q.copy(publicKey, 39);\n\n  return publicKey;\n}\n\nfunction genOpenSSLECDSAPriv(oid, pub, priv) {\n  var asnWriter = new Ber.Writer();\n  asnWriter.startSequence();\n    // version\n    asnWriter.writeInt(0x01, Ber.Integer);\n    // privateKey\n    asnWriter.writeBuffer(priv, Ber.OctetString);\n    // parameters (optional)\n    asnWriter.startSequence(0xA0);\n      asnWriter.writeOID(oid);\n    asnWriter.endSequence();\n    // publicKey (optional)\n    asnWriter.startSequence(0xA1);\n      asnWriter.startSequence(Ber.BitString);\n        asnWriter.writeByte(0x00);\n        // XXX: hack to write a raw buffer without a tag -- yuck\n        asnWriter._ensure(pub.length);\n        pub.copy(asnWriter._buf, asnWriter._offset, 0, pub.length);\n        asnWriter._offset += pub.length;\n        // end hack\n      asnWriter.endSequence();\n    asnWriter.endSequence();\n  asnWriter.endSequence();\n  return makePEM('EC PRIVATE', asnWriter.buffer);\n}\n\nfunction genOpenSSLECDSAPubFromPriv(curveName, priv) {\n  var tempECDH = crypto.createECDH(curveName);\n  tempECDH.setPrivateKey(priv);\n  return tempECDH.getPublicKey();\n}\n\nvar baseKeySign = (function() {\n  if (typeof cryptoSign === 'function') {\n    return function sign(data) {\n      var pem = this[SYM_PRIV_PEM];\n      if (pem === null)\n        return new Error('No private key available');\n      try {\n        return cryptoSign(this[SYM_HASH_ALGO], data, pem);\n      } catch (ex) {\n        return ex;\n      }\n    };\n  } else {\n    function trySign(signature, privKey) {\n      try {\n        return signature.sign(privKey);\n      } catch (ex) {\n        return ex;\n      }\n    }\n\n    return function sign(data) {\n      var pem = this[SYM_PRIV_PEM];\n      if (pem === null)\n        return new Error('No private key available');\n      var signature = createSign(this[SYM_HASH_ALGO]);\n      signature.update(data);\n      return trySign(signature, pem);\n    };\n  }\n})();\n\nvar baseKeyVerify = (function() {\n  if (typeof cryptoVerify === 'function') {\n    return function verify(data, signature) {\n      var pem = this[SYM_PUB_PEM];\n      if (pem === null)\n        return new Error('No public key available');\n      try {\n        return cryptoVerify(this[SYM_HASH_ALGO], data, pem, signature);\n      } catch (ex) {\n        return ex;\n      }\n    };\n  } else {\n    function tryVerify(verifier, pubKey, signature) {\n      try {\n        return verifier.verify(pubKey, signature);\n      } catch (ex) {\n        return ex;\n      }\n    }\n\n    return function verify(data, signature) {\n      var pem = this[SYM_PUB_PEM];\n      if (pem === null)\n        return new Error('No public key available');\n      var verifier = createVerify(this[SYM_HASH_ALGO]);\n      verifier.update(data);\n      return tryVerify(verifier, pem, signature);\n    };\n  }\n})();\n\nvar BaseKey = {\n  sign: baseKeySign,\n  verify: baseKeyVerify,\n  getPrivatePEM: function getPrivatePEM() {\n    return this[SYM_PRIV_PEM];\n  },\n  getPublicPEM: function getPublicPEM() {\n    return this[SYM_PUB_PEM];\n  },\n  getPublicSSH: function getPublicSSH() {\n    return this[SYM_PUB_SSH];\n  },\n};\n\n\n\nfunction OpenSSH_Private(type, comment, privPEM, pubPEM, pubSSH, algo, decrypted) {\n  this.type = type;\n  this.comment = comment;\n  this[SYM_PRIV_PEM] = privPEM;\n  this[SYM_PUB_PEM] = pubPEM;\n  this[SYM_PUB_SSH] = pubSSH;\n  this[SYM_HASH_ALGO] = algo;\n  this[SYM_DECRYPTED] = decrypted;\n}\nOpenSSH_Private.prototype = BaseKey;\n(function() {\n  var regexp = /^-----BEGIN OPENSSH PRIVATE KEY-----(?:\\r\\n|\\n)([\\s\\S]+)(?:\\r\\n|\\n)-----END OPENSSH PRIVATE KEY-----$/;\n  OpenSSH_Private.parse = function(str, passphrase) {\n    var m = regexp.exec(str);\n    if (m === null)\n      return null;\n    var ret;\n    var data = Buffer.from(m[1], 'base64');\n    if (data.length < 31) // magic (+ magic null term.) + minimum field lengths\n      return new Error('Malformed OpenSSH private key');\n    var magic = data.toString('ascii', 0, 15);\n    if (magic !== 'openssh-key-v1\\0')\n      return new Error('Unsupported OpenSSH key magic: ' + magic);\n\n    // avoid cyclic require by requiring on first use\n    if (!utils)\n      utils = __webpack_require__(/*! ./utils */ \"./node_modules/ssh2-streams/lib/utils.js\");\n\n    var cipherName = utils.readString(data, 15, 'ascii');\n    if (cipherName === false)\n      return new Error('Malformed OpenSSH private key');\n    if (cipherName !== 'none' && SUPPORTED_CIPHER.indexOf(cipherName) === -1)\n      return new Error('Unsupported cipher for OpenSSH key: ' + cipherName);\n\n    var kdfName = utils.readString(data, data._pos, 'ascii');\n    if (kdfName === false)\n      return new Error('Malformed OpenSSH private key');\n    if (kdfName !== 'none') {\n      if (cipherName === 'none')\n        return new Error('Malformed OpenSSH private key');\n      if (kdfName !== 'bcrypt')\n        return new Error('Unsupported kdf name for OpenSSH key: ' + kdfName);\n      if (!passphrase) {\n        return new Error(\n          'Encrypted private OpenSSH key detected, but no passphrase given'\n        );\n      }\n    } else if (cipherName !== 'none') {\n      return new Error('Malformed OpenSSH private key');\n    }\n\n    var encInfo;\n    var cipherKey;\n    var cipherIV;\n    if (cipherName !== 'none')\n      encInfo = CIPHER_INFO[cipherName];\n    var kdfOptions = utils.readString(data, data._pos);\n    if (kdfOptions === false)\n      return new Error('Malformed OpenSSH private key');\n    if (kdfOptions.length) {\n      switch (kdfName) {\n        case 'none':\n          return new Error('Malformed OpenSSH private key');\n        case 'bcrypt':\n          /*\n            string salt\n            uint32 rounds\n          */\n          var salt = utils.readString(kdfOptions, 0);\n          if (salt === false || kdfOptions._pos + 4 > kdfOptions.length)\n            return new Error('Malformed OpenSSH private key');\n          var rounds = readUInt32BE(kdfOptions, kdfOptions._pos);\n          var gen = Buffer.allocUnsafe(encInfo.keyLen + encInfo.ivLen);\n          var r = bcrypt_pbkdf(passphrase,\n                               passphrase.length,\n                               salt,\n                               salt.length,\n                               gen,\n                               gen.length,\n                               rounds);\n          if (r !== 0)\n            return new Error('Failed to generate information to decrypt key');\n          cipherKey = gen.slice(0, encInfo.keyLen);\n          cipherIV = gen.slice(encInfo.keyLen);\n          break;\n      }\n    } else if (kdfName !== 'none') {\n      return new Error('Malformed OpenSSH private key');\n    }\n\n    var keyCount = utils.readInt(data, data._pos);\n    if (keyCount === false)\n      return new Error('Malformed OpenSSH private key');\n    data._pos += 4;\n\n    if (keyCount > 0) {\n      // TODO: place sensible limit on max `keyCount`\n\n      // Read public keys first\n      for (var i = 0; i < keyCount; ++i) {\n        var pubData = utils.readString(data, data._pos);\n        if (pubData === false)\n          return new Error('Malformed OpenSSH private key');\n        var type = utils.readString(pubData, 0, 'ascii');\n        if (type === false)\n          return new Error('Malformed OpenSSH private key');\n      }\n\n      var privBlob = utils.readString(data, data._pos);\n      if (privBlob === false)\n        return new Error('Malformed OpenSSH private key');\n\n      if (cipherKey !== undefined) {\n        // encrypted private key(s)\n        if (privBlob.length < encInfo.blockLen\n            || (privBlob.length % encInfo.blockLen) !== 0) {\n          return new Error('Malformed OpenSSH private key');\n        }\n        try {\n          var options = { authTagLength: encInfo.authLen };\n          var decipher = createDecipheriv(SSH_TO_OPENSSL[cipherName],\n                                          cipherKey,\n                                          cipherIV,\n                                          options);\n          if (encInfo.authLen > 0) {\n            if (data.length - data._pos < encInfo.authLen)\n              return new Error('Malformed OpenSSH private key');\n            decipher.setAuthTag(\n              data.slice(data._pos, data._pos += encInfo.authLen)\n            );\n          }\n          privBlob = combineBuffers(decipher.update(privBlob),\n                                    decipher.final());\n        } catch (ex) {\n          return ex;\n        }\n      }\n      // Nothing should we follow the private key(s), except a possible\n      // authentication tag for relevant ciphers\n      if (data._pos !== data.length)\n        return new Error('Malformed OpenSSH private key');\n\n      ret = parseOpenSSHPrivKeys(privBlob, keyCount, cipherKey !== undefined);\n    } else {\n      ret = [];\n    }\n    return ret;\n  };\n\n  function parseOpenSSHPrivKeys(data, nkeys, decrypted) {\n    var keys = [];\n    /*\n      uint32\tcheckint\n      uint32\tcheckint\n      string\tprivatekey1\n      string\tcomment1\n      string\tprivatekey2\n      string\tcomment2\n      ...\n      string\tprivatekeyN\n      string\tcommentN\n      char\t1\n      char\t2\n      char\t3\n      ...\n      char\tpadlen % 255\n    */\n    if (data.length < 8)\n      return new Error('Malformed OpenSSH private key');\n    var check1 = readUInt32BE(data, 0);\n    var check2 = readUInt32BE(data, 4);\n    if (check1 !== check2) {\n      if (decrypted)\n        return new Error('OpenSSH key integrity check failed -- bad passphrase?');\n      return new Error('OpenSSH key integrity check failed');\n    }\n    data._pos = 8;\n    var i;\n    var oid;\n    for (i = 0; i < nkeys; ++i) {\n      var algo = undefined;\n      var privPEM = undefined;\n      var pubPEM = undefined;\n      var pubSSH = undefined;\n      // The OpenSSH documentation for the key format actually lies, the entirety\n      // of the private key content is not contained with a string field, it's\n      // actually the literal contents of the private key, so to be able to find\n      // the end of the key data you need to know the layout/format of each key\n      // type ...\n      var type = utils.readString(data, data._pos, 'ascii');\n      if (type === false)\n        return new Error('Malformed OpenSSH private key');\n\n      switch (type) {\n        case 'ssh-rsa':\n          /*\n            string  n -- public\n            string  e -- public\n            string  d -- private\n            string  iqmp -- private\n            string  p -- private\n            string  q -- private\n          */\n          var n = utils.readString(data, data._pos);\n          if (n === false)\n            return new Error('Malformed OpenSSH private key');\n          var e = utils.readString(data, data._pos);\n          if (e === false)\n            return new Error('Malformed OpenSSH private key');\n          var d = utils.readString(data, data._pos);\n          if (d === false)\n            return new Error('Malformed OpenSSH private key');\n          var iqmp = utils.readString(data, data._pos);\n          if (iqmp === false)\n            return new Error('Malformed OpenSSH private key');\n          var p = utils.readString(data, data._pos);\n          if (p === false)\n            return new Error('Malformed OpenSSH private key');\n          var q = utils.readString(data, data._pos);\n          if (q === false)\n            return new Error('Malformed OpenSSH private key');\n\n          pubPEM = genOpenSSLRSAPub(n, e);\n          pubSSH = genOpenSSHRSAPub(n, e);\n          privPEM = genOpenSSLRSAPriv(n, e, d, iqmp, p, q);\n          algo = 'sha1';\n          break;\n        case 'ssh-dss':\n          /*\n            string  p -- public\n            string  q -- public\n            string  g -- public\n            string  y -- public\n            string  x -- private\n          */\n          var p = utils.readString(data, data._pos);\n          if (p === false)\n            return new Error('Malformed OpenSSH private key');\n          var q = utils.readString(data, data._pos);\n          if (q === false)\n            return new Error('Malformed OpenSSH private key');\n          var g = utils.readString(data, data._pos);\n          if (g === false)\n            return new Error('Malformed OpenSSH private key');\n          var y = utils.readString(data, data._pos);\n          if (y === false)\n            return new Error('Malformed OpenSSH private key');\n          var x = utils.readString(data, data._pos);\n          if (x === false)\n            return new Error('Malformed OpenSSH private key');\n\n          pubPEM = genOpenSSLDSAPub(p, q, g, y);\n          pubSSH = genOpenSSHDSAPub(p, q, g, y);\n          privPEM = genOpenSSLDSAPriv(p, q, g, y, x);\n          algo = 'sha1';\n          break;\n        case 'ssh-ed25519':\n          if (!EDDSA_SUPPORTED)\n            return new Error('Unsupported OpenSSH private key type: ' + type);\n          /*\n            * string  public key\n            * string  private key + public key\n          */\n          var edpub = utils.readString(data, data._pos);\n          if (edpub === false || edpub.length !== 32)\n            return new Error('Malformed OpenSSH private key');\n          var edpriv = utils.readString(data, data._pos);\n          if (edpriv === false || edpriv.length !== 64)\n            return new Error('Malformed OpenSSH private key');\n\n          pubPEM = genOpenSSLEdPub(edpub);\n          pubSSH = genOpenSSHEdPub(edpub);\n          privPEM = genOpenSSLEdPriv(edpriv.slice(0, 32));\n          algo = null;\n          break;\n        case 'ecdsa-sha2-nistp256':\n          algo = 'sha256';\n          oid = '1.2.840.10045.3.1.7';\n        case 'ecdsa-sha2-nistp384':\n          if (algo === undefined) {\n            algo = 'sha384';\n            oid = '1.3.132.0.34';\n          }\n        case 'ecdsa-sha2-nistp521':\n          if (algo === undefined) {\n            algo = 'sha512';\n            oid = '1.3.132.0.35';\n          }\n          /*\n            string  curve name\n            string  Q -- public\n            string  d -- private\n          */\n          // TODO: validate curve name against type\n          if (!skipFields(data, 1)) // Skip curve name\n            return new Error('Malformed OpenSSH private key');\n          var ecpub = utils.readString(data, data._pos);\n          if (ecpub === false)\n            return new Error('Malformed OpenSSH private key');\n          var ecpriv = utils.readString(data, data._pos);\n          if (ecpriv === false)\n            return new Error('Malformed OpenSSH private key');\n\n          pubPEM = genOpenSSLECDSAPub(oid, ecpub);\n          pubSSH = genOpenSSHECDSAPub(oid, ecpub);\n          privPEM = genOpenSSLECDSAPriv(oid, ecpub, ecpriv);\n          break;\n        default:\n          return new Error('Unsupported OpenSSH private key type: ' + type);\n      }\n\n      var privComment = utils.readString(data, data._pos, 'utf8');\n      if (privComment === false)\n        return new Error('Malformed OpenSSH private key');\n\n      keys.push(\n        new OpenSSH_Private(type, privComment, privPEM, pubPEM, pubSSH, algo,\n                            decrypted)\n      );\n    }\n    var cnt = 0;\n    for (i = data._pos; i < data.length; ++i) {\n      if (data[i] !== (++cnt % 255))\n        return new Error('Malformed OpenSSH private key');\n    }\n\n    return keys;\n  }\n})();\n\n\n\nfunction OpenSSH_Old_Private(type, comment, privPEM, pubPEM, pubSSH, algo, decrypted) {\n  this.type = type;\n  this.comment = comment;\n  this[SYM_PRIV_PEM] = privPEM;\n  this[SYM_PUB_PEM] = pubPEM;\n  this[SYM_PUB_SSH] = pubSSH;\n  this[SYM_HASH_ALGO] = algo;\n  this[SYM_DECRYPTED] = decrypted;\n}\nOpenSSH_Old_Private.prototype = BaseKey;\n(function() {\n  var regexp = /^-----BEGIN (RSA|DSA|EC) PRIVATE KEY-----(?:\\r\\n|\\n)((?:[^:]+:\\s*[\\S].*(?:\\r\\n|\\n))*)([\\s\\S]+)(?:\\r\\n|\\n)-----END (RSA|DSA|EC) PRIVATE KEY-----$/;\n  OpenSSH_Old_Private.parse = function(str, passphrase) {\n    var m = regexp.exec(str);\n    if (m === null)\n      return null;\n    var privBlob = Buffer.from(m[3], 'base64');\n    var headers = m[2];\n    var decrypted = false;\n    if (headers !== undefined) {\n      // encrypted key\n      headers = headers.split(/\\r\\n|\\n/g);\n      for (var i = 0; i < headers.length; ++i) {\n        var header = headers[i];\n        var sepIdx = header.indexOf(':');\n        if (header.slice(0, sepIdx) === 'DEK-Info') {\n          var val = header.slice(sepIdx + 2);\n          sepIdx = val.indexOf(',');\n          if (sepIdx === -1)\n            continue;\n          var cipherName = val.slice(0, sepIdx).toLowerCase();\n          if (supportedOpenSSLCiphers.indexOf(cipherName) === -1) {\n            return new Error(\n              'Cipher ('\n              + cipherName\n              + ') not supported for encrypted OpenSSH private key'\n            );\n          }\n          var encInfo = CIPHER_INFO_OPENSSL[cipherName];\n          if (!encInfo) {\n            return new Error(\n              'Cipher ('\n              + cipherName\n              + ') not supported for encrypted OpenSSH private key'\n            );\n          }\n          var cipherIV = Buffer.from(val.slice(sepIdx + 1), 'hex');\n          if (cipherIV.length !== encInfo.ivLen)\n            return new Error('Malformed encrypted OpenSSH private key');\n          if (!passphrase) {\n            return new Error(\n              'Encrypted OpenSSH private key detected, but no passphrase given'\n            );\n          }\n          var cipherKey = createHash('md5')\n                            .update(passphrase)\n                            .update(cipherIV.slice(0, 8))\n                            .digest();\n          while (cipherKey.length < encInfo.keyLen) {\n            cipherKey = combineBuffers(\n              cipherKey,\n              (createHash('md5')\n                .update(cipherKey)\n                .update(passphrase)\n                .update(cipherIV)\n                .digest()).slice(0, 8)\n            );\n          }\n          if (cipherKey.length > encInfo.keyLen)\n            cipherKey = cipherKey.slice(0, encInfo.keyLen);\n          try {\n            var decipher = createDecipheriv(cipherName, cipherKey, cipherIV);\n            decipher.setAutoPadding(false);\n            privBlob = combineBuffers(decipher.update(privBlob),\n                                      decipher.final());\n            decrypted = true;\n          } catch (ex) {\n            return ex;\n          }\n        }\n      }\n    }\n\n    var type;\n    var privPEM;\n    var pubPEM;\n    var pubSSH;\n    var algo;\n    var reader;\n    var errMsg = 'Malformed OpenSSH private key';\n    if (decrypted)\n      errMsg += '. Bad passphrase?';\n    switch (m[1]) {\n      case 'RSA':\n        type = 'ssh-rsa';\n        privPEM = makePEM('RSA PRIVATE', privBlob);\n        try {\n          reader = new Ber.Reader(privBlob);\n          reader.readSequence();\n          reader.readInt(); // skip version\n          var n = reader.readString(Ber.Integer, true);\n          if (n === null)\n            return new Error(errMsg);\n          var e = reader.readString(Ber.Integer, true);\n          if (e === null)\n            return new Error(errMsg);\n          pubPEM = genOpenSSLRSAPub(n, e);\n          pubSSH = genOpenSSHRSAPub(n, e);\n        } catch (ex) {\n          return new Error(errMsg);\n        }\n        algo = 'sha1';\n        break;\n      case 'DSA':\n        type = 'ssh-dss';\n        privPEM = makePEM('DSA PRIVATE', privBlob);\n        try {\n          reader = new Ber.Reader(privBlob);\n          reader.readSequence();\n          reader.readInt(); // skip version\n          var p = reader.readString(Ber.Integer, true);\n          if (p === null)\n            return new Error(errMsg);\n          var q = reader.readString(Ber.Integer, true);\n          if (q === null)\n            return new Error(errMsg);\n          var g = reader.readString(Ber.Integer, true);\n          if (g === null)\n            return new Error(errMsg);\n          var y = reader.readString(Ber.Integer, true);\n          if (y === null)\n            return new Error(errMsg);\n          pubPEM = genOpenSSLDSAPub(p, q, g, y);\n          pubSSH = genOpenSSHDSAPub(p, q, g, y);\n        } catch (ex) {\n          return new Error(errMsg);\n        }\n        algo = 'sha1';\n        break;\n      case 'EC':\n        var ecSSLName;\n        var ecPriv;\n        try {\n          reader = new Ber.Reader(privBlob);\n          reader.readSequence();\n          reader.readInt(); // skip version\n          ecPriv = reader.readString(Ber.OctetString, true);\n          reader.readByte(); // Skip \"complex\" context type byte\n          var offset = reader.readLength(); // Skip context length\n          if (offset !== null) {\n            reader._offset = offset;\n            var oid = reader.readOID();\n            if (oid === null)\n              return new Error(errMsg);\n            switch (oid) {\n              case '1.2.840.10045.3.1.7':\n                // prime256v1/secp256r1\n                ecSSLName = 'prime256v1';\n                type = 'ecdsa-sha2-nistp256';\n                algo = 'sha256';\n                break;\n              case '1.3.132.0.34':\n                // secp384r1\n                ecSSLName = 'secp384r1';\n                type = 'ecdsa-sha2-nistp384';\n                algo = 'sha384';\n                break;\n              case '1.3.132.0.35':\n                // secp521r1\n                ecSSLName = 'secp521r1';\n                type = 'ecdsa-sha2-nistp521';\n                algo = 'sha512';\n                break;\n              default:\n                return new Error('Unsupported private key EC OID: ' + oid);\n            }\n          } else {\n            return new Error(errMsg);\n          }\n        } catch (ex) {\n          return new Error(errMsg);\n        }\n        privPEM = makePEM('EC PRIVATE', privBlob);\n        var pubBlob = genOpenSSLECDSAPubFromPriv(ecSSLName, ecPriv);\n        pubPEM = genOpenSSLECDSAPub(oid, pubBlob);\n        pubSSH = genOpenSSHECDSAPub(oid, pubBlob);\n        break;\n    }\n\n    return new OpenSSH_Old_Private(type, '', privPEM, pubPEM, pubSSH, algo,\n                                   decrypted);\n  };\n})();\n\n\n\nfunction PPK_Private(type, comment, privPEM, pubPEM, pubSSH, algo, decrypted) {\n  this.type = type;\n  this.comment = comment;\n  this[SYM_PRIV_PEM] = privPEM;\n  this[SYM_PUB_PEM] = pubPEM;\n  this[SYM_PUB_SSH] = pubSSH;\n  this[SYM_HASH_ALGO] = algo;\n  this[SYM_DECRYPTED] = decrypted;\n}\nPPK_Private.prototype = BaseKey;\n(function() {\n  var EMPTY_PASSPHRASE = Buffer.alloc(0);\n  var PPK_IV = Buffer.from([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);\n  var PPK_PP1 = Buffer.from([0, 0, 0, 0]);\n  var PPK_PP2 = Buffer.from([0, 0, 0, 1]);\n  var regexp = /^PuTTY-User-Key-File-2: (ssh-(?:rsa|dss))\\r?\\nEncryption: (aes256-cbc|none)\\r?\\nComment: ([^\\r\\n]*)\\r?\\nPublic-Lines: \\d+\\r?\\n([\\s\\S]+?)\\r?\\nPrivate-Lines: \\d+\\r?\\n([\\s\\S]+?)\\r?\\nPrivate-MAC: ([^\\r\\n]+)/;\n  PPK_Private.parse = function(str, passphrase) {\n    var m = regexp.exec(str);\n    if (m === null)\n      return null;\n    // m[1] = key type\n    // m[2] = encryption type\n    // m[3] = comment\n    // m[4] = base64-encoded public key data:\n    //         for \"ssh-rsa\":\n    //          string \"ssh-rsa\"\n    //          mpint  e    (public exponent)\n    //          mpint  n    (modulus)\n    //         for \"ssh-dss\":\n    //          string \"ssh-dss\"\n    //          mpint p     (modulus)\n    //          mpint q     (prime)\n    //          mpint g     (base number)\n    //          mpint y     (public key parameter: g^x mod p)\n    // m[5] = base64-encoded private key data:\n    //         for \"ssh-rsa\":\n    //          mpint  d    (private exponent)\n    //          mpint  p    (prime 1)\n    //          mpint  q    (prime 2)\n    //          mpint  iqmp ([inverse of q] mod p)\n    //         for \"ssh-dss\":\n    //          mpint x     (private key parameter)\n    // m[6] = SHA1 HMAC over:\n    //          string  name of algorithm (\"ssh-dss\", \"ssh-rsa\")\n    //          string  encryption type\n    //          string  comment\n    //          string  public key data\n    //          string  private-plaintext (including the final padding)\n    var cipherName = m[2];\n    var encrypted = (cipherName !== 'none');\n    if (encrypted && !passphrase) {\n      return new Error(\n        'Encrypted PPK private key detected, but no passphrase given'\n      );\n    }\n\n    var privBlob = Buffer.from(m[5], 'base64');\n\n    if (encrypted) {\n      var encInfo = CIPHER_INFO[cipherName];\n      var cipherKey = combineBuffers(\n        createHash('sha1').update(PPK_PP1).update(passphrase).digest(),\n        createHash('sha1').update(PPK_PP2).update(passphrase).digest()\n      );\n      if (cipherKey.length > encInfo.keyLen)\n        cipherKey = cipherKey.slice(0, encInfo.keyLen);\n      try {\n        var decipher = createDecipheriv(SSH_TO_OPENSSL[cipherName],\n                                        cipherKey,\n                                        PPK_IV);\n        decipher.setAutoPadding(false);\n        privBlob = combineBuffers(decipher.update(privBlob),\n                                  decipher.final());\n        decrypted = true;\n      } catch (ex) {\n        return ex;\n      }\n    }\n\n    var type = m[1];\n    var comment = m[3];\n    var pubBlob = Buffer.from(m[4], 'base64');\n\n    var mac = m[6];\n    var typeLen = type.length;\n    var cipherNameLen = cipherName.length;\n    var commentLen = Buffer.byteLength(comment);\n    var pubLen = pubBlob.length;\n    var privLen = privBlob.length;\n    var macData = Buffer.allocUnsafe(4 + typeLen\n                                     + 4 + cipherNameLen\n                                     + 4 + commentLen\n                                     + 4 + pubLen\n                                     + 4 + privLen);\n    var p = 0;\n\n    writeUInt32BE(macData, typeLen, p);\n    macData.write(type, p += 4, typeLen, 'ascii');\n    writeUInt32BE(macData, cipherNameLen, p += typeLen);\n    macData.write(cipherName, p += 4, cipherNameLen, 'ascii');\n    writeUInt32BE(macData, commentLen, p += cipherNameLen);\n    macData.write(comment, p += 4, commentLen, 'utf8');\n    writeUInt32BE(macData, pubLen, p += commentLen);\n    pubBlob.copy(macData, p += 4);\n    writeUInt32BE(macData, privLen, p += pubLen);\n    privBlob.copy(macData, p + 4);\n\n    if (!passphrase)\n      passphrase = EMPTY_PASSPHRASE;\n\n    var calcMAC = createHmac('sha1',\n                             createHash('sha1')\n                               .update('putty-private-key-file-mac-key')\n                               .update(passphrase)\n                               .digest())\n                    .update(macData)\n                    .digest('hex');\n\n    if (calcMAC !== mac) {\n      if (encrypted) {\n        return new Error(\n          'PPK private key integrity check failed -- bad passphrase?'\n        );\n      } else {\n        return new Error('PPK private key integrity check failed');\n      }\n    }\n\n    // avoid cyclic require by requiring on first use\n    if (!utils)\n      utils = __webpack_require__(/*! ./utils */ \"./node_modules/ssh2-streams/lib/utils.js\");\n\n    var pubPEM;\n    var pubSSH;\n    var privPEM;\n    pubBlob._pos = 0;\n    skipFields(pubBlob, 1); // skip (duplicate) key type\n    switch (type) {\n      case 'ssh-rsa':\n        var e = utils.readString(pubBlob, pubBlob._pos);\n        if (e === false)\n          return new Error('Malformed PPK public key');\n        var n = utils.readString(pubBlob, pubBlob._pos);\n        if (n === false)\n          return new Error('Malformed PPK public key');\n        var d = utils.readString(privBlob, 0);\n        if (d === false)\n          return new Error('Malformed PPK private key');\n        var p = utils.readString(privBlob, privBlob._pos);\n        if (p === false)\n          return new Error('Malformed PPK private key');\n        var q = utils.readString(privBlob, privBlob._pos);\n        if (q === false)\n          return new Error('Malformed PPK private key');\n        var iqmp = utils.readString(privBlob, privBlob._pos);\n        if (iqmp === false)\n          return new Error('Malformed PPK private key');\n        pubPEM = genOpenSSLRSAPub(n, e);\n        pubSSH = genOpenSSHRSAPub(n, e);\n        privPEM = genOpenSSLRSAPriv(n, e, d, iqmp, p, q);\n        break;\n      case 'ssh-dss':\n        var p = utils.readString(pubBlob, pubBlob._pos);\n        if (p === false)\n          return new Error('Malformed PPK public key');\n        var q = utils.readString(pubBlob, pubBlob._pos);\n        if (q === false)\n          return new Error('Malformed PPK public key');\n        var g = utils.readString(pubBlob, pubBlob._pos);\n        if (g === false)\n          return new Error('Malformed PPK public key');\n        var y = utils.readString(pubBlob, pubBlob._pos);\n        if (y === false)\n          return new Error('Malformed PPK public key');\n        var x = utils.readString(privBlob, 0);\n        if (x === false)\n          return new Error('Malformed PPK private key');\n\n        pubPEM = genOpenSSLDSAPub(p, q, g, y);\n        pubSSH = genOpenSSHDSAPub(p, q, g, y);\n        privPEM = genOpenSSLDSAPriv(p, q, g, y, x);\n        break;\n    }\n\n    return new PPK_Private(type, comment, privPEM, pubPEM, pubSSH, 'sha1',\n                           encrypted);\n  };\n})();\n\n\nfunction parseDER(data, baseType, comment, fullType) {\n  // avoid cyclic require by requiring on first use\n  if (!utils)\n    utils = __webpack_require__(/*! ./utils */ \"./node_modules/ssh2-streams/lib/utils.js\");\n\n  var algo;\n  var pubPEM = null;\n  var pubSSH = null;\n  switch (baseType) {\n    case 'ssh-rsa':\n      var e = utils.readString(data, data._pos);\n      if (e === false)\n        return new Error('Malformed OpenSSH public key');\n      var n = utils.readString(data, data._pos);\n      if (n === false)\n        return new Error('Malformed OpenSSH public key');\n      pubPEM = genOpenSSLRSAPub(n, e);\n      pubSSH = genOpenSSHRSAPub(n, e);\n      algo = 'sha1';\n      break;\n    case 'ssh-dss':\n      var p = utils.readString(data, data._pos);\n      if (p === false)\n        return new Error('Malformed OpenSSH public key');\n      var q = utils.readString(data, data._pos);\n      if (q === false)\n        return new Error('Malformed OpenSSH public key');\n      var g = utils.readString(data, data._pos);\n      if (g === false)\n        return new Error('Malformed OpenSSH public key');\n      var y = utils.readString(data, data._pos);\n      if (y === false)\n        return new Error('Malformed OpenSSH public key');\n      pubPEM = genOpenSSLDSAPub(p, q, g, y);\n      pubSSH = genOpenSSHDSAPub(p, q, g, y);\n      algo = 'sha1';\n      break;\n    case 'ssh-ed25519':\n      var edpub = utils.readString(data, data._pos);\n      if (edpub === false || edpub.length !== 32)\n        return new Error('Malformed OpenSSH public key');\n      pubPEM = genOpenSSLEdPub(edpub);\n      pubSSH = genOpenSSHEdPub(edpub);\n      algo = null;\n      break;\n    case 'ecdsa-sha2-nistp256':\n      algo = 'sha256';\n      oid = '1.2.840.10045.3.1.7';\n    case 'ecdsa-sha2-nistp384':\n      if (algo === undefined) {\n        algo = 'sha384';\n        oid = '1.3.132.0.34';\n      }\n    case 'ecdsa-sha2-nistp521':\n      if (algo === undefined) {\n        algo = 'sha512';\n        oid = '1.3.132.0.35';\n      }\n      // TODO: validate curve name against type\n      if (!skipFields(data, 1)) // Skip curve name\n        return new Error('Malformed OpenSSH public key');\n      var ecpub = utils.readString(data, data._pos);\n      if (ecpub === false)\n        return new Error('Malformed OpenSSH public key');\n      pubPEM = genOpenSSLECDSAPub(oid, ecpub);\n      pubSSH = genOpenSSHECDSAPub(oid, ecpub);\n      break;\n    default:\n      return new Error('Unsupported OpenSSH public key type: ' + baseType);\n  }\n\n  return new OpenSSH_Public(fullType, comment, pubPEM, pubSSH, algo);\n}\nfunction OpenSSH_Public(type, comment, pubPEM, pubSSH, algo) {\n  this.type = type;\n  this.comment = comment;\n  this[SYM_PRIV_PEM] = null;\n  this[SYM_PUB_PEM] = pubPEM;\n  this[SYM_PUB_SSH] = pubSSH;\n  this[SYM_HASH_ALGO] = algo;\n  this[SYM_DECRYPTED] = false;\n}\nOpenSSH_Public.prototype = BaseKey;\n(function() {\n  var regexp;\n  if (EDDSA_SUPPORTED)\n    regexp = /^(((?:ssh-(?:rsa|dss|ed25519))|ecdsa-sha2-nistp(?:256|384|521))(?:-cert-v0[01]@openssh.com)?) ([A-Z0-9a-z\\/+=]+)(?:$|\\s+([\\S].*)?)$/;\n  else\n    regexp = /^(((?:ssh-(?:rsa|dss))|ecdsa-sha2-nistp(?:256|384|521))(?:-cert-v0[01]@openssh.com)?) ([A-Z0-9a-z\\/+=]+)(?:$|\\s+([\\S].*)?)$/;\n  OpenSSH_Public.parse = function(str) {\n    var m = regexp.exec(str);\n    if (m === null)\n      return null;\n    // m[1] = full type\n    // m[2] = base type\n    // m[3] = base64-encoded public key\n    // m[4] = comment\n\n    // avoid cyclic require by requiring on first use\n    if (!utils)\n      utils = __webpack_require__(/*! ./utils */ \"./node_modules/ssh2-streams/lib/utils.js\");\n\n    var fullType = m[1];\n    var baseType = m[2];\n    var data = Buffer.from(m[3], 'base64');\n    var comment = (m[4] || '');\n\n    var type = utils.readString(data, data._pos, 'ascii');\n    if (type === false || type.indexOf(baseType) !== 0)\n      return new Error('Malformed OpenSSH public key');\n\n    return parseDER(data, baseType, comment, fullType);\n  };\n})();\n\n\n\nfunction RFC4716_Public(type, comment, pubPEM, pubSSH, algo) {\n  this.type = type;\n  this.comment = comment;\n  this[SYM_PRIV_PEM] = null;\n  this[SYM_PUB_PEM] = pubPEM;\n  this[SYM_PUB_SSH] = pubSSH;\n  this[SYM_HASH_ALGO] = algo;\n  this[SYM_DECRYPTED] = false;\n}\nRFC4716_Public.prototype = BaseKey;\n(function() {\n  var regexp = /^---- BEGIN SSH2 PUBLIC KEY ----(?:\\r\\n|\\n)((?:(?:[\\x21-\\x7E]+?):(?:(?:.*?\\\\\\r?\\n)*.*)(?:\\r\\n|\\n))*)((?:[A-Z0-9a-z\\/+=]+(?:\\r\\n|\\n))+)---- END SSH2 PUBLIC KEY ----$/;\n  var RE_HEADER = /^([\\x21-\\x7E]+?):((?:.*?\\\\\\r?\\n)*.*)$/gm;\n  var RE_HEADER_ENDS = /\\\\\\r?\\n/g;\n  RFC4716_Public.parse = function(str) {\n    var m = regexp.exec(str);\n    if (m === null)\n      return null;\n    // m[1] = header(s)\n    // m[2] = base64-encoded public key\n\n    var headers = m[1];\n    var data = Buffer.from(m[2], 'base64');\n    var comment = '';\n\n    if (headers !== undefined) {\n      while (m = RE_HEADER.exec(headers)) {\n        if (m[1].toLowerCase() === 'comment') {\n          comment = trimStart(m[2].replace(RE_HEADER_ENDS, ''));\n          if (comment.length > 1\n              && comment.charCodeAt(0) === 34/*'\"'*/\n              && comment.charCodeAt(comment.length - 1) === 34/*'\"'*/) {\n            comment = comment.slice(1, -1);\n          }\n        }\n      }\n    }\n\n    // avoid cyclic require by requiring on first use\n    if (!utils)\n      utils = __webpack_require__(/*! ./utils */ \"./node_modules/ssh2-streams/lib/utils.js\");\n\n    var type = utils.readString(data, 0, 'ascii');\n    if (type === false)\n      return new Error('Malformed RFC4716 public key');\n\n    var pubPEM = null;\n    var pubSSH = null;\n    switch (type) {\n      case 'ssh-rsa':\n        var e = utils.readString(data, data._pos);\n        if (e === false)\n          return new Error('Malformed RFC4716 public key');\n        var n = utils.readString(data, data._pos);\n        if (n === false)\n          return new Error('Malformed RFC4716 public key');\n        pubPEM = genOpenSSLRSAPub(n, e);\n        pubSSH = genOpenSSHRSAPub(n, e);\n        break;\n      case 'ssh-dss':\n        var p = utils.readString(data, data._pos);\n        if (p === false)\n          return new Error('Malformed RFC4716 public key');\n        var q = utils.readString(data, data._pos);\n        if (q === false)\n          return new Error('Malformed RFC4716 public key');\n        var g = utils.readString(data, data._pos);\n        if (g === false)\n          return new Error('Malformed RFC4716 public key');\n        var y = utils.readString(data, data._pos);\n        if (y === false)\n          return new Error('Malformed RFC4716 public key');\n        pubPEM = genOpenSSLDSAPub(p, q, g, y);\n        pubSSH = genOpenSSHDSAPub(p, q, g, y);\n        break;\n      default:\n        return new Error('Malformed RFC4716 public key');\n    }\n\n    return new RFC4716_Public(type, comment, pubPEM, pubSSH, 'sha1');\n  };\n})();\n\n\n\nmodule.exports = {\n  parseDERKey: function parseDERKey(data, type) {\n    return parseDER(data, type, '', type);\n  },\n  parseKey: function parseKey(data, passphrase) {\n    if (Buffer.isBuffer(data))\n      data = data.toString('utf8').trim();\n    else if (typeof data !== 'string')\n      return new Error('Key data must be a Buffer or string');\n    else\n      data = data.trim();\n\n    // intentional !=\n    if (passphrase != undefined) {\n      if (typeof passphrase === 'string')\n        passphrase = Buffer.from(passphrase);\n      else if (!Buffer.isBuffer(passphrase))\n        return new Error('Passphrase must be a string or Buffer when supplied');\n    }\n\n    var ret;\n\n    // Private keys\n    if ((ret = OpenSSH_Private.parse(data, passphrase)) !== null)\n      return ret;\n    if ((ret = OpenSSH_Old_Private.parse(data, passphrase)) !== null)\n      return ret;\n    if ((ret = PPK_Private.parse(data, passphrase)) !== null)\n      return ret;\n\n    // Public keys\n    if ((ret = OpenSSH_Public.parse(data)) !== null)\n      return ret;\n    if ((ret = RFC4716_Public.parse(data)) !== null)\n      return ret;\n\n    return new Error('Unsupported key format');\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/lib/keyParser.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/lib/node-fs-compat.js":
/*!*********************************************************!*\
  !*** ./node_modules/ssh2-streams/lib/node-fs-compat.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar inspect = __webpack_require__(/*! util */ \"util\").inspect;\n\nfunction assert(value, message) {\n  if (!value)\n    throw new ERR_INTERNAL_ASSERTION(message);\n}\nassert.fail = function fail(message) {\n  throw new ERR_INTERNAL_ASSERTION(message);\n};\n\n// Only use this for integers! Decimal numbers do not work with this function.\nfunction addNumericalSeparator(val) {\n  var res = '';\n  var i = val.length;\n  var start = val[0] === '-' ? 1 : 0;\n  for (; i >= start + 4; i -= 3)\n    res = `_${val.slice(i - 3, i)}${res}`;\n  return `${val.slice(0, i)}${res}`;\n}\n\nfunction oneOf(expected, thing) {\n  assert(typeof thing === 'string', '`thing` has to be of type string');\n  if (Array.isArray(expected)) {\n    var len = expected.length;\n    assert(len > 0, 'At least one expected value needs to be specified');\n    expected = expected.map((i) => String(i));\n    if (len > 2) {\n      return `one of ${thing} ${expected.slice(0, len - 1).join(', ')}, or `\n              + expected[len - 1];\n    } else if (len === 2) {\n      return `one of ${thing} ${expected[0]} or ${expected[1]}`;\n    } else {\n      return `of ${thing} ${expected[0]}`;\n    }\n  } else {\n    return `of ${thing} ${String(expected)}`;\n  }\n}\n\n\n\nexports.ERR_INTERNAL_ASSERTION = class ERR_INTERNAL_ASSERTION extends Error {\n  constructor(message) {\n    super();\n    Error.captureStackTrace(this, ERR_INTERNAL_ASSERTION);\n\n    var suffix = 'This is caused by either a bug in ssh2-streams '\n                 + 'or incorrect usage of ssh2-streams internals.\\n'\n                 + 'Please open an issue with this stack trace at '\n                 + 'https://github.com/mscdex/ssh2-streams/issues\\n';\n\n    this.message = (message === undefined ? suffix : `${message}\\n${suffix}`);\n  }\n};\n\nvar MAX_32BIT_INT = Math.pow(2, 32);\nvar MAX_32BIT_BIGINT = (function() {\n  try {\n    return new Function('return 2n ** 32n')();\n  } catch (ex) {}\n})();\nexports.ERR_OUT_OF_RANGE = class ERR_OUT_OF_RANGE extends RangeError {\n  constructor(str, range, input, replaceDefaultBoolean) {\n    super();\n    Error.captureStackTrace(this, ERR_OUT_OF_RANGE);\n\n    assert(range, 'Missing \"range\" argument');\n    var msg = (replaceDefaultBoolean\n               ? str\n               : `The value of \"${str}\" is out of range.`);\n    var received;\n    if (Number.isInteger(input) && Math.abs(input) > MAX_32BIT_INT) {\n      received = addNumericalSeparator(String(input));\n    } else if (typeof input === 'bigint') {\n      received = String(input);\n      if (input > MAX_32BIT_BIGINT || input < -MAX_32BIT_BIGINT)\n        received = addNumericalSeparator(received);\n      received += 'n';\n    } else {\n      received = inspect(input);\n    }\n    msg += ` It must be ${range}. Received ${received}`;\n\n    this.message = msg;\n  }\n};\n\nexports.ERR_INVALID_ARG_TYPE = class ERR_INVALID_ARG_TYPE extends TypeError {\n  constructor(name, expected, actual) {\n    super();\n    Error.captureStackTrace(this, ERR_INVALID_ARG_TYPE);\n\n    assert(typeof name === 'string', `'name' must be a string`);\n\n    // determiner: 'must be' or 'must not be'\n    var determiner;\n    if (typeof expected === 'string' && expected.startsWith('not ')) {\n      determiner = 'must not be';\n      expected = expected.replace(/^not /, '');\n    } else {\n      determiner = 'must be';\n    }\n\n    var msg;\n    if (name.endsWith(' argument')) {\n      // For cases like 'first argument'\n      msg = `The ${name} ${determiner} ${oneOf(expected, 'type')}`;\n    } else {\n      var type = (name.includes('.') ? 'property' : 'argument');\n      msg = `The \"${name}\" ${type} ${determiner} ${oneOf(expected, 'type')}`;\n    }\n\n    msg += `. Received type ${typeof actual}`;\n\n    this.message = msg;\n  }\n};\n\nexports.validateNumber = function validateNumber(value, name) {\n  if (typeof value !== 'number')\n    throw new ERR_INVALID_ARG_TYPE(name, 'number', value);\n};\n\n\n// =============================================================================\n// Following code is only needed to support node v6.x ....\n\n// Undocumented cb() API, needed for core, not for public API\nexports.destroyImpl = function destroy(err, cb) {\n  const readableDestroyed = this._readableState &&\n    this._readableState.destroyed;\n  const writableDestroyed = this._writableState &&\n    this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err) {\n      if (!this._writableState) {\n        process.nextTick(emitErrorNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorNT, this, err);\n      }\n    }\n\n    return this;\n  }\n\n  // We set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // If this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, (err) => {\n    if (!cb && err) {\n      if (!this._writableState) {\n        process.nextTick(emitErrorAndCloseNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorAndCloseNT, this, err);\n      } else {\n        process.nextTick(emitCloseNT, this);\n      }\n    } else if (cb) {\n      process.nextTick(emitCloseNT, this);\n      cb(err);\n    } else {\n      process.nextTick(emitCloseNT, this);\n    }\n  });\n\n  return this;\n};\n\nfunction emitErrorAndCloseNT(self, err) {\n  emitErrorNT(self, err);\n  emitCloseNT(self);\n}\n\nfunction emitCloseNT(self) {\n  if (self._writableState && !self._writableState.emitClose)\n    return;\n  if (self._readableState && !self._readableState.emitClose)\n    return;\n  self.emit('close');\n}\n// =============================================================================\n\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/lib/node-fs-compat.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/lib/sftp.js":
/*!***********************************************!*\
  !*** ./node_modules/ssh2-streams/lib/sftp.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// TODO: support EXTENDED request packets\n\nvar TransformStream = __webpack_require__(/*! stream */ \"stream\").Transform;\nvar ReadableStream = __webpack_require__(/*! stream */ \"stream\").Readable;\nvar WritableStream = __webpack_require__(/*! stream */ \"stream\").Writable;\nvar constants = __webpack_require__(/*! fs */ \"fs\").constants || process.binding('constants');\nvar util = __webpack_require__(/*! util */ \"util\");\nvar inherits = util.inherits;\nvar isDate = util.isDate;\nvar listenerCount = __webpack_require__(/*! events */ \"events\").EventEmitter.listenerCount;\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\nvar readString = __webpack_require__(/*! ./utils */ \"./node_modules/ssh2-streams/lib/utils.js\").readString;\nvar readInt = __webpack_require__(/*! ./utils */ \"./node_modules/ssh2-streams/lib/utils.js\").readInt;\nvar readUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2-streams/lib/buffer-helpers.js\").readUInt32BE;\nvar writeUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2-streams/lib/buffer-helpers.js\").writeUInt32BE;\n\nvar ATTR = {\n  SIZE: 0x00000001,\n  UIDGID: 0x00000002,\n  PERMISSIONS: 0x00000004,\n  ACMODTIME: 0x00000008,\n  EXTENDED: 0x80000000\n};\n\nvar STATUS_CODE = {\n  OK: 0,\n  EOF: 1,\n  NO_SUCH_FILE: 2,\n  PERMISSION_DENIED: 3,\n  FAILURE: 4,\n  BAD_MESSAGE: 5,\n  NO_CONNECTION: 6,\n  CONNECTION_LOST: 7,\n  OP_UNSUPPORTED: 8\n};\nObject.keys(STATUS_CODE).forEach(function(key) {\n  STATUS_CODE[STATUS_CODE[key]] = key;\n});\nvar STATUS_CODE_STR = {\n  0: 'No error',\n  1: 'End of file',\n  2: 'No such file or directory',\n  3: 'Permission denied',\n  4: 'Failure',\n  5: 'Bad message',\n  6: 'No connection',\n  7: 'Connection lost',\n  8: 'Operation unsupported'\n};\nSFTPStream.STATUS_CODE = STATUS_CODE;\n\nvar REQUEST = {\n  INIT: 1,\n  OPEN: 3,\n  CLOSE: 4,\n  READ: 5,\n  WRITE: 6,\n  LSTAT: 7,\n  FSTAT: 8,\n  SETSTAT: 9,\n  FSETSTAT: 10,\n  OPENDIR: 11,\n  READDIR: 12,\n  REMOVE: 13,\n  MKDIR: 14,\n  RMDIR: 15,\n  REALPATH: 16,\n  STAT: 17,\n  RENAME: 18,\n  READLINK: 19,\n  SYMLINK: 20,\n  EXTENDED: 200\n};\nObject.keys(REQUEST).forEach(function(key) {\n  REQUEST[REQUEST[key]] = key;\n});\n\nvar RESPONSE = {\n  VERSION: 2,\n  STATUS: 101,\n  HANDLE: 102,\n  DATA: 103,\n  NAME: 104,\n  ATTRS: 105,\n  EXTENDED: 201\n};\nObject.keys(RESPONSE).forEach(function(key) {\n  RESPONSE[RESPONSE[key]] = key;\n});\n\nvar OPEN_MODE = {\n  READ: 0x00000001,\n  WRITE: 0x00000002,\n  APPEND: 0x00000004,\n  CREAT: 0x00000008,\n  TRUNC: 0x00000010,\n  EXCL: 0x00000020\n};\nSFTPStream.OPEN_MODE = OPEN_MODE;\n\nvar MAX_PKT_LEN = 34000;\nvar MAX_REQID = Math.pow(2, 32) - 1;\nvar CLIENT_VERSION_BUFFER = Buffer.from([0, 0, 0, 5 /* length */,\n                                         REQUEST.INIT,\n                                         0, 0, 0, 3 /* version */]);\nvar SERVER_VERSION_BUFFER = Buffer.from([0, 0, 0, 5 /* length */,\n                                         RESPONSE.VERSION,\n                                         0, 0, 0, 3 /* version */]);\n/*\n  http://tools.ietf.org/html/draft-ietf-secsh-filexfer-02:\n\n     The maximum size of a packet is in practice determined by the client\n     (the maximum size of read or write requests that it sends, plus a few\n     bytes of packet overhead).  All servers SHOULD support packets of at\n     least 34000 bytes (where the packet size refers to the full length,\n     including the header above).  This should allow for reads and writes\n     of at most 32768 bytes.\n\n  OpenSSH caps this to 256kb instead of the ~34kb as mentioned in the sftpv3\n  spec.\n*/\nvar RE_OPENSSH = /^SSH-2.0-(?:OpenSSH|dropbear)/;\nvar OPENSSH_MAX_DATA_LEN = (256 * 1024) - (2 * 1024)/*account for header data*/;\n\nfunction DEBUG_NOOP(msg) {}\n\nfunction SFTPStream(cfg, remoteIdentRaw) {\n  if (typeof cfg === 'string' && !remoteIdentRaw) {\n    remoteIdentRaw = cfg;\n    cfg = undefined;\n  }\n  if (typeof cfg !== 'object' || !cfg)\n    cfg = {};\n\n  TransformStream.call(this, {\n    highWaterMark: (typeof cfg.highWaterMark === 'number'\n                    ? cfg.highWaterMark\n                    : 32 * 1024)\n  });\n\n  this.debug = (typeof cfg.debug === 'function' ? cfg.debug : DEBUG_NOOP);\n  this.server = (cfg.server ? true : false);\n  this._isOpenSSH = (remoteIdentRaw && RE_OPENSSH.test(remoteIdentRaw));\n  this._needContinue = false;\n  this._state = {\n    // common\n    status: 'packet_header',\n    writeReqid: -1,\n    pktLeft: undefined,\n    pktHdrBuf: Buffer.allocUnsafe(9), // room for pktLen + pktType + req id\n    pktBuf: undefined,\n    pktType: undefined,\n    version: undefined,\n    extensions: {},\n\n    // client\n    maxDataLen: (this._isOpenSSH ? OPENSSH_MAX_DATA_LEN : 32768),\n    requests: {}\n  };\n\n  var self = this;\n  this.on('end', function() {\n    self.readable = false;\n  }).on('finish', onFinish)\n    .on('prefinish', onFinish);\n  function onFinish() {\n    self.writable = false;\n    self._cleanup(false);\n  }\n\n  if (!this.server)\n    this.push(CLIENT_VERSION_BUFFER);\n}\ninherits(SFTPStream, TransformStream);\n\nSFTPStream.prototype.__read = TransformStream.prototype._read;\nSFTPStream.prototype._read = function(n) {\n  if (this._needContinue) {\n    this._needContinue = false;\n    this.emit('continue');\n  }\n  return this.__read(n);\n};\nSFTPStream.prototype.__push = TransformStream.prototype.push;\nSFTPStream.prototype.push = function(chunk, encoding) {\n  if (!this.readable)\n    return false;\n  if (chunk === null)\n    this.readable = false;\n  var ret = this.__push(chunk, encoding);\n  this._needContinue = (ret === false);\n  return ret;\n};\n\nSFTPStream.prototype._cleanup = function(callback) {\n  var state = this._state;\n\n  state.pktBuf = undefined; // give GC something to do\n\n  var requests = state.requests;\n  var keys = Object.keys(requests);\n  var len = keys.length;\n  if (len) {\n    if (this.readable) {\n      var err = new Error('SFTP session ended early');\n      for (var i = 0, cb; i < len; ++i)\n        (cb = requests[keys[i]].cb) && cb(err);\n    }\n    state.requests = {};\n  }\n\n  if (this.readable)\n    this.push(null);\n  if (!this._readableState.endEmitted && !this._readableState.flowing) {\n    // Ugh!\n    this.resume();\n  }\n  if (callback !== false) {\n    this.debug('DEBUG[SFTP]: Parser: Malformed packet');\n    callback && callback(new Error('Malformed packet'));\n  }\n};\n\nSFTPStream.prototype._transform = function(chunk, encoding, callback) {\n  var state = this._state;\n  var server = this.server;\n  var status = state.status;\n  var pktType = state.pktType;\n  var pktBuf = state.pktBuf;\n  var pktLeft = state.pktLeft;\n  var version = state.version;\n  var pktHdrBuf = state.pktHdrBuf;\n  var requests = state.requests;\n  var debug = this.debug;\n  var chunkLen = chunk.length;\n  var chunkPos = 0;\n  var buffer;\n  var chunkLeft;\n  var id;\n\n  while (true) {\n    if (status === 'discard') {\n      chunkLeft = (chunkLen - chunkPos);\n      if (pktLeft <= chunkLeft) {\n        chunkPos += pktLeft;\n        pktLeft = 0;\n        status = 'packet_header';\n        buffer = pktBuf = undefined;\n      } else {\n        pktLeft -= chunkLeft;\n        break;\n      }\n    } else if (pktBuf !== undefined) {\n      chunkLeft = (chunkLen - chunkPos);\n      if (pktLeft <= chunkLeft) {\n        chunk.copy(pktBuf,\n                   pktBuf.length - pktLeft,\n                   chunkPos,\n                   chunkPos + pktLeft);\n        chunkPos += pktLeft;\n        pktLeft = 0;\n        buffer = pktBuf;\n        pktBuf = undefined;\n        continue;\n      } else {\n        chunk.copy(pktBuf, pktBuf.length - pktLeft, chunkPos);\n        pktLeft -= chunkLeft;\n        break;\n      }\n    } else if (status === 'packet_header') {\n      if (!buffer) {\n        pktLeft = 5;\n        pktBuf = pktHdrBuf;\n      } else {\n        // here we read the right-most 5 bytes from buffer (pktHdrBuf)\n        pktLeft = readUInt32BE(buffer, 4) - 1; // account for type byte\n        pktType = buffer[8];\n\n        if (server) {\n          if (version === undefined && pktType !== REQUEST.INIT) {\n            debug('DEBUG[SFTP]: Parser: Unexpected packet before init');\n            this._cleanup(false);\n            return callback(new Error('Unexpected packet before init'));\n          } else if (version !== undefined && pktType === REQUEST.INIT) {\n            debug('DEBUG[SFTP]: Parser: Unexpected duplicate init');\n            status = 'bad_pkt';\n          } else if (pktLeft > MAX_PKT_LEN) {\n            var msg = 'Packet length ('\n                      + pktLeft\n                      + ') exceeds max length ('\n                      + MAX_PKT_LEN\n                      + ')';\n            debug('DEBUG[SFTP]: Parser: ' + msg);\n            this._cleanup(false);\n            return callback(new Error(msg));\n          } else if (pktType === REQUEST.EXTENDED) {\n            status = 'bad_pkt';\n          } else if (REQUEST[pktType] === undefined) {\n            debug('DEBUG[SFTP]: Parser: Unsupported packet type: ' + pktType);\n            status = 'discard';\n          }\n        } else if (version === undefined && pktType !== RESPONSE.VERSION) {\n          debug('DEBUG[SFTP]: Parser: Unexpected packet before version');\n          this._cleanup(false);\n          return callback(new Error('Unexpected packet before version'));\n        } else if (version !== undefined && pktType === RESPONSE.VERSION) {\n          debug('DEBUG[SFTP]: Parser: Unexpected duplicate version');\n          status = 'bad_pkt';\n        } else if (RESPONSE[pktType] === undefined) {\n          status = 'discard';\n        }\n\n        if (status === 'bad_pkt') {\n          // Copy original packet info to left of pktHdrBuf\n          writeUInt32BE(pktHdrBuf, pktLeft + 1, 0);\n          pktHdrBuf[4] = pktType;\n\n          pktLeft = 4;\n          pktBuf = pktHdrBuf;\n        } else {\n          pktBuf = Buffer.allocUnsafe(pktLeft);\n          status = 'payload';\n        }\n      }\n    } else if (status === 'payload') {\n      if (pktType === RESPONSE.VERSION || pktType === REQUEST.INIT) {\n        /*\n          uint32 version\n          <extension data>\n        */\n        version = state.version = readInt(buffer, 0, this, callback);\n        if (version === false)\n          return;\n        if (version < 3) {\n          this._cleanup(false);\n          return callback(new Error('Incompatible SFTP version: ' + version));\n        } else if (server)\n          this.push(SERVER_VERSION_BUFFER);\n\n        var buflen = buffer.length;\n        var extname;\n        var extdata;\n        buffer._pos = 4;\n        while (buffer._pos < buflen) {\n          extname = readString(buffer, buffer._pos, 'ascii', this, callback);\n          if (extname === false)\n            return;\n          extdata = readString(buffer, buffer._pos, 'ascii', this, callback);\n          if (extdata === false)\n            return;\n          if (state.extensions[extname])\n            state.extensions[extname].push(extdata);\n          else\n            state.extensions[extname] = [ extdata ];\n        }\n\n        this.emit('ready');\n      } else {\n        /*\n          All other packets (client and server) begin with a (client) request\n          id:\n          uint32     id\n        */\n        id = readInt(buffer, 0, this, callback);\n        if (id === false)\n          return;\n\n        var filename;\n        var attrs;\n        var handle;\n        var data;\n\n        if (!server) {\n          var req = requests[id];\n          var cb = req && req.cb;\n          debug('DEBUG[SFTP]: Parser: Response: ' + RESPONSE[pktType]);\n          if (req && cb) {\n            if (pktType === RESPONSE.STATUS) {\n              /*\n                uint32     error/status code\n                string     error message (ISO-10646 UTF-8)\n                string     language tag\n              */\n              var code = readInt(buffer, 4, this, callback);\n              if (code === false)\n                return;\n              if (code === STATUS_CODE.OK) {\n                cb();\n              } else {\n                // We borrow OpenSSH behavior here, specifically we make the\n                // message and language fields optional, despite the\n                // specification requiring them (even if they are empty). This\n                // helps to avoid problems with buggy implementations that do\n                // not fully conform to the SFTP(v3) specification.\n                var msg;\n                var lang = '';\n                if (buffer.length >= 12) {\n                  msg = readString(buffer, 8, 'utf8', this, callback);\n                  if (msg === false)\n                    return;\n                  if ((buffer._pos + 4) < buffer.length) {\n                    lang = readString(buffer,\n                                      buffer._pos,\n                                      'ascii',\n                                      this,\n                                      callback);\n                    if (lang === false)\n                      return;\n                  }\n                }\n                var err = new Error(msg\n                                    || STATUS_CODE_STR[code]\n                                    || 'Unknown status');\n                err.code = code;\n                err.lang = lang;\n                cb(err);\n              }\n            } else if (pktType === RESPONSE.HANDLE) {\n              /*\n                string     handle\n              */\n              handle = readString(buffer, 4, this, callback);\n              if (handle === false)\n                return;\n              cb(undefined, handle);\n            } else if (pktType === RESPONSE.DATA) {\n              /*\n                string     data\n              */\n              if (req.buffer) {\n                // we have already pre-allocated space to store the data\n                var dataLen = readInt(buffer, 4, this, callback);\n                if (dataLen === false)\n                  return;\n                var reqBufLen = req.buffer.length;\n                if (dataLen > reqBufLen) {\n                  // truncate response data to fit expected size\n                  writeUInt32BE(buffer, reqBufLen, 4);\n                }\n                data = readString(buffer, 4, req.buffer, this, callback);\n                if (data === false)\n                  return;\n                cb(undefined, data, dataLen);\n              } else {\n                data = readString(buffer, 4, this, callback);\n                if (data === false)\n                  return;\n                cb(undefined, data);\n              }\n            } else if (pktType === RESPONSE.NAME) {\n              /*\n                uint32     count\n                repeats count times:\n                        string     filename\n                        string     longname\n                        ATTRS      attrs\n              */\n              var namesLen = readInt(buffer, 4, this, callback);\n              if (namesLen === false)\n                return;\n              var names = [],\n                  longname;\n              buffer._pos = 8;\n              for (var i = 0; i < namesLen; ++i) {\n                // we are going to assume UTF-8 for filenames despite the SFTPv3\n                // spec not specifying an encoding because the specs for newer\n                // versions of the protocol all explicitly specify UTF-8 for\n                // filenames\n                filename = readString(buffer,\n                                      buffer._pos,\n                                      'utf8',\n                                      this,\n                                      callback);\n                if (filename === false)\n                  return;\n                // `longname` only exists in SFTPv3 and since it typically will\n                // contain the filename, we assume it is also UTF-8\n                longname = readString(buffer,\n                                      buffer._pos,\n                                      'utf8',\n                                      this,\n                                      callback);\n                if (longname === false)\n                  return;\n                attrs = readAttrs(buffer, buffer._pos, this, callback);\n                if (attrs === false)\n                  return;\n                names.push({\n                  filename: filename,\n                  longname: longname,\n                  attrs: attrs\n                });\n              }\n              cb(undefined, names);\n            } else if (pktType === RESPONSE.ATTRS) {\n              /*\n                ATTRS      attrs\n              */\n              attrs = readAttrs(buffer, 4, this, callback);\n              if (attrs === false)\n                return;\n              cb(undefined, attrs);\n            } else if (pktType === RESPONSE.EXTENDED) {\n              if (req.extended) {\n                switch (req.extended) {\n                  case 'statvfs@openssh.com':\n                  case 'fstatvfs@openssh.com':\n                    /*\n                      uint64    f_bsize   // file system block size\n                      uint64    f_frsize  // fundamental fs block size\n                      uint64    f_blocks  // number of blocks (unit f_frsize)\n                      uint64    f_bfree   // free blocks in file system\n                      uint64    f_bavail  // free blocks for non-root\n                      uint64    f_files   // total file inodes\n                      uint64    f_ffree   // free file inodes\n                      uint64    f_favail  // free file inodes for to non-root\n                      uint64    f_fsid    // file system id\n                      uint64    f_flag    // bit mask of f_flag values\n                      uint64    f_namemax // maximum filename length\n                    */\n                    var stats = {\n                      f_bsize: undefined,\n                      f_frsize: undefined,\n                      f_blocks: undefined,\n                      f_bfree: undefined,\n                      f_bavail: undefined,\n                      f_files: undefined,\n                      f_ffree: undefined,\n                      f_favail: undefined,\n                      f_sid: undefined,\n                      f_flag: undefined,\n                      f_namemax: undefined\n                    };\n                    stats.f_bsize = readUInt64BE(buffer, 4, this, callback);\n                    if (stats.f_bsize === false)\n                      return;\n                    stats.f_frsize = readUInt64BE(buffer, 12, this, callback);\n                    if (stats.f_frsize === false)\n                      return;\n                    stats.f_blocks = readUInt64BE(buffer, 20, this, callback);\n                    if (stats.f_blocks === false)\n                      return;\n                    stats.f_bfree = readUInt64BE(buffer, 28, this, callback);\n                    if (stats.f_bfree === false)\n                      return;\n                    stats.f_bavail = readUInt64BE(buffer, 36, this, callback);\n                    if (stats.f_bavail === false)\n                      return;\n                    stats.f_files = readUInt64BE(buffer, 44, this, callback);\n                    if (stats.f_files === false)\n                      return;\n                    stats.f_ffree = readUInt64BE(buffer, 52, this, callback);\n                    if (stats.f_ffree === false)\n                      return;\n                    stats.f_favail = readUInt64BE(buffer, 60, this, callback);\n                    if (stats.f_favail === false)\n                      return;\n                    stats.f_sid = readUInt64BE(buffer, 68, this, callback);\n                    if (stats.f_sid === false)\n                      return;\n                    stats.f_flag = readUInt64BE(buffer, 76, this, callback);\n                    if (stats.f_flag === false)\n                      return;\n                    stats.f_namemax = readUInt64BE(buffer, 84, this, callback);\n                    if (stats.f_namemax === false)\n                      return;\n                    cb(undefined, stats);\n                  break;\n                }\n              }\n              // XXX: at least provide the raw buffer data to the callback in\n              // case of unexpected extended response?\n              cb();\n            }\n          }\n          if (req)\n            delete requests[id];\n        } else {\n          // server\n          var evName = REQUEST[pktType];\n          var offset;\n          var path;\n\n          debug('DEBUG[SFTP]: Parser: Request: ' + evName);\n          if (listenerCount(this, evName)) {\n            if (pktType === REQUEST.OPEN) {\n              /*\n                string        filename\n                uint32        pflags\n                ATTRS         attrs\n              */\n              filename = readString(buffer, 4, 'utf8', this, callback);\n              if (filename === false)\n                return;\n              var pflags = readInt(buffer, buffer._pos, this, callback);\n              if (pflags === false)\n                return;\n              attrs = readAttrs(buffer, buffer._pos + 4, this, callback);\n              if (attrs === false)\n                return;\n              this.emit(evName, id, filename, pflags, attrs);\n            } else if (pktType === REQUEST.CLOSE\n                       || pktType === REQUEST.FSTAT\n                       || pktType === REQUEST.READDIR) {\n              /*\n                string     handle\n              */\n              handle = readString(buffer, 4, this, callback);\n              if (handle === false)\n                return;\n              this.emit(evName, id, handle);\n            } else if (pktType === REQUEST.READ) {\n              /*\n                string     handle\n                uint64     offset\n                uint32     len\n              */\n              handle = readString(buffer, 4, this, callback);\n              if (handle === false)\n                return;\n              offset = readUInt64BE(buffer, buffer._pos, this, callback);\n              if (offset === false)\n                return;\n              var len = readInt(buffer, buffer._pos, this, callback);\n              if (len === false)\n                return;\n              this.emit(evName, id, handle, offset, len);\n            } else if (pktType === REQUEST.WRITE) {\n              /*\n                string     handle\n                uint64     offset\n                string     data\n              */\n              handle = readString(buffer, 4, this, callback);\n              if (handle === false)\n                return;\n              offset = readUInt64BE(buffer, buffer._pos, this, callback);\n              if (offset === false)\n                return;\n              data = readString(buffer, buffer._pos, this, callback);\n              if (data === false)\n                return;\n              this.emit(evName, id, handle, offset, data);\n            } else if (pktType === REQUEST.LSTAT\n                       || pktType === REQUEST.STAT\n                       || pktType === REQUEST.OPENDIR\n                       || pktType === REQUEST.REMOVE\n                       || pktType === REQUEST.RMDIR\n                       || pktType === REQUEST.REALPATH\n                       || pktType === REQUEST.READLINK) {\n              /*\n                string     path\n              */\n              path = readString(buffer, 4, 'utf8', this, callback);\n              if (path === false)\n                return;\n              this.emit(evName, id, path);\n            } else if (pktType === REQUEST.SETSTAT\n                       || pktType === REQUEST.MKDIR) {\n              /*\n                string     path\n                ATTRS      attrs\n              */\n              path = readString(buffer, 4, 'utf8', this, callback);\n              if (path === false)\n                return;\n              attrs = readAttrs(buffer, buffer._pos, this, callback);\n              if (attrs === false)\n                return;\n              this.emit(evName, id, path, attrs);\n            } else if (pktType === REQUEST.FSETSTAT) {\n              /*\n                string     handle\n                ATTRS      attrs\n              */\n              handle = readString(buffer, 4, this, callback);\n              if (handle === false)\n                return;\n              attrs = readAttrs(buffer, buffer._pos, this, callback);\n              if (attrs === false)\n                return;\n              this.emit(evName, id, handle, attrs);\n            } else if (pktType === REQUEST.RENAME\n                       || pktType === REQUEST.SYMLINK) {\n              /*\n                RENAME:\n                  string     oldpath\n                  string     newpath\n                SYMLINK:\n                  string     linkpath\n                  string     targetpath\n              */\n              var str1;\n              var str2;\n              str1 = readString(buffer, 4, 'utf8', this, callback);\n              if (str1 === false)\n                return;\n              str2 = readString(buffer, buffer._pos, 'utf8', this, callback);\n              if (str2 === false)\n                return;\n              if (pktType === REQUEST.SYMLINK && this._isOpenSSH) {\n                // OpenSSH has linkpath and targetpath positions switched\n                this.emit(evName, id, str2, str1);\n              } else\n                this.emit(evName, id, str1, str2);\n            }\n          } else {\n            // automatically reject request if no handler for request type\n            this.status(id, STATUS_CODE.OP_UNSUPPORTED);\n          }\n        }\n      }\n\n      // prepare for next packet\n      status = 'packet_header';\n      buffer = pktBuf = undefined;\n    } else if (status === 'bad_pkt') {\n      if (server && buffer[4] !== REQUEST.INIT) {\n        var errCode = (buffer[4] === REQUEST.EXTENDED\n                       ? STATUS_CODE.OP_UNSUPPORTED\n                       : STATUS_CODE.FAILURE);\n\n        // no request id for init/version packets, so we have no way to send a\n        // status response, so we just close up shop ...\n        if (buffer[4] === REQUEST.INIT || buffer[4] === RESPONSE.VERSION)\n          return this._cleanup(callback);\n\n        id = readInt(buffer, 5, this, callback);\n        if (id === false)\n          return;\n        this.status(id, errCode);\n      }\n\n      // by this point we have already read the type byte and the id bytes, so\n      // we subtract those from the number of bytes to skip\n      pktLeft = readUInt32BE(buffer, 0) - 5;\n\n      status = 'discard';\n    }\n\n    if (chunkPos >= chunkLen)\n      break;\n  }\n\n  state.status = status;\n  state.pktType = pktType;\n  state.pktBuf = pktBuf;\n  state.pktLeft = pktLeft;\n  state.version = version;\n\n  callback();\n};\n\n// client\nSFTPStream.prototype.createReadStream = function(path, options) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  return new ReadStream(this, path, options);\n};\nSFTPStream.prototype.createWriteStream = function(path, options) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  return new WriteStream(this, path, options);\n};\nSFTPStream.prototype.open = function(path, flags_, attrs, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  if (typeof attrs === 'function') {\n    cb = attrs;\n    attrs = undefined;\n  }\n\n  var flags = (typeof flags_ === 'number' ? flags_ : stringToFlags(flags_));\n  if (flags === null)\n    throw new Error('Unknown flags string: ' + flags_);\n\n  var attrFlags = 0;\n  var attrBytes = 0;\n  if (typeof attrs === 'string' || typeof attrs === 'number') {\n    attrs = { mode: attrs };\n  }\n  if (typeof attrs === 'object' && attrs !== null) {\n    attrs = attrsToBytes(attrs);\n    attrFlags = attrs.flags;\n    attrBytes = attrs.nbytes;\n    attrs = attrs.bytes;\n  }\n\n  /*\n    uint32        id\n    string        filename\n    uint32        pflags\n    ATTRS         attrs\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + pathlen + 4 + 4 + attrBytes);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.OPEN;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(path, p += 4, pathlen, 'utf8');\n  writeUInt32BE(buf, flags, p += pathlen);\n  writeUInt32BE(buf, attrFlags, p += 4);\n  if (attrs && attrFlags) {\n    p += 4;\n    for (var i = 0, len = attrs.length; i < len; ++i)\n      for (var j = 0, len2 = attrs[i].length; j < len2; ++j)\n        buf[p++] = attrs[i][j];\n  }\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing OPEN');\n  return this.push(buf);\n};\nSFTPStream.prototype.close = function(handle, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!Buffer.isBuffer(handle))\n    throw new Error('handle is not a Buffer');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     handle\n  */\n  var handlelen = handle.length;\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + handlelen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.CLOSE;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, handlelen, p);\n  handle.copy(buf, p += 4);\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing CLOSE');\n  return this.push(buf);\n};\nSFTPStream.prototype.readData = function(handle, buf, off, len, position, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!Buffer.isBuffer(handle))\n    throw new Error('handle is not a Buffer');\n  else if (!Buffer.isBuffer(buf))\n    throw new Error('buffer is not a Buffer');\n  else if (off >= buf.length)\n    throw new Error('offset is out of bounds');\n  else if (off + len > buf.length)\n    throw new Error('length extends beyond buffer');\n  else if (position === null)\n    throw new Error('null position currently unsupported');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     handle\n    uint64     offset\n    uint32     len\n  */\n  var handlelen = handle.length;\n  var p = 9;\n  var pos = position;\n  var out = Buffer.allocUnsafe(4 + 1 + 4 + 4 + handlelen + 8 + 4);\n\n  writeUInt32BE(out, out.length - 4, 0);\n  out[4] = REQUEST.READ;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(out, reqid, 5);\n\n  writeUInt32BE(out, handlelen, p);\n  handle.copy(out, p += 4);\n  p += handlelen;\n  for (var i = 7; i >= 0; --i) {\n    out[p + i] = pos & 0xFF;\n    pos /= 256;\n  }\n  writeUInt32BE(out, len, p += 8);\n\n  state.requests[reqid] = {\n    cb: function(err, data, nb) {\n      if (err) {\n        if (cb._wantEOFError || err.code !== STATUS_CODE.EOF)\n          return cb(err);\n      } else if (nb > len) {\n        return cb(new Error('Received more data than requested'));\n      }\n      cb(undefined, nb || 0, data, position);\n    },\n    buffer: buf.slice(off, off + len)\n  };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing READ');\n  return this.push(out);\n};\nSFTPStream.prototype.writeData = function(handle, buf, off, len, position, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!Buffer.isBuffer(handle))\n    throw new Error('handle is not a Buffer');\n  else if (!Buffer.isBuffer(buf))\n    throw new Error('buffer is not a Buffer');\n  else if (off > buf.length)\n    throw new Error('offset is out of bounds');\n  else if (off + len > buf.length)\n    throw new Error('length extends beyond buffer');\n  else if (position === null)\n    throw new Error('null position currently unsupported');\n\n  var self = this;\n  var state = this._state;\n\n  if (!len) {\n    cb && process.nextTick(function() { cb(undefined, 0); });\n    return;\n  }\n\n  var overflow = (len > state.maxDataLen\n                  ? len - state.maxDataLen\n                  : 0);\n  var origPosition = position;\n\n  if (overflow)\n    len = state.maxDataLen;\n\n  /*\n    uint32     id\n    string     handle\n    uint64     offset\n    string     data\n  */\n  var handlelen = handle.length;\n  var p = 9;\n  var out = Buffer.allocUnsafe(4 + 1 + 4 + 4 + handlelen + 8 + 4 + len);\n\n  writeUInt32BE(out, out.length - 4, 0);\n  out[4] = REQUEST.WRITE;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(out, reqid, 5);\n\n  writeUInt32BE(out, handlelen, p);\n  handle.copy(out, p += 4);\n  p += handlelen;\n  for (var i = 7; i >= 0; --i) {\n    out[p + i] = position & 0xFF;\n    position /= 256;\n  }\n  writeUInt32BE(out, len, p += 8);\n  buf.copy(out, p += 4, off, off + len);\n\n  state.requests[reqid] = {\n    cb: function(err) {\n      if (err)\n        cb && cb(err);\n      else if (overflow) {\n        self.writeData(handle,\n                       buf,\n                       off + len,\n                       overflow,\n                       origPosition + len,\n                       cb);\n      } else\n        cb && cb(undefined, off + len);\n    }\n  };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing WRITE');\n  return this.push(out);\n};\nfunction tryCreateBuffer(size) {\n  try {\n    return Buffer.allocUnsafe(size);\n  } catch (ex) {\n    return ex;\n  }\n}\nfunction fastXfer(src, dst, srcPath, dstPath, opts, cb) {\n  var concurrency = 64;\n  var chunkSize = 32768;\n  //var preserve = false;\n  var onstep;\n  var mode;\n  var fileSize;\n\n  if (typeof opts === 'function') {\n    cb = opts;\n  } else if (typeof opts === 'object' && opts !== null) {\n    if (typeof opts.concurrency === 'number'\n        && opts.concurrency > 0\n        && !isNaN(opts.concurrency))\n      concurrency = opts.concurrency;\n    if (typeof opts.chunkSize === 'number'\n        && opts.chunkSize > 0\n        && !isNaN(opts.chunkSize))\n      chunkSize = opts.chunkSize;\n    if (typeof opts.fileSize === 'number'\n        && opts.fileSize > 0\n        && !isNaN(opts.fileSize))\n      fileSize = opts.fileSize;\n    if (typeof opts.step === 'function')\n      onstep = opts.step;\n    //preserve = (opts.preserve ? true : false);\n    if (typeof opts.mode === 'string' || typeof opts.mode === 'number')\n      mode = modeNum(opts.mode);\n  }\n\n  // internal state variables\n  var fsize;\n  var pdst = 0;\n  var total = 0;\n  var hadError = false;\n  var srcHandle;\n  var dstHandle;\n  var readbuf;\n  var bufsize = chunkSize * concurrency;\n\n  function onerror(err) {\n    if (hadError)\n      return;\n\n    hadError = true;\n\n    var left = 0;\n    var cbfinal;\n\n    if (srcHandle || dstHandle) {\n      cbfinal = function() {\n        if (--left === 0)\n          cb(err);\n      };\n      if (srcHandle && (src === fs || src.writable))\n        ++left;\n      if (dstHandle && (dst === fs || dst.writable))\n        ++left;\n      if (srcHandle && (src === fs || src.writable))\n        src.close(srcHandle, cbfinal);\n      if (dstHandle && (dst === fs || dst.writable))\n        dst.close(dstHandle, cbfinal);\n    } else\n      cb(err);\n  }\n\n  src.open(srcPath, 'r', function(err, sourceHandle) {\n    if (err)\n      return onerror(err);\n\n    srcHandle = sourceHandle;\n\n    if (fileSize === undefined)\n      src.fstat(srcHandle, tryStat);\n    else\n      tryStat(null, { size: fileSize });\n\n    function tryStat(err, attrs) {\n      if (err) {\n        if (src !== fs) {\n          // Try stat() for sftp servers that may not support fstat() for\n          // whatever reason\n          src.stat(srcPath, function(err_, attrs_) {\n            if (err_)\n              return onerror(err);\n            tryStat(null, attrs_);\n          });\n          return;\n        }\n        return onerror(err);\n      }\n      fsize = attrs.size;\n\n      dst.open(dstPath, 'w', function(err, destHandle) {\n        if (err)\n          return onerror(err);\n\n        dstHandle = destHandle;\n\n        if (fsize <= 0)\n          return onerror();\n\n        // Use less memory where possible\n        while (bufsize > fsize) {\n          if (concurrency === 1) {\n            bufsize = fsize;\n            break;\n          }\n          bufsize -= chunkSize;\n          --concurrency;\n        }\n\n        readbuf = tryCreateBuffer(bufsize);\n        if (readbuf instanceof Error)\n          return onerror(readbuf);\n\n        if (mode !== undefined) {\n          dst.fchmod(dstHandle, mode, function tryAgain(err) {\n            if (err) {\n              // Try chmod() for sftp servers that may not support fchmod() for\n              // whatever reason\n              dst.chmod(dstPath, mode, function(err_) {\n                tryAgain();\n              });\n              return;\n            }\n            startReads();\n          });\n        } else {\n          startReads();\n        }\n\n        function onread(err, nb, data, dstpos, datapos, origChunkLen) {\n          if (err)\n            return onerror(err);\n\n          datapos = datapos || 0;\n\n          if (src === fs)\n            dst.writeData(dstHandle, readbuf, datapos, nb, dstpos, writeCb);\n          else\n            dst.write(dstHandle, readbuf, datapos, nb, dstpos, writeCb);\n\n          function writeCb(err) {\n            if (err)\n              return onerror(err);\n\n            total += nb;\n            onstep && onstep(total, nb, fsize);\n\n            if (nb < origChunkLen)\n              return singleRead(datapos, dstpos + nb, origChunkLen - nb);\n\n            if (total === fsize) {\n              dst.close(dstHandle, function(err) {\n                dstHandle = undefined;\n                if (err)\n                  return onerror(err);\n                src.close(srcHandle, function(err) {\n                  srcHandle = undefined;\n                  if (err)\n                    return onerror(err);\n                  cb();\n                });\n              });\n              return;\n            }\n\n            if (pdst >= fsize)\n              return;\n\n            var chunk = (pdst + chunkSize > fsize ? fsize - pdst : chunkSize);\n            singleRead(datapos, pdst, chunk);\n            pdst += chunk;\n          }\n        }\n\n        function makeCb(psrc, pdst, chunk) {\n          return function(err, nb, data) {\n            onread(err, nb, data, pdst, psrc, chunk);\n          };\n        }\n\n        function singleRead(psrc, pdst, chunk) {\n          if (src === fs) {\n            src.read(srcHandle,\n                     readbuf,\n                     psrc,\n                     chunk,\n                     pdst,\n                     makeCb(psrc, pdst, chunk));\n          } else {\n            src.readData(srcHandle,\n                         readbuf,\n                         psrc,\n                         chunk,\n                         pdst,\n                         makeCb(psrc, pdst, chunk));\n          }\n        }\n\n        function startReads() {\n          var reads = 0;\n          var psrc = 0;\n          while (pdst < fsize && reads < concurrency) {\n            var chunk = (pdst + chunkSize > fsize ? fsize - pdst : chunkSize);\n            singleRead(psrc, pdst, chunk);\n            psrc += chunk;\n            pdst += chunk;\n            ++reads;\n          }\n        }\n      });\n    }\n  });\n}\nSFTPStream.prototype.fastGet = function(remotePath, localPath, opts, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  fastXfer(this, fs, remotePath, localPath, opts, cb);\n};\nSFTPStream.prototype.fastPut = function(localPath, remotePath, opts, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  fastXfer(fs, this, localPath, remotePath, opts, cb);\n};\nSFTPStream.prototype.readFile = function(path, options, callback_) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var callback;\n  if (typeof callback_ === 'function') {\n    callback = callback_;\n  } else if (typeof options === 'function') {\n    callback = options;\n    options = undefined;\n  }\n\n  var self = this;\n\n  if (typeof options === 'string')\n    options = { encoding: options, flag: 'r' };\n  else if (!options)\n    options = { encoding: null, flag: 'r' };\n  else if (typeof options !== 'object')\n    throw new TypeError('Bad arguments');\n\n  var encoding = options.encoding;\n  if (encoding && !Buffer.isEncoding(encoding))\n    throw new Error('Unknown encoding: ' + encoding);\n\n  // first, stat the file, so we know the size.\n  var size;\n  var buffer; // single buffer with file data\n  var buffers; // list for when size is unknown\n  var pos = 0;\n  var handle;\n\n  // SFTPv3 does not support using -1 for read position, so we have to track\n  // read position manually\n  var bytesRead = 0;\n\n  var flag = options.flag || 'r';\n  this.open(path, flag, 438 /*=0666*/, function(er, handle_) {\n    if (er)\n      return callback && callback(er);\n    handle = handle_;\n\n    self.fstat(handle, function tryStat(er, st) {\n      if (er) {\n        // Try stat() for sftp servers that may not support fstat() for\n        // whatever reason\n        self.stat(path, function(er_, st_) {\n          if (er_) {\n            return self.close(handle, function() {\n              callback && callback(er);\n            });\n          }\n          tryStat(null, st_);\n        });\n        return;\n      }\n\n      size = st.size || 0;\n      if (size === 0) {\n        // the kernel lies about many files.\n        // Go ahead and try to read some bytes.\n        buffers = [];\n        return read();\n      }\n\n      buffer = Buffer.allocUnsafe(size);\n      read();\n    });\n  });\n\n  function read() {\n    if (size === 0) {\n      buffer = Buffer.allocUnsafe(8192);\n      self.readData(handle, buffer, 0, 8192, bytesRead, afterRead);\n    } else {\n      self.readData(handle, buffer, pos, size - pos, bytesRead, afterRead);\n    }\n  }\n\n  function afterRead(er, nbytes) {\n    var eof;\n    if (er) {\n      eof = (er.code === STATUS_CODE.EOF);\n      if (!eof) {\n        return self.close(handle, function() {\n          return callback && callback(er);\n        });\n      }\n    } else {\n      eof = false;\n    }\n\n    if (eof || (size === 0 && nbytes === 0))\n      return close();\n\n    bytesRead += nbytes;\n    pos += nbytes;\n    if (size !== 0) {\n      if (pos === size)\n        close();\n      else\n        read();\n    } else {\n      // unknown size, just read until we don't get bytes.\n      buffers.push(buffer.slice(0, nbytes));\n      read();\n    }\n  }\n  afterRead._wantEOFError = true;\n\n  function close() {\n    self.close(handle, function(er) {\n      if (size === 0) {\n        // collected the data into the buffers list.\n        buffer = Buffer.concat(buffers, pos);\n      } else if (pos < size) {\n        buffer = buffer.slice(0, pos);\n      }\n\n      if (encoding)\n        buffer = buffer.toString(encoding);\n      return callback && callback(er, buffer);\n    });\n  }\n};\nfunction writeAll(self, handle, buffer, offset, length, position, callback_) {\n  var callback = (typeof callback_ === 'function' ? callback_ : undefined);\n\n  self.writeData(handle,\n                 buffer,\n                 offset,\n                 length,\n                 position,\n                 function(writeErr, written) {\n    if (writeErr) {\n      return self.close(handle, function() {\n        callback && callback(writeErr);\n      });\n    }\n    if (written === length)\n      self.close(handle, callback);\n    else {\n      offset += written;\n      length -= written;\n      position += written;\n      writeAll(self, handle, buffer, offset, length, position, callback);\n    }\n  });\n}\nSFTPStream.prototype.writeFile = function(path, data, options, callback_) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var callback;\n  if (typeof callback_ === 'function') {\n    callback = callback_;\n  } else if (typeof options === 'function') {\n    callback = options;\n    options = undefined;\n  }\n  var self = this;\n\n  if (typeof options === 'string')\n    options = { encoding: options, mode: 438, flag: 'w' };\n  else if (!options)\n    options = { encoding: 'utf8', mode: 438 /*=0666*/, flag: 'w' };\n  else if (typeof options !== 'object')\n    throw new TypeError('Bad arguments');\n\n  if (options.encoding && !Buffer.isEncoding(options.encoding))\n    throw new Error('Unknown encoding: ' + options.encoding);\n\n  var flag = options.flag || 'w';\n  this.open(path, flag, options.mode, function(openErr, handle) {\n    if (openErr)\n      callback && callback(openErr);\n    else {\n      var buffer = (Buffer.isBuffer(data)\n                    ? data\n                    : Buffer.from('' + data, options.encoding || 'utf8'));\n      var position = (/a/.test(flag) ? null : 0);\n\n      // SFTPv3 does not support the notion of 'current position'\n      // (null position), so we just attempt to append to the end of the file\n      // instead\n      if (position === null) {\n        self.fstat(handle, function tryStat(er, st) {\n          if (er) {\n            // Try stat() for sftp servers that may not support fstat() for\n            // whatever reason\n            self.stat(path, function(er_, st_) {\n              if (er_) {\n                return self.close(handle, function() {\n                  callback && callback(er);\n                });\n              }\n              tryStat(null, st_);\n            });\n            return;\n          }\n          writeAll(self, handle, buffer, 0, buffer.length, st.size, callback);\n        });\n        return;\n      }\n      writeAll(self, handle, buffer, 0, buffer.length, position, callback);\n    }\n  });\n};\nSFTPStream.prototype.appendFile = function(path, data, options, callback_) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var callback;\n  if (typeof callback_ === 'function') {\n    callback = callback_;\n  } else if (typeof options === 'function') {\n    callback = options;\n    options = undefined;\n  }\n\n  if (typeof options === 'string')\n    options = { encoding: options, mode: 438, flag: 'a' };\n  else if (!options)\n    options = { encoding: 'utf8', mode: 438 /*=0666*/, flag: 'a' };\n  else if (typeof options !== 'object')\n    throw new TypeError('Bad arguments');\n\n  if (!options.flag)\n    options = util._extend({ flag: 'a' }, options);\n  this.writeFile(path, data, options, callback);\n};\nSFTPStream.prototype.exists = function(path, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  this.stat(path, function(err) {\n    cb && cb(err ? false : true);\n  });\n};\nSFTPStream.prototype.unlink = function(filename, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     filename\n  */\n  var fnamelen = Buffer.byteLength(filename);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + fnamelen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.REMOVE;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, fnamelen, p);\n  buf.write(filename, p += 4, fnamelen, 'utf8');\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing REMOVE');\n  return this.push(buf);\n};\nSFTPStream.prototype.rename = function(oldPath, newPath, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     oldpath\n    string     newpath\n  */\n  var oldlen = Buffer.byteLength(oldPath);\n  var newlen = Buffer.byteLength(newPath);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + oldlen + 4 + newlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.RENAME;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, oldlen, p);\n  buf.write(oldPath, p += 4, oldlen, 'utf8');\n  writeUInt32BE(buf, newlen, p += oldlen);\n  buf.write(newPath, p += 4, newlen, 'utf8');\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing RENAME');\n  return this.push(buf);\n};\nSFTPStream.prototype.mkdir = function(path, attrs, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var flags = 0;\n  var attrBytes = 0;\n  var state = this._state;\n\n  if (typeof attrs === 'function') {\n    cb = attrs;\n    attrs = undefined;\n  }\n  if (typeof attrs === 'object' && attrs !== null) {\n    attrs = attrsToBytes(attrs);\n    flags = attrs.flags;\n    attrBytes = attrs.nbytes;\n    attrs = attrs.bytes;\n  }\n\n  /*\n    uint32     id\n    string     path\n    ATTRS      attrs\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + pathlen + 4 + attrBytes);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.MKDIR;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(path, p += 4, pathlen, 'utf8');\n  writeUInt32BE(buf, flags, p += pathlen);\n  if (flags) {\n    p += 4;\n    for (var i = 0, len = attrs.length; i < len; ++i)\n      for (var j = 0, len2 = attrs[i].length; j < len2; ++j)\n        buf[p++] = attrs[i][j];\n  }\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing MKDIR');\n  return this.push(buf);\n};\nSFTPStream.prototype.rmdir = function(path, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     path\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + pathlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.RMDIR;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(path, p += 4, pathlen, 'utf8');\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing RMDIR');\n  return this.push(buf);\n};\nSFTPStream.prototype.readdir = function(where, opts, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n  var doFilter;\n\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof opts !== 'object' || opts === null)\n    opts = {};\n\n  doFilter = (opts && opts.full ? false : true);\n\n  if (!Buffer.isBuffer(where) && typeof where !== 'string')\n    throw new Error('missing directory handle or path');\n\n  if (typeof where === 'string') {\n    var self = this;\n    var entries = [];\n    var e = 0;\n\n    return this.opendir(where, function reread(err, handle) {\n      if (err)\n        return cb(err);\n\n      self.readdir(handle, opts, function(err, list) {\n        var eof = (err && err.code === STATUS_CODE.EOF);\n\n        if (err && !eof) {\n          return self.close(handle, function() {\n            cb(err);\n          });\n        } else if (eof) {\n          return self.close(handle, function(err) {\n            if (err)\n              return cb(err);\n            cb(undefined, entries);\n          });\n        }\n\n        for (var i = 0, len = list.length; i < len; ++i, ++e)\n          entries[e] = list[i];\n\n        reread(undefined, handle);\n      });\n    });\n  }\n\n  /*\n    uint32     id\n    string     handle\n  */\n  var handlelen = where.length;\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + handlelen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.READDIR;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, handlelen, p);\n  where.copy(buf, p += 4);\n\n  state.requests[reqid] = {\n    cb: (doFilter\n         ? function(err, list) {\n             if (err)\n               return cb(err);\n\n             for (var i = list.length - 1; i >= 0; --i) {\n               if (list[i].filename === '.' || list[i].filename === '..')\n                 list.splice(i, 1);\n             }\n\n             cb(undefined, list);\n           }\n         : cb)\n  };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing READDIR');\n  return this.push(buf);\n};\nSFTPStream.prototype.fstat = function(handle, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!Buffer.isBuffer(handle))\n    throw new Error('handle is not a Buffer');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     handle\n  */\n  var handlelen = handle.length;\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + handlelen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.FSTAT;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, handlelen, p);\n  handle.copy(buf, p += 4);\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing FSTAT');\n  return this.push(buf);\n};\nSFTPStream.prototype.stat = function(path, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     path\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + pathlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.STAT;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(path, p += 4, pathlen, 'utf8');\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing STAT');\n  return this.push(buf);\n};\nSFTPStream.prototype.lstat = function(path, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     path\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + pathlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.LSTAT;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(path, p += 4, pathlen, 'utf8');\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing LSTAT');\n  return this.push(buf);\n};\nSFTPStream.prototype.opendir = function(path, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     path\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + pathlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.OPENDIR;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(path, p += 4, pathlen, 'utf8');\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing OPENDIR');\n  return this.push(buf);\n};\nSFTPStream.prototype.setstat = function(path, attrs, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var flags = 0;\n  var attrBytes = 0;\n  var state = this._state;\n\n  if (typeof attrs === 'object' && attrs !== null) {\n    attrs = attrsToBytes(attrs);\n    flags = attrs.flags;\n    attrBytes = attrs.nbytes;\n    attrs = attrs.bytes;\n  } else if (typeof attrs === 'function')\n    cb = attrs;\n\n  /*\n    uint32     id\n    string     path\n    ATTRS      attrs\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + pathlen + 4 + attrBytes);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.SETSTAT;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(path, p += 4, pathlen, 'utf8');\n  writeUInt32BE(buf, flags, p += pathlen);\n  if (flags) {\n    p += 4;\n    for (var i = 0, len = attrs.length; i < len; ++i)\n      for (var j = 0, len2 = attrs[i].length; j < len2; ++j)\n        buf[p++] = attrs[i][j];\n  }\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing SETSTAT');\n  return this.push(buf);\n};\nSFTPStream.prototype.fsetstat = function(handle, attrs, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!Buffer.isBuffer(handle))\n    throw new Error('handle is not a Buffer');\n\n  var flags = 0;\n  var attrBytes = 0;\n  var state = this._state;\n\n  if (typeof attrs === 'object' && attrs !== null) {\n    attrs = attrsToBytes(attrs);\n    flags = attrs.flags;\n    attrBytes = attrs.nbytes;\n    attrs = attrs.bytes;\n  } else if (typeof attrs === 'function')\n    cb = attrs;\n\n  /*\n    uint32     id\n    string     handle\n    ATTRS      attrs\n  */\n  var handlelen = handle.length;\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + handlelen + 4 + attrBytes);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.FSETSTAT;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, handlelen, p);\n  handle.copy(buf, p += 4);\n  writeUInt32BE(buf, flags, p += handlelen);\n  if (flags) {\n    p += 4;\n    for (var i = 0, len = attrs.length; i < len; ++i)\n      for (var j = 0, len2 = attrs[i].length; j < len2; ++j)\n        buf[p++] = attrs[i][j];\n  }\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing FSETSTAT');\n  return this.push(buf);\n};\nSFTPStream.prototype.futimes = function(handle, atime, mtime, cb) {\n  return this.fsetstat(handle, {\n    atime: toUnixTimestamp(atime),\n    mtime: toUnixTimestamp(mtime)\n  }, cb);\n};\nSFTPStream.prototype.utimes = function(path, atime, mtime, cb) {\n  return this.setstat(path, {\n    atime: toUnixTimestamp(atime),\n    mtime: toUnixTimestamp(mtime)\n  }, cb);\n};\nSFTPStream.prototype.fchown = function(handle, uid, gid, cb) {\n  return this.fsetstat(handle, {\n    uid: uid,\n    gid: gid\n  }, cb);\n};\nSFTPStream.prototype.chown = function(path, uid, gid, cb) {\n  return this.setstat(path, {\n    uid: uid,\n    gid: gid\n  }, cb);\n};\nSFTPStream.prototype.fchmod = function(handle, mode, cb) {\n  return this.fsetstat(handle, {\n    mode: mode\n  }, cb);\n};\nSFTPStream.prototype.chmod = function(path, mode, cb) {\n  return this.setstat(path, {\n    mode: mode\n  }, cb);\n};\nSFTPStream.prototype.readlink = function(path, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     path\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + pathlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.READLINK;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(path, p += 4, pathlen, 'utf8');\n\n  state.requests[reqid] = {\n    cb: function(err, names) {\n      if (err)\n        return cb(err);\n      else if (!names || !names.length)\n        return cb(new Error('Response missing link info'));\n      cb(undefined, names[0].filename);\n    }\n  };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing READLINK');\n  return this.push(buf);\n};\nSFTPStream.prototype.symlink = function(targetPath, linkPath, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     linkpath\n    string     targetpath\n  */\n  var linklen = Buffer.byteLength(linkPath);\n  var targetlen = Buffer.byteLength(targetPath);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + linklen + 4 + targetlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.SYMLINK;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  if (this._isOpenSSH) {\n    // OpenSSH has linkpath and targetpath positions switched\n    writeUInt32BE(buf, targetlen, p);\n    buf.write(targetPath, p += 4, targetlen, 'utf8');\n    writeUInt32BE(buf, linklen, p += targetlen);\n    buf.write(linkPath, p += 4, linklen, 'utf8');\n  } else {\n    writeUInt32BE(buf, linklen, p);\n    buf.write(linkPath, p += 4, linklen, 'utf8');\n    writeUInt32BE(buf, targetlen, p += linklen);\n    buf.write(targetPath, p += 4, targetlen, 'utf8');\n  }\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing SYMLINK');\n  return this.push(buf);\n};\nSFTPStream.prototype.realpath = function(path, cb) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var state = this._state;\n\n  /*\n    uint32     id\n    string     path\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + pathlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.REALPATH;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(path, p += 4, pathlen, 'utf8');\n\n  state.requests[reqid] = {\n    cb: function(err, names) {\n      if (err)\n        return cb(err);\n      else if (!names || !names.length)\n        return cb(new Error('Response missing path info'));\n      cb(undefined, names[0].filename);\n    }\n  };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing REALPATH');\n  return this.push(buf);\n};\n// extended requests\nSFTPStream.prototype.ext_openssh_rename = function(oldPath, newPath, cb) {\n  var state = this._state;\n\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!state.extensions['posix-rename@openssh.com']\n           || state.extensions['posix-rename@openssh.com'].indexOf('1') === -1)\n    throw new Error('Server does not support this extended request');\n\n  /*\n    uint32    id\n    string    \"posix-rename@openssh.com\"\n    string    oldpath\n    string    newpath\n  */\n  var oldlen = Buffer.byteLength(oldPath);\n  var newlen = Buffer.byteLength(newPath);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + 24 + 4 + oldlen + 4 + newlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.EXTENDED;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n  writeUInt32BE(buf, 24, p);\n  buf.write('posix-rename@openssh.com', p += 4, 24, 'ascii');\n\n  writeUInt32BE(buf, oldlen, p += 24);\n  buf.write(oldPath, p += 4, oldlen, 'utf8');\n  writeUInt32BE(buf, newlen, p += oldlen);\n  buf.write(newPath, p += 4, newlen, 'utf8');\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing posix-rename@openssh.com');\n  return this.push(buf);\n};\nSFTPStream.prototype.ext_openssh_statvfs = function(path, cb) {\n  var state = this._state;\n\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!state.extensions['statvfs@openssh.com']\n           || state.extensions['statvfs@openssh.com'].indexOf('2') === -1)\n    throw new Error('Server does not support this extended request');\n\n  /*\n    uint32    id\n    string    \"statvfs@openssh.com\"\n    string    path\n  */\n  var pathlen = Buffer.byteLength(path);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + 19 + 4 + pathlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.EXTENDED;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n  writeUInt32BE(buf, 19, p);\n  buf.write('statvfs@openssh.com', p += 4, 19, 'ascii');\n\n  writeUInt32BE(buf, pathlen, p += 19);\n  buf.write(path, p += 4, pathlen, 'utf8');\n\n  state.requests[reqid] = {\n    extended: 'statvfs@openssh.com',\n    cb: cb\n  };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing statvfs@openssh.com');\n  return this.push(buf);\n};\nSFTPStream.prototype.ext_openssh_fstatvfs = function(handle, cb) {\n  var state = this._state;\n\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!state.extensions['fstatvfs@openssh.com']\n           || state.extensions['fstatvfs@openssh.com'].indexOf('2') === -1)\n    throw new Error('Server does not support this extended request');\n  else if (!Buffer.isBuffer(handle))\n    throw new Error('handle is not a Buffer');\n\n  /*\n    uint32    id\n    string    \"fstatvfs@openssh.com\"\n    string    handle\n  */\n  var handlelen = handle.length;\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + 20 + 4 + handlelen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.EXTENDED;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n  writeUInt32BE(buf, 20, p);\n  buf.write('fstatvfs@openssh.com', p += 4, 20, 'ascii');\n\n  writeUInt32BE(buf, handlelen, p += 20);\n  buf.write(handle, p += 4, handlelen, 'utf8');\n\n  state.requests[reqid] = {\n    extended: 'fstatvfs@openssh.com',\n    cb: cb\n  };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing fstatvfs@openssh.com');\n  return this.push(buf);\n};\nSFTPStream.prototype.ext_openssh_hardlink = function(oldPath, newPath, cb) {\n  var state = this._state;\n\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!state.extensions['hardlink@openssh.com']\n           || state.extensions['hardlink@openssh.com'].indexOf('1') === -1)\n    throw new Error('Server does not support this extended request');\n\n  /*\n    uint32    id\n    string    \"hardlink@openssh.com\"\n    string    oldpath\n    string    newpath\n  */\n  var oldlen = Buffer.byteLength(oldPath);\n  var newlen = Buffer.byteLength(newPath);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + 20 + 4 + oldlen + 4 + newlen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.EXTENDED;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n  writeUInt32BE(buf, 20, p);\n  buf.write('hardlink@openssh.com', p += 4, 20, 'ascii');\n\n  writeUInt32BE(buf, oldlen, p += 20);\n  buf.write(oldPath, p += 4, oldlen, 'utf8');\n  writeUInt32BE(buf, newlen, p += oldlen);\n  buf.write(newPath, p += 4, newlen, 'utf8');\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing hardlink@openssh.com');\n  return this.push(buf);\n};\nSFTPStream.prototype.ext_openssh_fsync = function(handle, cb) {\n  var state = this._state;\n\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n  else if (!state.extensions['fsync@openssh.com']\n           || state.extensions['fsync@openssh.com'].indexOf('1') === -1)\n    throw new Error('Server does not support this extended request');\n  else if (!Buffer.isBuffer(handle))\n    throw new Error('handle is not a Buffer');\n\n  /*\n    uint32    id\n    string    \"fsync@openssh.com\"\n    string    handle\n  */\n  var handlelen = handle.length;\n  var p = 9;\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + 17 + 4 + handlelen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = REQUEST.EXTENDED;\n  var reqid = state.writeReqid = (state.writeReqid + 1) % MAX_REQID;\n  writeUInt32BE(buf, reqid, 5);\n  writeUInt32BE(buf, 17, p);\n  buf.write('fsync@openssh.com', p += 4, 17, 'ascii');\n\n  writeUInt32BE(buf, handlelen, p += 17);\n  buf.write(handle, p += 4, handlelen, 'utf8');\n\n  state.requests[reqid] = { cb: cb };\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing fsync@openssh.com');\n  return this.push(buf);\n};\n\n// server\nSFTPStream.prototype.status = function(id, code, message, lang) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  if (!STATUS_CODE[code] || typeof code !== 'number')\n    throw new Error('Bad status code: ' + code);\n\n  message || (message = '');\n  lang || (lang = '');\n\n  var msgLen = Buffer.byteLength(message);\n  var langLen = Buffer.byteLength(lang);\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + 4 + msgLen + 4 + langLen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = RESPONSE.STATUS;\n  writeUInt32BE(buf, id, 5);\n\n  writeUInt32BE(buf, code, 9);\n\n  writeUInt32BE(buf, msgLen, 13);\n  if (msgLen)\n    buf.write(message, 17, msgLen, 'utf8');\n\n  writeUInt32BE(buf, langLen, 17 + msgLen);\n  if (langLen)\n    buf.write(lang, 17 + msgLen + 4, langLen, 'ascii');\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing STATUS');\n  return this.push(buf);\n};\nSFTPStream.prototype.handle = function(id, handle) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  if (!Buffer.isBuffer(handle))\n    throw new Error('handle is not a Buffer');\n\n  var handleLen = handle.length;\n\n  if (handleLen > 256)\n    throw new Error('handle too large (> 256 bytes)');\n\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + handleLen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = RESPONSE.HANDLE;\n  writeUInt32BE(buf, id, 5);\n\n  writeUInt32BE(buf, handleLen, 9);\n  if (handleLen)\n    handle.copy(buf, 13);\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing HANDLE');\n  return this.push(buf);\n};\nSFTPStream.prototype.data = function(id, data, encoding) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var isBuffer = Buffer.isBuffer(data);\n\n  if (!isBuffer && typeof data !== 'string')\n    throw new Error('data is not a Buffer or string');\n\n  if (!isBuffer)\n    encoding || (encoding = 'utf8');\n\n  var dataLen = (isBuffer ? data.length : Buffer.byteLength(data, encoding));\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + dataLen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = RESPONSE.DATA;\n  writeUInt32BE(buf, id, 5);\n\n  writeUInt32BE(buf, dataLen, 9);\n  if (dataLen) {\n    if (isBuffer)\n      data.copy(buf, 13);\n    else\n      buf.write(data, 13, dataLen, encoding);\n  }\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing DATA');\n  return this.push(buf);\n};\nSFTPStream.prototype.name = function(id, names) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  if (!Array.isArray(names)) {\n    if (typeof names !== 'object' || names === null)\n      throw new Error('names is not an object or array');\n    names = [ names ];\n  }\n\n  var count = names.length;\n  var namesLen = 0;\n  var nameAttrs;\n  var attrs = [];\n  var name;\n  var filename;\n  var longname;\n  var attr;\n  var len;\n  var len2;\n  var buf;\n  var p;\n  var i;\n  var j;\n  var k;\n\n  for (i = 0; i < count; ++i) {\n    name = names[i];\n    filename = (!name || !name.filename || typeof name.filename !== 'string'\n                ? ''\n                : name.filename);\n    namesLen += 4 + Buffer.byteLength(filename);\n    longname = (!name || !name.longname || typeof name.longname !== 'string'\n                ? ''\n                : name.longname);\n    namesLen += 4 + Buffer.byteLength(longname);\n\n    if (typeof name.attrs === 'object' && name.attrs !== null) {\n      nameAttrs = attrsToBytes(name.attrs);\n      namesLen += 4 + nameAttrs.nbytes;\n      attrs.push(nameAttrs);\n    } else {\n      namesLen += 4;\n      attrs.push(null);\n    }\n  }\n\n  buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + namesLen);\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = RESPONSE.NAME;\n  writeUInt32BE(buf, id, 5);\n\n  writeUInt32BE(buf, count, 9);\n\n  p = 13;\n\n  for (i = 0; i < count; ++i) {\n    name = names[i];\n\n    filename = (!name || !name.filename || typeof name.filename !== 'string'\n                ? ''\n                : name.filename);\n    len = Buffer.byteLength(filename);\n    writeUInt32BE(buf, len, p);\n    p += 4;\n    if (len) {\n      buf.write(filename, p, len, 'utf8');\n      p += len;\n    }\n\n    longname = (!name || !name.longname || typeof name.longname !== 'string'\n                ? ''\n                : name.longname);\n    len = Buffer.byteLength(longname);\n    writeUInt32BE(buf, len, p);\n    p += 4;\n    if (len) {\n      buf.write(longname, p, len, 'utf8');\n      p += len;\n    }\n\n    attr = attrs[i];\n    if (attr) {\n      writeUInt32BE(buf, attr.flags, p);\n      p += 4;\n      if (attr.flags && attr.bytes) {\n        var bytes = attr.bytes;\n        for (j = 0, len = bytes.length; j < len; ++j)\n          for (k = 0, len2 = bytes[j].length; k < len2; ++k)\n            buf[p++] = bytes[j][k];\n      }\n    } else {\n      writeUInt32BE(buf, 0, p);\n      p += 4;\n    }\n  }\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing NAME');\n  return this.push(buf);\n};\nSFTPStream.prototype.attrs = function(id, attrs) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  if (typeof attrs !== 'object' || attrs === null)\n    throw new Error('attrs is not an object');\n\n  var info = attrsToBytes(attrs);\n  var buf = Buffer.allocUnsafe(4 + 1 + 4 + 4 + info.nbytes);\n  var p = 13;\n\n  writeUInt32BE(buf, buf.length - 4, 0);\n  buf[4] = RESPONSE.ATTRS;\n  writeUInt32BE(buf, id, 5);\n\n  writeUInt32BE(buf, info.flags, 9);\n\n  if (info.flags && info.bytes) {\n    var bytes = info.bytes;\n    for (var j = 0, len = bytes.length; j < len; ++j)\n      for (var k = 0, len2 = bytes[j].length; k < len2; ++k)\n        buf[p++] = bytes[j][k];\n  }\n\n  this.debug('DEBUG[SFTP]: Outgoing: Writing ATTRS');\n  return this.push(buf);\n};\n\nfunction readAttrs(buf, p, stream, callback) {\n  /*\n    uint32   flags\n    uint64   size           present only if flag SSH_FILEXFER_ATTR_SIZE\n    uint32   uid            present only if flag SSH_FILEXFER_ATTR_UIDGID\n    uint32   gid            present only if flag SSH_FILEXFER_ATTR_UIDGID\n    uint32   permissions    present only if flag SSH_FILEXFER_ATTR_PERMISSIONS\n    uint32   atime          present only if flag SSH_FILEXFER_ACMODTIME\n    uint32   mtime          present only if flag SSH_FILEXFER_ACMODTIME\n    uint32   extended_count present only if flag SSH_FILEXFER_ATTR_EXTENDED\n    string   extended_type\n    string   extended_data\n    ...      more extended data (extended_type - extended_data pairs),\n               so that number of pairs equals extended_count\n  */\n  var flags = readUInt32BE(buf, p);\n  var attrs = new Stats();\n\n  p += 4;\n\n  if (flags & ATTR.SIZE) {\n    var size = readUInt64BE(buf, p, stream, callback);\n    if (size === false)\n      return false;\n    attrs.size = size;\n    p += 8;\n  }\n  if (flags & ATTR.UIDGID) {\n    var uid;\n    var gid;\n    uid = readInt(buf, p, this, callback);\n    if (uid === false)\n      return false;\n    attrs.uid = uid;\n    p += 4;\n    gid = readInt(buf, p, this, callback);\n    if (gid === false)\n      return false;\n    attrs.gid = gid;\n    p += 4;\n  }\n  if (flags & ATTR.PERMISSIONS) {\n    var mode = readInt(buf, p, this, callback);\n    if (mode === false)\n      return false;\n    attrs.mode = mode;\n    // backwards compatibility\n    attrs.permissions = mode;\n    p += 4;\n  }\n  if (flags & ATTR.ACMODTIME) {\n    var atime;\n    var mtime;\n    atime = readInt(buf, p, this, callback);\n    if (atime === false)\n      return false;\n    attrs.atime = atime;\n    p += 4;\n    mtime = readInt(buf, p, this, callback);\n    if (mtime === false)\n      return false;\n    attrs.mtime = mtime;\n    p += 4;\n  }\n  if (flags & ATTR.EXTENDED) {\n    // TODO: read/parse extended data\n    var extcount = readInt(buf, p, this, callback);\n    if (extcount === false)\n      return false;\n    p += 4;\n    for (var i = 0, len; i < extcount; ++i) {\n      len = readInt(buf, p, this, callback);\n      if (len === false)\n        return false;\n      p += 4 + len;\n    }\n  }\n\n  buf._pos = p;\n\n  return attrs;\n}\n\nfunction readUInt64BE(buffer, p, stream, callback) {\n  if ((buffer.length - p) < 8) {\n    stream && stream._cleanup(callback);\n    return false;\n  }\n\n  var val = 0;\n\n  for (var len = p + 8; p < len; ++p) {\n    val *= 256;\n    val += buffer[p];\n  }\n\n  buffer._pos = p;\n\n  return val;\n}\n\nfunction attrsToBytes(attrs) {\n  var flags = 0;\n  var attrBytes = 0;\n  var ret = [];\n  var i = 0;\n\n  if (typeof attrs !== 'object' || attrs === null)\n    return { flags: flags, nbytes: attrBytes, bytes: ret };\n\n  if (typeof attrs.size === 'number') {\n    flags |= ATTR.SIZE;\n    attrBytes += 8;\n    var sizeBytes = new Array(8);\n    var val = attrs.size;\n    for (i = 7; i >= 0; --i) {\n      sizeBytes[i] = val & 0xFF;\n      val /= 256;\n    }\n    ret.push(sizeBytes);\n  }\n  if (typeof attrs.uid === 'number' && typeof attrs.gid === 'number') {\n    flags |= ATTR.UIDGID;\n    attrBytes += 8;\n    ret.push([(attrs.uid >> 24) & 0xFF, (attrs.uid >> 16) & 0xFF,\n              (attrs.uid >> 8) & 0xFF, attrs.uid & 0xFF]);\n    ret.push([(attrs.gid >> 24) & 0xFF, (attrs.gid >> 16) & 0xFF,\n              (attrs.gid >> 8) & 0xFF, attrs.gid & 0xFF]);\n  }\n  if (typeof attrs.permissions === 'number'\n      || typeof attrs.permissions === 'string'\n      || typeof attrs.mode === 'number'\n      || typeof attrs.mode === 'string') {\n    var mode = modeNum(attrs.mode || attrs.permissions);\n    flags |= ATTR.PERMISSIONS;\n    attrBytes += 4;\n    ret.push([(mode >> 24) & 0xFF,\n              (mode >> 16) & 0xFF,\n              (mode >> 8) & 0xFF,\n              mode & 0xFF]);\n  }\n  if ((typeof attrs.atime === 'number' || isDate(attrs.atime))\n      && (typeof attrs.mtime === 'number' || isDate(attrs.mtime))) {\n    var atime = toUnixTimestamp(attrs.atime);\n    var mtime = toUnixTimestamp(attrs.mtime);\n\n    flags |= ATTR.ACMODTIME;\n    attrBytes += 8;\n    ret.push([(atime >> 24) & 0xFF, (atime >> 16) & 0xFF,\n              (atime >> 8) & 0xFF, atime & 0xFF]);\n    ret.push([(mtime >> 24) & 0xFF, (mtime >> 16) & 0xFF,\n              (mtime >> 8) & 0xFF, mtime & 0xFF]);\n  }\n  // TODO: extended attributes\n\n  return { flags: flags, nbytes: attrBytes, bytes: ret };\n}\n\nfunction toUnixTimestamp(time) {\n  if (typeof time === 'number' && !isNaN(time))\n    return time;\n  else if (isDate(time))\n    return parseInt(time.getTime() / 1000, 10);\n  throw new Error('Cannot parse time: ' + time);\n}\n\nfunction modeNum(mode) {\n  if (typeof mode === 'number' && !isNaN(mode))\n    return mode;\n  else if (typeof mode === 'string')\n    return modeNum(parseInt(mode, 8));\n  throw new Error('Cannot parse mode: ' + mode);\n}\n\nvar stringFlagMap = {\n  'r': OPEN_MODE.READ,\n  'r+': OPEN_MODE.READ | OPEN_MODE.WRITE,\n  'w': OPEN_MODE.TRUNC | OPEN_MODE.CREAT | OPEN_MODE.WRITE,\n  'wx': OPEN_MODE.TRUNC | OPEN_MODE.CREAT | OPEN_MODE.WRITE | OPEN_MODE.EXCL,\n  'xw': OPEN_MODE.TRUNC | OPEN_MODE.CREAT | OPEN_MODE.WRITE | OPEN_MODE.EXCL,\n  'w+': OPEN_MODE.TRUNC | OPEN_MODE.CREAT | OPEN_MODE.READ | OPEN_MODE.WRITE,\n  'wx+': OPEN_MODE.TRUNC | OPEN_MODE.CREAT | OPEN_MODE.READ | OPEN_MODE.WRITE\n         | OPEN_MODE.EXCL,\n  'xw+': OPEN_MODE.TRUNC | OPEN_MODE.CREAT | OPEN_MODE.READ | OPEN_MODE.WRITE\n         | OPEN_MODE.EXCL,\n  'a': OPEN_MODE.APPEND | OPEN_MODE.CREAT | OPEN_MODE.WRITE,\n  'ax': OPEN_MODE.APPEND | OPEN_MODE.CREAT | OPEN_MODE.WRITE | OPEN_MODE.EXCL,\n  'xa': OPEN_MODE.APPEND | OPEN_MODE.CREAT | OPEN_MODE.WRITE | OPEN_MODE.EXCL,\n  'a+': OPEN_MODE.APPEND | OPEN_MODE.CREAT | OPEN_MODE.READ | OPEN_MODE.WRITE,\n  'ax+': OPEN_MODE.APPEND | OPEN_MODE.CREAT | OPEN_MODE.READ | OPEN_MODE.WRITE\n         | OPEN_MODE.EXCL,\n  'xa+': OPEN_MODE.APPEND | OPEN_MODE.CREAT | OPEN_MODE.READ | OPEN_MODE.WRITE\n         | OPEN_MODE.EXCL\n};\nvar stringFlagMapKeys = Object.keys(stringFlagMap);\n\nfunction stringToFlags(str) {\n  var flags = stringFlagMap[str];\n  if (flags !== undefined)\n    return flags;\n  return null;\n}\nSFTPStream.stringToFlags = stringToFlags;\n\nfunction flagsToString(flags) {\n  for (var i = 0; i < stringFlagMapKeys.length; ++i) {\n    var key = stringFlagMapKeys[i];\n    if (stringFlagMap[key] === flags)\n      return key;\n  }\n  return null;\n}\nSFTPStream.flagsToString = flagsToString;\n\nfunction Stats(initial) {\n  this.mode = (initial && initial.mode);\n  this.permissions = this.mode; // backwards compatiblity\n  this.uid = (initial && initial.uid);\n  this.gid = (initial && initial.gid);\n  this.size = (initial && initial.size);\n  this.atime = (initial && initial.atime);\n  this.mtime = (initial && initial.mtime);\n}\nStats.prototype._checkModeProperty = function(property) {\n  return ((this.mode & constants.S_IFMT) === property);\n};\nStats.prototype.isDirectory = function() {\n  return this._checkModeProperty(constants.S_IFDIR);\n};\nStats.prototype.isFile = function() {\n  return this._checkModeProperty(constants.S_IFREG);\n};\nStats.prototype.isBlockDevice = function() {\n  return this._checkModeProperty(constants.S_IFBLK);\n};\nStats.prototype.isCharacterDevice = function() {\n  return this._checkModeProperty(constants.S_IFCHR);\n};\nStats.prototype.isSymbolicLink = function() {\n  return this._checkModeProperty(constants.S_IFLNK);\n};\nStats.prototype.isFIFO = function() {\n  return this._checkModeProperty(constants.S_IFIFO);\n};\nStats.prototype.isSocket = function() {\n  return this._checkModeProperty(constants.S_IFSOCK);\n};\nSFTPStream.Stats = Stats;\n\n// =============================================================================\n// ReadStream/WriteStream-related\nvar {\n  validateNumber,\n  destroyImpl,\n  ERR_OUT_OF_RANGE,\n  ERR_INVALID_ARG_TYPE\n} = __webpack_require__(/*! ./node-fs-compat */ \"./node_modules/ssh2-streams/lib/node-fs-compat.js\");\n\nvar kMinPoolSpace = 128;\n\nvar pool;\n// It can happen that we expect to read a large chunk of data, and reserve\n// a large chunk of the pool accordingly, but the read() call only filled\n// a portion of it. If a concurrently executing read() then uses the same pool,\n// the \"reserved\" portion cannot be used, so we allow it to be re-used as a\n// new pool later.\nvar poolFragments = [];\n\nfunction allocNewPool(poolSize) {\n  if (poolFragments.length > 0)\n    pool = poolFragments.pop();\n  else\n    pool = Buffer.allocUnsafe(poolSize);\n  pool.used = 0;\n}\n\n// Check the `this.start` and `this.end` of stream.\nfunction checkPosition(pos, name) {\n  if (!Number.isSafeInteger(pos)) {\n    validateNumber(pos, name);\n    if (!Number.isInteger(pos))\n      throw new ERR_OUT_OF_RANGE(name, 'an integer', pos);\n    throw new ERR_OUT_OF_RANGE(name, '>= 0 and <= 2 ** 53 - 1', pos);\n  }\n  if (pos < 0)\n    throw new ERR_OUT_OF_RANGE(name, '>= 0 and <= 2 ** 53 - 1', pos);\n}\n\nfunction roundUpToMultipleOf8(n) {\n  return (n + 7) & ~7;  // Align to 8 byte boundary.\n}\n\nfunction ReadStream(sftp, path, options) {\n  if (options === undefined)\n    options = {};\n  else if (typeof options === 'string')\n    options = { encoding: options };\n  else if (options === null || typeof options !== 'object')\n    throw new TypeError('\"options\" argument must be a string or an object');\n  else\n    options = Object.create(options);\n\n  // A little bit bigger buffer and water marks by default\n  if (options.highWaterMark === undefined)\n    options.highWaterMark = 64 * 1024;\n\n  // For backwards compat do not emit close on destroy.\n  options.emitClose = false;\n\n  ReadableStream.call(this, options);\n\n  this.path = path;\n  this.flags = options.flags === undefined ? 'r' : options.flags;\n  this.mode = options.mode === undefined ? 0o666 : options.mode;\n\n  this.start = options.start;\n  this.end = options.end;\n  this.autoClose = options.autoClose === undefined ? true : options.autoClose;\n  this.pos = 0;\n  this.bytesRead = 0;\n  this.closed = false;\n\n  this.handle = options.handle === undefined ? null : options.handle;\n  this.sftp = sftp;\n  this._opening = false;\n\n  if (this.start !== undefined) {\n    checkPosition(this.start, 'start');\n\n    this.pos = this.start;\n  }\n\n  if (this.end === undefined) {\n    this.end = Infinity;\n  } else if (this.end !== Infinity) {\n    checkPosition(this.end, 'end');\n\n    if (this.start !== undefined && this.start > this.end) {\n      throw new ERR_OUT_OF_RANGE(\n        'start',\n        `<= \"end\" (here: ${this.end})`,\n        this.start\n      );\n    }\n  }\n\n  this.on('end', function() {\n    if (this.autoClose)\n      this.destroy();\n  });\n\n  if (!Buffer.isBuffer(this.handle))\n    this.open();\n}\ninherits(ReadStream, ReadableStream);\n\nReadStream.prototype.open = function() {\n  if (this._opening)\n    return;\n\n  this._opening = true;\n\n  this.sftp.open(this.path, this.flags, this.mode, (er, handle) => {\n    this._opening = false;\n\n    if (er) {\n      this.emit('error', er);\n      if (this.autoClose)\n        this.destroy();\n      return;\n    }\n\n    this.handle = handle;\n    this.emit('open', handle);\n    this.emit('ready');\n    // start the flow of data.\n    this.read();\n  });\n};\n\nReadStream.prototype._read = function(n) {\n  if (!Buffer.isBuffer(this.handle)) {\n    return this.once('open', function() {\n      this._read(n);\n    });\n  }\n\n  // XXX: safe to remove this?\n  if (this.destroyed)\n    return;\n\n  if (!pool || pool.length - pool.used < kMinPoolSpace) {\n    // discard the old pool.\n    allocNewPool(this.readableHighWaterMark\n                 || this._readableState.highWaterMark);\n  }\n\n  // Grab another reference to the pool in the case that while we're\n  // in the thread pool another read() finishes up the pool, and\n  // allocates a new one.\n  var thisPool = pool;\n  var toRead = Math.min(pool.length - pool.used, n);\n  var start = pool.used;\n\n  if (this.end !== undefined)\n    toRead = Math.min(this.end - this.pos + 1, toRead);\n\n  // Already read everything we were supposed to read!\n  // treat as EOF.\n  if (toRead <= 0)\n    return this.push(null);\n\n  // the actual read.\n  this.sftp.readData(this.handle,\n                     pool,\n                     pool.used,\n                     toRead,\n                     this.pos,\n                     (er, bytesRead) => {\n    if (er) {\n      this.emit('error', er);\n      if (this.autoClose)\n        this.destroy();\n      return;\n    }\n    var b = null;\n\n    // Now that we know how much data we have actually read, re-wind the\n    // 'used' field if we can, and otherwise allow the remainder of our\n    // reservation to be used as a new pool later.\n    if (start + toRead === thisPool.used && thisPool === pool) {\n      var newUsed = thisPool.used + bytesRead - toRead;\n      thisPool.used = roundUpToMultipleOf8(newUsed);\n    } else {\n      // Round down to the next lowest multiple of 8 to ensure the new pool\n      // fragment start and end positions are aligned to an 8 byte boundary.\n      var alignedEnd = (start + toRead) & ~7;\n      var alignedStart = roundUpToMultipleOf8(start + bytesRead);\n      if (alignedEnd - alignedStart >= kMinPoolSpace)\n        poolFragments.push(thisPool.slice(alignedStart, alignedEnd));\n    }\n\n    if (bytesRead > 0) {\n      this.bytesRead += bytesRead;\n      b = thisPool.slice(start, start + bytesRead);\n    }\n\n    // Move the pool positions, and internal position for reading.\n    this.pos += bytesRead;\n\n    this.push(b);\n  });\n\n  pool.used = roundUpToMultipleOf8(pool.used + toRead);\n};\n\nif (typeof ReadableStream.prototype.destroy !== 'function')\n  ReadStream.prototype.destroy = destroyImpl;\n\nReadStream.prototype._destroy = function(err, cb) {\n  if (this._opening && !Buffer.isBuffer(this.handle)) {\n    this.once('open', closeStream.bind(null, this, cb, err));\n    return;\n  }\n\n  closeStream(this, cb, err);\n  this.handle = null;\n  this._opening = false;\n};\n\nfunction closeStream(stream, cb, err) {\n  if (!stream.handle)\n    return onclose();\n\n  stream.sftp.close(stream.handle, onclose);\n\n  function onclose(er) {\n    er = er || err;\n    cb(er);\n    stream.closed = true;\n    if (!er)\n      stream.emit('close');\n  }\n}\n\nReadStream.prototype.close = function(cb) {\n  this.destroy(null, cb);\n};\n\nObject.defineProperty(ReadStream.prototype, 'pending', {\n  get() { return this.handle === null; },\n  configurable: true\n});\n\nfunction WriteStream(sftp, path, options) {\n  if (options === undefined)\n    options = {};\n  else if (typeof options === 'string')\n    options = { encoding: options };\n  else if (options === null || typeof options !== 'object')\n    throw new TypeError('\"options\" argument must be a string or an object');\n  else\n    options = Object.create(options);\n\n  // For backwards compat do not emit close on destroy.\n  options.emitClose = false;\n\n  WritableStream.call(this, options);\n\n  this.path = path;\n  this.flags = options.flags === undefined ? 'w' : options.flags;\n  this.mode = options.mode === undefined ? 0o666 : options.mode;\n\n  this.start = options.start;\n  this.autoClose = options.autoClose === undefined ? true : options.autoClose;\n  this.pos = 0;\n  this.bytesWritten = 0;\n  this.closed = false;\n\n  this.handle = options.handle === undefined ? null : options.handle;\n  this.sftp = sftp;\n  this._opening = false;\n\n  if (this.start !== undefined) {\n    checkPosition(this.start, 'start');\n\n    this.pos = this.start;\n  }\n\n  if (options.encoding)\n    this.setDefaultEncoding(options.encoding);\n\n  // Node v6.x only\n  this.on('finish', function() {\n    if (this._writableState.finalCalled)\n      return;\n    if (this.autoClose)\n      this.destroy();\n  });\n\n  if (!Buffer.isBuffer(this.handle))\n    this.open();\n}\ninherits(WriteStream, WritableStream);\n\nWriteStream.prototype._final = function(cb) {\n  if (this.autoClose)\n    this.destroy();\n  cb();\n};\n\nWriteStream.prototype.open = function() {\n  if (this._opening)\n    return;\n\n  this._opening = true;\n\n  this.sftp.open(this.path, this.flags, this.mode, (er, handle) => {\n    this._opening = false;\n\n    if (er) {\n      this.emit('error', er);\n      if (this.autoClose)\n        this.destroy();\n      return;\n    }\n\n    this.handle = handle;\n\n    var tryAgain = (err) => {\n      if (err) {\n        // Try chmod() for sftp servers that may not support fchmod() for\n        // whatever reason\n        this.sftp.chmod(this.path, this.mode, (err_) => {\n          tryAgain();\n        });\n        return;\n      }\n\n      // SFTPv3 requires absolute offsets, no matter the open flag used\n      if (this.flags[0] === 'a') {\n        var tryStat = (err, st) => {\n          if (err) {\n            // Try stat() for sftp servers that may not support fstat() for\n            // whatever reason\n            this.sftp.stat(this.path, (err_, st_) => {\n              if (err_) {\n                this.destroy();\n                this.emit('error', err);\n                return;\n              }\n              tryStat(null, st_);\n            });\n            return;\n          }\n\n          this.pos = st.size;\n          this.emit('open', handle);\n          this.emit('ready');\n        };\n\n        this.sftp.fstat(handle, tryStat);\n        return;\n      }\n\n      this.emit('open', handle);\n      this.emit('ready');\n    };\n\n    this.sftp.fchmod(handle, this.mode, tryAgain);\n  });\n};\n\nWriteStream.prototype._write = function(data, encoding, cb) {\n  if (!Buffer.isBuffer(data)) {\n    const err = new ERR_INVALID_ARG_TYPE('data', 'Buffer', data);\n    return this.emit('error', err);\n  }\n\n  if (!Buffer.isBuffer(this.handle)) {\n    return this.once('open', function() {\n      this._write(data, encoding, cb);\n    });\n  }\n\n  this.sftp.writeData(this.handle,\n                      data,\n                      0,\n                      data.length,\n                      this.pos,\n                      (er, bytes) => {\n    if (er) {\n      if (this.autoClose)\n        this.destroy();\n      return cb(er);\n    }\n    this.bytesWritten += bytes;\n    cb();\n  });\n\n  this.pos += data.length;\n};\n\nWriteStream.prototype._writev = function(data, cb) {\n  if (!Buffer.isBuffer(this.handle)) {\n    return this.once('open', function() {\n      this._writev(data, cb);\n    });\n  }\n\n  var sftp = this.sftp;\n  var handle = this.handle;\n  var writesLeft = data.length;\n\n  var onwrite = (er, bytes) => {\n    if (er) {\n      this.destroy();\n      return cb(er);\n    }\n    this.bytesWritten += bytes;\n    if (--writesLeft === 0)\n      cb();\n  };\n\n  for (var i = 0; i < data.length; ++i) {\n    var chunk = data[i].chunk;\n\n    sftp.writeData(handle, chunk, 0, chunk.length, this.pos, onwrite);\n    this.pos += chunk.length;\n  }\n};\n\nif (typeof WritableStream.prototype.destroy !== 'function')\n  WriteStream.prototype.destroy = ReadStream.prototype.destroy;\n\nWriteStream.prototype._destroy = ReadStream.prototype._destroy;\nWriteStream.prototype.close = function(cb) {\n  if (cb) {\n    if (this.closed) {\n      process.nextTick(cb);\n      return;\n    } else {\n      this.on('close', cb);\n    }\n  }\n\n  // If we are not autoClosing, we should call\n  // destroy on 'finish'.\n  if (!this.autoClose)\n    this.on('finish', this.destroy.bind(this));\n\n  this.end();\n};\n\n// There is no shutdown() for files.\nWriteStream.prototype.destroySoon = WriteStream.prototype.end;\n\nObject.defineProperty(WriteStream.prototype, 'pending', {\n  get() { return this.handle === null; },\n  configurable: true\n});\n\nmodule.exports = SFTPStream;\n\n\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/lib/sftp.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/lib/ssh.js":
/*!**********************************************!*\
  !*** ./node_modules/ssh2-streams/lib/ssh.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// TODO: * Automatic re-key every (configurable) n bytes or length of time\n//         - RFC suggests every 1GB of transmitted data or 1 hour, whichever\n//           comes sooner\n//       * Filter control codes from strings\n//         (as per http://tools.ietf.org/html/rfc4251#section-9.2)\n\nvar crypto = __webpack_require__(/*! crypto */ \"crypto\");\nvar zlib = __webpack_require__(/*! zlib */ \"zlib\");\nvar TransformStream = __webpack_require__(/*! stream */ \"stream\").Transform;\nvar inherits = __webpack_require__(/*! util */ \"util\").inherits;\nvar inspect = __webpack_require__(/*! util */ \"util\").inspect;\n\nvar StreamSearch = __webpack_require__(/*! streamsearch */ \"./node_modules/streamsearch/lib/sbmh.js\");\n\nvar readUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2-streams/lib/buffer-helpers.js\").readUInt32BE;\nvar writeUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2-streams/lib/buffer-helpers.js\").writeUInt32BE;\nvar consts = __webpack_require__(/*! ./constants */ \"./node_modules/ssh2-streams/lib/constants.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/ssh2-streams/lib/utils.js\");\nvar iv_inc = utils.iv_inc;\nvar readString = utils.readString;\nvar readInt = utils.readInt;\nvar DSASigBERToBare = utils.DSASigBERToBare;\nvar ECDSASigASN1ToSSH = utils.ECDSASigASN1ToSSH;\nvar sigSSHToASN1 = utils.sigSSHToASN1;\nvar parseDERKey = __webpack_require__(/*! ./keyParser */ \"./node_modules/ssh2-streams/lib/keyParser.js\").parseDERKey;\n\nvar CIPHER_INFO = consts.CIPHER_INFO;\nvar HMAC_INFO = consts.HMAC_INFO;\nvar MESSAGE = consts.MESSAGE;\nvar DYNAMIC_KEXDH_MESSAGE = consts.DYNAMIC_KEXDH_MESSAGE;\nvar KEXDH_MESSAGE = consts.KEXDH_MESSAGE;\nvar ALGORITHMS = consts.ALGORITHMS;\nvar DISCONNECT_REASON = consts.DISCONNECT_REASON;\nvar CHANNEL_OPEN_FAILURE = consts.CHANNEL_OPEN_FAILURE;\nvar SSH_TO_OPENSSL = consts.SSH_TO_OPENSSL;\nvar TERMINAL_MODE = consts.TERMINAL_MODE;\nvar SIGNALS = consts.SIGNALS;\nvar EDDSA_SUPPORTED = consts.EDDSA_SUPPORTED;\nvar BUGS = consts.BUGS;\nvar BUGGY_IMPLS = consts.BUGGY_IMPLS;\nvar BUGGY_IMPLS_LEN = BUGGY_IMPLS.length;\nvar MODULE_VER = __webpack_require__(/*! ../package.json */ \"./node_modules/ssh2-streams/package.json\").version;\nvar I = 0;\nvar IN_INIT = I++;\nvar IN_GREETING = I++;\nvar IN_HEADER = I++;\nvar IN_PACKETBEFORE = I++;\nvar IN_PACKET = I++;\nvar IN_PACKETDATA = I++;\nvar IN_PACKETDATAVERIFY = I++;\nvar IN_PACKETDATAAFTER = I++;\nvar OUT_INIT = I++;\nvar OUT_READY = I++;\nvar OUT_REKEYING = I++;\nvar MAX_SEQNO = 4294967295;\nvar MAX_PACKET_SIZE = 35000;\nvar MAX_PACKETS_REKEYING = 50;\nvar EXP_TYPE_HEADER = 0;\nvar EXP_TYPE_LF = 1;\nvar EXP_TYPE_BYTES = 2; // Waits until n bytes have been seen\nvar Z_PARTIAL_FLUSH = zlib.Z_PARTIAL_FLUSH;\nvar ZLIB_OPTS = { flush: Z_PARTIAL_FLUSH };\n\nvar RE_KEX_HASH = /-(.+)$/;\nvar RE_GEX = /^gex-/;\nvar RE_NULL = /\\x00/g;\n\nvar IDENT_PREFIX_BUFFER = Buffer.from('SSH-');\nvar EMPTY_BUFFER = Buffer.allocUnsafe(0);\nvar HMAC_COMPUTE = Buffer.allocUnsafe(9);\nvar PING_PACKET = Buffer.from([\n  MESSAGE.GLOBAL_REQUEST,\n  // \"keepalive@openssh.com\"\n  0, 0, 0, 21,\n    107, 101, 101, 112, 97, 108, 105, 118, 101, 64, 111, 112, 101, 110, 115,\n    115, 104, 46, 99, 111, 109,\n  // Request a reply\n  1\n]);\nvar NEWKEYS_PACKET = Buffer.from([MESSAGE.NEWKEYS]);\nvar USERAUTH_SUCCESS_PACKET = Buffer.from([MESSAGE.USERAUTH_SUCCESS]);\nvar REQUEST_SUCCESS_PACKET = Buffer.from([MESSAGE.REQUEST_SUCCESS]);\nvar REQUEST_FAILURE_PACKET = Buffer.from([MESSAGE.REQUEST_FAILURE]);\nvar NO_TERMINAL_MODES_BUFFER = Buffer.from([TERMINAL_MODE.TTY_OP_END]);\nvar KEXDH_GEX_REQ_PACKET = Buffer.from([\n  MESSAGE.KEXDH_GEX_REQUEST,\n  // Minimal size in bits of an acceptable group\n  0, 0, 4, 0, // 1024, modp2\n  // Preferred size in bits of the group the server will send\n  0, 0, 16, 0, // 4096, modp16\n  // Maximal size in bits of an acceptable group\n  0, 0, 32, 0 // 8192, modp18\n]);\n\nfunction DEBUG_NOOP(msg) {}\n\nfunction SSH2Stream(cfg) {\n  if (typeof cfg !== 'object' || cfg === null)\n    cfg = {};\n\n  TransformStream.call(this, {\n    highWaterMark: (typeof cfg.highWaterMark === 'number'\n                    ? cfg.highWaterMark\n                    : 32 * 1024)\n  });\n\n  this._needContinue = false;\n  this.bytesSent = this.bytesReceived = 0;\n  this.debug = (typeof cfg.debug === 'function' ? cfg.debug : DEBUG_NOOP);\n  this.server = (cfg.server === true);\n  this.maxPacketSize = (typeof cfg.maxPacketSize === 'number'\n                        ? cfg.maxPacketSize\n                        : MAX_PACKET_SIZE);\n  // Bitmap that indicates any bugs the remote side has. This is determined\n  // by the reported software version.\n  this.remoteBugs = 0;\n\n  if (this.server) {\n    // TODO: Remove when we support group exchange for server implementation\n    this.remoteBugs = BUGS.BAD_DHGEX;\n  }\n\n  this.readable = true;\n\n  var self = this;\n\n  var hostKeys = cfg.hostKeys;\n  if (this.server && (typeof hostKeys !== 'object' || hostKeys === null))\n    throw new Error('hostKeys must be an object keyed on host key type');\n\n  this.config = {\n    // Server\n    hostKeys: hostKeys, // All keys supported by server\n\n    // Client/Server\n    ident: 'SSH-2.0-'\n           + (cfg.ident\n              || ('ssh2js' + MODULE_VER + (this.server ? 'srv' : ''))),\n    algorithms: {\n      kex: ALGORITHMS.KEX,\n      kexBuf: ALGORITHMS.KEX_BUF,\n      serverHostKey: ALGORITHMS.SERVER_HOST_KEY,\n      serverHostKeyBuf: ALGORITHMS.SERVER_HOST_KEY_BUF,\n      cipher: ALGORITHMS.CIPHER,\n      cipherBuf: ALGORITHMS.CIPHER_BUF,\n      hmac: ALGORITHMS.HMAC,\n      hmacBuf: ALGORITHMS.HMAC_BUF,\n      compress: ALGORITHMS.COMPRESS,\n      compressBuf: ALGORITHMS.COMPRESS_BUF\n    }\n  };\n  // RFC 4253 states the identification string must not contain NULL\n  this.config.ident.replace(RE_NULL, '');\n\n  if (this.config.ident.length + 2 /* Account for \"\\r\\n\" */ > 255)\n    throw new Error('ident too long');\n\n  if (typeof cfg.algorithms === 'object' && cfg.algorithms !== null) {\n    var algos = cfg.algorithms;\n    if (Array.isArray(algos.kex) && algos.kex.length > 0) {\n      this.config.algorithms.kex = algos.kex;\n      if (!Buffer.isBuffer(algos.kexBuf))\n        algos.kexBuf = Buffer.from(algos.kex.join(','), 'ascii');\n      this.config.algorithms.kexBuf = algos.kexBuf;\n    }\n    if (Array.isArray(algos.serverHostKey) && algos.serverHostKey.length > 0) {\n      this.config.algorithms.serverHostKey = algos.serverHostKey;\n      if (!Buffer.isBuffer(algos.serverHostKeyBuf)) {\n        algos.serverHostKeyBuf = Buffer.from(algos.serverHostKey.join(','),\n                                             'ascii');\n      }\n      this.config.algorithms.serverHostKeyBuf = algos.serverHostKeyBuf;\n    }\n    if (Array.isArray(algos.cipher) && algos.cipher.length > 0) {\n      this.config.algorithms.cipher = algos.cipher;\n      if (!Buffer.isBuffer(algos.cipherBuf))\n        algos.cipherBuf = Buffer.from(algos.cipher.join(','), 'ascii');\n      this.config.algorithms.cipherBuf = algos.cipherBuf;\n    }\n    if (Array.isArray(algos.hmac) && algos.hmac.length > 0) {\n      this.config.algorithms.hmac = algos.hmac;\n      if (!Buffer.isBuffer(algos.hmacBuf))\n        algos.hmacBuf = Buffer.from(algos.hmac.join(','), 'ascii');\n      this.config.algorithms.hmacBuf = algos.hmacBuf;\n    }\n    if (Array.isArray(algos.compress) && algos.compress.length > 0) {\n      this.config.algorithms.compress = algos.compress;\n      if (!Buffer.isBuffer(algos.compressBuf))\n        algos.compressBuf = Buffer.from(algos.compress.join(','), 'ascii');\n      this.config.algorithms.compressBuf = algos.compressBuf;\n    }\n  }\n\n  this.reset(true);\n\n  // Common events\n  this.on('end', function() {\n    // Let GC collect any Buffers we were previously storing\n    self.readable = false;\n    self._state = undefined;\n    self.reset();\n    self._state.outgoing.bufSeqno = undefined;\n  });\n  this.on('DISCONNECT', function(reason, code, desc, lang) {\n    onDISCONNECT(self, reason, code, desc, lang);\n  });\n  this.on('KEXINIT', function(init, firstFollows) {\n    onKEXINIT(self, init, firstFollows);\n  });\n  this.on('NEWKEYS', function() { onNEWKEYS(self); });\n\n  if (this.server) {\n    // Server-specific events\n    this.on('KEXDH_INIT', function(e) { onKEXDH_INIT(self, e); });\n  } else {\n    // Client-specific events\n    this.on('KEXDH_REPLY', function(info) { onKEXDH_REPLY(self, info); })\n        .on('KEXDH_GEX_GROUP',\n            function(prime, gen) { onKEXDH_GEX_GROUP(self, prime, gen); });\n  }\n\n  if (this.server) {\n    // Greeting displayed before the ssh identification string is sent, this is\n    // usually ignored by most clients\n    if (typeof cfg.greeting === 'string' && cfg.greeting.length) {\n      if (cfg.greeting.slice(-2) === '\\r\\n')\n        this.push(cfg.greeting);\n      else\n        this.push(cfg.greeting + '\\r\\n');\n    }\n    // Banner shown after the handshake completes, but before user\n    // authentication begins\n    if (typeof cfg.banner === 'string' && cfg.banner.length) {\n      if (cfg.banner.slice(-2) === '\\r\\n')\n        this.banner = cfg.banner;\n      else\n        this.banner = cfg.banner + '\\r\\n';\n    }\n  }\n  this.debug('DEBUG: Local ident: ' + inspect(this.config.ident));\n  this.push(this.config.ident + '\\r\\n');\n\n  this._state.incoming.expectedPacket = 'KEXINIT';\n}\ninherits(SSH2Stream, TransformStream);\n\nSSH2Stream.prototype.__read = TransformStream.prototype._read;\nSSH2Stream.prototype._read = function(n) {\n  if (this._needContinue) {\n    this._needContinue = false;\n    this.emit('continue');\n  }\n  return this.__read(n);\n};\nSSH2Stream.prototype.__push = TransformStream.prototype.push;\nSSH2Stream.prototype.push = function(chunk, encoding) {\n  var ret = this.__push(chunk, encoding);\n  this._needContinue = (ret === false);\n  return ret;\n};\n\nSSH2Stream.prototype._cleanup = function(callback) {\n  this.reset();\n  this.debug('DEBUG: Parser: Malformed packet');\n  callback && callback(new Error('Malformed packet'));\n};\n\nSSH2Stream.prototype._transform = function(chunk, encoding, callback, decomp) {\n  var skipDecrypt = false;\n  var decryptAuthMode = false;\n  var state = this._state;\n  var instate = state.incoming;\n  var outstate = state.outgoing;\n  var expect = instate.expect;\n  var decrypt = instate.decrypt;\n  var decompress = instate.decompress;\n  var chlen = chunk.length;\n  var chleft = 0;\n  var debug = this.debug;\n  var self = this;\n  var i = 0;\n  var p = i;\n  var blockLen;\n  var buffer;\n  var buf;\n  var r;\n\n  this.bytesReceived += chlen;\n\n  while (true) {\n    if (expect.type !== undefined) {\n      if (i >= chlen)\n        break;\n      if (expect.type === EXP_TYPE_BYTES) {\n        chleft = (chlen - i);\n        var pktLeft = (expect.buf.length - expect.ptr);\n        if (pktLeft <= chleft) {\n          chunk.copy(expect.buf, expect.ptr, i, i + pktLeft);\n          i += pktLeft;\n          buffer = expect.buf;\n          expect.buf = undefined;\n          expect.ptr = 0;\n          expect.type = undefined;\n        } else {\n          chunk.copy(expect.buf, expect.ptr, i);\n          expect.ptr += chleft;\n          i += chleft;\n        }\n        continue;\n      } else if (expect.type === EXP_TYPE_HEADER) {\n        i += instate.search.push(chunk);\n        if (expect.type !== undefined)\n          continue;\n      } else if (expect.type === EXP_TYPE_LF) {\n        if (++expect.ptr + 4 /* Account for \"SSH-\" */ > 255) {\n          this.reset();\n          debug('DEBUG: Parser: Identification string exceeded 255 characters');\n          return callback(new Error('Max identification string size exceeded'));\n        }\n        if (chunk[i] === 0x0A) {\n          expect.type = undefined;\n          if (p < i) {\n            if (expect.buf === undefined)\n              expect.buf = chunk.toString('ascii', p, i);\n            else\n              expect.buf += chunk.toString('ascii', p, i);\n          }\n          buffer = expect.buf;\n          expect.buf = undefined;\n          ++i;\n        } else {\n          if (++i === chlen && p < i) {\n            if (expect.buf === undefined)\n              expect.buf = chunk.toString('ascii', p, i);\n            else\n              expect.buf += chunk.toString('ascii', p, i);\n          }\n          continue;\n        }\n      }\n    }\n\n    if (instate.status === IN_INIT) {\n      if (!this.readable)\n        return callback();\n      if (this.server) {\n        // Retrieve what should be the start of the protocol version exchange\n        if (!buffer) {\n          debug('DEBUG: Parser: IN_INIT (waiting for identification begin)');\n          expectData(this, EXP_TYPE_BYTES, 4);\n        } else {\n          if (buffer[0] === 0x53       // S\n              && buffer[1] === 0x53    // S\n              && buffer[2] === 0x48    // H\n              && buffer[3] === 0x2D) { // -\n            instate.status = IN_GREETING;\n            debug('DEBUG: Parser: IN_INIT (waiting for rest of identification)');\n          } else {\n            this.reset();\n            debug('DEBUG: Parser: Bad identification start');\n            return callback(new Error('Bad identification start'));\n          }\n        }\n      } else {\n        debug('DEBUG: Parser: IN_INIT');\n        // Retrieve any bytes that may come before the protocol version exchange\n        var ss = instate.search = new StreamSearch(IDENT_PREFIX_BUFFER);\n        ss.on('info', function onInfo(matched, data, start, end) {\n          if (data) {\n            if (instate.greeting === undefined)\n              instate.greeting = data.toString('binary', start, end);\n            else\n              instate.greeting += data.toString('binary', start, end);\n          }\n          if (matched) {\n            expect.type = undefined;\n            instate.search.removeListener('info', onInfo);\n          }\n        });\n        ss.maxMatches = 1;\n        expectData(this, EXP_TYPE_HEADER);\n        instate.status = IN_GREETING;\n      }\n    } else if (instate.status === IN_GREETING) {\n      debug('DEBUG: Parser: IN_GREETING');\n      instate.search = undefined;\n      // Retrieve the identification bytes after the \"SSH-\" header\n      p = i;\n      expectData(this, EXP_TYPE_LF);\n      instate.status = IN_HEADER;\n    } else if (instate.status === IN_HEADER) {\n      debug('DEBUG: Parser: IN_HEADER');\n      if (buffer.charCodeAt(buffer.length - 1) === 13)\n        buffer = buffer.slice(0, -1);\n      var idxDash = buffer.indexOf('-');\n      var idxSpace = buffer.indexOf(' ');\n      var header = {\n        // RFC says greeting SHOULD be utf8\n        greeting: instate.greeting,\n        identRaw: 'SSH-' + buffer,\n        versions: {\n          protocol: buffer.substr(0, idxDash),\n          software: (idxSpace === -1\n                     ? buffer.substring(idxDash + 1)\n                     : buffer.substring(idxDash + 1, idxSpace))\n        },\n        comments: (idxSpace > -1 ? buffer.substring(idxSpace + 1) : undefined)\n      };\n      instate.greeting = undefined;\n\n      if (header.versions.protocol !== '1.99'\n          && header.versions.protocol !== '2.0') {\n        this.reset();\n        debug('DEBUG: Parser: protocol version not supported: '\n              + header.versions.protocol);\n        return callback(new Error('Protocol version not supported'));\n      } else\n        this.emit('header', header);\n\n      if (instate.status === IN_INIT) {\n        // We reset from an event handler, possibly due to an unsupported SSH\n        // protocol version?\n        return;\n      }\n\n      var identRaw = header.identRaw;\n      var software = header.versions.software;\n      this.debug('DEBUG: Remote ident: ' + inspect(identRaw));\n      for (var j = 0, rule; j < BUGGY_IMPLS_LEN; ++j) {\n        rule = BUGGY_IMPLS[j];\n        if (typeof rule[0] === 'string') {\n          if (software === rule[0])\n            this.remoteBugs |= rule[1];\n        } else if (rule[0].test(software))\n          this.remoteBugs |= rule[1];\n      }\n      instate.identRaw = identRaw;\n      // Adjust bytesReceived first otherwise it will have an incorrectly larger\n      // total when we call back into this function after completing KEXINIT\n      this.bytesReceived -= (chlen - i);\n      KEXINIT(this, function() {\n        if (i === chlen)\n          callback();\n        else\n          self._transform(chunk.slice(i), encoding, callback);\n      });\n      instate.status = IN_PACKETBEFORE;\n      return;\n    } else if (instate.status === IN_PACKETBEFORE) {\n      blockLen = (decrypt.instance ? decrypt.info.blockLen : 8);\n      debug('DEBUG: Parser: IN_PACKETBEFORE (expecting ' + blockLen + ')');\n      // Wait for the right number of bytes so we can determine the incoming\n      // packet length\n      expectData(this, EXP_TYPE_BYTES, blockLen, decrypt.buf);\n      instate.status = IN_PACKET;\n    } else if (instate.status === IN_PACKET) {\n      debug('DEBUG: Parser: IN_PACKET');\n      if (decrypt.instance) {\n        decryptAuthMode = (decrypt.info.authLen > 0);\n        if (!decryptAuthMode)\n          buffer = decryptData(this, buffer);\n        blockLen = decrypt.info.blockLen;\n      } else {\n        decryptAuthMode = false;\n        blockLen = 8;\n      }\n\n      r = readInt(buffer, 0, this, callback);\n      if (r === false)\n        return;\n      var hmacInfo = instate.hmac.info;\n      var macSize;\n      if (hmacInfo)\n        macSize = hmacInfo.actualLen;\n      else\n        macSize = 0;\n      var fullPacketLen = r + 4 + macSize;\n      var maxPayloadLen = this.maxPacketSize;\n      if (decompress.instance) {\n        // Account for compressed payloads\n        // This formula is taken from dropbear which derives it from zlib's\n        // documentation. Explanation from dropbear:\n        /* For exact details see http://www.zlib.net/zlib_tech.html\n         * 5 bytes per 16kB block, plus 6 bytes for the stream.\n         * We might allocate 5 unnecessary bytes here if it's an\n         * exact multiple. */\n        maxPayloadLen += (((this.maxPacketSize / 16384) + 1) * 5 + 6);\n      }\n      if (r > maxPayloadLen\n          // TODO: Change 16 to \"MAX(16, decrypt.info.blockLen)\" when/if SSH2\n          // adopts 512-bit ciphers\n          || fullPacketLen < (16 + macSize)\n          || ((r + (decryptAuthMode ? 0 : 4)) % blockLen) !== 0) {\n        this.disconnect(DISCONNECT_REASON.PROTOCOL_ERROR);\n        debug('DEBUG: Parser: Bad packet length (' + fullPacketLen + ')');\n        return callback(new Error('Bad packet length'));\n      }\n\n      instate.pktLen = r;\n      var remainLen = instate.pktLen + 4 - blockLen;\n      if (decryptAuthMode) {\n        decrypt.instance.setAAD(buffer.slice(0, 4));\n        debug('DEBUG: Parser: pktLen:'\n              + instate.pktLen\n              + ',remainLen:'\n              + remainLen);\n      } else {\n        instate.padLen = buffer[4];\n        debug('DEBUG: Parser: pktLen:'\n              + instate.pktLen\n              + ',padLen:'\n              + instate.padLen\n              + ',remainLen:'\n              + remainLen);\n      }\n      if (remainLen > 0) {\n        if (decryptAuthMode)\n          instate.pktExtra = buffer.slice(4);\n        else\n          instate.pktExtra = buffer.slice(5);\n        // Grab the rest of the packet\n        expectData(this, EXP_TYPE_BYTES, remainLen);\n        instate.status = IN_PACKETDATA;\n      } else if (remainLen < 0)\n        instate.status = IN_PACKETBEFORE;\n      else {\n        // Entire message fit into one block\n        skipDecrypt = true;\n        instate.status = IN_PACKETDATA;\n        continue;\n      }\n    } else if (instate.status === IN_PACKETDATA) {\n      debug('DEBUG: Parser: IN_PACKETDATA');\n      if (decrypt.instance) {\n        decryptAuthMode = (decrypt.info.authLen > 0);\n        if (!skipDecrypt) {\n          if (!decryptAuthMode)\n            buffer = decryptData(this, buffer);\n        } else {\n          skipDecrypt = false;\n        }\n      } else {\n        decryptAuthMode = false;\n        skipDecrypt = false;\n      }\n      var padStart = instate.pktLen - instate.padLen - 1;\n      // TODO: Allocate a Buffer once that is slightly larger than maxPacketSize\n      // (to accommodate for packet length field and MAC) and re-use that\n      // instead\n      if (instate.pktExtra) {\n        buf = Buffer.allocUnsafe(instate.pktExtra.length + buffer.length);\n        instate.pktExtra.copy(buf);\n        buffer.copy(buf, instate.pktExtra.length);\n        instate.payload = buf.slice(0, padStart);\n      } else {\n        // Entire message fit into one block\n        if (decryptAuthMode)\n          buf = buffer.slice(4);\n        else\n          buf = buffer.slice(5);\n        instate.payload = buffer.slice(5, 5 + padStart);\n      }\n      if (instate.hmac.info !== undefined) {\n        // Wait for hmac hash\n        var inHMACSize = decrypt.info.authLen || instate.hmac.info.actualLen;\n        debug('DEBUG: Parser: HMAC size:' + inHMACSize);\n        expectData(this, EXP_TYPE_BYTES, inHMACSize, instate.hmac.buf);\n        instate.status = IN_PACKETDATAVERIFY;\n        instate.packet = buf;\n      } else\n        instate.status = IN_PACKETDATAAFTER;\n      instate.pktExtra = undefined;\n      buf = undefined;\n    } else if (instate.status === IN_PACKETDATAVERIFY) {\n      debug('DEBUG: Parser: IN_PACKETDATAVERIFY');\n      // Verify packet data integrity\n      if (hmacVerify(this, buffer)) {\n        debug('DEBUG: Parser: IN_PACKETDATAVERIFY (Valid HMAC)');\n        instate.status = IN_PACKETDATAAFTER;\n        instate.packet = undefined;\n      } else {\n        this.reset();\n        debug('DEBUG: Parser: IN_PACKETDATAVERIFY (Invalid HMAC)');\n        return callback(new Error('Invalid HMAC'));\n      }\n    } else if (instate.status === IN_PACKETDATAAFTER) {\n      if (decompress.instance) {\n        if (!decomp) {\n          debug('DEBUG: Parser: Decompressing');\n          decompress.instance.write(instate.payload);\n          var decompBuf = [];\n          var decompBufLen = 0;\n          decompress.instance.on('readable', function() {\n            var buf;\n            while (buf = this.read()) {\n              decompBuf.push(buf);\n              decompBufLen += buf.length;\n            }\n          }).flush(Z_PARTIAL_FLUSH, function() {\n            decompress.instance.removeAllListeners('readable');\n            if (decompBuf.length === 1)\n              instate.payload = decompBuf[0];\n            else\n              instate.payload = Buffer.concat(decompBuf, decompBufLen);\n            decompBuf = null;\n            var nextSlice;\n            if (i === chlen)\n              nextSlice = EMPTY_BUFFER; // Avoid slicing a zero-length buffer\n            else\n              nextSlice = chunk.slice(i);\n            self._transform(nextSlice, encoding, callback, true);\n          });\n          return;\n        } else {\n          // Make sure we reset this after this first time in the loop,\n          // otherwise we could end up trying to interpret as-is another\n          // compressed packet that is within the same chunk\n          decomp = false;\n        }\n      }\n\n      this.emit('packet');\n\n      var ptype = instate.payload[0];\n\n      if (debug !== DEBUG_NOOP) {\n        var msgPacket = 'DEBUG: Parser: IN_PACKETDATAAFTER, packet: ';\n        var kexdh = state.kexdh;\n        var authMethod = state.authsQueue[0];\n        var msgPktType = null;\n\n        if (outstate.status === OUT_REKEYING\n            && !(ptype <= 4 || (ptype >= 20 && ptype <= 49)))\n          msgPacket += '(enqueued) ';\n\n        if (ptype === MESSAGE.KEXDH_INIT) {\n          if (kexdh === 'group')\n            msgPktType = 'KEXDH_INIT';\n          else if (kexdh[0] === 'e')\n            msgPktType = 'KEXECDH_INIT';\n          else\n            msgPktType = 'KEXDH_GEX_REQUEST';\n        } else if (ptype === MESSAGE.KEXDH_REPLY) {\n          if (kexdh === 'group')\n            msgPktType = 'KEXDH_REPLY';\n          else if (kexdh[0] === 'e')\n            msgPktType = 'KEXECDH_REPLY';\n          else\n            msgPktType = 'KEXDH_GEX_GROUP';\n        } else if (ptype === MESSAGE.KEXDH_GEX_GROUP)\n          msgPktType = 'KEXDH_GEX_GROUP';\n        else if (ptype === MESSAGE.KEXDH_GEX_REPLY)\n          msgPktType = 'KEXDH_GEX_REPLY';\n        else if (ptype === 60) {\n          if (authMethod === 'password')\n            msgPktType = 'USERAUTH_PASSWD_CHANGEREQ';\n          else if (authMethod === 'keyboard-interactive')\n            msgPktType = 'USERAUTH_INFO_REQUEST';\n          else if (authMethod === 'publickey')\n            msgPktType = 'USERAUTH_PK_OK';\n          else\n            msgPktType = 'UNKNOWN PACKET 60';\n        } else if (ptype === 61) {\n          if (authMethod === 'keyboard-interactive')\n            msgPktType = 'USERAUTH_INFO_RESPONSE';\n          else\n            msgPktType = 'UNKNOWN PACKET 61';\n        }\n\n        if (msgPktType === null)\n          msgPktType = MESSAGE[ptype];\n\n        // Don't write debug output for messages we custom make in parsePacket()\n        if (ptype !== MESSAGE.CHANNEL_OPEN\n            && ptype !== MESSAGE.CHANNEL_REQUEST\n            && ptype !== MESSAGE.CHANNEL_SUCCESS\n            && ptype !== MESSAGE.CHANNEL_FAILURE\n            && ptype !== MESSAGE.CHANNEL_EOF\n            && ptype !== MESSAGE.CHANNEL_CLOSE\n            && ptype !== MESSAGE.CHANNEL_DATA\n            && ptype !== MESSAGE.CHANNEL_EXTENDED_DATA\n            && ptype !== MESSAGE.CHANNEL_WINDOW_ADJUST\n            && ptype !== MESSAGE.DISCONNECT\n            && ptype !== MESSAGE.USERAUTH_REQUEST\n            && ptype !== MESSAGE.GLOBAL_REQUEST)\n          debug(msgPacket + msgPktType);\n      }\n\n      // Only parse packet if we are not re-keying or the packet is not a\n      // transport layer packet needed for re-keying\n      if (outstate.status === OUT_READY\n          || ptype <= 4\n          || (ptype >= 20 && ptype <= 49)) {\n        if (parsePacket(this, callback) === false)\n          return;\n\n        if (instate.status === IN_INIT) {\n          // We were reset due to some error/disagreement ?\n          return;\n        }\n      } else if (outstate.status === OUT_REKEYING) {\n        if (instate.rekeyQueue.length === MAX_PACKETS_REKEYING) {\n          debug('DEBUG: Parser: Max incoming re-key queue length reached');\n          this.disconnect(DISCONNECT_REASON.PROTOCOL_ERROR);\n          return callback(\n            new Error('Incoming re-key queue length limit reached')\n          );\n        }\n\n        // Make sure to record the sequence number in case we need it later on\n        // when we drain the queue (e.g. unknown packet)\n        var seqno = instate.seqno;\n        if (++instate.seqno > MAX_SEQNO)\n          instate.seqno = 0;\n\n        instate.rekeyQueue.push([seqno, instate.payload]);\n      }\n\n      instate.status = IN_PACKETBEFORE;\n      instate.payload = undefined;\n    }\n    if (buffer !== undefined)\n      buffer = undefined;\n  }\n\n  callback();\n};\n\nSSH2Stream.prototype.reset = function(noend) {\n  if (this._state) {\n    var state = this._state;\n    state.incoming.status = IN_INIT;\n    state.outgoing.status = OUT_INIT;\n  } else {\n    this._state = {\n      authsQueue: [],\n      hostkeyFormat: undefined,\n      kex: undefined,\n      kexdh: undefined,\n\n      incoming: {\n        status: IN_INIT,\n        expectedPacket: undefined,\n        search: undefined,\n        greeting: undefined,\n        seqno: 0,\n        pktLen: undefined,\n        padLen: undefined,\n        pktExtra: undefined,\n        payload: undefined,\n        packet: undefined,\n        kexinit: undefined,\n        identRaw: undefined,\n        rekeyQueue: [],\n        ignoreNext: false,\n\n        expect: {\n          amount: undefined,\n          type: undefined,\n          ptr: 0,\n          buf: undefined\n        },\n\n        decrypt: {\n          instance: false,\n          info: undefined,\n          iv: undefined,\n          key: undefined,\n          buf: undefined,\n          type: undefined\n        },\n\n        hmac: {\n          info: undefined,\n          key: undefined,\n          buf: undefined,\n          type: false\n        },\n\n        decompress: {\n          instance: false,\n          type: false\n        }\n      },\n\n      outgoing: {\n        status: OUT_INIT,\n        seqno: 0,\n        bufSeqno: Buffer.allocUnsafe(4),\n        rekeyQueue: [],\n        kexinit: undefined,\n        kexsecret: undefined,\n        pubkey: undefined,\n        exchangeHash: undefined,\n        sessionId: undefined,\n        sentNEWKEYS: false,\n\n        encrypt: {\n          instance: false,\n          info: undefined,\n          iv: undefined,\n          key: undefined,\n          type: undefined\n        },\n\n        hmac: {\n          info: undefined,\n          key: undefined,\n          buf: undefined,\n          type: false\n        },\n\n        compress: {\n          instance: false,\n          type: false,\n          queue: null\n        }\n      }\n    };\n  }\n  if (!noend) {\n    if (this.readable)\n      this.push(null);\n  }\n};\n\n// Common methods\n// Global\nSSH2Stream.prototype.disconnect = function(reason) {\n  /*\n    byte      SSH_MSG_DISCONNECT\n    uint32    reason code\n    string    description in ISO-10646 UTF-8 encoding\n    string    language tag\n  */\n  var buf = Buffer.alloc(1 + 4 + 4 + 4);\n\n  buf[0] = MESSAGE.DISCONNECT;\n\n  if (DISCONNECT_REASON[reason] === undefined)\n    reason = DISCONNECT_REASON.BY_APPLICATION;\n  writeUInt32BE(buf, reason, 1);\n\n  this.debug('DEBUG: Outgoing: Writing DISCONNECT ('\n             + DISCONNECT_REASON[reason]\n             + ')');\n  send(this, buf);\n  this.reset();\n\n  return false;\n};\nSSH2Stream.prototype.ping = function() {\n  this.debug('DEBUG: Outgoing: Writing ping (GLOBAL_REQUEST: keepalive@openssh.com)');\n  return send(this, PING_PACKET);\n};\nSSH2Stream.prototype.rekey = function() {\n  var status = this._state.outgoing.status;\n  if (status === OUT_REKEYING)\n    throw new Error('A re-key is already in progress');\n  else if (status !== OUT_READY)\n    throw new Error('Cannot re-key yet');\n\n  this.debug('DEBUG: Outgoing: Starting re-key');\n  return KEXINIT(this);\n};\n\n// 'ssh-connection' service-specific\nSSH2Stream.prototype.requestSuccess = function(data) {\n  var buf;\n  if (Buffer.isBuffer(data)) {\n    buf = Buffer.allocUnsafe(1 + data.length);\n\n    buf[0] = MESSAGE.REQUEST_SUCCESS;\n\n    data.copy(buf, 1);\n  } else\n    buf = REQUEST_SUCCESS_PACKET;\n\n  this.debug('DEBUG: Outgoing: Writing REQUEST_SUCCESS');\n  return send(this, buf);\n};\nSSH2Stream.prototype.requestFailure = function() {\n  this.debug('DEBUG: Outgoing: Writing REQUEST_FAILURE');\n  return send(this, REQUEST_FAILURE_PACKET);\n};\nSSH2Stream.prototype.channelSuccess = function(chan) {\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_SUCCESS;\n\n  writeUInt32BE(buf, chan, 1);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_SUCCESS (' + chan + ')');\n  return send(this, buf);\n};\nSSH2Stream.prototype.channelFailure = function(chan) {\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_FAILURE;\n\n  writeUInt32BE(buf, chan, 1);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_FAILURE (' + chan + ')');\n  return send(this, buf);\n};\nSSH2Stream.prototype.channelEOF = function(chan) {\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_EOF;\n\n  writeUInt32BE(buf, chan, 1);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_EOF (' + chan + ')');\n  return send(this, buf);\n};\nSSH2Stream.prototype.channelClose = function(chan) {\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_CLOSE;\n\n  writeUInt32BE(buf, chan, 1);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_CLOSE (' + chan + ')');\n  return send(this, buf);\n};\nSSH2Stream.prototype.channelWindowAdjust = function(chan, amount) {\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_WINDOW_ADJUST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, amount, 5);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_WINDOW_ADJUST ('\n             + chan\n             + ', '\n             + amount\n             + ')');\n  return send(this, buf);\n};\nSSH2Stream.prototype.channelData = function(chan, data) {\n  var dataIsBuffer = Buffer.isBuffer(data);\n  var dataLen = (dataIsBuffer ? data.length : Buffer.byteLength(data));\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + dataLen);\n\n  buf[0] = MESSAGE.CHANNEL_DATA;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, dataLen, 5);\n  if (dataIsBuffer)\n    data.copy(buf, 9);\n  else\n    buf.write(data, 9, dataLen, 'utf8');\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_DATA (' + chan + ')');\n  return send(this, buf);\n};\nSSH2Stream.prototype.channelExtData = function(chan, data, type) {\n  var dataIsBuffer = Buffer.isBuffer(data);\n  var dataLen = (dataIsBuffer ? data.length : Buffer.byteLength(data));\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 4 + dataLen);\n\n  buf[0] = MESSAGE.CHANNEL_EXTENDED_DATA;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, type, 5);\n\n  writeUInt32BE(buf, dataLen, 9);\n  if (dataIsBuffer)\n    data.copy(buf, 13);\n  else\n    buf.write(data, 13, dataLen, 'utf8');\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_EXTENDED_DATA (' + chan + ')');\n  return send(this, buf);\n};\nSSH2Stream.prototype.channelOpenConfirm = function(remoteChan, localChan,\n                                                   initWindow, maxPacket) {\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 4 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_OPEN_CONFIRMATION;\n\n  writeUInt32BE(buf, remoteChan, 1);\n\n  writeUInt32BE(buf, localChan, 5);\n\n  writeUInt32BE(buf, initWindow, 9);\n\n  writeUInt32BE(buf, maxPacket, 13);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_OPEN_CONFIRMATION (r:'\n             + remoteChan\n             + ', l:'\n             + localChan\n             + ')');\n  return send(this, buf);\n};\nSSH2Stream.prototype.channelOpenFail = function(remoteChan, reason, desc,\n                                                lang) {\n  if (typeof desc !== 'string')\n    desc = '';\n  if (typeof lang !== 'string')\n    lang = '';\n\n  var descLen = Buffer.byteLength(desc);\n  var langLen = Buffer.byteLength(lang);\n  var p = 9;\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 4 + descLen + 4 + langLen);\n\n  buf[0] = MESSAGE.CHANNEL_OPEN_FAILURE;\n\n  writeUInt32BE(buf, remoteChan, 1);\n\n  writeUInt32BE(buf, reason, 5);\n\n  writeUInt32BE(buf, descLen, p);\n  p += 4;\n  if (descLen) {\n    buf.write(desc, p, descLen, 'utf8');\n    p += descLen;\n  }\n\n  writeUInt32BE(buf, langLen, p);\n  if (langLen)\n    buf.write(lang, p += 4, langLen, 'ascii');\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_OPEN_FAILURE ('\n             + remoteChan\n             + ')');\n  return send(this, buf);\n};\n\n// Client-specific methods\n// Global\nSSH2Stream.prototype.service = function(svcName) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var svcNameLen = Buffer.byteLength(svcName);\n  var buf = Buffer.allocUnsafe(1 + 4 + svcNameLen);\n\n  buf[0] = MESSAGE.SERVICE_REQUEST;\n\n  writeUInt32BE(buf, svcNameLen, 1);\n  buf.write(svcName, 5, svcNameLen, 'ascii');\n\n  this.debug('DEBUG: Outgoing: Writing SERVICE_REQUEST (' + svcName + ')');\n  return send(this, buf);\n};\n// 'ssh-connection' service-specific\nSSH2Stream.prototype.tcpipForward = function(bindAddr, bindPort, wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var addrlen = Buffer.byteLength(bindAddr);\n  var buf = Buffer.allocUnsafe(1 + 4 + 13 + 1 + 4 + addrlen + 4);\n\n  buf[0] = MESSAGE.GLOBAL_REQUEST;\n\n  writeUInt32BE(buf, 13, 1);\n  buf.write('tcpip-forward', 5, 13, 'ascii');\n\n  buf[18] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  writeUInt32BE(buf, addrlen, 19);\n  buf.write(bindAddr, 23, addrlen, 'ascii');\n\n  writeUInt32BE(buf, bindPort, 23 + addrlen);\n\n  this.debug('DEBUG: Outgoing: Writing GLOBAL_REQUEST (tcpip-forward)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.cancelTcpipForward = function(bindAddr, bindPort,\n                                                   wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var addrlen = Buffer.byteLength(bindAddr);\n  var buf = Buffer.allocUnsafe(1 + 4 + 20 + 1 + 4 + addrlen + 4);\n\n  buf[0] = MESSAGE.GLOBAL_REQUEST;\n\n  writeUInt32BE(buf, 20, 1);\n  buf.write('cancel-tcpip-forward', 5, 20, 'ascii');\n\n  buf[25] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  writeUInt32BE(buf, addrlen, 26);\n  buf.write(bindAddr, 30, addrlen, 'ascii');\n\n  writeUInt32BE(buf, bindPort, 30 + addrlen);\n\n  this.debug('DEBUG: Outgoing: Writing GLOBAL_REQUEST (cancel-tcpip-forward)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.openssh_streamLocalForward = function(socketPath,\n                                                           wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var pathlen = Buffer.byteLength(socketPath);\n  var buf = Buffer.allocUnsafe(1 + 4 + 31 + 1 + 4 + pathlen);\n\n  buf[0] = MESSAGE.GLOBAL_REQUEST;\n\n  writeUInt32BE(buf, 31, 1);\n  buf.write('streamlocal-forward@openssh.com', 5, 31, 'ascii');\n\n  buf[36] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  writeUInt32BE(buf, pathlen, 37);\n  buf.write(socketPath, 41, pathlen, 'utf8');\n\n  this.debug('DEBUG: Outgoing: Writing GLOBAL_REQUEST (streamlocal-forward@openssh.com)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.openssh_cancelStreamLocalForward = function(socketPath,\n                                                                 wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var pathlen = Buffer.byteLength(socketPath);\n  var buf = Buffer.allocUnsafe(1 + 4 + 38 + 1 + 4 + pathlen);\n\n  buf[0] = MESSAGE.GLOBAL_REQUEST;\n\n  writeUInt32BE(buf, 38, 1);\n  buf.write('cancel-streamlocal-forward@openssh.com', 5, 38, 'ascii');\n\n  buf[43] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  writeUInt32BE(buf, pathlen, 44);\n  buf.write(socketPath, 48, pathlen, 'utf8');\n\n  this.debug('DEBUG: Outgoing: Writing GLOBAL_REQUEST (cancel-streamlocal-forward@openssh.com)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.directTcpip = function(chan, initWindow, maxPacket, cfg) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var srclen = Buffer.byteLength(cfg.srcIP);\n  var dstlen = Buffer.byteLength(cfg.dstIP);\n  var p = 29;\n  var buf = Buffer.allocUnsafe(1 + 4 + 12 + 4 + 4 + 4 + 4 + srclen + 4 + 4\n                               + dstlen + 4);\n\n  buf[0] = MESSAGE.CHANNEL_OPEN;\n\n  writeUInt32BE(buf, 12, 1);\n  buf.write('direct-tcpip', 5, 12, 'ascii');\n\n  writeUInt32BE(buf, chan, 17);\n\n  writeUInt32BE(buf, initWindow, 21);\n\n  writeUInt32BE(buf, maxPacket, 25);\n\n  writeUInt32BE(buf, dstlen, p);\n  buf.write(cfg.dstIP, p += 4, dstlen, 'ascii');\n\n  writeUInt32BE(buf, cfg.dstPort, p += dstlen);\n\n  writeUInt32BE(buf, srclen, p += 4);\n  buf.write(cfg.srcIP, p += 4, srclen, 'ascii');\n\n  writeUInt32BE(buf, cfg.srcPort, p += srclen);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_OPEN ('\n             + chan\n             + ', direct-tcpip)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.openssh_directStreamLocal = function(chan, initWindow,\n                                                          maxPacket, cfg) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var pathlen = Buffer.byteLength(cfg.socketPath);\n  var p = 47;\n  var buf = Buffer.allocUnsafe(1 + 4 + 30 + 4 + 4 + 4 + 4 + pathlen + 4 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_OPEN;\n\n  writeUInt32BE(buf, 30, 1);\n  buf.write('direct-streamlocal@openssh.com', 5, 30, 'ascii');\n\n  writeUInt32BE(buf, chan, 35);\n\n  writeUInt32BE(buf, initWindow, 39);\n\n  writeUInt32BE(buf, maxPacket, 43);\n\n  writeUInt32BE(buf, pathlen, p);\n  buf.write(cfg.socketPath, p += 4, pathlen, 'utf8');\n\n  // reserved fields (string and uint32)\n  buf.fill(0, buf.length - 8);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_OPEN ('\n             + chan\n             + ', direct-streamlocal@openssh.com)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.openssh_noMoreSessions = function(wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var buf = Buffer.allocUnsafe(1 + 4 + 28 + 1);\n\n  buf[0] = MESSAGE.GLOBAL_REQUEST;\n\n  writeUInt32BE(buf, 28, 1);\n  buf.write('no-more-sessions@openssh.com', 5, 28, 'ascii');\n\n  buf[33] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  this.debug('DEBUG: Outgoing: Writing GLOBAL_REQUEST (no-more-sessions@openssh.com)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.session = function(chan, initWindow, maxPacket) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4 + 7 + 4 + 4 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_OPEN;\n\n  writeUInt32BE(buf, 7, 1);\n  buf.write('session', 5, 7, 'ascii');\n\n  writeUInt32BE(buf, chan, 12);\n\n  writeUInt32BE(buf, initWindow, 16);\n\n  writeUInt32BE(buf, maxPacket, 20);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_OPEN ('\n             + chan\n             + ', session)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.windowChange = function(chan, rows, cols, height, width) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 13 + 1 + 4 + 4 + 4 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 13, 5);\n  buf.write('window-change', 9, 13, 'ascii');\n\n  buf[22] = 0;\n\n  writeUInt32BE(buf, cols, 23);\n\n  writeUInt32BE(buf, rows, 27);\n\n  writeUInt32BE(buf, width, 31);\n\n  writeUInt32BE(buf, height, 35);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', window-change)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.pty = function(chan, rows, cols, height,\n                                    width, term, modes, wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  if (!term || !term.length)\n    term = 'vt100';\n  if (modes\n      && !Buffer.isBuffer(modes)\n      && !Array.isArray(modes)\n      && typeof modes === 'object')\n    modes = modesToBytes(modes);\n  if (!modes || !modes.length)\n    modes = NO_TERMINAL_MODES_BUFFER;\n\n  var termLen = term.length;\n  var modesLen = modes.length;\n  var p = 21;\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 7 + 1 + 4 + termLen + 4 + 4 + 4 + 4\n                               + 4 + modesLen);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 7, 5);\n  buf.write('pty-req', 9, 7, 'ascii');\n\n  buf[16] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  writeUInt32BE(buf, termLen, 17);\n  buf.write(term, 21, termLen, 'utf8');\n\n  writeUInt32BE(buf, cols, p += termLen);\n\n  writeUInt32BE(buf, rows, p += 4);\n\n  writeUInt32BE(buf, width, p += 4);\n\n  writeUInt32BE(buf, height, p += 4);\n\n  writeUInt32BE(buf, modesLen, p += 4);\n  p += 4;\n  if (Array.isArray(modes)) {\n    for (var i = 0; i < modesLen; ++i)\n      buf[p++] = modes[i];\n  } else if (Buffer.isBuffer(modes)) {\n    modes.copy(buf, p);\n  }\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', pty-req)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.shell = function(chan, wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 5 + 1);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 5, 5);\n  buf.write('shell', 9, 5, 'ascii');\n\n  buf[14] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', shell)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.exec = function(chan, cmd, wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  var cmdlen = (Buffer.isBuffer(cmd) ? cmd.length : Buffer.byteLength(cmd));\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 4 + 1 + 4 + cmdlen);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 4, 5);\n  buf.write('exec', 9, 4, 'ascii');\n\n  buf[13] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  writeUInt32BE(buf, cmdlen, 14);\n  if (Buffer.isBuffer(cmd))\n    cmd.copy(buf, 18);\n  else\n    buf.write(cmd, 18, cmdlen, 'utf8');\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', exec)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.signal = function(chan, signal) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  signal = signal.toUpperCase();\n  if (signal.slice(0, 3) === 'SIG')\n    signal = signal.substring(3);\n\n  if (SIGNALS.indexOf(signal) === -1)\n    throw new Error('Invalid signal: ' + signal);\n\n  var signalLen = signal.length;\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 6 + 1 + 4 + signalLen);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 6, 5);\n  buf.write('signal', 9, 6, 'ascii');\n\n  buf[15] = 0;\n\n  writeUInt32BE(buf, signalLen, 16);\n  buf.write(signal, 20, signalLen, 'ascii');\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', signal)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.env = function(chan, key, val, wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  var keyLen = Buffer.byteLength(key);\n  var valLen = (Buffer.isBuffer(val) ? val.length : Buffer.byteLength(val));\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 3 + 1 + 4 + keyLen + 4 + valLen);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 3, 5);\n  buf.write('env', 9, 3, 'ascii');\n\n  buf[12] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  writeUInt32BE(buf, keyLen, 13);\n  buf.write(key, 17, keyLen, 'ascii');\n\n  writeUInt32BE(buf, valLen, 17 + keyLen);\n  if (Buffer.isBuffer(val))\n    val.copy(buf, 17 + keyLen + 4);\n  else\n    buf.write(val, 17 + keyLen + 4, valLen, 'utf8');\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', env)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.x11Forward = function(chan, cfg, wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  var protolen = Buffer.byteLength(cfg.protocol);\n  var cookielen = Buffer.byteLength(cfg.cookie);\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 7 + 1 + 1 + 4 + protolen + 4\n                               + cookielen + 4);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 7, 5);\n  buf.write('x11-req', 9, 7, 'ascii');\n\n  buf[16] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  buf[17] = (cfg.single ? 1 : 0);\n\n  writeUInt32BE(buf, protolen, 18);\n  var bp = 22;\n  if (Buffer.isBuffer(cfg.protocol))\n    cfg.protocol.copy(buf, bp);\n  else\n    buf.write(cfg.protocol, bp, protolen, 'utf8');\n  bp += protolen;\n\n  writeUInt32BE(buf, cookielen, bp);\n  bp += 4;\n  if (Buffer.isBuffer(cfg.cookie))\n    cfg.cookie.copy(buf, bp);\n  else\n    buf.write(cfg.cookie, bp, cookielen, 'binary');\n  bp += cookielen;\n\n  writeUInt32BE(buf, (cfg.screen || 0), bp);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', x11-req)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.subsystem = function(chan, name, wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  var nameLen = Buffer.byteLength(name);\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 9 + 1 + 4 + nameLen);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 9, 5);\n  buf.write('subsystem', 9, 9, 'ascii');\n\n  buf[18] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  writeUInt32BE(buf, nameLen, 19);\n  buf.write(name, 23, nameLen, 'ascii');\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', subsystem: '\n             + name\n             + ')');\n  return send(this, buf);\n};\nSSH2Stream.prototype.openssh_agentForward = function(chan, wantReply) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 26 + 1);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 26, 5);\n  buf.write('auth-agent-req@openssh.com', 9, 26, 'ascii');\n\n  buf[35] = (wantReply === undefined || wantReply === true ? 1 : 0);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', auth-agent-req@openssh.com)');\n  return send(this, buf);\n};\n// 'ssh-userauth' service-specific\nSSH2Stream.prototype.authPassword = function(username, password) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var userLen = Buffer.byteLength(username);\n  var passLen = Buffer.byteLength(password);\n  var p = 0;\n  var buf = Buffer.allocUnsafe(1\n                               + 4 + userLen\n                               + 4 + 14 // \"ssh-connection\"\n                               + 4 + 8 // \"password\"\n                               + 1\n                               + 4 + passLen);\n\n  buf[p] = MESSAGE.USERAUTH_REQUEST;\n\n  writeUInt32BE(buf, userLen, ++p);\n  buf.write(username, p += 4, userLen, 'utf8');\n\n  writeUInt32BE(buf, 14, p += userLen);\n  buf.write('ssh-connection', p += 4, 14, 'ascii');\n\n  writeUInt32BE(buf, 8, p += 14);\n  buf.write('password', p += 4, 8, 'ascii');\n\n  buf[p += 8] = 0;\n\n  writeUInt32BE(buf, passLen, ++p);\n  buf.write(password, p += 4, passLen, 'utf8');\n\n  this._state.authsQueue.push('password');\n  this.debug('DEBUG: Outgoing: Writing USERAUTH_REQUEST (password)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.authPK = function(username, pubKey, cbSign) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var self = this;\n  var outstate = this._state.outgoing;\n  var keyType;\n\n  if (typeof pubKey.getPublicSSH === 'function') {\n    keyType = pubKey.type;\n    pubKey = pubKey.getPublicSSH();\n  } else {\n    keyType = pubKey.toString('ascii',\n                              4,\n                              4 + readUInt32BE(pubKey, 0));\n  }\n\n  var userLen = Buffer.byteLength(username);\n  var algoLen = Buffer.byteLength(keyType);\n  var pubKeyLen = pubKey.length;\n  var sesLen = outstate.sessionId.length;\n  var p = 0;\n  var buf = Buffer.allocUnsafe((cbSign ? 4 + sesLen : 0)\n                               + 1\n                               + 4 + userLen\n                               + 4 + 14 // \"ssh-connection\"\n                               + 4 + 9 // \"publickey\"\n                               + 1\n                               + 4 + algoLen\n                               + 4 + pubKeyLen\n                              );\n\n  if (cbSign) {\n    writeUInt32BE(buf, sesLen, p);\n    outstate.sessionId.copy(buf, p += 4);\n    buf[p += sesLen] = MESSAGE.USERAUTH_REQUEST;\n  } else {\n    buf[p] = MESSAGE.USERAUTH_REQUEST;\n  }\n\n  writeUInt32BE(buf, userLen, ++p);\n  buf.write(username, p += 4, userLen, 'utf8');\n\n  writeUInt32BE(buf, 14, p += userLen);\n  buf.write('ssh-connection', p += 4, 14, 'ascii');\n\n  writeUInt32BE(buf, 9, p += 14);\n  buf.write('publickey', p += 4, 9, 'ascii');\n\n  buf[p += 9] = (cbSign ? 1 : 0);\n\n  writeUInt32BE(buf, algoLen, ++p);\n  buf.write(keyType, p += 4, algoLen, 'ascii');\n\n  writeUInt32BE(buf, pubKeyLen, p += algoLen);\n  pubKey.copy(buf, p += 4);\n\n  if (!cbSign) {\n    this._state.authsQueue.push('publickey');\n    this.debug('DEBUG: Outgoing: Writing USERAUTH_REQUEST (publickey -- check)');\n    return send(this, buf);\n  }\n\n  cbSign(buf, function(signature) {\n    signature = convertSignature(signature, keyType);\n    if (signature === false)\n      throw new Error('Error while converting handshake signature');\n\n    var sigLen = signature.length;\n    var sigbuf = Buffer.allocUnsafe(1\n                                    + 4 + userLen\n                                    + 4 + 14 // \"ssh-connection\"\n                                    + 4 + 9 // \"publickey\"\n                                    + 1\n                                    + 4 + algoLen\n                                    + 4 + pubKeyLen\n                                    + 4 // 4 + algoLen + 4 + sigLen\n                                    + 4 + algoLen\n                                    + 4 + sigLen);\n\n    p = 0;\n\n    sigbuf[p] = MESSAGE.USERAUTH_REQUEST;\n\n    writeUInt32BE(sigbuf, userLen, ++p);\n    sigbuf.write(username, p += 4, userLen, 'utf8');\n\n    writeUInt32BE(sigbuf, 14, p += userLen);\n    sigbuf.write('ssh-connection', p += 4, 14, 'ascii');\n\n    writeUInt32BE(sigbuf, 9, p += 14);\n    sigbuf.write('publickey', p += 4, 9, 'ascii');\n\n    sigbuf[p += 9] = 1;\n\n    writeUInt32BE(sigbuf, algoLen, ++p);\n    sigbuf.write(keyType, p += 4, algoLen, 'ascii');\n\n    writeUInt32BE(sigbuf, pubKeyLen, p += algoLen);\n    pubKey.copy(sigbuf, p += 4);\n    writeUInt32BE(sigbuf, 4 + algoLen + 4 + sigLen, p += pubKeyLen);\n    writeUInt32BE(sigbuf, algoLen, p += 4);\n    sigbuf.write(keyType, p += 4, algoLen, 'ascii');\n    writeUInt32BE(sigbuf, sigLen, p += algoLen);\n    signature.copy(sigbuf, p += 4);\n\n    // Servers shouldn't send packet type 60 in response to signed publickey\n    // attempts, but if they do, interpret as type 60.\n    self._state.authsQueue.push('publickey');\n    self.debug('DEBUG: Outgoing: Writing USERAUTH_REQUEST (publickey)');\n    return send(self, sigbuf);\n  });\n  return true;\n};\nSSH2Stream.prototype.authHostbased = function(username, pubKey, hostname,\n                                              userlocal, cbSign) {\n  // TODO: Make DRY by sharing similar code with authPK()\n\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var self = this;\n  var outstate = this._state.outgoing;\n  var keyType;\n\n  if (typeof pubKey.getPublicSSH === 'function') {\n    keyType = pubKey.type;\n    pubKey = pubKey.getPublicSSH();\n  } else {\n    keyType = pubKey.toString('ascii',\n                              4,\n                              4 + readUInt32BE(pubKey, 0));\n  }\n\n  var userLen = Buffer.byteLength(username);\n  var algoLen = Buffer.byteLength(keyType);\n  var pubKeyLen = pubKey.length;\n  var sesLen = outstate.sessionId.length;\n  var hostnameLen = Buffer.byteLength(hostname);\n  var userlocalLen = Buffer.byteLength(userlocal);\n  var p = 0;\n  var buf = Buffer.allocUnsafe(4 + sesLen\n                               + 1\n                               + 4 + userLen\n                               + 4 + 14 // \"ssh-connection\"\n                               + 4 + 9 // \"hostbased\"\n                               + 4 + algoLen\n                               + 4 + pubKeyLen\n                               + 4 + hostnameLen\n                               + 4 + userlocalLen\n                              );\n\n  writeUInt32BE(buf, sesLen, p);\n  outstate.sessionId.copy(buf, p += 4);\n\n  buf[p += sesLen] = MESSAGE.USERAUTH_REQUEST;\n\n  writeUInt32BE(buf, userLen, ++p);\n  buf.write(username, p += 4, userLen, 'utf8');\n\n  writeUInt32BE(buf, 14, p += userLen);\n  buf.write('ssh-connection', p += 4, 14, 'ascii');\n\n  writeUInt32BE(buf, 9, p += 14);\n  buf.write('hostbased', p += 4, 9, 'ascii');\n\n  writeUInt32BE(buf, algoLen, p += 9);\n  buf.write(keyType, p += 4, algoLen, 'ascii');\n\n  writeUInt32BE(buf, pubKeyLen, p += algoLen);\n  pubKey.copy(buf, p += 4);\n\n  writeUInt32BE(buf, hostnameLen, p += pubKeyLen);\n  buf.write(hostname, p += 4, hostnameLen, 'ascii');\n\n  writeUInt32BE(buf, userlocalLen, p += hostnameLen);\n  buf.write(userlocal, p += 4, userlocalLen, 'utf8');\n\n  cbSign(buf, function(signature) {\n    signature = convertSignature(signature, keyType);\n    if (signature === false)\n      throw new Error('Error while converting handshake signature');\n\n    var sigLen = signature.length;\n    var sigbuf = Buffer.allocUnsafe((buf.length - sesLen) + sigLen);\n\n    buf.copy(sigbuf, 0, 4 + sesLen);\n    writeUInt32BE(sigbuf, sigLen, sigbuf.length - sigLen - 4);\n    signature.copy(sigbuf, sigbuf.length - sigLen);\n\n    self._state.authsQueue.push('hostbased');\n    self.debug('DEBUG: Outgoing: Writing USERAUTH_REQUEST (hostbased)');\n    return send(self, sigbuf);\n  });\n  return true;\n};\nSSH2Stream.prototype.authKeyboard = function(username) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var userLen = Buffer.byteLength(username);\n  var p = 0;\n  var buf = Buffer.allocUnsafe(1\n                               + 4 + userLen\n                               + 4 + 14 // \"ssh-connection\"\n                               + 4 + 20 // \"keyboard-interactive\"\n                               + 4 // no language set\n                               + 4 // no submethods\n                              );\n\n  buf[p] = MESSAGE.USERAUTH_REQUEST;\n\n  writeUInt32BE(buf, userLen, ++p);\n  buf.write(username, p += 4, userLen, 'utf8');\n\n  writeUInt32BE(buf, 14, p += userLen);\n  buf.write('ssh-connection', p += 4, 14, 'ascii');\n\n  writeUInt32BE(buf, 20, p += 14);\n  buf.write('keyboard-interactive', p += 4, 20, 'ascii');\n\n  writeUInt32BE(buf, 0, p += 20);\n\n  writeUInt32BE(buf, 0, p += 4);\n\n  this._state.authsQueue.push('keyboard-interactive');\n  this.debug('DEBUG: Outgoing: Writing USERAUTH_REQUEST (keyboard-interactive)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.authNone = function(username) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var userLen = Buffer.byteLength(username);\n  var p = 0;\n  var buf = Buffer.allocUnsafe(1\n                               + 4 + userLen\n                               + 4 + 14 // \"ssh-connection\"\n                               + 4 + 4 // \"none\"\n                              );\n\n  buf[p] = MESSAGE.USERAUTH_REQUEST;\n\n  writeUInt32BE(buf, userLen, ++p);\n  buf.write(username, p += 4, userLen, 'utf8');\n\n  writeUInt32BE(buf, 14, p += userLen);\n  buf.write('ssh-connection', p += 4, 14, 'ascii');\n\n  writeUInt32BE(buf, 4, p += 14);\n  buf.write('none', p += 4, 4, 'ascii');\n\n  this._state.authsQueue.push('none');\n  this.debug('DEBUG: Outgoing: Writing USERAUTH_REQUEST (none)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.authInfoRes = function(responses) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  var responsesLen = 0;\n  var p = 0;\n  var resLen;\n  var len;\n  var i;\n\n  if (responses) {\n    for (i = 0, len = responses.length; i < len; ++i)\n      responsesLen += 4 + Buffer.byteLength(responses[i]);\n  }\n  var buf = Buffer.allocUnsafe(1 + 4 + responsesLen);\n\n  buf[p++] = MESSAGE.USERAUTH_INFO_RESPONSE;\n\n  writeUInt32BE(buf, responses ? responses.length : 0, p);\n  if (responses) {\n    p += 4;\n    for (i = 0, len = responses.length; i < len; ++i) {\n      resLen = Buffer.byteLength(responses[i]);\n      writeUInt32BE(buf, resLen, p);\n      p += 4;\n      if (resLen) {\n        buf.write(responses[i], p, resLen, 'utf8');\n        p += resLen;\n      }\n    }\n  }\n\n  this.debug('DEBUG: Outgoing: Writing USERAUTH_INFO_RESPONSE');\n  return send(this, buf);\n};\n\n// Server-specific methods\n// Global\nSSH2Stream.prototype.serviceAccept = function(svcName) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var svcNameLen = svcName.length;\n  var buf = Buffer.allocUnsafe(1 + 4 + svcNameLen);\n\n  buf[0] = MESSAGE.SERVICE_ACCEPT;\n\n  writeUInt32BE(buf, svcNameLen, 1);\n  buf.write(svcName, 5, svcNameLen, 'ascii');\n\n  this.debug('DEBUG: Outgoing: Writing SERVICE_ACCEPT (' + svcName + ')');\n  send(this, buf);\n\n  if (this.server && this.banner && svcName === 'ssh-userauth') {\n    /*\n      byte      SSH_MSG_USERAUTH_BANNER\n      string    message in ISO-10646 UTF-8 encoding\n      string    language tag\n    */\n    var bannerLen = Buffer.byteLength(this.banner);\n    var packetLen = 1 + 4 + bannerLen + 4;\n    var packet = Buffer.allocUnsafe(packetLen);\n    packet[0] = MESSAGE.USERAUTH_BANNER;\n    writeUInt32BE(packet, bannerLen, 1);\n    packet.write(this.banner, 5, bannerLen, 'utf8');\n    packet.fill(0, packetLen - 4); // Empty language tag\n    this.debug('DEBUG: Outgoing: Writing USERAUTH_BANNER');\n    send(this, packet);\n    this.banner = undefined; // Prevent banner from being displayed again\n  }\n};\n// 'ssh-connection' service-specific\nSSH2Stream.prototype.forwardedTcpip = function(chan, initWindow, maxPacket,\n                                               cfg) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var boundAddrLen = Buffer.byteLength(cfg.boundAddr);\n  var remoteAddrLen = Buffer.byteLength(cfg.remoteAddr);\n  var p = 36 + boundAddrLen;\n  var buf = Buffer.allocUnsafe(1 + 4 + 15 + 4 + 4 + 4 + 4 + boundAddrLen + 4 + 4\n                               + remoteAddrLen + 4);\n\n  buf[0] = MESSAGE.CHANNEL_OPEN;\n\n  writeUInt32BE(buf, 15, 1);\n  buf.write('forwarded-tcpip', 5, 15, 'ascii');\n\n  writeUInt32BE(buf, chan, 20);\n\n  writeUInt32BE(buf, initWindow, 24);\n\n  writeUInt32BE(buf, maxPacket, 28);\n\n  writeUInt32BE(buf, boundAddrLen, 32);\n  buf.write(cfg.boundAddr, 36, boundAddrLen, 'ascii');\n\n  writeUInt32BE(buf, cfg.boundPort, p);\n\n  writeUInt32BE(buf, remoteAddrLen, p += 4);\n  buf.write(cfg.remoteAddr, p += 4, remoteAddrLen, 'ascii');\n\n  writeUInt32BE(buf, cfg.remotePort, p += remoteAddrLen);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_OPEN ('\n             + chan\n             + ', forwarded-tcpip)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.x11 = function(chan, initWindow, maxPacket, cfg) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var addrLen = Buffer.byteLength(cfg.originAddr);\n  var p = 24 + addrLen;\n  var buf = Buffer.allocUnsafe(1 + 4 + 3 + 4 + 4 + 4 + 4 + addrLen + 4);\n\n  buf[0] = MESSAGE.CHANNEL_OPEN;\n\n  writeUInt32BE(buf, 3, 1);\n  buf.write('x11', 5, 3, 'ascii');\n\n  writeUInt32BE(buf, chan, 8);\n\n  writeUInt32BE(buf, initWindow, 12);\n\n  writeUInt32BE(buf, maxPacket, 16);\n\n  writeUInt32BE(buf, addrLen, 20);\n  buf.write(cfg.originAddr, 24, addrLen, 'ascii');\n\n  writeUInt32BE(buf, cfg.originPort, p);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_OPEN ('\n             + chan\n             + ', x11)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.openssh_authAgent = function(chan, initWindow, maxPacket) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var buf = Buffer.allocUnsafe(1 + 4 + 22 + 4 + 4 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_OPEN;\n\n  writeUInt32BE(buf, 22, 1);\n  buf.write('auth-agent@openssh.com', 5, 22, 'ascii');\n\n  writeUInt32BE(buf, chan, 27);\n\n  writeUInt32BE(buf, initWindow, 31);\n\n  writeUInt32BE(buf, maxPacket, 35);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_OPEN ('\n             + chan\n             + ', auth-agent@openssh.com)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.openssh_forwardedStreamLocal = function(chan, initWindow,\n                                                             maxPacket, cfg) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var pathlen = Buffer.byteLength(cfg.socketPath);\n  var buf = Buffer.allocUnsafe(1 + 4 + 33 + 4 + 4 + 4 + 4 + pathlen + 4);\n\n  buf[0] = MESSAGE.CHANNEL_OPEN;\n\n  writeUInt32BE(buf, 33, 1);\n  buf.write('forwarded-streamlocal@openssh.com', 5, 33, 'ascii');\n\n  writeUInt32BE(buf, chan, 38);\n\n  writeUInt32BE(buf, initWindow, 42);\n\n  writeUInt32BE(buf, maxPacket, 46);\n\n  writeUInt32BE(buf, pathlen, 50);\n  buf.write(cfg.socketPath, 54, pathlen, 'utf8');\n\n  writeUInt32BE(buf, 0, 54 + pathlen);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_OPEN ('\n             + chan\n             + ', forwarded-streamlocal@openssh.com)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.exitStatus = function(chan, status) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  // Does not consume window space\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 11 + 1 + 4);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 11, 5);\n  buf.write('exit-status', 9, 11, 'ascii');\n\n  buf[20] = 0;\n\n  writeUInt32BE(buf, status, 21);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', exit-status)');\n  return send(this, buf);\n};\nSSH2Stream.prototype.exitSignal = function(chan, name, coreDumped, msg) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  // Does not consume window space\n  var nameLen = Buffer.byteLength(name);\n  var msgLen = (msg ? Buffer.byteLength(msg) : 0);\n  var p = 25 + nameLen;\n  var buf = Buffer.allocUnsafe(1 + 4 + 4 + 11 + 1 + 4 + nameLen + 1 + 4 + msgLen\n                               + 4);\n\n  buf[0] = MESSAGE.CHANNEL_REQUEST;\n\n  writeUInt32BE(buf, chan, 1);\n\n  writeUInt32BE(buf, 11, 5);\n  buf.write('exit-signal', 9, 11, 'ascii');\n\n  buf[20] = 0;\n\n  writeUInt32BE(buf, nameLen, 21);\n  buf.write(name, 25, nameLen, 'utf8');\n\n  buf[p++] = (coreDumped ? 1 : 0);\n\n  writeUInt32BE(buf, msgLen, p);\n  p += 4;\n  if (msgLen) {\n    buf.write(msg, p, msgLen, 'utf8');\n    p += msgLen;\n  }\n\n  writeUInt32BE(buf, 0, p);\n\n  this.debug('DEBUG: Outgoing: Writing CHANNEL_REQUEST ('\n             + chan\n             + ', exit-signal)');\n  return send(this, buf);\n};\n// 'ssh-userauth' service-specific\nSSH2Stream.prototype.authFailure = function(authMethods, isPartial) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var authsQueue = this._state.authsQueue;\n  if (!authsQueue.length)\n    throw new Error('No auth in progress');\n\n  var methods;\n\n  if (typeof authMethods === 'boolean') {\n    isPartial = authMethods;\n    authMethods = undefined;\n  }\n\n  if (authMethods) {\n    methods = [];\n    for (var i = 0, len = authMethods.length; i < len; ++i) {\n      if (authMethods[i].toLowerCase() === 'none')\n        continue;\n      methods.push(authMethods[i]);\n    }\n    methods = methods.join(',');\n  } else\n    methods = '';\n\n  var methodsLen = methods.length;\n  var buf = Buffer.allocUnsafe(1 + 4 + methodsLen + 1);\n\n  buf[0] = MESSAGE.USERAUTH_FAILURE;\n\n  writeUInt32BE(buf, methodsLen, 1);\n  buf.write(methods, 5, methodsLen, 'ascii');\n\n  buf[5 + methodsLen] = (isPartial === true ? 1 : 0);\n\n  this._state.authsQueue.shift();\n  this.debug('DEBUG: Outgoing: Writing USERAUTH_FAILURE');\n  return send(this, buf);\n};\nSSH2Stream.prototype.authSuccess = function() {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var authsQueue = this._state.authsQueue;\n  if (!authsQueue.length)\n    throw new Error('No auth in progress');\n\n  var state = this._state;\n  var outstate = state.outgoing;\n  var instate = state.incoming;\n\n  state.authsQueue.shift();\n\n  this.debug('DEBUG: Outgoing: Writing USERAUTH_SUCCESS');\n  var ret = send(this, USERAUTH_SUCCESS_PACKET);\n\n  if (outstate.compress.type === 'zlib@openssh.com') {\n    outstate.compress.instance = zlib.createDeflate(ZLIB_OPTS);\n    outstate.compress.queue = [];\n  }\n  if (instate.decompress.type === 'zlib@openssh.com')\n    instate.decompress.instance = zlib.createInflate(ZLIB_OPTS);\n\n  return ret;\n};\nSSH2Stream.prototype.authPKOK = function(keyAlgo, key) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var authsQueue = this._state.authsQueue;\n  if (!authsQueue.length || authsQueue[0] !== 'publickey')\n    throw new Error('\"publickey\" auth not in progress');\n\n  var keyAlgoLen = keyAlgo.length;\n  var keyLen = key.length;\n  var buf = Buffer.allocUnsafe(1 + 4 + keyAlgoLen + 4 + keyLen);\n\n  buf[0] = MESSAGE.USERAUTH_PK_OK;\n\n  writeUInt32BE(buf, keyAlgoLen, 1);\n  buf.write(keyAlgo, 5, keyAlgoLen, 'ascii');\n\n  writeUInt32BE(buf, keyLen, 5 + keyAlgoLen);\n  key.copy(buf, 5 + keyAlgoLen + 4);\n\n  this._state.authsQueue.shift();\n  this.debug('DEBUG: Outgoing: Writing USERAUTH_PK_OK');\n  return send(this, buf);\n};\nSSH2Stream.prototype.authPasswdChg = function(prompt, lang) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var promptLen = Buffer.byteLength(prompt);\n  var langLen = lang ? lang.length : 0;\n  var p = 0;\n  var buf = Buffer.allocUnsafe(1 + 4 + promptLen + 4 + langLen);\n\n  buf[p] = MESSAGE.USERAUTH_PASSWD_CHANGEREQ;\n\n  writeUInt32BE(buf, promptLen, ++p);\n  buf.write(prompt, p += 4, promptLen, 'utf8');\n\n  writeUInt32BE(buf, langLen, p += promptLen);\n  if (langLen)\n    buf.write(lang, p += 4, langLen, 'ascii');\n\n  this.debug('DEBUG: Outgoing: Writing USERAUTH_PASSWD_CHANGEREQ');\n  return send(this, buf);\n};\nSSH2Stream.prototype.authInfoReq = function(name, instructions, prompts) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  var promptsLen = 0;\n  var nameLen = name ? Buffer.byteLength(name) : 0;\n  var instrLen = instructions ? Buffer.byteLength(instructions) : 0;\n  var p = 0;\n  var promptLen;\n  var prompt;\n  var len;\n  var i;\n\n  for (i = 0, len = prompts.length; i < len; ++i)\n    promptsLen += 4 + Buffer.byteLength(prompts[i].prompt) + 1;\n  var buf = Buffer.allocUnsafe(1 + 4 + nameLen + 4 + instrLen + 4 + 4\n                               + promptsLen);\n\n  buf[p++] = MESSAGE.USERAUTH_INFO_REQUEST;\n\n  writeUInt32BE(buf, nameLen, p);\n  p += 4;\n  if (name) {\n    buf.write(name, p, nameLen, 'utf8');\n    p += nameLen;\n  }\n\n  writeUInt32BE(buf, instrLen, p);\n  p += 4;\n  if (instructions) {\n    buf.write(instructions, p, instrLen, 'utf8');\n    p += instrLen;\n  }\n\n  writeUInt32BE(buf, 0, p);\n  p += 4;\n\n  writeUInt32BE(buf, prompts.length, p);\n  p += 4;\n  for (i = 0, len = prompts.length; i < len; ++i) {\n    prompt = prompts[i];\n    promptLen = Buffer.byteLength(prompt.prompt);\n    writeUInt32BE(buf, promptLen, p);\n    p += 4;\n    if (promptLen) {\n      buf.write(prompt.prompt, p, promptLen, 'utf8');\n      p += promptLen;\n    }\n    buf[p++] = (prompt.echo ? 1 : 0);\n  }\n\n  this.debug('DEBUG: Outgoing: Writing USERAUTH_INFO_REQUEST');\n  return send(this, buf);\n};\n\n// Shared incoming/parser functions\nfunction onDISCONNECT(self, reason, code, desc, lang) { // Client/Server\n  if (code !== DISCONNECT_REASON.BY_APPLICATION) {\n    var err = new Error(desc || reason);\n    err.code = code;\n    self.emit('error', err);\n  }\n  self.reset();\n}\n\nfunction onKEXINIT(self, init, firstFollows) { // Client/Server\n  var state = self._state;\n  var outstate = state.outgoing;\n\n  if (outstate.status === OUT_READY) {\n    self.debug('DEBUG: Received re-key request');\n    outstate.status = OUT_REKEYING;\n    outstate.kexinit = undefined;\n    KEXINIT(self, check);\n  } else\n    check();\n\n  function check() {\n    if (check_KEXINIT(self, init, firstFollows) === true) {\n      var isGEX = RE_GEX.test(state.kexdh);\n      if (!self.server) {\n        if (isGEX)\n          KEXDH_GEX_REQ(self);\n        else\n          KEXDH_INIT(self);\n      } else {\n        if (isGEX)\n          state.incoming.expectedPacket = 'KEXDH_GEX_REQ';\n        else\n          state.incoming.expectedPacket = 'KEXDH_INIT';\n      }\n    }\n  }\n}\n\nfunction check_KEXINIT(self, init, firstFollows) {\n  var state = self._state;\n  var instate = state.incoming;\n  var outstate = state.outgoing;\n  var debug = self.debug;\n  var serverList;\n  var clientList;\n  var val;\n  var len;\n  var i;\n\n  debug('DEBUG: Comparing KEXINITs ...');\n\n  var algos = self.config.algorithms;\n\n  var kexList = algos.kex;\n  if (self.remoteBugs & BUGS.BAD_DHGEX) {\n    var copied = false;\n    for (var j = kexList.length - 1; j >= 0; --j) {\n      if (kexList[j].indexOf('group-exchange') !== -1) {\n        if (!copied) {\n          kexList = kexList.slice();\n          copied = true;\n        }\n        kexList.splice(j, 1);\n      }\n    }\n  }\n\n  debug('DEBUG: (local) KEX algorithms: ' + kexList);\n  debug('DEBUG: (remote) KEX algorithms: ' + init.algorithms.kex);\n  if (self.server) {\n    serverList = kexList;\n    clientList = init.algorithms.kex;\n  } else {\n    serverList = init.algorithms.kex;\n    clientList = kexList;\n  }\n  // Check for agreeable key exchange algorithm\n  for (i = 0, len = clientList.length;\n       i < len && serverList.indexOf(clientList[i]) === -1;\n       ++i);\n  if (i === len) {\n    // No suitable match found!\n    debug('DEBUG: No matching key exchange algorithm');\n    var err = new Error('Handshake failed: no matching key exchange algorithm');\n    err.level = 'handshake';\n    self.emit('error', err);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  var kex_algorithm = clientList[i];\n  debug('DEBUG: KEX algorithm: ' + kex_algorithm);\n  if (firstFollows\n      && (!init.algorithms.kex.length\n          || kex_algorithm !== init.algorithms.kex[0])) {\n    // Ignore next incoming packet, it was a wrong first guess at KEX algorithm\n    instate.ignoreNext = true;\n  }\n\n  debug('DEBUG: (local) Host key formats: ' + algos.serverHostKey);\n  debug('DEBUG: (remote) Host key formats: ' + init.algorithms.srvHostKey);\n  if (self.server) {\n    serverList = algos.serverHostKey;\n    clientList = init.algorithms.srvHostKey;\n  } else {\n    serverList = init.algorithms.srvHostKey;\n    clientList = algos.serverHostKey;\n  }\n  // Check for agreeable server host key format\n  for (i = 0, len = clientList.length;\n       i < len && serverList.indexOf(clientList[i]) === -1;\n       ++i);\n  if (i === len) {\n    // No suitable match found!\n    debug('DEBUG: No matching host key format');\n    var err = new Error('Handshake failed: no matching host key format');\n    err.level = 'handshake';\n    self.emit('error', err);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  state.hostkeyFormat = clientList[i];\n  debug('DEBUG: Host key format: ' + state.hostkeyFormat);\n\n  debug('DEBUG: (local) Client->Server ciphers: ' + algos.cipher);\n  debug('DEBUG: (remote) Client->Server ciphers: '\n        + init.algorithms.cs.encrypt);\n  if (self.server) {\n    serverList = algos.cipher;\n    clientList = init.algorithms.cs.encrypt;\n  } else {\n    serverList = init.algorithms.cs.encrypt;\n    clientList = algos.cipher;\n  }\n  // Check for agreeable client->server cipher\n  for (i = 0, len = clientList.length;\n       i < len && serverList.indexOf(clientList[i]) === -1;\n       ++i);\n  if (i === len) {\n    // No suitable match found!\n    debug('DEBUG: No matching Client->Server cipher');\n    var err = new Error('Handshake failed: no matching client->server cipher');\n    err.level = 'handshake';\n    self.emit('error', err);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  if (self.server)\n    val = instate.decrypt.type = clientList[i];\n  else\n    val = outstate.encrypt.type = clientList[i];\n  debug('DEBUG: Client->Server Cipher: ' + val);\n\n  debug('DEBUG: (local) Server->Client ciphers: ' + algos.cipher);\n  debug('DEBUG: (remote) Server->Client ciphers: '\n        + (init.algorithms.sc.encrypt));\n  if (self.server) {\n    serverList = algos.cipher;\n    clientList = init.algorithms.sc.encrypt;\n  } else {\n    serverList = init.algorithms.sc.encrypt;\n    clientList = algos.cipher;\n  }\n  // Check for agreeable server->client cipher\n  for (i = 0, len = clientList.length;\n       i < len && serverList.indexOf(clientList[i]) === -1;\n       ++i);\n  if (i === len) {\n    // No suitable match found!\n    debug('DEBUG: No matching Server->Client cipher');\n    var err = new Error('Handshake failed: no matching server->client cipher');\n    err.level = 'handshake';\n    self.emit('error', err);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  if (self.server)\n    val = outstate.encrypt.type = clientList[i];\n  else\n    val = instate.decrypt.type = clientList[i];\n  debug('DEBUG: Server->Client Cipher: ' + val);\n\n  debug('DEBUG: (local) Client->Server HMAC algorithms: ' + algos.hmac);\n  debug('DEBUG: (remote) Client->Server HMAC algorithms: '\n        + init.algorithms.cs.mac);\n  if (self.server) {\n    serverList = algos.hmac;\n    clientList = init.algorithms.cs.mac;\n  } else {\n    serverList = init.algorithms.cs.mac;\n    clientList = algos.hmac;\n  }\n  // Check for agreeable client->server hmac algorithm\n  for (i = 0, len = clientList.length;\n       i < len && serverList.indexOf(clientList[i]) === -1;\n       ++i);\n  if (i === len) {\n    // No suitable match found!\n    debug('DEBUG: No matching Client->Server HMAC algorithm');\n    var err = new Error('Handshake failed: no matching client->server HMAC');\n    err.level = 'handshake';\n    self.emit('error', err);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  if (self.server)\n    val = instate.hmac.type = clientList[i];\n  else\n    val = outstate.hmac.type = clientList[i];\n  debug('DEBUG: Client->Server HMAC algorithm: ' + val);\n\n  debug('DEBUG: (local) Server->Client HMAC algorithms: ' + algos.hmac);\n  debug('DEBUG: (remote) Server->Client HMAC algorithms: '\n        + init.algorithms.sc.mac);\n  if (self.server) {\n    serverList = algos.hmac;\n    clientList = init.algorithms.sc.mac;\n  } else {\n    serverList = init.algorithms.sc.mac;\n    clientList = algos.hmac;\n  }\n  // Check for agreeable server->client hmac algorithm\n  for (i = 0, len = clientList.length;\n       i < len && serverList.indexOf(clientList[i]) === -1;\n       ++i);\n  if (i === len) {\n    // No suitable match found!\n    debug('DEBUG: No matching Server->Client HMAC algorithm');\n    var err = new Error('Handshake failed: no matching server->client HMAC');\n    err.level = 'handshake';\n    self.emit('error', err);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  if (self.server)\n    val = outstate.hmac.type = clientList[i];\n  else\n    val = instate.hmac.type = clientList[i];\n  debug('DEBUG: Server->Client HMAC algorithm: ' + val);\n\n  debug('DEBUG: (local) Client->Server compression algorithms: '\n        + algos.compress);\n  debug('DEBUG: (remote) Client->Server compression algorithms: '\n        + init.algorithms.cs.compress);\n  if (self.server) {\n    serverList = algos.compress;\n    clientList = init.algorithms.cs.compress;\n  } else {\n    serverList = init.algorithms.cs.compress;\n    clientList = algos.compress;\n  }\n  // Check for agreeable client->server compression algorithm\n  for (i = 0, len = clientList.length;\n       i < len && serverList.indexOf(clientList[i]) === -1;\n       ++i);\n  if (i === len) {\n    // No suitable match found!\n    debug('DEBUG: No matching Client->Server compression algorithm');\n    var err = new Error('Handshake failed: no matching client->server '\n                        + 'compression algorithm');\n    err.level = 'handshake';\n    self.emit('error', err);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  if (self.server)\n    val = instate.decompress.type = clientList[i];\n  else\n    val = outstate.compress.type = clientList[i];\n  debug('DEBUG: Client->Server compression algorithm: ' + val);\n\n  debug('DEBUG: (local) Server->Client compression algorithms: '\n        + algos.compress);\n  debug('DEBUG: (remote) Server->Client compression algorithms: '\n        + init.algorithms.sc.compress);\n  if (self.server) {\n    serverList = algos.compress;\n    clientList = init.algorithms.sc.compress;\n  } else {\n    serverList = init.algorithms.sc.compress;\n    clientList = algos.compress;\n  }\n  // Check for agreeable server->client compression algorithm\n  for (i = 0, len = clientList.length;\n       i < len && serverList.indexOf(clientList[i]) === -1;\n       ++i);\n  if (i === len) {\n    // No suitable match found!\n    debug('DEBUG: No matching Server->Client compression algorithm');\n    var err = new Error('Handshake failed: no matching server->client '\n                        + 'compression algorithm');\n    err.level = 'handshake';\n    self.emit('error', err);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  if (self.server)\n    val = outstate.compress.type = clientList[i];\n  else\n    val = instate.decompress.type = clientList[i];\n  debug('DEBUG: Server->Client compression algorithm: ' + val);\n\n  switch (kex_algorithm) {\n    case 'diffie-hellman-group1-sha1':\n      state.kexdh = 'group';\n      state.kex = crypto.getDiffieHellman('modp2');\n      break;\n    case 'diffie-hellman-group14-sha1':\n      state.kexdh = 'group';\n      state.kex = crypto.getDiffieHellman('modp14');\n      break;\n    case 'ecdh-sha2-nistp256':\n      state.kexdh = 'ec-sha256';\n      state.kex = crypto.createECDH(SSH_TO_OPENSSL[kex_algorithm]);\n      break;\n    case 'ecdh-sha2-nistp384':\n      state.kexdh = 'ec-sha384';\n      state.kex = crypto.createECDH(SSH_TO_OPENSSL[kex_algorithm]);\n      break;\n    case 'ecdh-sha2-nistp521':\n      state.kexdh = 'ec-sha512';\n      state.kex = crypto.createECDH(SSH_TO_OPENSSL[kex_algorithm]);\n      break;\n    default:\n      if (kex_algorithm === 'diffie-hellman-group-exchange-sha1')\n        state.kexdh = 'gex-sha1';\n      else if (kex_algorithm === 'diffie-hellman-group-exchange-sha256')\n        state.kexdh = 'gex-sha256';\n      // Reset kex object if DH group exchange is selected on re-key and DH\n      // group exchange was used before the re-key. This ensures that we send\n      // the right DH packet after the KEXINIT exchange\n      state.kex = undefined;\n  }\n\n  if (state.kex) {\n    outstate.pubkey = state.kex.generateKeys();\n    var idx = 0;\n    len = outstate.pubkey.length;\n    while (outstate.pubkey[idx] === 0x00) {\n      ++idx;\n      --len;\n    }\n    if (outstate.pubkey[idx] & 0x80) {\n      var key = Buffer.allocUnsafe(len + 1);\n      key[0] = 0;\n      outstate.pubkey.copy(key, 1, idx);\n      outstate.pubkey = key;\n    }\n  }\n\n  return true;\n}\n\nfunction onKEXDH_GEX_GROUP(self, prime, gen) {\n  var state = self._state;\n  var outstate = state.outgoing;\n\n  state.kex = crypto.createDiffieHellman(prime, gen);\n  outstate.pubkey = state.kex.generateKeys();\n  var idx = 0;\n  var len = outstate.pubkey.length;\n  while (outstate.pubkey[idx] === 0x00) {\n    ++idx;\n    --len;\n  }\n  if (outstate.pubkey[idx] & 0x80) {\n    var key = Buffer.allocUnsafe(len + 1);\n    key[0] = 0;\n    outstate.pubkey.copy(key, 1, idx);\n    outstate.pubkey = key;\n  }\n  KEXDH_INIT(self);\n}\n\nfunction onKEXDH_INIT(self, e) { // Server\n  KEXDH_REPLY(self, e);\n}\n\nfunction onKEXDH_REPLY(self, info, verifiedHost) { // Client\n  var state = self._state;\n  var instate = state.incoming;\n  var outstate = state.outgoing;\n  var debug = self.debug;\n  var len;\n  var i;\n\n  if (verifiedHost === undefined) {\n    instate.expectedPacket = 'NEWKEYS';\n    outstate.sentNEWKEYS = false;\n\n    debug('DEBUG: Checking host key format');\n    // Ensure all host key formats agree\n    var hostkey_format = readString(info.hostkey, 0, 'ascii', self);\n    if (hostkey_format === false)\n      return false;\n    if (info.hostkey_format !== state.hostkeyFormat\n        || info.hostkey_format !== hostkey_format) {\n      // Expected and actual server host key format do not match!\n      debug('DEBUG: Host key format mismatch');\n      self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n      self.reset();\n      var err = new Error('Handshake failed: host key format mismatch');\n      err.level = 'handshake';\n      self.emit('error', err);\n      return false;\n    }\n\n    debug('DEBUG: Checking signature format');\n    // Ensure signature formats agree\n    var sig_format = readString(info.sig, 0, 'ascii', self);\n    if (sig_format === false)\n      return false;\n    if (info.sig_format !== sig_format) {\n      debug('DEBUG: Signature format mismatch');\n      self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n      self.reset();\n      var err = new Error('Handshake failed: signature format mismatch');\n      err.level = 'handshake';\n      self.emit('error', err);\n      return false;\n    }\n  }\n\n  // Verify the host fingerprint first if needed\n  if (outstate.status === OUT_INIT) {\n    if (verifiedHost === undefined) {\n      debug('DEBUG: Verifying host fingerprint');\n      var sync = true;\n      var emitted = self.emit('fingerprint', info.hostkey, function(permitted) {\n        // Prevent multiple calls to this callback\n        if (verifiedHost !== undefined)\n          return;\n        verifiedHost = !!permitted;\n        if (!sync) {\n          // Continue execution by re-entry\n          onKEXDH_REPLY(self, info, verifiedHost);\n        }\n      });\n      sync = false;\n      // Support async calling of verification callback\n      if (emitted && verifiedHost === undefined)\n        return;\n    }\n    if (verifiedHost === undefined)\n      debug('DEBUG: Host accepted by default (no verification)');\n    else if (verifiedHost === true)\n      debug('DEBUG: Host accepted (verified)');\n    else {\n      debug('DEBUG: Host denied via fingerprint verification');\n      self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n      self.reset();\n      var err = new Error('Handshake failed: '\n                          + 'host fingerprint verification failed');\n      err.level = 'handshake';\n      self.emit('error', err);\n      return false;\n    }\n  }\n\n  var slicepos = -1;\n  for (i = 0, len = info.pubkey.length; i < len; ++i) {\n    if (info.pubkey[i] === 0)\n      ++slicepos;\n    else\n      break;\n  }\n  if (slicepos > -1)\n    info.pubkey = info.pubkey.slice(slicepos + 1);\n  info.secret = tryComputeSecret(state.kex, info.pubkey);\n  if (info.secret instanceof Error) {\n    info.secret.message = 'Error while computing DH secret ('\n                          + state.kexdh + '): '\n                          + info.secret.message;\n    info.secret.level = 'handshake';\n    self.emit('error', info.secret);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  var hashAlgo;\n  if (state.kexdh === 'group')\n    hashAlgo = 'sha1';\n  else\n    hashAlgo = RE_KEX_HASH.exec(state.kexdh)[1];\n  var hash = crypto.createHash(hashAlgo);\n\n  var len_ident = Buffer.byteLength(self.config.ident);\n  var len_sident = Buffer.byteLength(instate.identRaw);\n  var len_init = outstate.kexinit.length;\n  var len_sinit = instate.kexinit.length;\n  var len_hostkey = info.hostkey.length;\n  var len_pubkey = outstate.pubkey.length;\n  var len_spubkey = info.pubkey.length;\n  var len_secret = info.secret.length;\n\n  var idx_pubkey = 0;\n  var idx_spubkey = 0;\n  var idx_secret = 0;\n\n  while (outstate.pubkey[idx_pubkey] === 0x00) {\n    ++idx_pubkey;\n    --len_pubkey;\n  }\n  while (info.pubkey[idx_spubkey] === 0x00) {\n    ++idx_spubkey;\n    --len_spubkey;\n  }\n  while (info.secret[idx_secret] === 0x00) {\n    ++idx_secret;\n    --len_secret;\n  }\n  if (outstate.pubkey[idx_pubkey] & 0x80)\n    ++len_pubkey;\n  if (info.pubkey[idx_spubkey] & 0x80)\n    ++len_spubkey;\n  if (info.secret[idx_secret] & 0x80)\n    ++len_secret;\n\n  var exchangeBufLen = len_ident\n                       + len_sident\n                       + len_init\n                       + len_sinit\n                       + len_hostkey\n                       + len_pubkey\n                       + len_spubkey\n                       + len_secret\n                       + (4 * 8); // Length fields for above values\n\n  // Group exchange-related\n  var isGEX = RE_GEX.test(state.kexdh);\n  var len_gex_prime = 0;\n  var len_gex_gen = 0;\n  var idx_gex_prime = 0;\n  var idx_gex_gen = 0;\n  var gex_prime;\n  var gex_gen;\n  if (isGEX) {\n    gex_prime = state.kex.getPrime();\n    gex_gen = state.kex.getGenerator();\n    len_gex_prime = gex_prime.length;\n    len_gex_gen = gex_gen.length;\n    while (gex_prime[idx_gex_prime] === 0x00) {\n      ++idx_gex_prime;\n      --len_gex_prime;\n    }\n    while (gex_gen[idx_gex_gen] === 0x00) {\n      ++idx_gex_gen;\n      --len_gex_gen;\n    }\n    if (gex_prime[idx_gex_prime] & 0x80)\n      ++len_gex_prime;\n    if (gex_gen[idx_gex_gen] & 0x80)\n      ++len_gex_gen;\n    exchangeBufLen += (4 * 3); // min, n, max values\n    exchangeBufLen += (4 * 2); // prime, generator length fields\n    exchangeBufLen += len_gex_prime;\n    exchangeBufLen += len_gex_gen;\n  }\n\n\n  var bp = 0;\n  var exchangeBuf = Buffer.allocUnsafe(exchangeBufLen);\n\n  writeUInt32BE(exchangeBuf, len_ident, bp);\n  bp += 4;\n  exchangeBuf.write(self.config.ident, bp, 'utf8'); // V_C\n  bp += len_ident;\n\n  writeUInt32BE(exchangeBuf, len_sident, bp);\n  bp += 4;\n  exchangeBuf.write(instate.identRaw, bp, 'utf8'); // V_S\n  bp += len_sident;\n\n  writeUInt32BE(exchangeBuf, len_init, bp);\n  bp += 4;\n  outstate.kexinit.copy(exchangeBuf, bp); // I_C\n  bp += len_init;\n  outstate.kexinit = undefined;\n\n  writeUInt32BE(exchangeBuf, len_sinit, bp);\n  bp += 4;\n  instate.kexinit.copy(exchangeBuf, bp); // I_S\n  bp += len_sinit;\n  instate.kexinit = undefined;\n\n  writeUInt32BE(exchangeBuf, len_hostkey, bp);\n  bp += 4;\n  info.hostkey.copy(exchangeBuf, bp); // K_S\n  bp += len_hostkey;\n\n  if (isGEX) {\n    KEXDH_GEX_REQ_PACKET.slice(1).copy(exchangeBuf, bp); // min, n, max\n    bp += (4 * 3); // Skip over bytes just copied\n\n    writeUInt32BE(exchangeBuf, len_gex_prime, bp);\n    bp += 4;\n    if (gex_prime[idx_gex_prime] & 0x80)\n      exchangeBuf[bp++] = 0;\n    gex_prime.copy(exchangeBuf, bp, idx_gex_prime); // p\n    bp += len_gex_prime - (gex_prime[idx_gex_prime] & 0x80 ? 1 : 0);\n\n    writeUInt32BE(exchangeBuf, len_gex_gen, bp);\n    bp += 4;\n    if (gex_gen[idx_gex_gen] & 0x80)\n      exchangeBuf[bp++] = 0;\n    gex_gen.copy(exchangeBuf, bp, idx_gex_gen); // g\n    bp += len_gex_gen - (gex_gen[idx_gex_gen] & 0x80 ? 1 : 0);\n  }\n\n  writeUInt32BE(exchangeBuf, len_pubkey, bp);\n  bp += 4;\n  if (outstate.pubkey[idx_pubkey] & 0x80)\n    exchangeBuf[bp++] = 0;\n  outstate.pubkey.copy(exchangeBuf, bp, idx_pubkey); // e\n  bp += len_pubkey - (outstate.pubkey[idx_pubkey] & 0x80 ? 1 : 0);\n\n  writeUInt32BE(exchangeBuf, len_spubkey, bp);\n  bp += 4;\n  if (info.pubkey[idx_spubkey] & 0x80)\n    exchangeBuf[bp++] = 0;\n  info.pubkey.copy(exchangeBuf, bp, idx_spubkey); // f\n  bp += len_spubkey - (info.pubkey[idx_spubkey] & 0x80 ? 1 : 0);\n\n  writeUInt32BE(exchangeBuf, len_secret, bp);\n  bp += 4;\n  if (info.secret[idx_secret] & 0x80)\n    exchangeBuf[bp++] = 0;\n  info.secret.copy(exchangeBuf, bp, idx_secret); // K\n\n  outstate.exchangeHash = hash.update(exchangeBuf).digest(); // H\n\n  var rawsig = readString(info.sig, info.sig._pos, self); // s\n  if (rawsig === false\n      || !(rawsig = sigSSHToASN1(rawsig, info.sig_format, self))) {\n    return false;\n  }\n\n  var hostPubKey = parseDERKey(info.hostkey, info.sig_format);\n  if (hostPubKey instanceof Error)\n    return false;\n\n  debug('DEBUG: Verifying signature');\n\n  if (!hostPubKey.verify(outstate.exchangeHash, rawsig)) {\n    debug('DEBUG: Signature verification failed');\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    self.reset();\n    var err = new Error('Handshake failed: signature verification failed');\n    err.level = 'handshake';\n    self.emit('error', err);\n    return false;\n  }\n\n  if (outstate.sessionId === undefined)\n    outstate.sessionId = outstate.exchangeHash;\n  outstate.kexsecret = info.secret;\n\n  debug('DEBUG: Outgoing: Writing NEWKEYS');\n  if (outstate.status === OUT_REKEYING)\n    send(self, NEWKEYS_PACKET, undefined, true);\n  else\n    send(self, NEWKEYS_PACKET);\n  outstate.sentNEWKEYS = true;\n\n  if (verifiedHost !== undefined && instate.expectedPacket === undefined) {\n    // We received NEWKEYS while we were waiting for the fingerprint\n    // verification callback to be called. In this case we have to re-execute\n    // onNEWKEYS to finish the handshake.\n    onNEWKEYS(self);\n  }\n}\n\nfunction onNEWKEYS(self) { // Client/Server\n  var state = self._state;\n  var outstate = state.outgoing;\n  var instate = state.incoming;\n\n  instate.expectedPacket = undefined;\n\n  if (!outstate.sentNEWKEYS)\n    return;\n\n  var idx_secret = 0;\n  var len = outstate.kexsecret.length;\n  while (outstate.kexsecret[idx_secret] === 0x00) {\n    ++idx_secret;\n    --len;\n  }\n\n  var outCipherInfo = outstate.encrypt.info = CIPHER_INFO[outstate.encrypt.type];\n  var p = 0;\n\n  var dhHashAlgo;\n  if (state.kexdh === 'group')\n    dhHashAlgo = 'sha1';\n  else\n    dhHashAlgo = RE_KEX_HASH.exec(state.kexdh)[1];\n\n  var len_secret = (outstate.kexsecret[idx_secret] & 0x80 ? 1 : 0) + len;\n  var secret = Buffer.allocUnsafe(4 + len_secret);\n  var iv;\n  var key;\n\n  // Whenever the client sends a new authentication request, it is enqueued\n  // here.  Once the request is resolved (success, fail, or PK_OK),\n  // dequeue.  Whatever is at the front of the queue determines how we\n  // interpret packet type 60.\n  state.authsQueue = [];\n\n  writeUInt32BE(secret, len_secret, p);\n  p += 4;\n  if (outstate.kexsecret[idx_secret] & 0x80)\n    secret[p++] = 0;\n  outstate.kexsecret.copy(secret, p, idx_secret);\n  outstate.kexsecret = undefined;\n  if (!outCipherInfo.stream) {\n    iv = crypto.createHash(dhHashAlgo)\n               .update(secret)\n               .update(outstate.exchangeHash)\n               .update(!self.server ? 'A' : 'B', 'ascii')\n               .update(outstate.sessionId)\n               .digest();\n    while (iv.length < outCipherInfo.ivLen) {\n      iv = Buffer.concat([iv,\n                          crypto.createHash(dhHashAlgo)\n                                .update(secret)\n                                .update(outstate.exchangeHash)\n                                .update(iv)\n                                .digest()]);\n    }\n    if (iv.length > outCipherInfo.ivLen)\n      iv = iv.slice(0, outCipherInfo.ivLen);\n  } else {\n    iv = EMPTY_BUFFER; // Streaming ciphers don't use an IV upfront\n  }\n\n  key = crypto.createHash(dhHashAlgo)\n              .update(secret)\n              .update(outstate.exchangeHash)\n              .update(!self.server ? 'C' : 'D', 'ascii')\n              .update(outstate.sessionId)\n              .digest();\n  while (key.length < outCipherInfo.keyLen) {\n    key = Buffer.concat([key,\n                         crypto.createHash(dhHashAlgo)\n                               .update(secret)\n                               .update(outstate.exchangeHash)\n                               .update(key)\n                               .digest()]);\n  }\n  if (key.length > outCipherInfo.keyLen)\n    key = key.slice(0, outCipherInfo.keyLen);\n\n  if (outCipherInfo.authLen > 0) {\n    outstate.encrypt.iv = iv;\n    outstate.encrypt.key = key;\n    outstate.encrypt.instance = true;\n  } else {\n    var cipherAlgo = SSH_TO_OPENSSL[outstate.encrypt.type];\n    outstate.encrypt.instance = crypto.createCipheriv(cipherAlgo, key, iv);\n    outstate.encrypt.instance.setAutoPadding(false);\n  }\n\n  // And now for decrypting ...\n\n  var inCipherInfo = instate.decrypt.info = CIPHER_INFO[instate.decrypt.type];\n  if (!inCipherInfo.stream) {\n    iv = crypto.createHash(dhHashAlgo)\n               .update(secret)\n               .update(outstate.exchangeHash)\n               .update(!self.server ? 'B' : 'A', 'ascii')\n               .update(outstate.sessionId)\n               .digest();\n    while (iv.length < inCipherInfo.ivLen) {\n      iv = Buffer.concat([iv,\n                          crypto.createHash(dhHashAlgo)\n                                .update(secret)\n                                .update(outstate.exchangeHash)\n                                .update(iv)\n                                .digest()]);\n    }\n    if (iv.length > inCipherInfo.ivLen)\n      iv = iv.slice(0, inCipherInfo.ivLen);\n  } else {\n    iv = EMPTY_BUFFER; // Streaming ciphers don't use an IV upfront\n  }\n\n  // Create a reusable buffer for decryption purposes\n  instate.decrypt.buf = Buffer.allocUnsafe(inCipherInfo.blockLen);\n\n  key = crypto.createHash(dhHashAlgo)\n              .update(secret)\n              .update(outstate.exchangeHash)\n              .update(!self.server ? 'D' : 'C', 'ascii')\n              .update(outstate.sessionId)\n              .digest();\n  while (key.length < inCipherInfo.keyLen) {\n    key = Buffer.concat([key,\n                         crypto.createHash(dhHashAlgo)\n                               .update(secret)\n                               .update(outstate.exchangeHash)\n                               .update(key)\n                               .digest()]);\n  }\n  if (key.length > inCipherInfo.keyLen)\n    key = key.slice(0, inCipherInfo.keyLen);\n\n  var decipherAlgo = SSH_TO_OPENSSL[instate.decrypt.type];\n  instate.decrypt.instance = crypto.createDecipheriv(decipherAlgo, key, iv);\n  instate.decrypt.instance.setAutoPadding(false);\n  instate.decrypt.iv = iv;\n  instate.decrypt.key = key;\n\n  var emptyBuf;\n  if (outCipherInfo.discardLen > 0) {\n    emptyBuf = Buffer.alloc(outCipherInfo.discardLen);\n    outstate.encrypt.instance.update(emptyBuf);\n  }\n  if (inCipherInfo.discardLen > 0) {\n    if (!emptyBuf || emptyBuf.length !== inCipherInfo.discardLen)\n      emptyBuf = Buffer.alloc(outCipherInfo.discardLen);\n    instate.decrypt.instance.update(emptyBuf);\n  }\n\n  var outHMACInfo = outstate.hmac.info = HMAC_INFO[outstate.hmac.type];\n  var inHMACInfo = instate.hmac.info = HMAC_INFO[instate.hmac.type];\n\n  if (outCipherInfo.authLen === 0) {\n    key = crypto.createHash(dhHashAlgo)\n                .update(secret)\n                .update(outstate.exchangeHash)\n                .update(!self.server ? 'E' : 'F', 'ascii')\n                .update(outstate.sessionId)\n                .digest();\n    while (key.length < outHMACInfo.len) {\n      key = Buffer.concat([key,\n                           crypto.createHash(dhHashAlgo)\n                                 .update(secret)\n                                 .update(outstate.exchangeHash)\n                                 .update(key)\n                                 .digest()]);\n    }\n    if (key.length > outHMACInfo.len)\n      key = key.slice(0, outHMACInfo.len);\n    outstate.hmac.key = key;\n  } else {\n    outstate.hmac.key = undefined;\n  }\n  if (inCipherInfo.authLen === 0) {\n    key = crypto.createHash(dhHashAlgo)\n                .update(secret)\n                .update(outstate.exchangeHash)\n                .update(!self.server ? 'F' : 'E', 'ascii')\n                .update(outstate.sessionId)\n                .digest();\n    while (key.length < inHMACInfo.len) {\n      key = Buffer.concat([key,\n                           crypto.createHash(dhHashAlgo)\n                                 .update(secret)\n                                 .update(outstate.exchangeHash)\n                                 .update(key)\n                                 .digest()]);\n    }\n    if (key.length > inHMACInfo.len)\n      key = key.slice(0, inHMACInfo.len);\n    instate.hmac.key = key;\n  } else {\n    instate.hmac.key = undefined;\n  }\n\n  // Create a reusable buffer for message verification purposes\n  var inHMACSize = inCipherInfo.authLen || instate.hmac.info.actualLen;\n  if (!instate.hmac.buf\n      || instate.hmac.buf.length !== inHMACSize) {\n    instate.hmac.buf = Buffer.allocUnsafe(inHMACSize);\n  }\n\n  outstate.exchangeHash = undefined;\n\n  if (outstate.compress.type === 'zlib') {\n    outstate.compress.instance = zlib.createDeflate(ZLIB_OPTS);\n    outstate.compress.queue = [];\n  } else if (outstate.compress.type === 'none') {\n    outstate.compress.instance = false;\n    outstate.compress.queue = null;\n  }\n  if (instate.decompress.type === 'zlib')\n    instate.decompress.instance = zlib.createInflate(ZLIB_OPTS);\n  else if (instate.decompress.type === 'none')\n    instate.decompress.instance = false;\n\n  self.bytesSent = self.bytesReceived = 0;\n\n  if (outstate.status === OUT_REKEYING) {\n    outstate.status = OUT_READY;\n\n    // Empty our outbound buffer of any data we tried to send during the\n    // re-keying process\n    var queue = outstate.rekeyQueue;\n    var qlen = queue.length;\n    var q = 0;\n\n    outstate.rekeyQueue = [];\n\n    for (; q < qlen; ++q) {\n      if (Buffer.isBuffer(queue[q]))\n        send(self, queue[q]);\n      else\n        send(self, queue[q][0], queue[q][1]);\n    }\n\n    // Now empty our inbound buffer of any non-transport layer packets we\n    // received during the re-keying process\n    queue = instate.rekeyQueue;\n    qlen = queue.length;\n    q = 0;\n\n    instate.rekeyQueue = [];\n\n    var curSeqno = instate.seqno;\n    for (; q < qlen; ++q) {\n      instate.seqno = queue[q][0];\n      instate.payload = queue[q][1];\n      if (parsePacket(self) === false)\n        return;\n\n      if (instate.status === IN_INIT) {\n        // We were reset due to some error/disagreement ?\n        return;\n      }\n    }\n    instate.seqno = curSeqno;\n  } else {\n    outstate.status = OUT_READY;\n    if (instate.status === IN_PACKET) {\n      // Explicitly update incoming packet parser status in order to get the\n      // correct decipher, hmac, etc. states.\n\n      // We only get here if the host fingerprint callback was called\n      // asynchronously and the incoming packet parser is still expecting an\n      // unencrypted packet, etc.\n\n      self.debug('DEBUG: Parser: IN_PACKETBEFORE (update) (expecting '\n                 + inCipherInfo.blockLen + ')');\n      // Wait for the right number of bytes so we can determine the incoming\n      // packet length\n      expectData(self,\n                 EXP_TYPE_BYTES,\n                 inCipherInfo.blockLen,\n                 instate.decrypt.buf);\n    }\n    self.emit('ready');\n  }\n}\n\nfunction parsePacket(self, callback) {\n  var instate = self._state.incoming;\n  var outstate = self._state.outgoing;\n  var payload = instate.payload;\n  var seqno = instate.seqno;\n  var serviceName;\n  var lang;\n  var message;\n  var info;\n  var chan;\n  var data;\n  var srcIP;\n  var srcPort;\n  var sender;\n  var window;\n  var packetSize;\n  var recipient;\n  var description;\n  var socketPath;\n\n  if (++instate.seqno > MAX_SEQNO)\n    instate.seqno = 0;\n\n  if (instate.ignoreNext) {\n    self.debug('DEBUG: Parser: Packet ignored');\n    instate.ignoreNext = false;\n    return;\n  }\n\n  var type = payload[0];\n  if (type === undefined)\n    return false;\n\n  // If we receive a packet during handshake that is not the expected packet\n  // and it is not one of: DISCONNECT, IGNORE, UNIMPLEMENTED, or DEBUG, then we\n  // close the stream\n  if (outstate.status !== OUT_READY\n      && MESSAGE[type] !== instate.expectedPacket\n      && type < 1\n      && type > 4) {\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, expected: '\n               + instate.expectedPacket\n               + ' but got: '\n               + MESSAGE[type]);\n    // XXX: Potential issue where the module user decides to initiate a rekey\n    // via KEXINIT() (which sets `expectedPacket`) after receiving a packet\n    // and there is still another packet already waiting to be parsed at the\n    // time the KEXINIT is written. this will cause an unexpected disconnect...\n    self.disconnect(DISCONNECT_REASON.PROTOCOL_ERROR);\n    var err = new Error('Received unexpected packet');\n    err.level = 'protocol';\n    self.emit('error', err);\n    return false;\n  }\n\n  if (type === MESSAGE.CHANNEL_DATA) {\n    /*\n      byte      SSH_MSG_CHANNEL_DATA\n      uint32    recipient channel\n      string    data\n    */\n    chan = readInt(payload, 1, self, callback);\n    if (chan === false)\n      return false;\n    // TODO: MAX_CHAN_DATA_LEN here should really be dependent upon the\n    //       channel's packet size. The ssh2 module uses 32KB, so we'll hard\n    //       code this for now ...\n    data = readString(payload, 5, self, callback, 32768);\n    if (data === false)\n      return false;\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: CHANNEL_DATA ('\n               + chan\n               + ')');\n    self.emit('CHANNEL_DATA:' + chan, data);\n  } else if (type === MESSAGE.CHANNEL_EXTENDED_DATA) {\n    /*\n      byte      SSH_MSG_CHANNEL_EXTENDED_DATA\n      uint32    recipient channel\n      uint32    data_type_code\n      string    data\n    */\n    chan = readInt(payload, 1, self, callback);\n    if (chan === false)\n      return false;\n    var dataType = readInt(payload, 5, self, callback);\n    if (dataType === false)\n      return false;\n    data = readString(payload, 9, self, callback);\n    if (data === false)\n      return false;\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: '\n               + 'CHANNEL_EXTENDED_DATA ('\n               + chan\n               + ')');\n    self.emit('CHANNEL_EXTENDED_DATA:' + chan, dataType, data);\n  } else if (type === MESSAGE.CHANNEL_WINDOW_ADJUST) {\n    /*\n      byte      SSH_MSG_CHANNEL_WINDOW_ADJUST\n      uint32    recipient channel\n      uint32    bytes to add\n    */\n    chan = readInt(payload, 1, self, callback);\n    if (chan === false)\n      return false;\n    var bytesToAdd = readInt(payload, 5, self, callback);\n    if (bytesToAdd === false)\n      return false;\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: '\n               + 'CHANNEL_WINDOW_ADJUST ('\n               + chan\n               + ', '\n               + bytesToAdd\n               + ')');\n    self.emit('CHANNEL_WINDOW_ADJUST:' + chan, bytesToAdd);\n  } else if (type === MESSAGE.CHANNEL_SUCCESS) {\n    /*\n      byte      SSH_MSG_CHANNEL_SUCCESS\n      uint32    recipient channel\n    */\n    chan = readInt(payload, 1, self, callback);\n    if (chan === false)\n      return false;\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: CHANNEL_SUCCESS ('\n               + chan\n               + ')');\n    self.emit('CHANNEL_SUCCESS:' + chan);\n  } else if (type === MESSAGE.CHANNEL_FAILURE) {\n    /*\n      byte      SSH_MSG_CHANNEL_FAILURE\n      uint32    recipient channel\n    */\n    chan = readInt(payload, 1, self, callback);\n    if (chan === false)\n      return false;\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: CHANNEL_FAILURE ('\n               + chan\n               + ')');\n    self.emit('CHANNEL_FAILURE:' + chan);\n  } else if (type === MESSAGE.CHANNEL_EOF) {\n    /*\n      byte      SSH_MSG_CHANNEL_EOF\n      uint32    recipient channel\n    */\n    chan = readInt(payload, 1, self, callback);\n    if (chan === false)\n      return false;\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: CHANNEL_EOF ('\n               + chan\n               + ')');\n    self.emit('CHANNEL_EOF:' + chan);\n  } else if (type === MESSAGE.CHANNEL_OPEN) {\n    /*\n      byte      SSH_MSG_CHANNEL_OPEN\n      string    channel type in US-ASCII only\n      uint32    sender channel\n      uint32    initial window size\n      uint32    maximum packet size\n      ....      channel type specific data follows\n    */\n    var chanType = readString(payload, 1, 'ascii', self, callback);\n    if (chanType === false)\n      return false;\n    sender = readInt(payload, payload._pos, self, callback);\n    if (sender === false)\n      return false;\n    window = readInt(payload, payload._pos += 4, self, callback);\n    if (window === false)\n      return false;\n    packetSize = readInt(payload, payload._pos += 4, self, callback);\n    if (packetSize === false)\n      return false;\n    var channel;\n\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: CHANNEL_OPEN ('\n               + sender\n               + ', '\n               + chanType\n               + ')');\n\n    if (chanType === 'forwarded-tcpip' // Server->Client\n        || chanType === 'direct-tcpip') { // Client->Server\n      /*\n        string    address that was connected / host to connect\n        uint32    port that was connected / port to connect\n        string    originator IP address\n        uint32    originator port\n      */\n      var destIP = readString(payload,\n                              payload._pos += 4,\n                              'ascii',\n                              self,\n                              callback);\n      if (destIP === false)\n        return false;\n      var destPort = readInt(payload, payload._pos, self, callback);\n      if (destPort === false)\n        return false;\n      srcIP = readString(payload, payload._pos += 4, 'ascii', self, callback);\n      if (srcIP === false)\n        return false;\n      srcPort = readInt(payload, payload._pos, self, callback);\n      if (srcPort === false)\n        return false;\n      channel = {\n        type: chanType,\n        sender: sender,\n        window: window,\n        packetSize: packetSize,\n        data: {\n          destIP: destIP,\n          destPort: destPort,\n          srcIP: srcIP,\n          srcPort: srcPort\n        }\n      };\n    } else if (// Server->Client\n               chanType === 'forwarded-streamlocal@openssh.com'\n               // Client->Server\n               || chanType === 'direct-streamlocal@openssh.com') {\n      /*\n        string    socket path\n        string    reserved for future use\n      */\n      socketPath = readString(payload,\n                              payload._pos += 4,\n                              'utf8',\n                              self,\n                              callback);\n      if (socketPath === false)\n        return false;\n      channel = {\n        type: chanType,\n        sender: sender,\n        window: window,\n        packetSize: packetSize,\n        data: {\n          socketPath: socketPath,\n        }\n      };\n    } else if (chanType === 'x11') { // Server->Client\n      /*\n        string    originator address (e.g., \"192.168.7.38\")\n        uint32    originator port\n      */\n      srcIP = readString(payload, payload._pos += 4, 'ascii', self, callback);\n      if (srcIP === false)\n        return false;\n      srcPort = readInt(payload, payload._pos, self, callback);\n      if (srcPort === false)\n        return false;\n      channel = {\n        type: chanType,\n        sender: sender,\n        window: window,\n        packetSize: packetSize,\n        data: {\n          srcIP: srcIP,\n          srcPort: srcPort\n        }\n      };\n    } else {\n      // 'session' (Client->Server), 'auth-agent@openssh.com' (Server->Client)\n      channel = {\n        type: chanType,\n        sender: sender,\n        window: window,\n        packetSize: packetSize,\n        data: {}\n      };\n    }\n\n    self.emit('CHANNEL_OPEN', channel);\n  } else if (type === MESSAGE.CHANNEL_OPEN_CONFIRMATION) {\n    /*\n      byte      SSH_MSG_CHANNEL_OPEN_CONFIRMATION\n      uint32    recipient channel\n      uint32    sender channel\n      uint32    initial window size\n      uint32    maximum packet size\n      ....      channel type specific data follows\n    */\n    // \"The 'recipient channel' is the channel number given in the\n    // original open request, and 'sender channel' is the channel number\n    // allocated by the other side.\"\n    recipient = readInt(payload, 1, self, callback);\n    if (recipient === false)\n      return false;\n    sender = readInt(payload, 5, self, callback);\n    if (sender === false)\n      return false;\n    window = readInt(payload, 9, self, callback);\n    if (window === false)\n      return false;\n    packetSize = readInt(payload, 13, self, callback);\n    if (packetSize === false)\n      return false;\n\n    info = {\n      recipient: recipient,\n      sender: sender,\n      window: window,\n      packetSize: packetSize\n    };\n\n    if (payload.length > 17)\n      info.data = payload.slice(17);\n\n    self.emit('CHANNEL_OPEN_CONFIRMATION:' + info.recipient, info);\n  } else if (type === MESSAGE.CHANNEL_OPEN_FAILURE) {\n    /*\n      byte      SSH_MSG_CHANNEL_OPEN_FAILURE\n      uint32    recipient channel\n      uint32    reason code\n      string    description in ISO-10646 UTF-8 encoding\n      string    language tag\n    */\n    recipient = readInt(payload, 1, self, callback);\n    if (recipient === false)\n      return false;\n    var reasonCode = readInt(payload, 5, self, callback);\n    if (reasonCode === false)\n      return false;\n    description = readString(payload, 9, 'utf8', self, callback);\n    if (description === false)\n      return false;\n    lang = readString(payload, payload._pos, 'utf8', self, callback);\n    if (lang === false)\n      return false;\n    payload._pos = 9;\n    info = {\n      recipient: recipient,\n      reasonCode: reasonCode,\n      reason: CHANNEL_OPEN_FAILURE[reasonCode],\n      description: description,\n      lang: lang\n    };\n\n    self.emit('CHANNEL_OPEN_FAILURE:' + info.recipient, info);\n  } else if (type === MESSAGE.CHANNEL_CLOSE) {\n    /*\n      byte      SSH_MSG_CHANNEL_CLOSE\n      uint32    recipient channel\n    */\n    chan = readInt(payload, 1, self, callback);\n    if (chan === false)\n      return false;\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: CHANNEL_CLOSE ('\n               + chan\n               + ')');\n    self.emit('CHANNEL_CLOSE:' + chan);\n  } else if (type === MESSAGE.IGNORE) {\n    /*\n      byte      SSH_MSG_IGNORE\n      string    data\n    */\n  } else if (type === MESSAGE.DISCONNECT) {\n    /*\n      byte      SSH_MSG_DISCONNECT\n      uint32    reason code\n      string    description in ISO-10646 UTF-8 encoding\n      string    language tag\n    */\n    var reason = readInt(payload, 1, self, callback);\n    if (reason === false)\n      return false;\n    var reasonText = DISCONNECT_REASON[reason];\n    description = readString(payload, 5, 'utf8', self, callback);\n    if (description === false)\n      return false;\n\n    if (payload._pos < payload.length)\n      lang = readString(payload, payload._pos, 'ascii', self, callback);\n\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: DISCONNECT ('\n               + reasonText\n               + ')');\n\n    self.emit('DISCONNECT', reasonText, reason, description, lang);\n  } else if (type === MESSAGE.DEBUG) {\n    /*\n      byte      SSH_MSG_DEBUG\n      boolean   always_display\n      string    message in ISO-10646 UTF-8 encoding\n      string    language tag\n    */\n    message = readString(payload, 2, 'utf8', self, callback);\n    if (message === false)\n      return false;\n    lang = readString(payload, payload._pos, 'ascii', self, callback);\n    if (lang === false)\n      return false;\n\n    self.emit('DEBUG', message, lang);\n  } else if (type === MESSAGE.NEWKEYS) {\n    /*\n      byte      SSH_MSG_NEW_KEYS\n    */\n    self.emit('NEWKEYS');\n  } else if (type === MESSAGE.SERVICE_REQUEST) {\n    /*\n      byte      SSH_MSG_SERVICE_REQUEST\n      string    service name\n    */\n    serviceName = readString(payload, 1, 'ascii', self, callback);\n    if (serviceName === false)\n      return false;\n\n    self.emit('SERVICE_REQUEST', serviceName);\n  } else if (type === MESSAGE.SERVICE_ACCEPT) {\n    /*\n      byte      SSH_MSG_SERVICE_ACCEPT\n      string    service name\n    */\n    serviceName = readString(payload, 1, 'ascii', self, callback);\n    if (serviceName === false)\n      return false;\n\n    self.emit('SERVICE_ACCEPT', serviceName);\n  } else if (type === MESSAGE.USERAUTH_REQUEST) {\n    /*\n      byte      SSH_MSG_USERAUTH_REQUEST\n      string    user name in ISO-10646 UTF-8 encoding [RFC3629]\n      string    service name in US-ASCII\n      string    method name in US-ASCII\n      ....      method specific fields\n    */\n    var username = readString(payload, 1, 'utf8', self, callback);\n    if (username === false)\n      return false;\n    var svcName = readString(payload, payload._pos, 'ascii', self, callback);\n    if (svcName === false)\n      return false;\n    var method = readString(payload, payload._pos, 'ascii', self, callback);\n    if (method === false)\n      return false;\n    var methodData;\n\n    if (method === 'password') {\n      methodData = readString(payload,\n                              payload._pos + 1,\n                              'utf8',\n                              self,\n                              callback);\n      if (methodData === false)\n        return false;\n    } else if (method === 'publickey' || method === 'hostbased') {\n      var pkSigned;\n      var keyAlgo;\n      var key;\n      var signature;\n      var blob;\n      var hostname;\n      var userlocal;\n      if (method === 'publickey') {\n        pkSigned = payload[payload._pos++];\n        if (pkSigned === undefined)\n          return false;\n        pkSigned = (pkSigned !== 0);\n      }\n      keyAlgo = readString(payload, payload._pos, 'ascii', self, callback);\n      if (keyAlgo === false)\n        return false;\n      key = readString(payload, payload._pos, self, callback);\n      if (key === false)\n        return false;\n\n      if (pkSigned || method === 'hostbased') {\n        if (method === 'hostbased') {\n          hostname = readString(payload, payload._pos, 'ascii', self, callback);\n          if (hostname === false)\n            return false;\n          userlocal = readString(payload, payload._pos, 'utf8', self, callback);\n          if (userlocal === false)\n            return false;\n        }\n\n        var blobEnd = payload._pos;\n        signature = readString(payload, blobEnd, self, callback);\n        if (signature === false)\n          return false;\n\n        if (signature.length > (4 + keyAlgo.length + 4)\n            && signature.toString('ascii', 4, 4 + keyAlgo.length) === keyAlgo) {\n          // Skip algoLen + algo + sigLen\n          signature = signature.slice(4 + keyAlgo.length + 4);\n        }\n\n        signature = sigSSHToASN1(signature, keyAlgo, self, callback);\n        if (signature === false)\n          return false;\n\n        blob = Buffer.allocUnsafe(4 + outstate.sessionId.length + blobEnd);\n        writeUInt32BE(blob, outstate.sessionId.length, 0);\n        outstate.sessionId.copy(blob, 4);\n        payload.copy(blob, 4 + outstate.sessionId.length, 0, blobEnd);\n      }\n\n      methodData = {\n        keyAlgo: keyAlgo,\n        key: key,\n        signature: signature,\n        blob: blob,\n        localHostname: hostname,\n        localUsername: userlocal\n      };\n    } else if (method === 'keyboard-interactive') {\n      // Skip language, it's deprecated\n      var skipLen = readInt(payload, payload._pos, self, callback);\n      if (skipLen === false)\n        return false;\n      methodData = readString(payload,\n                              payload._pos + 4 + skipLen,\n                              'utf8',\n                              self,\n                              callback);\n      if (methodData === false)\n        return false;\n    } else if (method !== 'none')\n      methodData = payload.slice(payload._pos);\n\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: USERAUTH_REQUEST ('\n               + method\n               + ')');\n\n    self._state.authsQueue.push(method);\n    self.emit('USERAUTH_REQUEST', username, svcName, method, methodData);\n  } else if (type === MESSAGE.USERAUTH_SUCCESS) {\n    /*\n      byte      SSH_MSG_USERAUTH_SUCCESS\n    */\n    if (outstate.compress.type === 'zlib@openssh.com') {\n      outstate.compress.instance = zlib.createDeflate(ZLIB_OPTS);\n      outstate.compress.queue = [];\n    }\n    if (instate.decompress.type === 'zlib@openssh.com')\n      instate.decompress.instance = zlib.createInflate(ZLIB_OPTS);\n\n    self._state.authsQueue.shift();\n\n    self.emit('USERAUTH_SUCCESS');\n  } else if (type === MESSAGE.USERAUTH_FAILURE) {\n    /*\n      byte      SSH_MSG_USERAUTH_FAILURE\n      name-list    authentications that can continue\n      boolean      partial success\n    */\n    var auths = readString(payload, 1, 'ascii', self, callback);\n    if (auths === false)\n      return false;\n    var partSuccess = payload[payload._pos];\n    if (partSuccess === undefined)\n      return false;\n\n    partSuccess = (partSuccess !== 0);\n    auths = auths.split(',');\n\n    self._state.authsQueue.shift();\n    self.emit('USERAUTH_FAILURE', auths, partSuccess);\n  } else if (type === MESSAGE.USERAUTH_BANNER) {\n    /*\n      byte      SSH_MSG_USERAUTH_BANNER\n      string    message in ISO-10646 UTF-8 encoding\n      string    language tag\n    */\n    message = readString(payload, 1, 'utf8', self, callback);\n    if (message === false)\n      return false;\n    lang = readString(payload, payload._pos, 'utf8', self, callback);\n    if (lang === false)\n      return false;\n\n    self.emit('USERAUTH_BANNER', message, lang);\n  } else if (type === MESSAGE.GLOBAL_REQUEST) {\n    /*\n      byte      SSH_MSG_GLOBAL_REQUEST\n      string    request name in US-ASCII only\n      boolean   want reply\n      ....      request-specific data follows\n    */\n    var request = readString(payload, 1, 'ascii', self, callback);\n    if (request === false) {\n      self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: GLOBAL_REQUEST');\n      return false;\n    }\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: GLOBAL_REQUEST ('\n               + request\n               + ')');\n\n    var wantReply = payload[payload._pos++];\n    if (wantReply === undefined)\n      return false;\n    wantReply = (wantReply !== 0);\n\n    var reqData;\n    if (request === 'tcpip-forward' || request === 'cancel-tcpip-forward') {\n      var bindAddr = readString(payload, payload._pos, 'ascii', self, callback);\n      if (bindAddr === false)\n        return false;\n      var bindPort = readInt(payload, payload._pos, self, callback);\n      if (bindPort === false)\n        return false;\n      reqData = {\n        bindAddr: bindAddr,\n        bindPort: bindPort\n      };\n    } else if (request === 'streamlocal-forward@openssh.com'\n               || request === 'cancel-streamlocal-forward@openssh.com') {\n      socketPath = readString(payload, payload._pos, 'utf8', self, callback);\n      if (socketPath === false)\n        return false;\n      reqData = {\n        socketPath: socketPath\n      };\n    } else if (request === 'no-more-sessions@openssh.com') {\n      // No data\n    } else {\n      reqData = payload.slice(payload._pos);\n    }\n\n    self.emit('GLOBAL_REQUEST', request, wantReply, reqData);\n  } else if (type === MESSAGE.REQUEST_SUCCESS) {\n    /*\n      byte      SSH_MSG_REQUEST_SUCCESS\n      ....      response specific data\n    */\n    if (payload.length > 1)\n      self.emit('REQUEST_SUCCESS', payload.slice(1));\n    else\n      self.emit('REQUEST_SUCCESS');\n  } else if (type === MESSAGE.REQUEST_FAILURE) {\n    /*\n      byte      SSH_MSG_REQUEST_FAILURE\n    */\n    self.emit('REQUEST_FAILURE');\n  } else if (type === MESSAGE.UNIMPLEMENTED) {\n    /*\n      byte      SSH_MSG_UNIMPLEMENTED\n      uint32    packet sequence number of rejected message\n    */\n    // TODO\n  } else if (type === MESSAGE.KEXINIT)\n    return parse_KEXINIT(self, callback);\n  else if (type === MESSAGE.CHANNEL_REQUEST)\n    return parse_CHANNEL_REQUEST(self, callback);\n  else if (type >= 30 && type <= 49) // Key exchange method-specific messages\n    return parse_KEX(self, type, callback);\n  else if (type >= 60 && type <= 70) // User auth context-specific messages\n    return parse_USERAUTH(self, type, callback);\n  else {\n    // Unknown packet type\n    var unimpl = Buffer.allocUnsafe(1 + 4);\n    unimpl[0] = MESSAGE.UNIMPLEMENTED;\n    writeUInt32BE(unimpl, seqno, 1);\n    send(self, unimpl);\n  }\n}\n\nfunction parse_KEXINIT(self, callback) {\n  var instate = self._state.incoming;\n  var payload = instate.payload;\n\n  /*\n    byte         SSH_MSG_KEXINIT\n    byte[16]     cookie (random bytes)\n    name-list    kex_algorithms\n    name-list    server_host_key_algorithms\n    name-list    encryption_algorithms_client_to_server\n    name-list    encryption_algorithms_server_to_client\n    name-list    mac_algorithms_client_to_server\n    name-list    mac_algorithms_server_to_client\n    name-list    compression_algorithms_client_to_server\n    name-list    compression_algorithms_server_to_client\n    name-list    languages_client_to_server\n    name-list    languages_server_to_client\n    boolean      first_kex_packet_follows\n    uint32       0 (reserved for future extension)\n  */\n  var init = {\n    algorithms: {\n      kex: undefined,\n      srvHostKey: undefined,\n      cs: {\n        encrypt: undefined,\n        mac: undefined,\n        compress: undefined\n      },\n      sc: {\n        encrypt: undefined,\n        mac: undefined,\n        compress: undefined\n      }\n    },\n    languages: {\n      cs: undefined,\n      sc: undefined\n    }\n  };\n  var val;\n\n  val = readList(payload, 17, self, callback);\n  if (val === false)\n    return false;\n  init.algorithms.kex = val;\n  val = readList(payload, payload._pos, self, callback);\n  if (val === false)\n    return false;\n  init.algorithms.srvHostKey = val;\n  val = readList(payload, payload._pos, self, callback);\n  if (val === false)\n    return false;\n  init.algorithms.cs.encrypt = val;\n  val = readList(payload, payload._pos, self, callback);\n  if (val === false)\n    return false;\n  init.algorithms.sc.encrypt = val;\n  val = readList(payload, payload._pos, self, callback);\n  if (val === false)\n    return false;\n  init.algorithms.cs.mac = val;\n  val = readList(payload, payload._pos, self, callback);\n  if (val === false)\n    return false;\n  init.algorithms.sc.mac = val;\n  val = readList(payload, payload._pos, self, callback);\n  if (val === false)\n    return false;\n  init.algorithms.cs.compress = val;\n  val = readList(payload, payload._pos, self, callback);\n  if (val === false)\n    return false;\n  init.algorithms.sc.compress = val;\n  val = readList(payload, payload._pos, self, callback);\n  if (val === false)\n    return false;\n  init.languages.cs = val;\n  val = readList(payload, payload._pos, self, callback);\n  if (val === false)\n    return false;\n  init.languages.sc = val;\n\n  var firstFollows = (payload._pos < payload.length\n                      && payload[payload._pos] === 1);\n\n  instate.kexinit = payload;\n\n  self.emit('KEXINIT', init, firstFollows);\n}\n\nfunction parse_KEX(self, type, callback) {\n  var state = self._state;\n  var instate = state.incoming;\n  var payload = instate.payload;\n  var pktType = (RE_GEX.test(state.kexdh)\n                 ? DYNAMIC_KEXDH_MESSAGE[type]\n                 : KEXDH_MESSAGE[type]);\n\n  if (state.outgoing.status === OUT_READY\n      || instate.expectedPacket !== pktType) {\n    self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, expected: '\n               + instate.expectedPacket\n               + ' but got: '\n               + pktType);\n    self.disconnect(DISCONNECT_REASON.PROTOCOL_ERROR);\n    var err = new Error('Received unexpected packet');\n    err.level = 'protocol';\n    self.emit('error', err);\n    return false;\n  }\n\n  if (RE_GEX.test(state.kexdh)) {\n    // Dynamic group exchange-related\n\n    if (self.server) {\n      // TODO: Support group exchange server-side\n      self.disconnect(DISCONNECT_REASON.PROTOCOL_ERROR);\n      var err = new Error('DH group exchange not supported by server');\n      err.level = 'handshake';\n      self.emit('error', err);\n      return false;\n    } else {\n      if (type === MESSAGE.KEXDH_GEX_GROUP) {\n        /*\n          byte    SSH_MSG_KEX_DH_GEX_GROUP\n          mpint   p, safe prime\n          mpint   g, generator for subgroup in GF(p)\n        */\n        var prime = readString(payload, 1, self, callback);\n        if (prime === false)\n          return false;\n        var gen = readString(payload, payload._pos, self, callback);\n        if (gen === false)\n          return false;\n        self.emit('KEXDH_GEX_GROUP', prime, gen);\n      } else if (type === MESSAGE.KEXDH_GEX_REPLY)\n        return parse_KEXDH_REPLY(self, callback);\n    }\n  } else {\n    // Static group or ECDH-related\n\n    if (type === MESSAGE.KEXDH_INIT) {\n      /*\n        byte      SSH_MSG_KEXDH_INIT\n        mpint     e\n      */\n      var e = readString(payload, 1, self, callback);\n      if (e === false)\n        return false;\n\n      self.emit('KEXDH_INIT', e);\n    } else if (type === MESSAGE.KEXDH_REPLY)\n      return parse_KEXDH_REPLY(self, callback);\n  }\n}\n\nfunction parse_KEXDH_REPLY(self, callback) {\n  var payload = self._state.incoming.payload;\n  /*\n    byte      SSH_MSG_KEXDH_REPLY\n                / SSH_MSG_KEX_DH_GEX_REPLY\n                / SSH_MSG_KEX_ECDH_REPLY\n    string    server public host key and certificates (K_S)\n    mpint     f\n    string    signature of H\n  */\n  var hostkey = readString(payload, 1, self, callback);\n  if (hostkey === false)\n    return false;\n  var pubkey = readString(payload, payload._pos, self, callback);\n  if (pubkey === false)\n    return false;\n  var sig = readString(payload, payload._pos, self, callback);\n  if (sig === false)\n    return false;\n  var info = {\n    hostkey: hostkey,\n    hostkey_format: undefined,\n    pubkey: pubkey,\n    sig: sig,\n    sig_format: undefined\n  };\n  var hostkey_format = readString(hostkey, 0, 'ascii', self, callback);\n  if (hostkey_format === false)\n    return false;\n  info.hostkey_format = hostkey_format;\n  var sig_format = readString(sig, 0, 'ascii', self, callback);\n  if (sig_format === false)\n    return false;\n  info.sig_format = sig_format;\n  self.emit('KEXDH_REPLY', info);\n}\n\nfunction parse_USERAUTH(self, type, callback) {\n  var state = self._state;\n  var authMethod = state.authsQueue[0];\n  var payload = state.incoming.payload;\n  var message;\n  var lang;\n  var text;\n\n  if (authMethod === 'password') {\n    if (type === MESSAGE.USERAUTH_PASSWD_CHANGEREQ) {\n      /*\n        byte      SSH_MSG_USERAUTH_PASSWD_CHANGEREQ\n        string    prompt in ISO-10646 UTF-8 encoding\n        string    language tag\n      */\n      message = readString(payload, 1, 'utf8', self, callback);\n      if (message === false)\n        return false;\n      lang = readString(payload, payload._pos, 'utf8', self, callback);\n      if (lang === false)\n        return false;\n      self.emit('USERAUTH_PASSWD_CHANGEREQ', message, lang);\n    }\n  } else if (authMethod === 'keyboard-interactive') {\n    if (type === MESSAGE.USERAUTH_INFO_REQUEST) {\n      /*\n        byte      SSH_MSG_USERAUTH_INFO_REQUEST\n        string    name (ISO-10646 UTF-8)\n        string    instruction (ISO-10646 UTF-8)\n        string    language tag -- MAY be empty\n        int       num-prompts\n        string    prompt[1] (ISO-10646 UTF-8)\n        boolean   echo[1]\n        ...\n        string    prompt[num-prompts] (ISO-10646 UTF-8)\n        boolean   echo[num-prompts]\n      */\n      var name;\n      var instr;\n      var nprompts;\n\n      name = readString(payload, 1, 'utf8', self, callback);\n      if (name === false)\n        return false;\n      instr = readString(payload, payload._pos, 'utf8', self, callback);\n      if (instr === false)\n        return false;\n      lang = readString(payload, payload._pos, 'utf8', self, callback);\n      if (lang === false)\n        return false;\n      nprompts = readInt(payload, payload._pos, self, callback);\n      if (nprompts === false)\n        return false;\n\n      payload._pos += 4;\n\n      var prompts = [];\n      for (var prompt = 0; prompt < nprompts; ++prompt) {\n        text = readString(payload, payload._pos, 'utf8', self, callback);\n        if (text === false)\n          return false;\n        var echo = payload[payload._pos++];\n        if (echo === undefined)\n          return false;\n        echo = (echo !== 0);\n        prompts.push({\n          prompt: text,\n          echo: echo\n        });\n      }\n      self.emit('USERAUTH_INFO_REQUEST', name, instr, lang, prompts);\n    } else if (type === MESSAGE.USERAUTH_INFO_RESPONSE) {\n      /*\n        byte      SSH_MSG_USERAUTH_INFO_RESPONSE\n        int       num-responses\n        string    response[1] (ISO-10646 UTF-8)\n        ...\n        string    response[num-responses] (ISO-10646 UTF-8)\n      */\n      var nresponses = readInt(payload, 1, self, callback);\n      if (nresponses === false)\n        return false;\n\n      payload._pos = 5;\n\n      var responses = [];\n      for (var response = 0; response < nresponses; ++response) {\n        text = readString(payload, payload._pos, 'utf8', self, callback);\n        if (text === false)\n          return false;\n        responses.push(text);\n      }\n      self.emit('USERAUTH_INFO_RESPONSE', responses);\n    }\n  } else if (authMethod === 'publickey') {\n    if (type === MESSAGE.USERAUTH_PK_OK) {\n      /*\n        byte      SSH_MSG_USERAUTH_PK_OK\n        string    public key algorithm name from the request\n        string    public key blob from the request\n      */\n      var authsQueue = self._state.authsQueue;\n      if (!authsQueue.length || authsQueue[0] !== 'publickey')\n        return;\n      authsQueue.shift();\n      self.emit('USERAUTH_PK_OK');\n      // XXX: Parse public key info? client currently can ignore it because\n      // there is only one outstanding auth request at any given time, so it\n      // knows which key was OK'd\n    }\n  } else if (authMethod !== undefined) {\n    // Invalid packet for this auth type\n    self.disconnect(DISCONNECT_REASON.PROTOCOL_ERROR);\n    var err = new Error('Invalid authentication method: ' + authMethod);\n    err.level = 'protocol';\n    self.emit('error', err);\n  }\n}\n\nfunction parse_CHANNEL_REQUEST(self, callback) {\n  var payload = self._state.incoming.payload;\n  var info;\n  var cols;\n  var rows;\n  var width;\n  var height;\n  var wantReply;\n  var signal;\n\n  var recipient = readInt(payload, 1, self, callback);\n  if (recipient === false)\n    return false;\n  var request = readString(payload, 5, 'ascii', self, callback);\n  if (request === false)\n    return false;\n\n  if (request === 'exit-status') { // Server->Client\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"exit-status\"\n      boolean   FALSE\n      uint32    exit_status\n    */\n    var code = readInt(payload, ++payload._pos, self, callback);\n    if (code === false)\n      return false;\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: false,\n      code: code\n    };\n  } else if (request === 'exit-signal') { // Server->Client\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"exit-signal\"\n      boolean   FALSE\n      string    signal name (without the \"SIG\" prefix)\n      boolean   core dumped\n      string    error message in ISO-10646 UTF-8 encoding\n      string    language tag\n    */\n    var coredump;\n    if (!(self.remoteBugs & BUGS.OLD_EXIT)) {\n      signal = readString(payload, ++payload._pos, 'ascii', self, callback);\n      if (signal === false)\n        return false;\n      coredump = payload[payload._pos++];\n      if (coredump === undefined)\n        return false;\n      coredump = (coredump !== 0);\n    } else {\n      /*\n        Instead of `signal name` and `core dumped`, we have just:\n\n        uint32  signal number\n      */\n      signal = readInt(payload, ++payload._pos, self, callback);\n      if (signal === false)\n        return false;\n      switch (signal) {\n        case 1:\n          signal = 'HUP';\n          break;\n        case 2:\n          signal = 'INT';\n          break;\n        case 3:\n          signal = 'QUIT';\n          break;\n        case 6:\n          signal = 'ABRT';\n          break;\n        case 9:\n          signal = 'KILL';\n          break;\n        case 14:\n          signal = 'ALRM';\n          break;\n        case 15:\n          signal = 'TERM';\n          break;\n        default:\n          // Unknown or OS-specific\n          signal = 'UNKNOWN (' + signal + ')';\n      }\n      coredump = false;\n    }\n    var description = readString(payload, payload._pos, 'utf8', self,\n                                 callback);\n    if (description === false)\n      return false;\n    var lang = readString(payload, payload._pos, 'utf8', self, callback);\n    if (lang === false)\n      return false;\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: false,\n      signal: signal,\n      coredump: coredump,\n      description: description,\n      lang: lang\n    };\n  } else if (request === 'pty-req') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"pty-req\"\n      boolean   want_reply\n      string    TERM environment variable value (e.g., vt100)\n      uint32    terminal width, characters (e.g., 80)\n      uint32    terminal height, rows (e.g., 24)\n      uint32    terminal width, pixels (e.g., 640)\n      uint32    terminal height, pixels (e.g., 480)\n      string    encoded terminal modes\n    */\n    wantReply = payload[payload._pos++];\n    if (wantReply === undefined)\n      return false;\n    wantReply = (wantReply !== 0);\n    var term = readString(payload, payload._pos, 'ascii', self, callback);\n    if (term === false)\n      return false;\n    cols = readInt(payload, payload._pos, self, callback);\n    if (cols === false)\n      return false;\n    rows = readInt(payload, payload._pos += 4, self, callback);\n    if (rows === false)\n      return false;\n    width = readInt(payload, payload._pos += 4, self, callback);\n    if (width === false)\n      return false;\n    height = readInt(payload, payload._pos += 4, self, callback);\n    if (height === false)\n      return false;\n    var modes = readString(payload, payload._pos += 4, self, callback);\n    if (modes === false)\n      return false;\n    modes = bytesToModes(modes);\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: wantReply,\n      term: term,\n      cols: cols,\n      rows: rows,\n      width: width,\n      height: height,\n      modes: modes\n    };\n  } else if (request === 'window-change') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"window-change\"\n      boolean   FALSE\n      uint32    terminal width, columns\n      uint32    terminal height, rows\n      uint32    terminal width, pixels\n      uint32    terminal height, pixels\n    */\n    cols = readInt(payload, ++payload._pos, self, callback);\n    if (cols === false)\n      return false;\n    rows = readInt(payload, payload._pos += 4, self, callback);\n    if (rows === false)\n      return false;\n    width = readInt(payload, payload._pos += 4, self, callback);\n    if (width === false)\n      return false;\n    height = readInt(payload, payload._pos += 4, self, callback);\n    if (height === false)\n      return false;\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: false,\n      cols: cols,\n      rows: rows,\n      width: width,\n      height: height\n    };\n  } else if (request === 'x11-req') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"x11-req\"\n      boolean   want reply\n      boolean   single connection\n      string    x11 authentication protocol\n      string    x11 authentication cookie\n      uint32    x11 screen number\n    */\n    wantReply = payload[payload._pos++];\n    if (wantReply === undefined)\n      return false;\n    wantReply = (wantReply !== 0);\n    var single = payload[payload._pos++];\n    if (single === undefined)\n      return false;\n    single = (single !== 0);\n    var protocol = readString(payload, payload._pos, 'ascii', self, callback);\n    if (protocol === false)\n      return false;\n    var cookie = readString(payload, payload._pos, 'binary', self, callback);\n    if (cookie === false)\n      return false;\n    var screen = readInt(payload, payload._pos, self, callback);\n    if (screen === false)\n      return false;\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: wantReply,\n      single: single,\n      protocol: protocol,\n      cookie: cookie,\n      screen: screen\n    };\n  } else if (request === 'env') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"env\"\n      boolean   want reply\n      string    variable name\n      string    variable value\n    */\n    wantReply = payload[payload._pos++];\n    if (wantReply === undefined)\n      return false;\n    wantReply = (wantReply !== 0);\n    var key = readString(payload, payload._pos, 'utf8', self, callback);\n    if (key === false)\n      return false;\n    var val = readString(payload, payload._pos, 'utf8', self, callback);\n    if (val === false)\n      return false;\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: wantReply,\n      key: key,\n      val: val\n    };\n  } else if (request === 'shell') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"shell\"\n      boolean   want reply\n    */\n    wantReply = payload[payload._pos];\n    if (wantReply === undefined)\n      return false;\n    wantReply = (wantReply !== 0);\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: wantReply\n    };\n  } else if (request === 'exec') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"exec\"\n      boolean   want reply\n      string    command\n    */\n    wantReply = payload[payload._pos++];\n    if (wantReply === undefined)\n      return false;\n    wantReply = (wantReply !== 0);\n    var command = readString(payload, payload._pos, 'utf8', self, callback);\n    if (command === false)\n      return false;\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: wantReply,\n      command: command\n    };\n  } else if (request === 'subsystem') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"subsystem\"\n      boolean   want reply\n      string    subsystem name\n    */\n    wantReply = payload[payload._pos++];\n    if (wantReply === undefined)\n      return false;\n    wantReply = (wantReply !== 0);\n    var subsystem = readString(payload, payload._pos, 'utf8', self, callback);\n    if (subsystem === false)\n      return false;\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: wantReply,\n      subsystem: subsystem\n    };\n  } else if (request === 'signal') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"signal\"\n      boolean   FALSE\n      string    signal name (without the \"SIG\" prefix)\n    */\n    signal = readString(payload, ++payload._pos, 'ascii', self, callback);\n    if (signal === false)\n      return false;\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: false,\n      signal: 'SIG' + signal\n    };\n  } else if (request === 'xon-xoff') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"xon-xoff\"\n      boolean   FALSE\n      boolean   client can do\n    */\n    var clientControl = payload[++payload._pos];\n    if (clientControl === undefined)\n      return false;\n    clientControl = (clientControl !== 0);\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: false,\n      clientControl: clientControl\n    };\n  } else if (request === 'auth-agent-req@openssh.com') { // Client->Server\n    /*\n      byte      SSH_MSG_CHANNEL_REQUEST\n      uint32    recipient channel\n      string    \"auth-agent-req@openssh.com\"\n      boolean   want reply\n    */\n    wantReply = payload[payload._pos];\n    if (wantReply === undefined)\n      return false;\n    wantReply = (wantReply !== 0);\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: wantReply\n    };\n  } else {\n    // Unknown request type\n    wantReply = payload[payload._pos];\n    if (wantReply === undefined)\n      return false;\n    wantReply = (wantReply !== 0);\n    info = {\n      recipient: recipient,\n      request: request,\n      wantReply: wantReply\n    };\n  }\n  self.debug('DEBUG: Parser: IN_PACKETDATAAFTER, packet: CHANNEL_REQUEST ('\n             + recipient\n             + ', '\n             + request\n             + ')');\n  self.emit('CHANNEL_REQUEST:' + recipient, info);\n}\n\nfunction hmacVerify(self, data) {\n  var instate = self._state.incoming;\n  var hmac = instate.hmac;\n\n  self.debug('DEBUG: Parser: Verifying MAC');\n\n  if (instate.decrypt.info.authLen > 0) {\n    var decrypt = instate.decrypt;\n    var instance = decrypt.instance;\n\n    instance.setAuthTag(data);\n\n    var payload = instance.update(instate.packet);\n    instate.payload = payload.slice(1, instate.packet.length + 4 - payload[0]);\n    iv_inc(decrypt.iv);\n\n    decrypt.instance = crypto.createDecipheriv(\n                         SSH_TO_OPENSSL[decrypt.type],\n                         decrypt.key,\n                         decrypt.iv\n                       );\n    decrypt.instance.setAutoPadding(false);\n    return true;\n  } else {\n    var calcHmac = crypto.createHmac(SSH_TO_OPENSSL[hmac.type], hmac.key);\n\n    writeUInt32BE(HMAC_COMPUTE, instate.seqno, 0);\n    writeUInt32BE(HMAC_COMPUTE, instate.pktLen, 4);\n    HMAC_COMPUTE[8] = instate.padLen;\n\n    calcHmac.update(HMAC_COMPUTE);\n    calcHmac.update(instate.packet);\n\n    var mac = calcHmac.digest();\n    if (mac.length > instate.hmac.info.actualLen)\n      mac = mac.slice(0, instate.hmac.info.actualLen);\n    return timingSafeEqual(mac, data);\n  }\n}\n\nfunction decryptData(self, data) {\n  var instance = self._state.incoming.decrypt.instance;\n  self.debug('DEBUG: Parser: Decrypting');\n  return instance.update(data);\n}\n\nfunction expectData(self, type, amount, buffer) {\n  var expect = self._state.incoming.expect;\n  expect.amount = amount;\n  expect.type = type;\n  expect.ptr = 0;\n  if (buffer)\n    expect.buf = buffer;\n  else if (amount)\n    expect.buf = Buffer.allocUnsafe(amount);\n}\n\nfunction readList(buffer, start, stream, callback) {\n  var list = readString(buffer, start, 'ascii', stream, callback);\n  return (list !== false ? (list.length ? list.split(',') : []) : false);\n}\n\nfunction bytesToModes(buffer) {\n  var modes = {};\n\n  for (var i = 0, len = buffer.length, opcode; i < len; i += 5) {\n    opcode = buffer[i];\n    if (opcode === TERMINAL_MODE.TTY_OP_END\n        || TERMINAL_MODE[opcode] === undefined\n        || i + 5 > len)\n      break;\n    modes[TERMINAL_MODE[opcode]] = readUInt32BE(buffer, i + 1);\n  }\n\n  return modes;\n}\n\nfunction modesToBytes(modes) {\n  var RE_IS_NUM = /^\\d+$/;\n  var keys = Object.keys(modes);\n  var b = 0;\n  var bytes = [];\n\n  for (var i = 0, len = keys.length, key, opcode, val; i < len; ++i) {\n    key = keys[i];\n    opcode = TERMINAL_MODE[key];\n    if (opcode\n        && !RE_IS_NUM.test(key)\n        && typeof modes[key] === 'number'\n        && key !== 'TTY_OP_END') {\n      val = modes[key];\n      bytes[b++] = opcode;\n      bytes[b++] = (val >>> 24) & 0xFF;\n      bytes[b++] = (val >>> 16) & 0xFF;\n      bytes[b++] = (val >>> 8) & 0xFF;\n      bytes[b++] = val & 0xFF;\n    }\n  }\n\n  bytes[b] = TERMINAL_MODE.TTY_OP_END;\n\n  return bytes;\n}\n\n// Shared outgoing functions\nfunction KEXINIT(self, cb) { // Client/Server\n  randBytes(16, function(myCookie) {\n    /*\n      byte         SSH_MSG_KEXINIT\n      byte[16]     cookie (random bytes)\n      name-list    kex_algorithms\n      name-list    server_host_key_algorithms\n      name-list    encryption_algorithms_client_to_server\n      name-list    encryption_algorithms_server_to_client\n      name-list    mac_algorithms_client_to_server\n      name-list    mac_algorithms_server_to_client\n      name-list    compression_algorithms_client_to_server\n      name-list    compression_algorithms_server_to_client\n      name-list    languages_client_to_server\n      name-list    languages_server_to_client\n      boolean      first_kex_packet_follows\n      uint32       0 (reserved for future extension)\n    */\n    var algos = self.config.algorithms;\n\n    var kexBuf = algos.kexBuf;\n    if (self.remoteBugs & BUGS.BAD_DHGEX) {\n      var copied = false;\n      var kexList = algos.kex;\n      for (var j = kexList.length - 1; j >= 0; --j) {\n        if (kexList[j].indexOf('group-exchange') !== -1) {\n          if (!copied) {\n            kexList = kexList.slice();\n            copied = true;\n          }\n          kexList.splice(j, 1);\n        }\n      }\n      if (copied)\n        kexBuf = Buffer.from(kexList.join(','));\n    }\n\n    var hostKeyBuf = algos.serverHostKeyBuf;\n\n    var kexInitSize = 1 + 16\n                      + 4 + kexBuf.length\n                      + 4 + hostKeyBuf.length\n                      + (2 * (4 + algos.cipherBuf.length))\n                      + (2 * (4 + algos.hmacBuf.length))\n                      + (2 * (4 + algos.compressBuf.length))\n                      + (2 * (4 /* languages skipped */))\n                      + 1 + 4;\n    var buf = Buffer.allocUnsafe(kexInitSize);\n    var p = 17;\n\n    buf[0] = MESSAGE.KEXINIT;\n\n    if (myCookie !== false)\n      myCookie.copy(buf, 1);\n\n    writeUInt32BE(buf, kexBuf.length, p);\n    p += 4;\n    kexBuf.copy(buf, p);\n    p += kexBuf.length;\n\n    writeUInt32BE(buf, hostKeyBuf.length, p);\n    p += 4;\n    hostKeyBuf.copy(buf, p);\n    p += hostKeyBuf.length;\n\n    writeUInt32BE(buf, algos.cipherBuf.length, p);\n    p += 4;\n    algos.cipherBuf.copy(buf, p);\n    p += algos.cipherBuf.length;\n\n    writeUInt32BE(buf, algos.cipherBuf.length, p);\n    p += 4;\n    algos.cipherBuf.copy(buf, p);\n    p += algos.cipherBuf.length;\n\n    writeUInt32BE(buf, algos.hmacBuf.length, p);\n    p += 4;\n    algos.hmacBuf.copy(buf, p);\n    p += algos.hmacBuf.length;\n\n    writeUInt32BE(buf, algos.hmacBuf.length, p);\n    p += 4;\n    algos.hmacBuf.copy(buf, p);\n    p += algos.hmacBuf.length;\n\n    writeUInt32BE(buf, algos.compressBuf.length, p);\n    p += 4;\n    algos.compressBuf.copy(buf, p);\n    p += algos.compressBuf.length;\n\n    writeUInt32BE(buf, algos.compressBuf.length, p);\n    p += 4;\n    algos.compressBuf.copy(buf, p);\n    p += algos.compressBuf.length;\n\n    // Skip language lists, first_kex_packet_follows, and reserved bytes\n    buf.fill(0, buf.length - 13);\n\n    self.debug('DEBUG: Outgoing: Writing KEXINIT');\n\n    self._state.incoming.expectedPacket = 'KEXINIT';\n\n    var outstate = self._state.outgoing;\n\n    outstate.kexinit = buf;\n\n    if (outstate.status === OUT_READY) {\n      // We are the one starting the rekeying process ...\n      outstate.status = OUT_REKEYING;\n    }\n\n    send(self, buf, cb, true);\n  });\n  return true;\n}\n\nfunction KEXDH_INIT(self) { // Client\n  var state = self._state;\n  var outstate = state.outgoing;\n  var buf = Buffer.allocUnsafe(1 + 4 + outstate.pubkey.length);\n\n  if (RE_GEX.test(state.kexdh)) {\n    state.incoming.expectedPacket = 'KEXDH_GEX_REPLY';\n    buf[0] = MESSAGE.KEXDH_GEX_INIT;\n    self.debug('DEBUG: Outgoing: Writing KEXDH_GEX_INIT');\n  } else {\n    state.incoming.expectedPacket = 'KEXDH_REPLY';\n    buf[0] = MESSAGE.KEXDH_INIT;\n    if (state.kexdh !== 'group')\n      self.debug('DEBUG: Outgoing: Writing KEXECDH_INIT');\n    else\n      self.debug('DEBUG: Outgoing: Writing KEXDH_INIT');\n  }\n\n  writeUInt32BE(buf, outstate.pubkey.length, 1);\n  outstate.pubkey.copy(buf, 5);\n\n  return send(self, buf, undefined, true);\n}\n\nfunction KEXDH_REPLY(self, e) { // Server\n  var state = self._state;\n  var outstate = state.outgoing;\n  var instate = state.incoming;\n  var curHostKey = self.config.hostKeys[state.hostkeyFormat];\n  if (Array.isArray(curHostKey))\n    curHostKey = curHostKey[0];\n  var hostkey = curHostKey.getPublicSSH();\n  var hostkeyAlgo = curHostKey.type;\n\n  // e === client DH public key\n\n  var slicepos = -1;\n  for (var i = 0, len = e.length; i < len; ++i) {\n    if (e[i] === 0)\n      ++slicepos;\n    else\n      break;\n  }\n  if (slicepos > -1)\n    e = e.slice(slicepos + 1);\n\n  var secret = tryComputeSecret(state.kex, e);\n  if (secret instanceof Error) {\n    secret.message = 'Error while computing DH secret ('\n                     + state.kexdh + '): '\n                     + secret.message;\n    secret.level = 'handshake';\n    self.emit('error', secret);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  var hashAlgo;\n  if (state.kexdh === 'group')\n    hashAlgo = 'sha1';\n  else\n    hashAlgo = RE_KEX_HASH.exec(state.kexdh)[1];\n\n  var hash = crypto.createHash(hashAlgo);\n\n  var len_ident = Buffer.byteLength(instate.identRaw);\n  var len_sident = Buffer.byteLength(self.config.ident);\n  var len_init = instate.kexinit.length;\n  var len_sinit = outstate.kexinit.length;\n  var len_hostkey = hostkey.length;\n  var len_pubkey = e.length;\n  var len_spubkey = outstate.pubkey.length;\n  var len_secret = secret.length;\n\n  var idx_spubkey = 0;\n  var idx_secret = 0;\n\n  while (outstate.pubkey[idx_spubkey] === 0x00) {\n    ++idx_spubkey;\n    --len_spubkey;\n  }\n  while (secret[idx_secret] === 0x00) {\n    ++idx_secret;\n    --len_secret;\n  }\n  if (e[0] & 0x80)\n    ++len_pubkey;\n  if (outstate.pubkey[idx_spubkey] & 0x80)\n    ++len_spubkey;\n  if (secret[idx_secret] & 0x80)\n    ++len_secret;\n\n  var exchangeBufLen = len_ident\n                       + len_sident\n                       + len_init\n                       + len_sinit\n                       + len_hostkey\n                       + len_pubkey\n                       + len_spubkey\n                       + len_secret\n                       + (4 * 8); // Length fields for above values\n\n  // Group exchange-related\n  var isGEX = RE_GEX.test(state.kexdh);\n  var len_gex_prime = 0;\n  var len_gex_gen = 0;\n  var idx_gex_prime = 0;\n  var idx_gex_gen = 0;\n  var gex_prime;\n  var gex_gen;\n  if (isGEX) {\n    gex_prime = state.kex.getPrime();\n    gex_gen = state.kex.getGenerator();\n    len_gex_prime = gex_prime.length;\n    len_gex_gen = gex_gen.length;\n    while (gex_prime[idx_gex_prime] === 0x00) {\n      ++idx_gex_prime;\n      --len_gex_prime;\n    }\n    while (gex_gen[idx_gex_gen] === 0x00) {\n      ++idx_gex_gen;\n      --len_gex_gen;\n    }\n    if (gex_prime[idx_gex_prime] & 0x80)\n      ++len_gex_prime;\n    if (gex_gen[idx_gex_gen] & 0x80)\n      ++len_gex_gen;\n    exchangeBufLen += (4 * 3); // min, n, max values\n    exchangeBufLen += (4 * 2); // prime, generator length fields\n    exchangeBufLen += len_gex_prime;\n    exchangeBufLen += len_gex_gen;\n  }\n\n  var bp = 0;\n  var exchangeBuf = Buffer.allocUnsafe(exchangeBufLen);\n\n  writeUInt32BE(exchangeBuf, len_ident, bp);\n  bp += 4;\n  exchangeBuf.write(instate.identRaw, bp, 'utf8'); // V_C\n  bp += len_ident;\n\n  writeUInt32BE(exchangeBuf, len_sident, bp);\n  bp += 4;\n  exchangeBuf.write(self.config.ident, bp, 'utf8'); // V_S\n  bp += len_sident;\n\n  writeUInt32BE(exchangeBuf, len_init, bp);\n  bp += 4;\n  instate.kexinit.copy(exchangeBuf, bp); // I_C\n  bp += len_init;\n  instate.kexinit = undefined;\n\n  writeUInt32BE(exchangeBuf, len_sinit, bp);\n  bp += 4;\n  outstate.kexinit.copy(exchangeBuf, bp); // I_S\n  bp += len_sinit;\n  outstate.kexinit = undefined;\n\n  writeUInt32BE(exchangeBuf, len_hostkey, bp);\n  bp += 4;\n  hostkey.copy(exchangeBuf, bp); // K_S\n  bp += len_hostkey;\n\n  if (isGEX) {\n    KEXDH_GEX_REQ_PACKET.slice(1).copy(exchangeBuf, bp); // min, n, max\n    bp += (4 * 3); // Skip over bytes just copied\n\n    writeUInt32BE(exchangeBuf, len_gex_prime, bp);\n    bp += 4;\n    if (gex_prime[idx_gex_prime] & 0x80)\n      exchangeBuf[bp++] = 0;\n    gex_prime.copy(exchangeBuf, bp, idx_gex_prime); // p\n    bp += len_gex_prime - (gex_prime[idx_gex_prime] & 0x80 ? 1 : 0);\n\n    writeUInt32BE(exchangeBuf, len_gex_gen, bp);\n    bp += 4;\n    if (gex_gen[idx_gex_gen] & 0x80)\n      exchangeBuf[bp++] = 0;\n    gex_gen.copy(exchangeBuf, bp, idx_gex_gen); // g\n    bp += len_gex_gen - (gex_gen[idx_gex_gen] & 0x80 ? 1 : 0);\n  }\n\n  writeUInt32BE(exchangeBuf, len_pubkey, bp);\n  bp += 4;\n  if (e[0] & 0x80)\n    exchangeBuf[bp++] = 0;\n  e.copy(exchangeBuf, bp); // e\n  bp += len_pubkey - (e[0] & 0x80 ? 1 : 0);\n\n  writeUInt32BE(exchangeBuf, len_spubkey, bp);\n  bp += 4;\n  if (outstate.pubkey[idx_spubkey] & 0x80)\n    exchangeBuf[bp++] = 0;\n  outstate.pubkey.copy(exchangeBuf, bp, idx_spubkey); // f\n  bp += len_spubkey - (outstate.pubkey[idx_spubkey] & 0x80 ? 1 : 0);\n\n  writeUInt32BE(exchangeBuf, len_secret, bp);\n  bp += 4;\n  if (secret[idx_secret] & 0x80)\n    exchangeBuf[bp++] = 0;\n  secret.copy(exchangeBuf, bp, idx_secret); // K\n\n  outstate.exchangeHash = hash.update(exchangeBuf).digest(); // H\n\n  if (outstate.sessionId === undefined)\n    outstate.sessionId = outstate.exchangeHash;\n  outstate.kexsecret = secret;\n\n  var signature = curHostKey.sign(outstate.exchangeHash);\n  if (signature instanceof Error) {\n    signature.message = 'Error while signing data with host key ('\n                        + hostkeyAlgo + '): '\n                        + signature.message;\n    signature.level = 'handshake';\n    self.emit('error', signature);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  signature = convertSignature(signature, hostkeyAlgo);\n  if (signature === false) {\n    signature.message = 'Error while converting handshake signature';\n    signature.level = 'handshake';\n    self.emit('error', signature);\n    self.disconnect(DISCONNECT_REASON.KEY_EXCHANGE_FAILED);\n    return false;\n  }\n\n  /*\n    byte      SSH_MSG_KEXDH_REPLY\n    string    server public host key and certificates (K_S)\n    mpint     f\n    string    signature of H\n  */\n\n  var siglen = 4 + hostkeyAlgo.length + 4 + signature.length;\n  var buf = Buffer.allocUnsafe(1\n                               + 4 + len_hostkey\n                               + 4 + len_spubkey\n                               + 4 + siglen);\n\n  bp = 0;\n  buf[bp] = (!isGEX ? MESSAGE.KEXDH_REPLY : MESSAGE.KEXDH_GEX_REPLY);\n  ++bp;\n\n  writeUInt32BE(buf, len_hostkey, bp);\n  bp += 4;\n  hostkey.copy(buf, bp); // K_S\n  bp += len_hostkey;\n\n  writeUInt32BE(buf, len_spubkey, bp);\n  bp += 4;\n  if (outstate.pubkey[idx_spubkey] & 0x80)\n    buf[bp++] = 0;\n  outstate.pubkey.copy(buf, bp, idx_spubkey); // f\n  bp += len_spubkey - (outstate.pubkey[idx_spubkey] & 0x80 ? 1 : 0);\n\n  writeUInt32BE(buf, siglen, bp);\n  bp += 4;\n  writeUInt32BE(buf, hostkeyAlgo.length, bp);\n  bp += 4;\n  buf.write(hostkeyAlgo, bp, hostkeyAlgo.length, 'ascii');\n  bp += hostkeyAlgo.length;\n  writeUInt32BE(buf, signature.length, bp);\n  bp += 4;\n  signature.copy(buf, bp);\n\n  state.incoming.expectedPacket = 'NEWKEYS';\n\n  if (isGEX)\n    self.debug('DEBUG: Outgoing: Writing KEXDH_GEX_REPLY');\n  else if (state.kexdh !== 'group')\n    self.debug('DEBUG: Outgoing: Writing KEXECDH_REPLY');\n  else\n    self.debug('DEBUG: Outgoing: Writing KEXDH_REPLY');\n  send(self, buf, undefined, true);\n\n  outstate.sentNEWKEYS = true;\n  self.debug('DEBUG: Outgoing: Writing NEWKEYS');\n  return send(self, NEWKEYS_PACKET, undefined, true);\n}\n\nfunction KEXDH_GEX_REQ(self) { // Client\n  self._state.incoming.expectedPacket = 'KEXDH_GEX_GROUP';\n\n  self.debug('DEBUG: Outgoing: Writing KEXDH_GEX_REQUEST');\n  return send(self, KEXDH_GEX_REQ_PACKET, undefined, true);\n}\n\nfunction compressPayload(self, payload, cb) {\n  var compress = self._state.outgoing.compress.instance;\n  compress.write(payload);\n  compress.flush(Z_PARTIAL_FLUSH, compressFlushCb.bind(self, cb));\n}\n\nfunction compressFlushCb(cb) {\n  if (this._readableState.ended || this._writableState.ended)\n    return;\n  send_(this, this._state.outgoing.compress.instance.read(), cb);\n\n  var queue = this._state.outgoing.compress.queue;\n  queue.shift();\n  if (queue.length > 0)\n    compressPayload(this, queue[0][0], queue[0][1]);\n}\n\nfunction send(self, payload, cb, bypass) {\n  var state = self._state;\n\n  if (!state)\n    return false;\n\n  var outstate = state.outgoing;\n  if (outstate.status === OUT_REKEYING && !bypass) {\n    if (typeof cb === 'function')\n      outstate.rekeyQueue.push([payload, cb]);\n    else\n      outstate.rekeyQueue.push(payload);\n    return false;\n  } else if (self._readableState.ended || self._writableState.ended) {\n    return false;\n  }\n\n  if (outstate.compress.instance) {\n    // This queue nonsense only exists because of a change made in node v10.12.0\n    // that changed flushing behavior, which now coalesces multiple writes to a\n    // single flush, which does not work for us.\n    var queue = outstate.compress.queue;\n    queue.push([payload, cb]);\n    if (queue.length === 1)\n      compressPayload(self, queue[0][0], queue[0][1]);\n    return true;\n  } else {\n    return send_(self, payload, cb);\n  }\n}\n\nfunction send_(self, payload, cb) {\n  // TODO: Implement length checks\n\n  var state = self._state;\n  var outstate = state.outgoing;\n  var encrypt = outstate.encrypt;\n  var hmac = outstate.hmac;\n  var pktLen;\n  var padLen;\n  var buf;\n  var mac;\n  var ret;\n\n  pktLen = payload.length + 9;\n\n  if (encrypt.instance !== false) {\n    if (encrypt.info.authLen > 0) {\n      var ptlen = 1 + payload.length + 4/* Must have at least 4 bytes padding*/;\n      while ((ptlen % encrypt.info.blockLen) !== 0)\n        ++ptlen;\n      padLen = ptlen - 1 - payload.length;\n      pktLen = 4 + ptlen;\n    } else {\n      var blockLen = encrypt.info.blockLen;\n      pktLen += ((blockLen - 1) * pktLen) % blockLen;\n      padLen = pktLen - payload.length - 5;\n    }\n  } else {\n    pktLen += (7 * pktLen) % 8;\n    padLen = pktLen - payload.length - 5;\n  }\n\n  buf = Buffer.allocUnsafe(pktLen);\n\n  writeUInt32BE(buf, pktLen - 4, 0);\n  buf[4] = padLen;\n  payload.copy(buf, 5);\n\n  copyRandPadBytes(buf, 5 + payload.length, padLen);\n\n  if (hmac.type !== false && hmac.key) {\n    mac = crypto.createHmac(SSH_TO_OPENSSL[hmac.type], hmac.key);\n    writeUInt32BE(outstate.bufSeqno, outstate.seqno, 0);\n    mac.update(outstate.bufSeqno);\n    mac.update(buf);\n    mac = mac.digest();\n    if (mac.length > hmac.info.actualLen)\n      mac = mac.slice(0, hmac.info.actualLen);\n  }\n\n  var nb = 0;\n  var encData;\n\n  if (encrypt.instance !== false) {\n    if (encrypt.info.authLen > 0) {\n      var encrypter = crypto.createCipheriv(SSH_TO_OPENSSL[encrypt.type],\n                                            encrypt.key,\n                                            encrypt.iv);\n      encrypter.setAutoPadding(false);\n\n      var lenbuf = buf.slice(0, 4);\n\n      encrypter.setAAD(lenbuf);\n      self.push(lenbuf);\n      nb += lenbuf;\n\n      encData = encrypter.update(buf.slice(4));\n      self.push(encData);\n      nb += encData.length;\n\n      var final = encrypter.final();\n      if (final.length) {\n        self.push(final);\n        nb += final.length;\n      }\n\n      var authTag = encrypter.getAuthTag();\n      ret = self.push(authTag);\n      nb += authTag.length;\n\n      iv_inc(encrypt.iv);\n    } else {\n      encData = encrypt.instance.update(buf);\n      self.push(encData);\n      nb += encData.length;\n\n      ret = self.push(mac);\n      nb += mac.length;\n    }\n  } else {\n    ret = self.push(buf);\n    nb = buf.length;\n  }\n\n  self.bytesSent += nb;\n\n  if (++outstate.seqno > MAX_SEQNO)\n    outstate.seqno = 0;\n\n  cb && cb();\n\n  return ret;\n}\n\nvar copyRandPadBytes = (function() {\n  if (typeof crypto.randomFillSync === 'function') {\n    return crypto.randomFillSync;\n  } else {\n    return function copyRandPadBytes(buf, offset, count) {\n      var padBytes = crypto.randomBytes(count);\n      padBytes.copy(buf, offset);\n    };\n  }\n})();\n\nfunction randBytes(n, cb) {\n  crypto.randomBytes(n, function retry(err, buf) {\n    if (err)\n      return crypto.randomBytes(n, retry);\n    cb && cb(buf);\n  });\n}\n\nfunction tryComputeSecret(dh, e) {\n  try {\n    return dh.computeSecret(e);\n  } catch (err) {\n    return err;\n  }\n}\n\nfunction convertSignature(signature, keyType) {\n  switch (keyType) {\n    case 'ssh-dss':\n      return DSASigBERToBare(signature);\n    case 'ecdsa-sha2-nistp256':\n    case 'ecdsa-sha2-nistp384':\n    case 'ecdsa-sha2-nistp521':\n      return ECDSASigASN1ToSSH(signature);\n  }\n\n  return signature;\n}\n\nvar timingSafeEqual = (function() {\n  if (typeof crypto.timingSafeEqual === 'function') {\n    return function timingSafeEquals(a, b) {\n      if (a.length !== b.length) {\n        crypto.timingSafeEqual(a, a);\n        return false;\n      } else {\n        return crypto.timingSafeEqual(a, b);\n      }\n    };\n  } else {\n    return function timingSafeEquals(a, b) {\n      var val;\n      if (a.length === b.length) {\n        val = 0;\n      } else {\n        val = 1;\n        b = a;\n      }\n\n      for (var i = 0, len = a.length; i < len; ++i)\n        val |= (a[i] ^ b[i]);\n\n      return (val === 0);\n    }\n  }\n})();\n\nmodule.exports = SSH2Stream;\nmodule.exports._send = send;\n\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/lib/ssh.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/lib/utils.js":
/*!************************************************!*\
  !*** ./node_modules/ssh2-streams/lib/utils.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var Ber = __webpack_require__(/*! asn1 */ \"./node_modules/asn1/lib/index.js\").Ber;\n\nvar readUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2-streams/lib/buffer-helpers.js\").readUInt32BE;\nvar writeUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2-streams/lib/buffer-helpers.js\").writeUInt32BE;\n\n// XXX the value of 2400 from dropbear is only for certain strings, not all\n// strings. for example the list strings used during handshakes\nvar MAX_STRING_LEN = Infinity;//2400; // taken from dropbear\n\nmodule.exports = {\n  iv_inc: iv_inc,\n  readInt: readInt,\n  readString: readString,\n  parseKey: __webpack_require__(/*! ./keyParser */ \"./node_modules/ssh2-streams/lib/keyParser.js\").parseKey,\n  sigSSHToASN1: sigSSHToASN1,\n  DSASigBERToBare: DSASigBERToBare,\n  ECDSASigASN1ToSSH: ECDSASigASN1ToSSH\n};\n\nfunction iv_inc(iv) {\n  var n = 12;\n  var c = 0;\n  do {\n    --n;\n    c = iv[n];\n    if (c === 255)\n      iv[n] = 0;\n    else {\n      iv[n] = ++c;\n      return;\n    }\n  } while (n > 4);\n}\n\nfunction readInt(buffer, start, stream, cb) {\n  var bufferLen = buffer.length;\n  if (start < 0 || start >= bufferLen || (bufferLen - start) < 4) {\n    stream && stream._cleanup(cb);\n    return false;\n  }\n\n  return readUInt32BE(buffer, start);\n}\n\nfunction DSASigBERToBare(signature) {\n  if (signature.length <= 40)\n    return signature;\n  // This is a quick and dirty way to get from BER encoded r and s that\n  // OpenSSL gives us, to just the bare values back to back (40 bytes\n  // total) like OpenSSH (and possibly others) are expecting\n  var asnReader = new Ber.Reader(signature);\n  asnReader.readSequence();\n  var r = asnReader.readString(Ber.Integer, true);\n  var s = asnReader.readString(Ber.Integer, true);\n  var rOffset = 0;\n  var sOffset = 0;\n  if (r.length < 20) {\n    var rNew = Buffer.allocUnsafe(20);\n    r.copy(rNew, 1);\n    r = rNew;\n    r[0] = 0;\n  }\n  if (s.length < 20) {\n    var sNew = Buffer.allocUnsafe(20);\n    s.copy(sNew, 1);\n    s = sNew;\n    s[0] = 0;\n  }\n  if (r.length > 20 && r[0] === 0x00)\n    rOffset = 1;\n  if (s.length > 20 && s[0] === 0x00)\n    sOffset = 1;\n  var newSig = Buffer.allocUnsafe((r.length - rOffset) + (s.length - sOffset));\n  r.copy(newSig, 0, rOffset);\n  s.copy(newSig, r.length - rOffset, sOffset);\n  return newSig;\n}\n\nfunction ECDSASigASN1ToSSH(signature) {\n  if (signature[0] === 0x00)\n    return signature;\n  // Convert SSH signature parameters to ASN.1 BER values for OpenSSL\n  var asnReader = new Ber.Reader(signature);\n  asnReader.readSequence();\n  var r = asnReader.readString(Ber.Integer, true);\n  var s = asnReader.readString(Ber.Integer, true);\n  if (r === null || s === null)\n    return false;\n  var newSig = Buffer.allocUnsafe(4 + r.length + 4 + s.length);\n  writeUInt32BE(newSig, r.length, 0);\n  r.copy(newSig, 4);\n  writeUInt32BE(newSig, s.length, 4 + r.length);\n  s.copy(newSig, 4 + 4 + r.length);\n  return newSig;\n}\n\nfunction sigSSHToASN1(sig, type, self, callback) {\n  var asnWriter;\n  switch (type) {\n    case 'ssh-dss':\n      if (sig.length > 40)\n        return sig;\n      // Change bare signature r and s values to ASN.1 BER values for OpenSSL\n      asnWriter = new Ber.Writer();\n      asnWriter.startSequence();\n      var r = sig.slice(0, 20);\n      var s = sig.slice(20);\n      if (r[0] & 0x80) {\n        var rNew = Buffer.allocUnsafe(21);\n        rNew[0] = 0x00;\n        r.copy(rNew, 1);\n        r = rNew;\n      } else if (r[0] === 0x00 && !(r[1] & 0x80)) {\n        r = r.slice(1);\n      }\n      if (s[0] & 0x80) {\n        var sNew = Buffer.allocUnsafe(21);\n        sNew[0] = 0x00;\n        s.copy(sNew, 1);\n        s = sNew;\n      } else if (s[0] === 0x00 && !(s[1] & 0x80)) {\n        s = s.slice(1);\n      }\n      asnWriter.writeBuffer(r, Ber.Integer);\n      asnWriter.writeBuffer(s, Ber.Integer);\n      asnWriter.endSequence();\n      return asnWriter.buffer;\n    case 'ecdsa-sha2-nistp256':\n    case 'ecdsa-sha2-nistp384':\n    case 'ecdsa-sha2-nistp521':\n      var r = readString(sig, 0, self, callback);\n      if (r === false)\n        return false;\n      var s = readString(sig, sig._pos, self, callback);\n      if (s === false)\n        return false;\n\n      asnWriter = new Ber.Writer();\n      asnWriter.startSequence();\n      asnWriter.writeBuffer(r, Ber.Integer);\n      asnWriter.writeBuffer(s, Ber.Integer);\n      asnWriter.endSequence();\n      return asnWriter.buffer;\n    default:\n      return sig;\n  }\n}\n\nfunction readString(buffer, start, encoding, stream, cb, maxLen) {\n  if (encoding && !Buffer.isBuffer(encoding) && typeof encoding !== 'string') {\n    if (typeof cb === 'number')\n      maxLen = cb;\n    cb = stream;\n    stream = encoding;\n    encoding = undefined;\n  }\n\n  start || (start = 0);\n  var bufferLen = buffer.length;\n  var left = (bufferLen - start);\n  var len;\n  var end;\n  if (start < 0 || start >= bufferLen || left < 4) {\n    stream && stream._cleanup(cb);\n    return false;\n  }\n\n  len = readUInt32BE(buffer, start);\n  if (len > (maxLen || MAX_STRING_LEN) || left < (4 + len)) {\n    stream && stream._cleanup(cb);\n    return false;\n  }\n\n  start += 4;\n  end = start + len;\n  buffer._pos = end;\n\n  if (encoding) {\n    if (Buffer.isBuffer(encoding)) {\n      buffer.copy(encoding, 0, start, end);\n      return encoding;\n    } else {\n      return buffer.toString(encoding, start, end);\n    }\n  } else {\n    return buffer.slice(start, end);\n  }\n}\n\n\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/lib/utils.js?");

/***/ }),

/***/ "./node_modules/ssh2-streams/package.json":
/*!************************************************!*\
  !*** ./node_modules/ssh2-streams/package.json ***!
  \************************************************/
/*! exports provided: name, version, author, description, main, engines, dependencies, scripts, keywords, licenses, repository, default */
/***/ (function(module) {

eval("module.exports = JSON.parse(\"{\\\"name\\\":\\\"ssh2-streams\\\",\\\"version\\\":\\\"0.4.5\\\",\\\"author\\\":\\\"Brian White <mscdex@mscdex.net>\\\",\\\"description\\\":\\\"SSH2 and SFTP(v3) client/server protocol streams for node.js\\\",\\\"main\\\":\\\"./index\\\",\\\"engines\\\":{\\\"node\\\":\\\">=5.2.0\\\"},\\\"dependencies\\\":{\\\"asn1\\\":\\\"~0.2.0\\\",\\\"bcrypt-pbkdf\\\":\\\"^1.0.2\\\",\\\"streamsearch\\\":\\\"~0.1.2\\\"},\\\"scripts\\\":{\\\"test\\\":\\\"node test/test.js\\\"},\\\"keywords\\\":[\\\"ssh\\\",\\\"ssh2\\\",\\\"sftp\\\",\\\"secure\\\",\\\"protocol\\\",\\\"streams\\\",\\\"client\\\",\\\"server\\\"],\\\"licenses\\\":[{\\\"type\\\":\\\"MIT\\\",\\\"url\\\":\\\"http://github.com/mscdex/ssh2-streams/raw/master/LICENSE\\\"}],\\\"repository\\\":{\\\"type\\\":\\\"git\\\",\\\"url\\\":\\\"http://github.com/mscdex/ssh2-streams.git\\\"}}\");\n\n//# sourceURL=webpack:///./node_modules/ssh2-streams/package.json?");

/***/ }),

/***/ "./node_modules/ssh2/lib/Channel.js":
/*!******************************************!*\
  !*** ./node_modules/ssh2/lib/Channel.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var inherits = __webpack_require__(/*! util */ \"util\").inherits;\nvar DuplexStream = __webpack_require__(/*! stream */ \"stream\").Duplex;\nvar ReadableStream = __webpack_require__(/*! stream */ \"stream\").Readable;\nvar WritableStream = __webpack_require__(/*! stream */ \"stream\").Writable;\n\nvar STDERR = __webpack_require__(/*! ssh2-streams */ \"./node_modules/ssh2-streams/index.js\").constants.CHANNEL_EXTENDED_DATATYPE.STDERR;\n\nvar PACKET_SIZE = 32 * 1024;\nvar MAX_WINDOW = 2 * 1024 * 1024;\nvar WINDOW_THRESHOLD = MAX_WINDOW / 2;\nvar CUSTOM_EVENTS = [\n  'CHANNEL_EOF',\n  'CHANNEL_CLOSE',\n  'CHANNEL_DATA',\n  'CHANNEL_EXTENDED_DATA',\n  'CHANNEL_WINDOW_ADJUST',\n  'CHANNEL_SUCCESS',\n  'CHANNEL_FAILURE',\n  'CHANNEL_REQUEST'\n];\nvar CUSTOM_EVENTS_LEN = CUSTOM_EVENTS.length;\n\nfunction Channel(info, client, opts) {\n  var streamOpts = {\n    highWaterMark: MAX_WINDOW,\n    allowHalfOpen: (!opts || (opts && opts.allowHalfOpen !== false))\n  };\n\n  this.allowHalfOpen = streamOpts.allowHalfOpen;\n\n  DuplexStream.call(this, streamOpts);\n\n  var self = this;\n  var server = opts && opts.server;\n\n  this.server = server;\n  this.type = info.type;\n  this.subtype = undefined;\n  /*\n    incoming and outgoing contain these properties:\n    {\n      id: undefined,\n      window: undefined,\n      packetSize: undefined,\n      state: 'closed'\n    }\n  */\n  var incoming = this.incoming = info.incoming;\n  var incomingId = incoming.id;\n  var outgoing = this.outgoing = info.outgoing;\n  var callbacks = this._callbacks = [];\n  var exitCode;\n  var exitSignal;\n  var exitDump;\n  var exitDesc;\n  var exitLang;\n\n  this._client = client;\n  this._hasX11 = false;\n\n  var channels = client._channels;\n  var sshstream = client._sshstream;\n\n  function ondrain() {\n    if (self._waitClientDrain) {\n      self._waitClientDrain = false;\n      if (!self._waitWindow) {\n        if (self._chunk)\n          self._write(self._chunk, null, self._chunkcb);\n        else if (self._chunkcb)\n          self._chunkcb();\n        else if (self._chunkErr)\n          self.stderr._write(self._chunkErr, null, self._chunkcbErr);\n        else if (self._chunkcbErr)\n          self._chunkcbErr();\n      }\n    }\n  }\n  client._sock.on('drain', ondrain);\n\n  sshstream.once('CHANNEL_EOF:' + incomingId, function() {\n    if (incoming.state !== 'open')\n      return;\n    incoming.state = 'eof';\n\n    if (self.readable)\n      self.push(null);\n    if (!server && self.stderr.readable)\n      self.stderr.push(null);\n  }).once('CHANNEL_CLOSE:' + incomingId, function() {\n    if (incoming.state === 'closed')\n      return;\n    incoming.state = 'closed';\n\n    if (self.readable)\n      self.push(null);\n    if (server && self.stderr.writable)\n      self.stderr.end();\n    else if (!server && self.stderr.readable)\n      self.stderr.push(null);\n\n    if (outgoing.state === 'open' || outgoing.state === 'eof')\n      self.close();\n    if (outgoing.state === 'closing')\n      outgoing.state = 'closed';\n\n    delete channels[incomingId];\n\n    var state = self._writableState;\n    client._sock.removeListener('drain', ondrain);\n    if (!state.ending && !state.finished)\n      self.end();\n\n    // Take care of any outstanding channel requests\n    self._callbacks = [];\n    for (var i = 0; i < callbacks.length; ++i)\n      callbacks[i](true);\n    callbacks = self._callbacks;\n\n    if (!server) {\n      // align more with node child processes, where the close event gets the\n      // same arguments as the exit event\n      if (!self.readable) {\n        if (exitCode === null) {\n          self.emit('close', exitCode, exitSignal, exitDump, exitDesc,\n                    exitLang);\n        } else\n          self.emit('close', exitCode);\n      } else {\n        self.once('end', function() {\n          if (exitCode === null) {\n            self.emit('close', exitCode, exitSignal, exitDump, exitDesc,\n                      exitLang);\n          } else\n            self.emit('close', exitCode);\n        });\n      }\n\n      if (!self.stderr.readable)\n        self.stderr.emit('close');\n      else {\n        self.stderr.once('end', function() {\n          self.stderr.emit('close');\n        });\n      }\n    } else { // Server mode\n      if (!self.readable)\n        self.emit('close');\n      else {\n        self.once('end', function() {\n          self.emit('close');\n        });\n      }\n    }\n\n    for (var i = 0; i < CUSTOM_EVENTS_LEN; ++i)\n      sshstream.removeAllListeners(CUSTOM_EVENTS[i] + ':' + incomingId);\n  }).on('CHANNEL_DATA:' + incomingId, function(data) {\n    // the remote party should not be sending us data if there is no window\n    // space available ...\n    // TODO: raise error on data with not enough window\n    if (incoming.window === 0)\n      return;\n\n    incoming.window -= data.length;\n\n    if (!self.push(data)) {\n      self._waitChanDrain = true;\n      return;\n    }\n\n    if (incoming.window <= WINDOW_THRESHOLD)\n      windowAdjust(self);\n  }).on('CHANNEL_WINDOW_ADJUST:' + incomingId, function(amt) {\n    // the server is allowing us to send `amt` more bytes of data\n    outgoing.window += amt;\n\n    if (self._waitWindow) {\n      self._waitWindow = false;\n      if (!self._waitClientDrain) {\n        if (self._chunk)\n          self._write(self._chunk, null, self._chunkcb);\n        else if (self._chunkcb)\n          self._chunkcb();\n        else if (self._chunkErr)\n          self.stderr._write(self._chunkErr, null, self._chunkcbErr);\n        else if (self._chunkcbErr)\n          self._chunkcbErr();\n      }\n    }\n  }).on('CHANNEL_SUCCESS:' + incomingId, function() {\n    if (server) {\n      sshstream._kalast = Date.now();\n      sshstream._kacnt = 0;\n    } else\n      client._resetKA();\n    if (callbacks.length)\n      callbacks.shift()(false);\n  }).on('CHANNEL_FAILURE:' + incomingId, function() {\n    if (server) {\n      sshstream._kalast = Date.now();\n      sshstream._kacnt = 0;\n    } else\n      client._resetKA();\n    if (callbacks.length)\n      callbacks.shift()(true);\n  }).on('CHANNEL_REQUEST:' + incomingId, function(info) {\n    if (!server) {\n      if (info.request === 'exit-status') {\n        self.emit('exit', exitCode = info.code);\n        return;\n      } else if (info.request === 'exit-signal') {\n        self.emit('exit',\n                  exitCode = null,\n                  exitSignal = 'SIG' + info.signal,\n                  exitDump = info.coredump,\n                  exitDesc = info.description,\n                  exitLang = info.lang);\n        return;\n      }\n    }\n\n    // keepalive request? OpenSSH will send one as a channel request if there\n    // is a channel open\n\n    if (info.wantReply)\n      sshstream.channelFailure(outgoing.id);\n  });\n\n  this.stdin = this.stdout = this;\n\n  if (server)\n    this.stderr = new ServerStderr(this);\n  else {\n    this.stderr = new ReadableStream(streamOpts);\n    this.stderr._read = function(n) {\n      if (self._waitChanDrain) {\n        self._waitChanDrain = false;\n        if (incoming.window <= WINDOW_THRESHOLD)\n          windowAdjust(self);\n      }\n    };\n\n    sshstream.on('CHANNEL_EXTENDED_DATA:' + incomingId,\n      function(type, data) {\n        // the remote party should not be sending us data if there is no window\n        // space available ...\n        // TODO: raise error on data with not enough window\n        if (incoming.window === 0)\n          return;\n\n        incoming.window -= data.length;\n\n        if (!self.stderr.push(data)) {\n          self._waitChanDrain = true;\n          return;\n        }\n\n        if (incoming.window <= WINDOW_THRESHOLD)\n          windowAdjust(self);\n      }\n    );\n  }\n\n  // outgoing data\n  this._waitClientDrain = false; // Client stream-level backpressure\n  this._waitWindow = false; // SSH-level backpressure\n\n  // incoming data\n  this._waitChanDrain = false; // Channel Readable side backpressure\n\n  this._chunk = undefined;\n  this._chunkcb = undefined;\n  this._chunkErr = undefined;\n  this._chunkcbErr = undefined;\n\n  function onFinish() {\n    self.eof();\n    if (server || (!server && !self.allowHalfOpen))\n      self.close();\n    self.writable = false;\n  }\n  this.on('finish', onFinish)\n      .on('prefinish', onFinish); // for node v0.11+\n  function onEnd() {\n    self.readable = false;\n  }\n  this.on('end', onEnd)\n      .on('close', onEnd);\n}\ninherits(Channel, DuplexStream);\n\nChannel.prototype.eof = function() {\n  var ret = true;\n  var outgoing = this.outgoing;\n\n  if (outgoing.state === 'open') {\n    outgoing.state = 'eof';\n    ret = this._client._sshstream.channelEOF(outgoing.id);\n  }\n\n  return ret;\n};\n\nChannel.prototype.close = function() {\n  var ret = true;\n  var outgoing = this.outgoing;\n\n  if (outgoing.state === 'open' || outgoing.state === 'eof') {\n    outgoing.state = 'closing';\n    ret = this._client._sshstream.channelClose(outgoing.id);\n  }\n\n  return ret;\n};\n\nChannel.prototype._read = function(n) {\n  if (this._waitChanDrain) {\n    this._waitChanDrain = false;\n    if (this.incoming.window <= WINDOW_THRESHOLD)\n      windowAdjust(this);\n  }\n};\n\nChannel.prototype._write = function(data, encoding, cb) {\n  var sshstream = this._client._sshstream;\n  var outgoing = this.outgoing;\n  var packetSize = outgoing.packetSize;\n  var id = outgoing.id;\n  var window = outgoing.window;\n  var len = data.length;\n  var p = 0;\n  var ret;\n  var buf;\n  var sliceLen;\n\n  if (outgoing.state !== 'open')\n    return;\n\n  while (len - p > 0 && window > 0) {\n    sliceLen = len - p;\n    if (sliceLen > window)\n      sliceLen = window;\n    if (sliceLen > packetSize)\n      sliceLen = packetSize;\n\n    ret = sshstream.channelData(id, data.slice(p, p + sliceLen));\n\n    p += sliceLen;\n    window -= sliceLen;\n\n    if (!ret) {\n      this._waitClientDrain = true;\n      this._chunk = undefined;\n      this._chunkcb = cb;\n      break;\n    }\n  }\n\n  outgoing.window = window;\n\n  if (len - p > 0) {\n    if (window === 0)\n      this._waitWindow = true;\n    if (p > 0) {\n      // partial\n      buf = Buffer.allocUnsafe(len - p);\n      data.copy(buf, 0, p);\n      this._chunk = buf;\n    } else\n      this._chunk = data;\n    this._chunkcb = cb;\n    return;\n  }\n\n  if (!this._waitClientDrain)\n    cb();\n};\n\nChannel.prototype.destroy = function() {\n  this.end();\n};\n\n// session type-specific methods\nChannel.prototype.setWindow = function(rows, cols, height, width) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  if (this.type === 'session'\n      && (this.subtype === 'shell' || this.subtype === 'exec')\n      && this.writable\n      && this.outgoing.state === 'open') {\n    return this._client._sshstream.windowChange(this.outgoing.id,\n                                                rows,\n                                                cols,\n                                                height,\n                                                width);\n  }\n\n  return true;\n};\nChannel.prototype.signal = function(signalName) {\n  if (this.server)\n    throw new Error('Client-only method called in server mode');\n\n  if (this.type === 'session'\n      && this.writable\n      && this.outgoing.state === 'open')\n    return this._client._sshstream.signal(this.outgoing.id, signalName);\n\n  return true;\n};\nChannel.prototype.exit = function(name, coreDumped, msg) {\n  if (!this.server)\n    throw new Error('Server-only method called in client mode');\n\n  if (this.type === 'session'\n      && this.writable\n      && this.outgoing.state === 'open') {\n    if (typeof name === 'number')\n      return this._client._sshstream.exitStatus(this.outgoing.id, name);\n    else {\n      return this._client._sshstream.exitSignal(this.outgoing.id,\n                                                name,\n                                                coreDumped,\n                                                msg);\n    }\n  }\n\n  return true;\n};\n\nChannel.MAX_WINDOW = MAX_WINDOW;\nChannel.PACKET_SIZE = PACKET_SIZE;\n\nfunction windowAdjust(self) {\n  if (self.outgoing.state === 'closed')\n    return true;\n  var amt = MAX_WINDOW - self.incoming.window;\n  if (amt <= 0)\n    return true;\n  self.incoming.window += amt;\n  return self._client._sshstream.channelWindowAdjust(self.outgoing.id, amt);\n}\n\nfunction ServerStderr(channel) {\n  WritableStream.call(this, { highWaterMark: MAX_WINDOW });\n  this._channel = channel;\n}\ninherits(ServerStderr, WritableStream);\n\nServerStderr.prototype._write = function(data, encoding, cb) {\n  var channel = this._channel;\n  var sshstream = channel._client._sshstream;\n  var outgoing = channel.outgoing;\n  var packetSize = outgoing.packetSize;\n  var id = outgoing.id;\n  var window = outgoing.window;\n  var len = data.length;\n  var p = 0;\n  var ret;\n  var buf;\n  var sliceLen;\n\n  if (channel.outgoing.state !== 'open')\n    return;\n\n  while (len - p > 0 && window > 0) {\n    sliceLen = len - p;\n    if (sliceLen > window)\n      sliceLen = window;\n    if (sliceLen > packetSize)\n      sliceLen = packetSize;\n\n    ret = sshstream.channelExtData(id, data.slice(p, p + sliceLen), STDERR);\n\n    p += sliceLen;\n    window -= sliceLen;\n\n    if (!ret) {\n      channel._waitClientDrain = true;\n      channel._chunkErr = undefined;\n      channel._chunkcbErr = cb;\n      break;\n    }\n  }\n\n  outgoing.window = window;\n\n  if (len - p > 0) {\n    if (window === 0)\n      channel._waitWindow = true;\n    if (p > 0) {\n      // partial\n      buf = Buffer.allocUnsafe(len - p);\n      data.copy(buf, 0, p);\n      channel._chunkErr = buf;\n    } else\n      channel._chunkErr = data;\n    channel._chunkcbErr = cb;\n    return;\n  }\n\n  if (!channel._waitClientDrain)\n    cb();\n};\n\nmodule.exports = Channel;\n\n\n//# sourceURL=webpack:///./node_modules/ssh2/lib/Channel.js?");

/***/ }),

/***/ "./node_modules/ssh2/lib/SFTPWrapper.js":
/*!**********************************************!*\
  !*** ./node_modules/ssh2/lib/SFTPWrapper.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// This wrapper class is used to retain backwards compatibility with\n// pre-v0.4 ssh2. If it weren't for `read()` and `write()` being used by the\n// streams2/3 API, we could just pass the SFTPStream directly to the end user...\n\nvar inherits = __webpack_require__(/*! util */ \"util\").inherits;\nvar EventEmitter = __webpack_require__(/*! events */ \"events\").EventEmitter;\n\nfunction SFTPWrapper(stream) {\n  var self = this;\n\n  EventEmitter.call(this);\n\n  this._stream = stream;\n\n  stream.on('error', function(err) {\n    self.emit('error', err);\n  }).on('end', function() {\n    self.emit('end');\n  }).on('close', function() {\n    self.emit('close');\n  }).on('continue', function() {\n    self.emit('continue');\n  });\n}\ninherits(SFTPWrapper, EventEmitter);\n\n// stream-related methods to pass on\nSFTPWrapper.prototype.end = function() {\n  return this._stream.end();\n};\n// SFTPStream client methods\nSFTPWrapper.prototype.createReadStream = function(path, options) {\n  return this._stream.createReadStream(path, options);\n};\nSFTPWrapper.prototype.createWriteStream = function(path, options) {\n  return this._stream.createWriteStream(path, options);\n};\nSFTPWrapper.prototype.open = function(path, flags, attrs, cb) {\n  return this._stream.open(path, flags, attrs, cb);\n};\nSFTPWrapper.prototype.close = function(handle, cb) {\n  return this._stream.close(handle, cb);\n};\nSFTPWrapper.prototype.read = function(handle, buf, off, len, position, cb) {\n  return this._stream.readData(handle, buf, off, len, position, cb);\n};\nSFTPWrapper.prototype.write = function(handle, buf, off, len, position, cb) {\n  return this._stream.writeData(handle, buf, off, len, position, cb);\n};\nSFTPWrapper.prototype.fastGet = function(remotePath, localPath, opts, cb) {\n  return this._stream.fastGet(remotePath, localPath, opts, cb);\n};\nSFTPWrapper.prototype.fastPut = function(localPath, remotePath, opts, cb) {\n  return this._stream.fastPut(localPath, remotePath, opts, cb);\n};\nSFTPWrapper.prototype.readFile = function(path, options, callback_) {\n  return this._stream.readFile(path, options, callback_);\n};\nSFTPWrapper.prototype.writeFile = function(path, data, options, callback_) {\n  return this._stream.writeFile(path, data, options, callback_);\n};\nSFTPWrapper.prototype.appendFile = function(path, data, options, callback_) {\n  return this._stream.appendFile(path, data, options, callback_);\n};\nSFTPWrapper.prototype.exists = function(path, cb) {\n  return this._stream.exists(path, cb);\n};\nSFTPWrapper.prototype.unlink = function(filename, cb) {\n  return this._stream.unlink(filename, cb);\n};\nSFTPWrapper.prototype.rename = function(oldPath, newPath, cb) {\n  return this._stream.rename(oldPath, newPath, cb);\n};\nSFTPWrapper.prototype.mkdir = function(path, attrs, cb) {\n  return this._stream.mkdir(path, attrs, cb);\n};\nSFTPWrapper.prototype.rmdir = function(path, cb) {\n  return this._stream.rmdir(path, cb);\n};\nSFTPWrapper.prototype.readdir = function(where, opts, cb) {\n  return this._stream.readdir(where, opts, cb);\n};\nSFTPWrapper.prototype.fstat = function(handle, cb) {\n  return this._stream.fstat(handle, cb);\n};\nSFTPWrapper.prototype.stat = function(path, cb) {\n  return this._stream.stat(path, cb);\n};\nSFTPWrapper.prototype.lstat = function(path, cb) {\n  return this._stream.lstat(path, cb);\n};\nSFTPWrapper.prototype.opendir = function(path, cb) {\n  return this._stream.opendir(path, cb);\n};\nSFTPWrapper.prototype.setstat = function(path, attrs, cb) {\n  return this._stream.setstat(path, attrs, cb);\n};\nSFTPWrapper.prototype.fsetstat = function(handle, attrs, cb) {\n  return this._stream.fsetstat(handle, attrs, cb);\n};\nSFTPWrapper.prototype.futimes = function(handle, atime, mtime, cb) {\n  return this._stream.futimes(handle, atime, mtime, cb);\n};\nSFTPWrapper.prototype.utimes = function(path, atime, mtime, cb) {\n  return this._stream.utimes(path, atime, mtime, cb);\n};\nSFTPWrapper.prototype.fchown = function(handle, uid, gid, cb) {\n  return this._stream.fchown(handle, uid, gid, cb);\n};\nSFTPWrapper.prototype.chown = function(path, uid, gid, cb) {\n  return this._stream.chown(path, uid, gid, cb);\n};\nSFTPWrapper.prototype.fchmod = function(handle, mode, cb) {\n  return this._stream.fchmod(handle, mode, cb);\n};\nSFTPWrapper.prototype.chmod = function(path, mode, cb) {\n  return this._stream.chmod(path, mode, cb);\n};\nSFTPWrapper.prototype.readlink = function(path, cb) {\n  return this._stream.readlink(path, cb);\n};\nSFTPWrapper.prototype.symlink = function(targetPath, linkPath, cb) {\n  return this._stream.symlink(targetPath, linkPath, cb);\n};\nSFTPWrapper.prototype.realpath = function(path, cb) {\n  return this._stream.realpath(path, cb);\n};\n// extended requests\nSFTPWrapper.prototype.ext_openssh_rename = function(oldPath, newPath, cb) {\n  return this._stream.ext_openssh_rename(oldPath, newPath, cb);\n};\nSFTPWrapper.prototype.ext_openssh_statvfs = function(path, cb) {\n  return this._stream.ext_openssh_statvfs(path, cb);\n};\nSFTPWrapper.prototype.ext_openssh_fstatvfs = function(handle, cb) {\n  return this._stream.ext_openssh_fstatvfs(handle, cb);\n};\nSFTPWrapper.prototype.ext_openssh_hardlink = function(oldPath, newPath, cb) {\n  return this._stream.ext_openssh_hardlink(oldPath, newPath, cb);\n};\nSFTPWrapper.prototype.ext_openssh_fsync = function(handle, cb) {\n  return this._stream.ext_openssh_fsync(handle, cb);\n};\n\nmodule.exports = SFTPWrapper;\n\n\n//# sourceURL=webpack:///./node_modules/ssh2/lib/SFTPWrapper.js?");

/***/ }),

/***/ "./node_modules/ssh2/lib/agent.js":
/*!****************************************!*\
  !*** ./node_modules/ssh2/lib/agent.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var Socket = __webpack_require__(/*! net */ \"net\").Socket;\nvar EventEmitter = __webpack_require__(/*! events */ \"events\").EventEmitter;\nvar inherits = __webpack_require__(/*! util */ \"util\").inherits;\nvar path = __webpack_require__(/*! path */ \"path\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar cp = __webpack_require__(/*! child_process */ \"child_process\");\n\nvar readUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2/lib/buffer-helpers.js\").readUInt32BE;\nvar writeUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2/lib/buffer-helpers.js\").writeUInt32BE;\nvar writeUInt32LE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2/lib/buffer-helpers.js\").writeUInt32LE;\n\nvar REQUEST_IDENTITIES = 11;\nvar IDENTITIES_ANSWER = 12;\nvar SIGN_REQUEST = 13;\nvar SIGN_RESPONSE = 14;\nvar FAILURE = 5;\n\nvar RE_CYGWIN_SOCK = /^\\!<socket >(\\d+) s ([A-Z0-9]{8}\\-[A-Z0-9]{8}\\-[A-Z0-9]{8}\\-[A-Z0-9]{8})/;\n\n// Format of `//./pipe/ANYTHING`, with forward slashes and backward slashes being interchangeable\nvar WINDOWS_PIPE_REGEX = /^[/\\\\][/\\\\]\\.[/\\\\]pipe[/\\\\].+/;\n\nmodule.exports = function(sockPath, key, keyType, data, cb) {\n  var sock;\n  var error;\n  var sig;\n  var datalen;\n  var keylen = 0;\n  var isSigning = Buffer.isBuffer(key);\n  var type;\n  var count = 0;\n  var siglen = 0;\n  var nkeys = 0;\n  var keys;\n  var comlen = 0;\n  var comment = false;\n  var accept;\n  var reject;\n\n  if (typeof key === 'function' && typeof keyType === 'function') {\n    // agent forwarding\n    accept = key;\n    reject = keyType;\n  } else if (isSigning) {\n    keylen = key.length;\n    datalen = data.length;\n  } else {\n    cb = key;\n    key = undefined;\n  }\n\n  function onconnect() {\n    var buf;\n    if (isSigning) {\n      /*\n        byte        SSH2_AGENTC_SIGN_REQUEST\n        string      key_blob\n        string      data\n        uint32      flags\n      */\n      var p = 9;\n      buf = Buffer.allocUnsafe(4 + 1 + 4 + keylen + 4 + datalen + 4);\n      writeUInt32BE(buf, buf.length - 4, 0);\n      buf[4] = SIGN_REQUEST;\n      writeUInt32BE(buf, keylen, 5);\n      key.copy(buf, p);\n      writeUInt32BE(buf, datalen, p += keylen);\n      data.copy(buf, p += 4);\n      writeUInt32BE(buf, 0, p += datalen);\n      sock.write(buf);\n    } else {\n      /*\n        byte        SSH2_AGENTC_REQUEST_IDENTITIES\n      */\n      sock.write(Buffer.from([0, 0, 0, 1, REQUEST_IDENTITIES]));\n    }\n  }\n  function ondata(chunk) {\n    for (var i = 0, len = chunk.length; i < len; ++i) {\n      if (type === undefined) {\n        // skip over packet length\n        if (++count === 5) {\n          type = chunk[i];\n          count = 0;\n        }\n      } else if (type === SIGN_RESPONSE) {\n        /*\n          byte        SSH2_AGENT_SIGN_RESPONSE\n          string      signature_blob\n        */\n        if (!sig) {\n          siglen <<= 8;\n          siglen += chunk[i];\n          if (++count === 4) {\n            sig = Buffer.allocUnsafe(siglen);\n            count = 0;\n          }\n        } else {\n          sig[count] = chunk[i];\n          if (++count === siglen) {\n            sock.removeAllListeners('data');\n            return sock.destroy();\n          }\n        }\n      } else if (type === IDENTITIES_ANSWER) {\n        /*\n          byte        SSH2_AGENT_IDENTITIES_ANSWER\n          uint32      num_keys\n\n        Followed by zero or more consecutive keys, encoded as:\n\n          string      public key blob\n          string      public key comment\n        */\n        if (keys === undefined) {\n          nkeys <<= 8;\n          nkeys += chunk[i];\n          if (++count === 4) {\n            keys = new Array(nkeys);\n            count = 0;\n            if (nkeys === 0) {\n              sock.removeAllListeners('data');\n              return sock.destroy();\n            }\n          }\n        } else {\n          if (!key) {\n            keylen <<= 8;\n            keylen += chunk[i];\n            if (++count === 4) {\n              key = Buffer.allocUnsafe(keylen);\n              count = 0;\n            }\n          } else if (comment === false) {\n            key[count] = chunk[i];\n            if (++count === keylen) {\n              keys[nkeys - 1] = key;\n              keylen = 0;\n              count = 0;\n              comment = true;\n              if (--nkeys === 0) {\n                key = undefined;\n                sock.removeAllListeners('data');\n                return sock.destroy();\n              }\n            }\n          } else if (comment === true) {\n            comlen <<= 8;\n            comlen += chunk[i];\n            if (++count === 4) {\n              count = 0;\n              if (comlen > 0)\n                comment = comlen;\n              else {\n                key = undefined;\n                comment = false;\n              }\n              comlen = 0;\n            }\n          } else {\n            // skip comments\n            if (++count === comment) {\n              comment = false;\n              count = 0;\n              key = undefined;\n            }\n          }\n        }\n      } else if (type === FAILURE) {\n        if (isSigning)\n          error = new Error('Agent unable to sign data');\n        else\n          error = new Error('Unable to retrieve list of keys from agent');\n        sock.removeAllListeners('data');\n        return sock.destroy();\n      }\n    }\n  }\n  function onerror(err) {\n    error = err;\n  }\n  function onclose() {\n    if (error)\n      cb(error);\n    else if ((isSigning && !sig) || (!isSigning && !keys))\n      cb(new Error('Unexpected disconnection from agent'));\n    else if (isSigning && sig)\n      cb(undefined, sig);\n    else if (!isSigning && keys)\n      cb(undefined, keys);\n  }\n\n  if (process.platform === 'win32' && !WINDOWS_PIPE_REGEX.test(sockPath)) {\n    if (sockPath === 'pageant') {\n      // Pageant (PuTTY authentication agent)\n      sock = new PageantSock();\n    } else {\n      // cygwin ssh-agent instance\n      var triedCygpath = false;\n      fs.readFile(sockPath, function readCygsocket(err, data) {\n        if (err) {\n          if (triedCygpath)\n            return cb(new Error('Invalid cygwin unix socket path'));\n          // try using `cygpath` to convert a possible *nix-style path to the\n          // real Windows path before giving up ...\n          cp.exec('cygpath -w \"' + sockPath + '\"',\n                  function(err, stdout, stderr) {\n            if (err || stdout.length === 0)\n              return cb(new Error('Invalid cygwin unix socket path'));\n            triedCygpath = true;\n            sockPath = stdout.toString().replace(/[\\r\\n]/g, '');\n            fs.readFile(sockPath, readCygsocket);\n          });\n          return;\n        }\n\n        var m;\n        if (m = RE_CYGWIN_SOCK.exec(data.toString('ascii'))) {\n          var port;\n          var secret;\n          var secretbuf;\n          var state;\n          var bc = 0;\n          var isRetrying = false;\n          var inbuf = [];\n          var credsbuf = Buffer.allocUnsafe(12);\n          var i;\n          var j;\n\n          // use 0 for pid, uid, and gid to ensure we get an error and also\n          // a valid uid and gid from cygwin so that we don't have to figure it\n          // out ourselves\n          credsbuf.fill(0);\n\n          // parse cygwin unix socket file contents\n          port = parseInt(m[1], 10);\n          secret = m[2].replace(/\\-/g, '');\n          secretbuf = Buffer.allocUnsafe(16);\n          for (i = 0, j = 0; j < 32; ++i,j+=2)\n            secretbuf[i] = parseInt(secret.substring(j, j + 2), 16);\n\n          // convert to host order (always LE for Windows)\n          for (i = 0; i < 16; i += 4)\n            writeUInt32LE(secretbuf, readUInt32BE(secretbuf, i), i);\n\n          function _onconnect() {\n            bc = 0;\n            state = 'secret';\n            sock.write(secretbuf);\n          }\n          function _ondata(data) {\n            bc += data.length;\n            if (state === 'secret') {\n              // the secret we sent is echoed back to us by cygwin, not sure of\n              // the reason for that, but we ignore it nonetheless ...\n              if (bc === 16) {\n                bc = 0;\n                state = 'creds';\n                sock.write(credsbuf);\n              }\n            } else if (state === 'creds') {\n              // if this is the first attempt, make sure to gather the valid\n              // uid and gid for our next attempt\n              if (!isRetrying)\n                inbuf.push(data);\n\n              if (bc === 12) {\n                sock.removeListener('connect', _onconnect);\n                sock.removeListener('data', _ondata);\n                sock.removeListener('close', _onclose);\n                if (isRetrying) {\n                  addSockListeners();\n                  sock.emit('connect');\n                } else {\n                  isRetrying = true;\n                  credsbuf = Buffer.concat(inbuf);\n                  writeUInt32LE(credsbuf, process.pid, 0);\n                  sock.destroy();\n                  tryConnect();\n                }\n              }\n            }\n          }\n          function _onclose() {\n            cb(new Error('Problem negotiating cygwin unix socket security'));\n          }\n          function tryConnect() {\n            sock = new Socket();\n            sock.once('connect', _onconnect);\n            sock.on('data', _ondata);\n            sock.once('close', _onclose);\n            sock.connect(port);\n          }\n          tryConnect();\n        } else\n          cb(new Error('Malformed cygwin unix socket file'));\n      });\n      return;\n    }\n  } else\n    sock = new Socket();\n\n  function addSockListeners() {\n    if (!accept && !reject) {\n      sock.once('connect', onconnect);\n      sock.on('data', ondata);\n      sock.once('error', onerror);\n      sock.once('close', onclose);\n    } else {\n      var chan;\n      sock.once('connect', function() {\n        chan = accept();\n        var isDone = false;\n        function onDone() {\n          if (isDone)\n            return;\n          sock.destroy();\n          isDone = true;\n        }\n        chan.once('end', onDone)\n            .once('close', onDone)\n            .on('data', function(data) {\n          sock.write(data);\n        });\n        sock.on('data', function(data) {\n          chan.write(data);\n        });\n      });\n      sock.once('close', function() {\n        if (!chan)\n          reject();\n      });\n    }\n  }\n  addSockListeners();\n  sock.connect(sockPath);\n};\n\n\n// win32 only ------------------------------------------------------------------\nif (process.platform === 'win32') {\n  var RET_ERR_BADARGS = 10;\n  var RET_ERR_UNAVAILABLE = 11;\n  var RET_ERR_NOMAP = 12;\n  var RET_ERR_BINSTDIN = 13;\n  var RET_ERR_BINSTDOUT = 14;\n  var RET_ERR_BADLEN = 15;\n\n  var ERROR = {};\n  var EXEPATH = path.resolve(__dirname, '..', 'util/pagent.exe');\n  ERROR[RET_ERR_BADARGS] = new Error('Invalid pagent.exe arguments');\n  ERROR[RET_ERR_UNAVAILABLE] = new Error('Pageant is not running');\n  ERROR[RET_ERR_NOMAP] = new Error('pagent.exe could not create an mmap');\n  ERROR[RET_ERR_BINSTDIN] = new Error('pagent.exe could not set mode for stdin');\n  ERROR[RET_ERR_BINSTDOUT] = new Error('pagent.exe could not set mode for stdout');\n  ERROR[RET_ERR_BADLEN] = new Error('pagent.exe did not get expected input payload');\n\n  function PageantSock() {\n    this.proc = undefined;\n    this.buffer = null;\n  }\n  inherits(PageantSock, EventEmitter);\n\n  PageantSock.prototype.write = function(buf) {\n    if (this.buffer === null)\n      this.buffer = buf;\n    else {\n      this.buffer = Buffer.concat([this.buffer, buf],\n                                  this.buffer.length + buf.length);\n    }\n    // Wait for at least all length bytes\n    if (this.buffer.length < 4)\n      return;\n\n    var len = readUInt32BE(this.buffer, 0);\n    // Make sure we have a full message before querying pageant\n    if ((this.buffer.length - 4) < len)\n      return;\n\n    buf = this.buffer.slice(0, 4 + len);\n    if (this.buffer.length > (4 + len))\n      this.buffer = this.buffer.slice(4 + len);\n    else\n      this.buffer = null;\n\n    var self = this;\n    var proc;\n    var hadError = false;\n    proc = this.proc = cp.spawn(EXEPATH, [ buf.length ]);\n    proc.stdout.on('data', function(data) {\n      self.emit('data', data);\n    });\n    proc.once('error', function(err) {\n      if (!hadError) {\n        hadError = true;\n        self.emit('error', err);\n      }\n    });\n    proc.once('close', function(code) {\n      self.proc = undefined;\n      if (ERROR[code] && !hadError) {\n        hadError = true;\n        self.emit('error', ERROR[code]);\n      }\n      self.emit('close', hadError);\n    });\n    proc.stdin.end(buf);\n  };\n  PageantSock.prototype.end = PageantSock.prototype.destroy = function() {\n    this.buffer = null;\n    if (this.proc) {\n      this.proc.kill();\n      this.proc = undefined;\n    }\n  };\n  PageantSock.prototype.connect = function() {\n    this.emit('connect');\n  };\n}\n\n\n//# sourceURL=webpack:///./node_modules/ssh2/lib/agent.js?");

/***/ }),

/***/ "./node_modules/ssh2/lib/buffer-helpers.js":
/*!*************************************************!*\
  !*** ./node_modules/ssh2/lib/buffer-helpers.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = {\n  readUInt32BE: function readUInt32BE(buf, offset) {\n    return buf[offset++] * 16777216\n           + buf[offset++] * 65536\n           + buf[offset++] * 256\n           + buf[offset];\n  },\n  writeUInt32BE: function writeUInt32BE(buf, value, offset) {\n    buf[offset++] = (value >>> 24);\n    buf[offset++] = (value >>> 16);\n    buf[offset++] = (value >>> 8);\n    buf[offset++] = value;\n    return offset;\n  },\n  writeUInt32LE: function writeUInt32LE(buf, value, offset) {\n    buf[offset++] = value;\n    buf[offset++] = (value >>> 8);\n    buf[offset++] = (value >>> 16);\n    buf[offset++] = (value >>> 24);\n    return offset;\n  }\n};\n\n\n//# sourceURL=webpack:///./node_modules/ssh2/lib/buffer-helpers.js?");

/***/ }),

/***/ "./node_modules/ssh2/lib/client.js":
/*!*****************************************!*\
  !*** ./node_modules/ssh2/lib/client.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var crypto = __webpack_require__(/*! crypto */ \"crypto\");\nvar Socket = __webpack_require__(/*! net */ \"net\").Socket;\nvar dnsLookup = __webpack_require__(/*! dns */ \"dns\").lookup;\nvar EventEmitter = __webpack_require__(/*! events */ \"events\").EventEmitter;\nvar inherits = __webpack_require__(/*! util */ \"util\").inherits;\nvar HASHES = crypto.getHashes();\n\nvar ssh2_streams = __webpack_require__(/*! ssh2-streams */ \"./node_modules/ssh2-streams/index.js\");\nvar SSH2Stream = ssh2_streams.SSH2Stream;\nvar SFTPStream = ssh2_streams.SFTPStream;\nvar consts = ssh2_streams.constants;\nvar BUGS = consts.BUGS;\nvar ALGORITHMS = consts.ALGORITHMS;\nvar EDDSA_SUPPORTED = consts.EDDSA_SUPPORTED;\nvar parseKey = ssh2_streams.utils.parseKey;\n\nvar HTTPAgents = __webpack_require__(/*! ./http-agents */ \"./node_modules/ssh2/lib/http-agents.js\");\nvar Channel = __webpack_require__(/*! ./Channel */ \"./node_modules/ssh2/lib/Channel.js\");\nvar agentQuery = __webpack_require__(/*! ./agent */ \"./node_modules/ssh2/lib/agent.js\");\nvar SFTPWrapper = __webpack_require__(/*! ./SFTPWrapper */ \"./node_modules/ssh2/lib/SFTPWrapper.js\");\nvar readUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2/lib/buffer-helpers.js\").readUInt32BE;\n\nvar MAX_CHANNEL = Math.pow(2, 32) - 1;\nvar RE_OPENSSH = /^OpenSSH_(?:(?![0-4])\\d)|(?:\\d{2,})/;\nvar DEBUG_NOOP = function(msg) {};\n\nfunction Client() {\n  if (!(this instanceof Client))\n    return new Client();\n\n  EventEmitter.call(this);\n\n  this.config = {\n    host: undefined,\n    port: undefined,\n    localAddress: undefined,\n    localPort: undefined,\n    forceIPv4: undefined,\n    forceIPv6: undefined,\n    keepaliveCountMax: undefined,\n    keepaliveInterval: undefined,\n    readyTimeout: undefined,\n\n    username: undefined,\n    password: undefined,\n    privateKey: undefined,\n    tryKeyboard: undefined,\n    agent: undefined,\n    allowAgentFwd: undefined,\n    authHandler: undefined,\n\n    hostHashAlgo: undefined,\n    hostHashCb: undefined,\n    strictVendor: undefined,\n    debug: undefined\n  };\n\n  this._readyTimeout = undefined;\n  this._channels = undefined;\n  this._callbacks = undefined;\n  this._forwarding = undefined;\n  this._forwardingUnix = undefined;\n  this._acceptX11 = undefined;\n  this._agentFwdEnabled = undefined;\n  this._curChan = undefined;\n  this._remoteVer = undefined;\n\n  this._sshstream = undefined;\n  this._sock = undefined;\n  this._resetKA = undefined;\n}\ninherits(Client, EventEmitter);\n\nClient.prototype.connect = function(cfg) {\n  var self = this;\n\n  if (this._sock && this._sock.writable) {\n    this.once('close', function() {\n      self.connect(cfg);\n    });\n    this.end();\n    return;\n  }\n\n  this.config.host = cfg.hostname || cfg.host || 'localhost';\n  this.config.port = cfg.port || 22;\n  this.config.localAddress = (typeof cfg.localAddress === 'string'\n                              ? cfg.localAddress\n                              : undefined);\n  this.config.localPort = (typeof cfg.localPort === 'string'\n                           || typeof cfg.localPort === 'number'\n                           ? cfg.localPort\n                           : undefined);\n  this.config.forceIPv4 = cfg.forceIPv4 || false;\n  this.config.forceIPv6 = cfg.forceIPv6 || false;\n  this.config.keepaliveCountMax = (typeof cfg.keepaliveCountMax === 'number'\n                                   && cfg.keepaliveCountMax >= 0\n                                   ? cfg.keepaliveCountMax\n                                   : 3);\n  this.config.keepaliveInterval = (typeof cfg.keepaliveInterval === 'number'\n                                   && cfg.keepaliveInterval > 0\n                                   ? cfg.keepaliveInterval\n                                   : 0);\n  this.config.readyTimeout = (typeof cfg.readyTimeout === 'number'\n                              && cfg.readyTimeout >= 0\n                              ? cfg.readyTimeout\n                              : 20000);\n\n  var algorithms = {\n    kex: undefined,\n    kexBuf: undefined,\n    cipher: undefined,\n    cipherBuf: undefined,\n    serverHostKey: undefined,\n    serverHostKeyBuf: undefined,\n    hmac: undefined,\n    hmacBuf: undefined,\n    compress: undefined,\n    compressBuf: undefined\n  };\n  var i;\n  if (typeof cfg.algorithms === 'object' && cfg.algorithms !== null) {\n    var algosSupported;\n    var algoList;\n\n    algoList = cfg.algorithms.kex;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_KEX;\n      for (i = 0; i < algoList.length; ++i) {\n        if (algosSupported.indexOf(algoList[i]) === -1)\n          throw new Error('Unsupported key exchange algorithm: ' + algoList[i]);\n      }\n      algorithms.kex = algoList;\n    }\n\n    algoList = cfg.algorithms.cipher;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_CIPHER;\n      for (i = 0; i < algoList.length; ++i) {\n        if (algosSupported.indexOf(algoList[i]) === -1)\n          throw new Error('Unsupported cipher algorithm: ' + algoList[i]);\n      }\n      algorithms.cipher = algoList;\n    }\n\n    algoList = cfg.algorithms.serverHostKey;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_SERVER_HOST_KEY;\n      for (i = 0; i < algoList.length; ++i) {\n        if (algosSupported.indexOf(algoList[i]) === -1) {\n          throw new Error('Unsupported server host key algorithm: '\n                           + algoList[i]);\n        }\n      }\n      algorithms.serverHostKey = algoList;\n    }\n\n    algoList = cfg.algorithms.hmac;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_HMAC;\n      for (i = 0; i < algoList.length; ++i) {\n        if (algosSupported.indexOf(algoList[i]) === -1)\n          throw new Error('Unsupported HMAC algorithm: ' + algoList[i]);\n      }\n      algorithms.hmac = algoList;\n    }\n\n    algoList = cfg.algorithms.compress;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_COMPRESS;\n      for (i = 0; i < algoList.length; ++i) {\n        if (algosSupported.indexOf(algoList[i]) === -1)\n          throw new Error('Unsupported compression algorithm: ' + algoList[i]);\n      }\n      algorithms.compress = algoList;\n    }\n  }\n  if (algorithms.compress === undefined) {\n    if (cfg.compress) {\n      algorithms.compress = ['zlib@openssh.com', 'zlib'];\n      if (cfg.compress !== 'force')\n        algorithms.compress.push('none');\n    } else if (cfg.compress === false)\n      algorithms.compress = ['none'];\n  }\n\n  if (typeof cfg.username === 'string')\n    this.config.username = cfg.username;\n  else if (typeof cfg.user === 'string')\n    this.config.username = cfg.user;\n  else\n    throw new Error('Invalid username');\n\n  this.config.password = (typeof cfg.password === 'string'\n                          ? cfg.password\n                          : undefined);\n  this.config.privateKey = (typeof cfg.privateKey === 'string'\n                            || Buffer.isBuffer(cfg.privateKey)\n                            ? cfg.privateKey\n                            : undefined);\n  this.config.localHostname = (typeof cfg.localHostname === 'string'\n                               && cfg.localHostname.length\n                               ? cfg.localHostname\n                               : undefined);\n  this.config.localUsername = (typeof cfg.localUsername === 'string'\n                               && cfg.localUsername.length\n                               ? cfg.localUsername\n                               : undefined);\n  this.config.tryKeyboard = (cfg.tryKeyboard === true);\n  this.config.agent = (typeof cfg.agent === 'string' && cfg.agent.length\n                       ? cfg.agent\n                       : undefined);\n  this.config.allowAgentFwd = (cfg.agentForward === true\n                               && this.config.agent !== undefined);\n  var authHandler = this.config.authHandler = (\n    typeof cfg.authHandler === 'function' ? cfg.authHandler : undefined\n  );\n\n  this.config.strictVendor = (typeof cfg.strictVendor === 'boolean'\n                              ? cfg.strictVendor\n                              : true);\n\n  var debug = this.config.debug = (typeof cfg.debug === 'function'\n                                   ? cfg.debug\n                                   : DEBUG_NOOP);\n\n  if (cfg.agentForward === true && !this.config.allowAgentFwd)\n    throw new Error('You must set a valid agent path to allow agent forwarding');\n\n  var callbacks = this._callbacks = [];\n  this._channels = {};\n  this._forwarding = {};\n  this._forwardingUnix = {};\n  this._acceptX11 = 0;\n  this._agentFwdEnabled = false;\n  this._curChan = -1;\n  this._remoteVer = undefined;\n  var privateKey;\n\n  if (this.config.privateKey) {\n    privateKey = parseKey(this.config.privateKey, cfg.passphrase);\n    if (privateKey instanceof Error)\n      throw new Error('Cannot parse privateKey: ' + privateKey.message);\n    if (Array.isArray(privateKey))\n      privateKey = privateKey[0]; // OpenSSH's newer format only stores 1 key for now\n    if (privateKey.getPrivatePEM() === null)\n      throw new Error('privateKey value does not contain a (valid) private key');\n  }\n\n  var stream = this._sshstream = new SSH2Stream({\n    algorithms: algorithms,\n    debug: (debug === DEBUG_NOOP ? undefined : debug)\n  });\n  var sock = this._sock = (cfg.sock || new Socket());\n\n  // drain stderr if we are connection hopping using an exec stream\n  if (this._sock.stderr && typeof this._sock.stderr.resume === 'function')\n    this._sock.stderr.resume();\n\n  // keepalive-related\n  var kainterval = this.config.keepaliveInterval;\n  var kacountmax = this.config.keepaliveCountMax;\n  var kacount = 0;\n  var katimer;\n  function sendKA() {\n    if (++kacount > kacountmax) {\n      clearInterval(katimer);\n      if (sock.readable) {\n        var err = new Error('Keepalive timeout');\n        err.level = 'client-timeout';\n        self.emit('error', err);\n        sock.destroy();\n      }\n      return;\n    }\n    if (sock.writable) {\n      // append dummy callback to keep correct callback order\n      callbacks.push(resetKA);\n      stream.ping();\n    } else\n      clearInterval(katimer);\n  }\n  function resetKA() {\n    if (kainterval > 0) {\n      kacount = 0;\n      clearInterval(katimer);\n      if (sock.writable)\n        katimer = setInterval(sendKA, kainterval);\n    }\n  }\n  this._resetKA = resetKA;\n\n  stream.on('USERAUTH_BANNER', function(msg) {\n    self.emit('banner', msg);\n  });\n\n  sock.on('connect', function() {\n    debug('DEBUG: Client: Connected');\n    self.emit('connect');\n    if (!cfg.sock)\n      stream.pipe(sock).pipe(stream);\n  }).on('timeout', function() {\n    self.emit('timeout');\n  }).on('error', function(err) {\n    clearTimeout(self._readyTimeout);\n    err.level = 'client-socket';\n    self.emit('error', err);\n  }).on('end', function() {\n    stream.unpipe(sock);\n    clearTimeout(self._readyTimeout);\n    clearInterval(katimer);\n    self.emit('end');\n  }).on('close', function() {\n    stream.unpipe(sock);\n    clearTimeout(self._readyTimeout);\n    clearInterval(katimer);\n    self.emit('close');\n\n    // notify outstanding channel requests of disconnection ...\n    var callbacks_ = callbacks;\n    var err = new Error('No response from server');\n    callbacks = self._callbacks = [];\n    for (i = 0; i < callbacks_.length; ++i)\n      callbacks_[i](err);\n\n    // simulate error for any channels waiting to be opened. this is safe\n    // against successfully opened channels because the success and failure\n    // event handlers are automatically removed when a success/failure response\n    // is received\n    var channels = self._channels;\n    var chanNos = Object.keys(channels);\n    self._channels = {};\n    for (i = 0; i < chanNos.length; ++i) {\n      var ev1 = stream.emit('CHANNEL_OPEN_FAILURE:' + chanNos[i], err);\n      // emitting CHANNEL_CLOSE should be safe too and should help for any\n      // special channels which might otherwise keep the process alive, such\n      // as agent forwarding channels which have open unix sockets ...\n      var ev2 = stream.emit('CHANNEL_CLOSE:' + chanNos[i]);\n      var earlyCb;\n      if (!ev1 && !ev2 && (earlyCb = channels[chanNos[i]])\n          && typeof earlyCb === 'function') {\n        earlyCb(err);\n      }\n    }\n  });\n  stream.on('drain', function() {\n    self.emit('drain');\n  }).once('header', function(header) {\n    self._remoteVer = header.versions.software;\n    if (header.greeting)\n      self.emit('greeting', header.greeting);\n  }).on('continue', function() {\n    self.emit('continue');\n  }).on('error', function(err) {\n    if (err.level === undefined)\n      err.level = 'protocol';\n    else if (err.level === 'handshake')\n      clearTimeout(self._readyTimeout);\n    self.emit('error', err);\n  }).on('end', function() {\n    sock.resume();\n  });\n\n  if (typeof cfg.hostVerifier === 'function') {\n    if (HASHES.indexOf(cfg.hostHash) === -1)\n      throw new Error('Invalid host hash algorithm: ' + cfg.hostHash);\n    var hashCb = cfg.hostVerifier;\n    var hasher = crypto.createHash(cfg.hostHash);\n    stream.once('fingerprint', function(key, verify) {\n      hasher.update(key);\n      var ret = hashCb(hasher.digest('hex'), verify);\n      if (ret !== undefined)\n        verify(ret);\n    });\n  }\n\n  // begin authentication handling =============================================\n  var curAuth;\n  var curPartial = null;\n  var curAuthsLeft = null;\n  var agentKeys;\n  var agentKeyPos = 0;\n  var authsAllowed = ['none'];\n  if (this.config.password !== undefined)\n    authsAllowed.push('password');\n  if (privateKey !== undefined)\n    authsAllowed.push('publickey');\n  if (this.config.agent !== undefined)\n    authsAllowed.push('agent');\n  if (this.config.tryKeyboard)\n    authsAllowed.push('keyboard-interactive');\n  if (privateKey !== undefined\n      && this.config.localHostname !== undefined\n      && this.config.localUsername !== undefined) {\n    authsAllowed.push('hostbased');\n  }\n\n  if (authHandler === undefined) {\n    var authPos = 0;\n    authHandler = function authHandler(authsLeft, partial, cb) {\n      if (authPos === authsAllowed.length)\n        return false;\n      return authsAllowed[authPos++];\n    };\n  }\n\n  var hasSentAuth = false;\n  function doNextAuth(authName) {\n    hasSentAuth = true;\n    if (authName === false) {\n      stream.removeListener('USERAUTH_FAILURE', onUSERAUTH_FAILURE);\n      stream.removeListener('USERAUTH_PK_OK', onUSERAUTH_PK_OK);\n      var err = new Error('All configured authentication methods failed');\n      err.level = 'client-authentication';\n      self.emit('error', err);\n      if (stream.writable)\n        self.end();\n      return;\n    }\n    if (authsAllowed.indexOf(authName) === -1)\n      throw new Error('Authentication method not allowed: ' + authName);\n    curAuth = authName;\n    switch (curAuth) {\n      case 'password':\n        stream.authPassword(self.config.username, self.config.password);\n      break;\n      case 'publickey':\n        stream.authPK(self.config.username, privateKey);\n        stream.once('USERAUTH_PK_OK', onUSERAUTH_PK_OK);\n      break;\n      case 'hostbased':\n        function hostbasedCb(buf, cb) {\n          var signature = privateKey.sign(buf);\n          if (signature instanceof Error) {\n            signature.message = 'Error while signing data with privateKey: '\n                                + signature.message;\n            signature.level = 'client-authentication';\n            self.emit('error', signature);\n            return tryNextAuth();\n          }\n\n          cb(signature);\n        }\n        stream.authHostbased(self.config.username,\n                             privateKey,\n                             self.config.localHostname,\n                             self.config.localUsername,\n                             hostbasedCb);\n      break;\n      case 'agent':\n        agentQuery(self.config.agent, function(err, keys) {\n          if (err) {\n            err.level = 'agent';\n            self.emit('error', err);\n            agentKeys = undefined;\n            return tryNextAuth();\n          } else if (keys.length === 0) {\n            debug('DEBUG: Agent: No keys stored in agent');\n            agentKeys = undefined;\n            return tryNextAuth();\n          }\n\n          agentKeys = keys;\n          agentKeyPos = 0;\n\n          stream.authPK(self.config.username, keys[0]);\n          stream.once('USERAUTH_PK_OK', onUSERAUTH_PK_OK);\n        });\n      break;\n      case 'keyboard-interactive':\n        stream.authKeyboard(self.config.username);\n        stream.on('USERAUTH_INFO_REQUEST', onUSERAUTH_INFO_REQUEST);\n      break;\n      case 'none':\n        stream.authNone(self.config.username);\n      break;\n    }\n  }\n  function tryNextAuth() {\n    hasSentAuth = false;\n    var auth = authHandler(curAuthsLeft, curPartial, doNextAuth);\n    if (hasSentAuth || auth === undefined)\n      return;\n    doNextAuth(auth);\n  }\n  function tryNextAgentKey() {\n    if (curAuth === 'agent') {\n      if (agentKeyPos >= agentKeys.length)\n        return;\n      if (++agentKeyPos >= agentKeys.length) {\n        debug('DEBUG: Agent: No more keys left to try');\n        debug('DEBUG: Client: agent auth failed');\n        agentKeys = undefined;\n        tryNextAuth();\n      } else {\n        debug('DEBUG: Agent: Trying key #' + (agentKeyPos + 1));\n        stream.authPK(self.config.username, agentKeys[agentKeyPos]);\n        stream.once('USERAUTH_PK_OK', onUSERAUTH_PK_OK);\n      }\n    }\n  }\n  function onUSERAUTH_INFO_REQUEST(name, instructions, lang, prompts) {\n    var nprompts = (Array.isArray(prompts) ? prompts.length : 0);\n    if (nprompts === 0) {\n      debug('DEBUG: Client: Sending automatic USERAUTH_INFO_RESPONSE');\n      return stream.authInfoRes();\n    }\n    // we sent a keyboard-interactive user authentication request and now the\n    // server is sending us the prompts we need to present to the user\n    self.emit('keyboard-interactive',\n              name,\n              instructions,\n              lang,\n              prompts,\n              function(answers) {\n                stream.authInfoRes(answers);\n              }\n    );\n  }\n  function onUSERAUTH_PK_OK() {\n    if (curAuth === 'agent') {\n      var agentKey = agentKeys[agentKeyPos];\n      var keyLen = readUInt32BE(agentKey, 0);\n      var pubKeyFullType = agentKey.toString('ascii', 4, 4 + keyLen);\n      var pubKeyType = pubKeyFullType.slice(4);\n      // Check that we support the key type first\n      // TODO: move key type checking logic to ssh2-streams\n      switch (pubKeyFullType) {\n        case 'ssh-rsa':\n        case 'ssh-dss':\n        case 'ecdsa-sha2-nistp256':\n        case 'ecdsa-sha2-nistp384':\n        case 'ecdsa-sha2-nistp521':\n          break;\n        default:\n          if (EDDSA_SUPPORTED && pubKeyFullType === 'ssh-ed25519')\n            break;\n          debug('DEBUG: Agent: Skipping unsupported key type: '\n                + pubKeyFullType);\n          return tryNextAgentKey();\n      }\n      stream.authPK(self.config.username, \n                    agentKey,\n                    function(buf, cb) {\n        agentQuery(self.config.agent,\n                   agentKey,\n                   pubKeyType,\n                   buf,\n                   function(err, signed) {\n          if (err) {\n            err.level = 'agent';\n            self.emit('error', err);\n          } else {\n            var sigFullTypeLen = readUInt32BE(signed, 0);\n            if (4 + sigFullTypeLen + 4 < signed.length) {\n              var sigFullType = signed.toString('ascii', 4, 4 + sigFullTypeLen);\n              if (sigFullType !== pubKeyFullType) {\n                err = new Error('Agent key/signature type mismatch');\n                err.level = 'agent';\n                self.emit('error', err);\n              } else {\n                // skip algoLen + algo + sigLen\n                return cb(signed.slice(4 + sigFullTypeLen + 4));\n              }\n            }\n          }\n\n          tryNextAgentKey();\n        });\n      });\n    } else if (curAuth === 'publickey') {\n      stream.authPK(self.config.username, privateKey, function(buf, cb) {\n        var signature = privateKey.sign(buf);\n        if (signature instanceof Error) {\n          signature.message = 'Error while signing data with privateKey: '\n                              + signature.message;\n          signature.level = 'client-authentication';\n          self.emit('error', signature);\n          return tryNextAuth();\n        }\n        cb(signature);\n      });\n    }\n  }\n  function onUSERAUTH_FAILURE(authsLeft, partial) {\n    stream.removeListener('USERAUTH_PK_OK', onUSERAUTH_PK_OK);\n    stream.removeListener('USERAUTH_INFO_REQUEST', onUSERAUTH_INFO_REQUEST);\n    if (curAuth === 'agent') {\n      debug('DEBUG: Client: Agent key #' + (agentKeyPos + 1) + ' failed');\n      return tryNextAgentKey();\n    } else {\n      debug('DEBUG: Client: ' + curAuth + ' auth failed');\n    }\n\n    curPartial = partial;\n    curAuthsLeft = authsLeft;\n    tryNextAuth();\n  }\n  stream.once('USERAUTH_SUCCESS', function() {\n    stream.removeListener('USERAUTH_FAILURE', onUSERAUTH_FAILURE);\n    stream.removeListener('USERAUTH_INFO_REQUEST', onUSERAUTH_INFO_REQUEST);\n\n    // start keepalive mechanism\n    resetKA();\n\n    clearTimeout(self._readyTimeout);\n\n    self.emit('ready');\n  }).on('USERAUTH_FAILURE', onUSERAUTH_FAILURE);\n  // end authentication handling ===============================================\n\n  // handle initial handshake completion\n  stream.once('ready', function() {\n    stream.service('ssh-userauth');\n    stream.once('SERVICE_ACCEPT', function(svcName) {\n      if (svcName === 'ssh-userauth')\n        tryNextAuth();\n    });\n  });\n\n  // handle incoming requests from server, typically a forwarded TCP or X11\n  // connection\n  stream.on('CHANNEL_OPEN', function(info) {\n    onCHANNEL_OPEN(self, info);\n  });\n\n  // handle responses for tcpip-forward and other global requests\n  stream.on('REQUEST_SUCCESS', function(data) {\n    if (callbacks.length)\n      callbacks.shift()(false, data);\n  }).on('REQUEST_FAILURE', function() {\n    if (callbacks.length)\n      callbacks.shift()(true);\n  });\n\n  stream.on('GLOBAL_REQUEST', function(name, wantReply, data) {\n    // auto-reject all global requests, this can be especially useful if the\n    // server is sending us dummy keepalive global requests\n    if (wantReply)\n      stream.requestFailure();\n  });\n\n  if (!cfg.sock) {\n    var host = this.config.host;\n    var forceIPv4 = this.config.forceIPv4;\n    var forceIPv6 = this.config.forceIPv6;\n\n    debug('DEBUG: Client: Trying '\n          + host\n          + ' on port '\n          + this.config.port\n          + ' ...');\n\n    function doConnect() {\n      startTimeout();\n      self._sock.connect({\n        host: host,\n        port: self.config.port,\n        localAddress: self.config.localAddress,\n        localPort: self.config.localPort\n      });\n      self._sock.setNoDelay(true);\n      self._sock.setMaxListeners(0);\n      self._sock.setTimeout(typeof cfg.timeout === 'number' ? cfg.timeout : 0);\n    }\n\n    if ((!forceIPv4 && !forceIPv6) || (forceIPv4 && forceIPv6))\n      doConnect();\n    else {\n      dnsLookup(host, (forceIPv4 ? 4 : 6), function(err, address, family) {\n        if (err) {\n          var error = new Error('Error while looking up '\n                                + (forceIPv4 ? 'IPv4' : 'IPv6')\n                                + ' address for host '\n                                + host\n                                + ': ' + err);\n          clearTimeout(self._readyTimeout);\n          error.level = 'client-dns';\n          self.emit('error', error);\n          self.emit('close');\n          return;\n        }\n        host = address;\n        doConnect();\n      });\n    }\n  } else {\n    startTimeout();\n    stream.pipe(sock).pipe(stream);\n  }\n\n  function startTimeout() {\n    if (self.config.readyTimeout > 0) {\n      self._readyTimeout = setTimeout(function() {\n        var err = new Error('Timed out while waiting for handshake');\n        err.level = 'client-timeout';\n        self.emit('error', err);\n        sock.destroy();\n      }, self.config.readyTimeout);\n    }\n  }\n};\n\nClient.prototype.end = function() {\n  if (this._sock\n      && this._sock.writable\n      && this._sshstream\n      && this._sshstream.writable)\n    return this._sshstream.disconnect();\n  return false;\n};\n\nClient.prototype.destroy = function() {\n  this._sock && this._sock.destroy();\n};\n\nClient.prototype.exec = function(cmd, opts, cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n\n  var self = this;\n  var extraOpts = { allowHalfOpen: (opts.allowHalfOpen !== false) };\n\n  return openChannel(this, 'session', extraOpts, function(err, chan) {\n    if (err)\n      return cb(err);\n\n    var todo = [];\n\n    function reqCb(err) {\n      if (err) {\n        chan.close();\n        return cb(err);\n      }\n      if (todo.length)\n        todo.shift()();\n    }\n\n    if (self.config.allowAgentFwd === true\n        || (opts\n            && opts.agentForward === true\n            && self.config.agent !== undefined)) {\n      todo.push(function() {\n        reqAgentFwd(chan, reqCb);\n      });\n    }\n\n    if (typeof opts === 'object' && opts !== null) {\n      if (typeof opts.env === 'object' && opts.env !== null)\n        reqEnv(chan, opts.env);\n      if ((typeof opts.pty === 'object' && opts.pty !== null)\n          || opts.pty === true) {\n        todo.push(function() { reqPty(chan, opts.pty, reqCb); });\n      }\n      if ((typeof opts.x11 === 'object' && opts.x11 !== null)\n          || opts.x11 === 'number'\n          || opts.x11 === true) {\n        todo.push(function() { reqX11(chan, opts.x11, reqCb); });\n      }\n    }\n\n    todo.push(function() { reqExec(chan, cmd, opts, cb); });\n    todo.shift()();\n  });\n};\n\nClient.prototype.shell = function(wndopts, opts, cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  // start an interactive terminal/shell session\n  var self = this;\n\n  if (typeof wndopts === 'function') {\n    cb = wndopts;\n    wndopts = opts = undefined;\n  } else if (typeof opts === 'function') {\n    cb = opts;\n    opts = undefined;\n  }\n  if (wndopts && (wndopts.x11 !== undefined || wndopts.env !== undefined)) {\n    opts = wndopts;\n    wndopts = undefined;\n  }\n\n  return openChannel(this, 'session', function(err, chan) {\n    if (err)\n      return cb(err);\n\n    var todo = [];\n\n    function reqCb(err) {\n      if (err) {\n        chan.close();\n        return cb(err);\n      }\n      if (todo.length)\n        todo.shift()();\n    }\n\n    if (self.config.allowAgentFwd === true\n        || (opts\n            && opts.agentForward === true\n            && self.config.agent !== undefined)) {\n      todo.push(function() { reqAgentFwd(chan, reqCb); });\n    }\n\n    if (wndopts !== false)\n      todo.push(function() { reqPty(chan, wndopts, reqCb); });\n\n    if (typeof opts === 'object' && opts !== null) {\n      if (typeof opts.env === 'object' && opts.env !== null)\n        reqEnv(chan, opts.env);\n      if ((typeof opts.x11 === 'object' && opts.x11 !== null)\n          || opts.x11 === 'number'\n          || opts.x11 === true) {\n        todo.push(function() { reqX11(chan, opts.x11, reqCb); });\n      }\n    }\n\n    todo.push(function() { reqShell(chan, cb); });\n    todo.shift()();\n  });\n};\n\nClient.prototype.subsys = function(name, cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n\treturn openChannel(this, 'session', function(err, chan) {\n\t\tif (err)\n\t\t\treturn cb(err);\n\n\t\treqSubsystem(chan, name, function(err, stream) {\n\t\t\tif (err)\n\t\t\t\treturn cb(err);\n\n\t\t\tcb(undefined, stream);\n\t\t});\n\t});\n};\n\nClient.prototype.sftp = function(cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  var self = this;\n\n  // start an SFTP session\n  return openChannel(this, 'session', function(err, chan) {\n    if (err)\n      return cb(err);\n\n    reqSubsystem(chan, 'sftp', function(err, stream) {\n      if (err)\n        return cb(err);\n\n      var serverIdentRaw = self._sshstream._state.incoming.identRaw;\n      var cfg = { debug: self.config.debug };\n      var sftp = new SFTPStream(cfg, serverIdentRaw);\n\n      function onError(err) {\n        sftp.removeListener('ready', onReady);\n        stream.removeListener('exit', onExit);\n        cb(err);\n      }\n\n      function onReady() {\n        sftp.removeListener('error', onError);\n        stream.removeListener('exit', onExit);\n        cb(undefined, new SFTPWrapper(sftp));\n      }\n\n      function onExit(code, signal) {\n        sftp.removeListener('ready', onReady);\n        sftp.removeListener('error', onError);\n        var msg;\n        if (typeof code === 'number') {\n          msg = 'Received exit code '\n                + code\n                + ' while establishing SFTP session';\n        } else {\n          msg = 'Received signal '\n                + signal\n                + ' while establishing SFTP session';\n        }\n        var err = new Error(msg);\n        err.code = code;\n        err.signal = signal;\n        cb(err);\n      }\n\n      sftp.once('error', onError)\n          .once('ready', onReady)\n          .once('close', function() {\n            stream.end();\n          });\n\n      // OpenSSH server sends an exit-status if there was a problem spinning up\n      // an sftp server child process, so we listen for that here in order to\n      // properly raise an error.\n      stream.once('exit', onExit);\n\n      sftp.pipe(stream).pipe(sftp);\n    });\n  });\n};\n\nClient.prototype.forwardIn = function(bindAddr, bindPort, cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  // send a request for the server to start forwarding TCP connections to us\n  // on a particular address and port\n\n  var self = this;\n  var wantReply = (typeof cb === 'function');\n\n  if (wantReply) {\n    this._callbacks.push(function(had_err, data) {\n      if (had_err) {\n        return cb(had_err !== true\n                  ? had_err\n                  : new Error('Unable to bind to ' + bindAddr + ':' + bindPort));\n      }\n\n      var realPort = bindPort;\n      if (bindPort === 0 && data && data.length >= 4) {\n        realPort = readUInt32BE(data, 0);\n        if (!(self._sshstream.remoteBugs & BUGS.DYN_RPORT_BUG))\n          bindPort = realPort;\n      }\n\n      self._forwarding[bindAddr + ':' + bindPort] = realPort;\n\n      cb(undefined, realPort);\n    });\n  }\n\n  return this._sshstream.tcpipForward(bindAddr, bindPort, wantReply);\n};\n\nClient.prototype.unforwardIn = function(bindAddr, bindPort, cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  // send a request to stop forwarding us new connections for a particular\n  // address and port\n\n  var self = this;\n  var wantReply = (typeof cb === 'function');\n\n  if (wantReply) {\n    this._callbacks.push(function(had_err) {\n      if (had_err) {\n        return cb(had_err !== true\n                  ? had_err\n                  : new Error('Unable to unbind from '\n                              + bindAddr + ':' + bindPort));\n      }\n\n      delete self._forwarding[bindAddr + ':' + bindPort];\n\n      cb();\n    });\n  }\n\n  return this._sshstream.cancelTcpipForward(bindAddr, bindPort, wantReply);\n};\n\nClient.prototype.forwardOut = function(srcIP, srcPort, dstIP, dstPort, cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  // send a request to forward a TCP connection to the server\n\n  var cfg = {\n    srcIP: srcIP,\n    srcPort: srcPort,\n    dstIP: dstIP,\n    dstPort: dstPort\n  };\n\n  return openChannel(this, 'direct-tcpip', cfg, cb);\n};\n\nClient.prototype.openssh_noMoreSessions = function(cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  var wantReply = (typeof cb === 'function');\n\n  if (!this.config.strictVendor\n      || (this.config.strictVendor && RE_OPENSSH.test(this._remoteVer))) {\n    if (wantReply) {\n      this._callbacks.push(function(had_err) {\n        if (had_err) {\n          return cb(had_err !== true\n                    ? had_err\n                    : new Error('Unable to disable future sessions'));\n        }\n\n        cb();\n      });\n    }\n\n    return this._sshstream.openssh_noMoreSessions(wantReply);\n  } else if (wantReply) {\n    process.nextTick(function() {\n      cb(new Error('strictVendor enabled and server is not OpenSSH or compatible version'));\n    });\n  }\n\n  return true;\n};\n\nClient.prototype.openssh_forwardInStreamLocal = function(socketPath, cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  var wantReply = (typeof cb === 'function');\n  var self = this;\n\n  if (!this.config.strictVendor\n      || (this.config.strictVendor && RE_OPENSSH.test(this._remoteVer))) {\n    if (wantReply) {\n      this._callbacks.push(function(had_err) {\n        if (had_err) {\n          return cb(had_err !== true\n                    ? had_err\n                    : new Error('Unable to bind to ' + socketPath));\n        }\n        self._forwardingUnix[socketPath] = true;\n        cb();\n      });\n    }\n\n    return this._sshstream.openssh_streamLocalForward(socketPath, wantReply);\n  } else if (wantReply) {\n    process.nextTick(function() {\n      cb(new Error('strictVendor enabled and server is not OpenSSH or compatible version'));\n    });\n  }\n\n  return true;\n};\n\nClient.prototype.openssh_unforwardInStreamLocal = function(socketPath, cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  var wantReply = (typeof cb === 'function');\n  var self = this;\n\n  if (!this.config.strictVendor\n      || (this.config.strictVendor && RE_OPENSSH.test(this._remoteVer))) {\n    if (wantReply) {\n      this._callbacks.push(function(had_err) {\n        if (had_err) {\n          return cb(had_err !== true\n                    ? had_err\n                    : new Error('Unable to unbind on ' + socketPath));\n        }\n        delete self._forwardingUnix[socketPath];\n        cb();\n      });\n    }\n\n    return this._sshstream.openssh_cancelStreamLocalForward(socketPath,\n                                                            wantReply);\n  } else if (wantReply) {\n    process.nextTick(function() {\n      cb(new Error('strictVendor enabled and server is not OpenSSH or compatible version'));\n    });\n  }\n\n  return true;\n};\n\nClient.prototype.openssh_forwardOutStreamLocal = function(socketPath, cb) {\n  if (!this._sock\n      || !this._sock.writable\n      || !this._sshstream\n      || !this._sshstream.writable)\n    throw new Error('Not connected');\n\n  if (!this.config.strictVendor\n      || (this.config.strictVendor && RE_OPENSSH.test(this._remoteVer))) {\n    var cfg = { socketPath: socketPath };\n    return openChannel(this, 'direct-streamlocal@openssh.com', cfg, cb);\n  } else {\n    process.nextTick(function() {\n      cb(new Error('strictVendor enabled and server is not OpenSSH or compatible version'));\n    });\n  }\n\n  return true;\n};\n\nfunction openChannel(self, type, opts, cb) {\n  // ask the server to open a channel for some purpose\n  // (e.g. session (sftp, exec, shell), or forwarding a TCP connection\n  var localChan = nextChannel(self);\n  var initWindow = Channel.MAX_WINDOW;\n  var maxPacket = Channel.PACKET_SIZE;\n  var ret = true;\n\n  if (localChan === false)\n    return cb(new Error('No free channels available'));\n\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n\n  self._channels[localChan] = cb;\n\n  var sshstream = self._sshstream;\n  sshstream.once('CHANNEL_OPEN_CONFIRMATION:' + localChan, onSuccess)\n           .once('CHANNEL_OPEN_FAILURE:' + localChan, onFailure)\n           .once('CHANNEL_CLOSE:' + localChan, onFailure);\n\n  if (type === 'session')\n    ret = sshstream.session(localChan, initWindow, maxPacket);\n  else if (type === 'direct-tcpip')\n    ret = sshstream.directTcpip(localChan, initWindow, maxPacket, opts);\n  else if (type === 'direct-streamlocal@openssh.com') {\n    ret = sshstream.openssh_directStreamLocal(localChan,\n                                              initWindow,\n                                              maxPacket,\n                                              opts);\n  }\n\n  return ret;\n\n  function onSuccess(info) {\n    sshstream.removeListener('CHANNEL_OPEN_FAILURE:' + localChan, onFailure);\n    sshstream.removeListener('CHANNEL_CLOSE:' + localChan, onFailure);\n\n    var chaninfo = {\n      type: type,\n      incoming: {\n        id: localChan,\n        window: initWindow,\n        packetSize: maxPacket,\n        state: 'open'\n      },\n      outgoing: {\n        id: info.sender,\n        window: info.window,\n        packetSize: info.packetSize,\n        state: 'open'\n      }\n    };\n    cb(undefined, new Channel(chaninfo, self));\n  }\n\n  function onFailure(info) {\n    sshstream.removeListener('CHANNEL_OPEN_CONFIRMATION:' + localChan,\n                             onSuccess);\n    sshstream.removeListener('CHANNEL_OPEN_FAILURE:' + localChan, onFailure);\n    sshstream.removeListener('CHANNEL_CLOSE:' + localChan, onFailure);\n\n    delete self._channels[localChan];\n\n    var err;\n    if (info instanceof Error)\n      err = info;\n    else if (typeof info === 'object' && info !== null) {\n      err = new Error('(SSH) Channel open failure: ' + info.description);\n      err.reason = info.reason;\n      err.lang = info.lang;\n    } else {\n      err = new Error('(SSH) Channel open failure: '\n                      + 'server closed channel unexpectedly');\n      err.reason = err.lang = '';\n    }\n    cb(err);\n  }\n}\n\nfunction nextChannel(self) {\n  // get the next available channel number\n\n  // optimized path\n  if (self._curChan < MAX_CHANNEL)\n    return ++self._curChan;\n\n  // slower lookup path\n  for (var i = 0, channels = self._channels; i < MAX_CHANNEL; ++i)\n    if (!channels[i])\n      return i;\n\n  return false;\n}\n\nfunction reqX11(chan, screen, cb) {\n  // asks server to start sending us X11 connections\n  var cfg = {\n    single: false,\n    protocol: 'MIT-MAGIC-COOKIE-1',\n    cookie: undefined,\n    screen: 0\n  };\n\n  if (typeof screen === 'function') {\n    cb = screen;\n  } else if (typeof screen === 'object' && screen !== null) {\n    if (typeof screen.single === 'boolean')\n      cfg.single = screen.single;\n    if (typeof screen.screen === 'number')\n      cfg.screen = screen.screen;\n    if (typeof screen.protocol === 'string')\n      cfg.protocol = screen.protocol;\n    if (typeof screen.cookie === 'string')\n      cfg.cookie = screen.cookie;\n    else if (Buffer.isBuffer(screen.cookie))\n      cfg.cookie = screen.cookie.toString('hex');\n  }\n  if (cfg.cookie === undefined)\n    cfg.cookie = randomCookie();\n\n  var wantReply = (typeof cb === 'function');\n\n  if (chan.outgoing.state !== 'open') {\n    wantReply && cb(new Error('Channel is not open'));\n    return true;\n  }\n\n  if (wantReply) {\n    chan._callbacks.push(function(had_err) {\n      if (had_err) {\n        return cb(had_err !== true\n                  ? had_err\n                  : new Error('Unable to request X11'));\n      }\n\n      chan._hasX11 = true;\n      ++chan._client._acceptX11;\n      chan.once('close', function() {\n        if (chan._client._acceptX11)\n          --chan._client._acceptX11;\n      });\n\n      cb();\n    });\n  }\n\n  return chan._client._sshstream.x11Forward(chan.outgoing.id, cfg, wantReply);\n}\n\nfunction reqPty(chan, opts, cb) {\n  var rows = 24;\n  var cols = 80;\n  var width = 640;\n  var height = 480;\n  var term = 'vt100';\n  var modes = null;\n\n  if (typeof opts === 'function')\n    cb = opts;\n  else if (typeof opts === 'object' && opts !== null) {\n    if (typeof opts.rows === 'number')\n      rows = opts.rows;\n    if (typeof opts.cols === 'number')\n      cols = opts.cols;\n    if (typeof opts.width === 'number')\n      width = opts.width;\n    if (typeof opts.height === 'number')\n      height = opts.height;\n    if (typeof opts.term === 'string')\n      term = opts.term;\n    if (typeof opts.modes === 'object')\n      modes = opts.modes;\n  }\n\n  var wantReply = (typeof cb === 'function');\n\n  if (chan.outgoing.state !== 'open') {\n    wantReply && cb(new Error('Channel is not open'));\n    return true;\n  }\n\n  if (wantReply) {\n    chan._callbacks.push(function(had_err) {\n      if (had_err) {\n        return cb(had_err !== true\n                  ? had_err\n                  : new Error('Unable to request a pseudo-terminal'));\n      }\n      cb();\n    });\n  }\n\n  return chan._client._sshstream.pty(chan.outgoing.id,\n                                     rows,\n                                     cols,\n                                     height,\n                                     width,\n                                     term,\n                                     modes,\n                                     wantReply);\n}\n\nfunction reqAgentFwd(chan, cb) {\n  var wantReply = (typeof cb === 'function');\n\n  if (chan.outgoing.state !== 'open') {\n    wantReply && cb(new Error('Channel is not open'));\n    return true;\n  } else if (chan._client._agentFwdEnabled) {\n    wantReply && cb(false);\n    return true;\n  }\n\n  chan._client._agentFwdEnabled = true;\n\n  chan._callbacks.push(function(had_err) {\n    if (had_err) {\n      chan._client._agentFwdEnabled = false;\n      wantReply && cb(had_err !== true\n                      ? had_err\n                      : new Error('Unable to request agent forwarding'));\n      return;\n    }\n\n    wantReply && cb();\n  });\n\n  return chan._client._sshstream.openssh_agentForward(chan.outgoing.id, true);\n}\n\nfunction reqShell(chan, cb) {\n  if (chan.outgoing.state !== 'open') {\n    cb(new Error('Channel is not open'));\n    return true;\n  }\n  chan._callbacks.push(function(had_err) {\n    if (had_err) {\n      return cb(had_err !== true\n                ? had_err\n                : new Error('Unable to open shell'));\n    }\n    chan.subtype = 'shell';\n    cb(undefined, chan);\n  });\n\n  return chan._client._sshstream.shell(chan.outgoing.id, true);\n}\n\nfunction reqExec(chan, cmd, opts, cb) {\n  if (chan.outgoing.state !== 'open') {\n    cb(new Error('Channel is not open'));\n    return true;\n  }\n  chan._callbacks.push(function(had_err) {\n    if (had_err) {\n      return cb(had_err !== true\n                ? had_err\n                : new Error('Unable to exec'));\n    }\n    chan.subtype = 'exec';\n    chan.allowHalfOpen = (opts.allowHalfOpen !== false);\n    cb(undefined, chan);\n  });\n\n  return chan._client._sshstream.exec(chan.outgoing.id, cmd, true);\n}\n\nfunction reqEnv(chan, env) {\n  if (chan.outgoing.state !== 'open')\n    return true;\n  var ret = true;\n  var keys = Object.keys(env || {});\n  var key;\n  var val;\n\n  for (var i = 0, len = keys.length; i < len; ++i) {\n    key = keys[i];\n    val = env[key];\n    ret = chan._client._sshstream.env(chan.outgoing.id, key, val, false);\n  }\n\n  return ret;\n}\n\nfunction reqSubsystem(chan, name, cb) {\n  if (chan.outgoing.state !== 'open') {\n    cb(new Error('Channel is not open'));\n    return true;\n  }\n  chan._callbacks.push(function(had_err) {\n    if (had_err) {\n      return cb(had_err !== true\n                ? had_err\n                : new Error('Unable to start subsystem: ' + name));\n    }\n    chan.subtype = 'subsystem';\n    cb(undefined, chan);\n  });\n\n  return chan._client._sshstream.subsystem(chan.outgoing.id, name, true);\n}\n\nfunction onCHANNEL_OPEN(self, info) {\n  // the server is trying to open a channel with us, this is usually when\n  // we asked the server to forward us connections on some port and now they\n  // are asking us to accept/deny an incoming connection on their side\n\n  var localChan = false;\n  var reason;\n\n  function accept() {\n    var chaninfo = {\n      type: info.type,\n      incoming: {\n        id: localChan,\n        window: Channel.MAX_WINDOW,\n        packetSize: Channel.PACKET_SIZE,\n        state: 'open'\n      },\n      outgoing: {\n        id: info.sender,\n        window: info.window,\n        packetSize: info.packetSize,\n        state: 'open'\n      }\n    };\n    var stream = new Channel(chaninfo, self);\n\n    self._sshstream.channelOpenConfirm(info.sender,\n                                       localChan,\n                                       Channel.MAX_WINDOW,\n                                       Channel.PACKET_SIZE);\n    return stream;\n  }\n  function reject() {\n    if (reason === undefined) {\n      if (localChan === false)\n        reason = consts.CHANNEL_OPEN_FAILURE.RESOURCE_SHORTAGE;\n      else\n        reason = consts.CHANNEL_OPEN_FAILURE.CONNECT_FAILED;\n    }\n\n    self._sshstream.channelOpenFail(info.sender, reason, '', '');\n  }\n\n  if (info.type === 'forwarded-tcpip'\n      || info.type === 'x11'\n      || info.type === 'auth-agent@openssh.com'\n      || info.type === 'forwarded-streamlocal@openssh.com') {\n\n    // check for conditions for automatic rejection\n    var rejectConn = (\n     (info.type === 'forwarded-tcpip'\n      && self._forwarding[info.data.destIP\n                         + ':'\n                         + info.data.destPort] === undefined)\n     || (info.type === 'forwarded-streamlocal@openssh.com'\n         && self._forwardingUnix[info.data.socketPath] === undefined)\n     || (info.type === 'x11' && self._acceptX11 === 0)\n     || (info.type === 'auth-agent@openssh.com'\n         && !self._agentFwdEnabled)\n    );\n\n    if (!rejectConn) {\n      localChan = nextChannel(self);\n\n      if (localChan === false) {\n        self.config.debug('DEBUG: Client: Automatic rejection of incoming channel open: no channels available');\n        rejectConn = true;\n      } else\n        self._channels[localChan] = true;\n    } else {\n      reason = consts.CHANNEL_OPEN_FAILURE.ADMINISTRATIVELY_PROHIBITED;\n      self.config.debug('DEBUG: Client: Automatic rejection of incoming channel open: unexpected channel open for: '\n                        + info.type);\n    }\n\n    // TODO: automatic rejection after some timeout?\n\n    if (rejectConn)\n      reject();\n\n    if (localChan !== false) {\n      if (info.type === 'forwarded-tcpip') {\n        if (info.data.destPort === 0) {\n          info.data.destPort = self._forwarding[info.data.destIP\n                                                + ':'\n                                                + info.data.destPort];\n        }\n        self.emit('tcp connection', info.data, accept, reject);\n      } else if (info.type === 'x11') {\n        self.emit('x11', info.data, accept, reject);\n      } else if (info.type === 'forwarded-streamlocal@openssh.com') {\n        self.emit('unix connection', info.data, accept, reject);\n      } else {\n        agentQuery(self.config.agent, accept, reject);\n      }\n    }\n  } else {\n    // automatically reject any unsupported channel open requests\n    self.config.debug('DEBUG: Client: Automatic rejection of incoming channel open: unsupported type: '\n                      + info.type);\n    reason = consts.CHANNEL_OPEN_FAILURE.UNKNOWN_CHANNEL_TYPE;\n    reject();\n  }\n}\n\nvar randomCookie = (function() {\n  if (typeof crypto.randomFillSync === 'function') {\n    var buffer = Buffer.alloc(16);\n    return function randomCookie() {\n      crypto.randomFillSync(buffer, 0, 16);\n      return buffer.toString('hex');\n    };\n  } else {\n    return function randomCookie() {\n      return crypto.randomBytes(16).toString('hex');\n    };\n  }\n})();\n\nClient.Client = Client;\nClient.Server = __webpack_require__(/*! ./server */ \"./node_modules/ssh2/lib/server.js\");\n// pass some useful utilities on to end user (e.g. parseKey())\nClient.utils = ssh2_streams.utils;\n// expose useful SFTPStream constants for sftp server usage\nClient.SFTP_STATUS_CODE = SFTPStream.STATUS_CODE;\nClient.SFTP_OPEN_MODE = SFTPStream.OPEN_MODE;\n// expose http(s).Agent implementations to allow easy tunneling of HTTP(S)\n// requests\nClient.HTTPAgent = HTTPAgents.SSHTTPAgent;\nClient.HTTPSAgent = HTTPAgents.SSHTTPSAgent;\n\nmodule.exports = Client; // backwards compatibility\n\n\n//# sourceURL=webpack:///./node_modules/ssh2/lib/client.js?");

/***/ }),

/***/ "./node_modules/ssh2/lib/http-agents.js":
/*!**********************************************!*\
  !*** ./node_modules/ssh2/lib/http-agents.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var HttpAgent = __webpack_require__(/*! http */ \"http\").Agent;\nvar HttpsAgent = __webpack_require__(/*! https */ \"https\").Agent;\nvar inherits = __webpack_require__(/*! util */ \"util\").inherits;\n\nvar Client;\n\n[HttpAgent, HttpsAgent].forEach((ctor) => {\n  function SSHAgent(connectCfg, agentOptions) {\n    if (!(this instanceof SSHAgent))\n      return new SSHAgent(connectCfg, agentOptions);\n\n    ctor.call(this, agentOptions);\n\n    this._connectCfg = connectCfg;\n    this._defaultSrcIP = (agentOptions && agentOptions.srcIP) || 'localhost';\n  }\n  inherits(SSHAgent, ctor);\n\n  SSHAgent.prototype.createConnection = createConnection;\n\n  exports[ctor === HttpAgent ? 'SSHTTPAgent' : 'SSHTTPSAgent'] = SSHAgent;\n});\n\nfunction createConnection(options, cb) {\n  var srcIP = (options && options.localAddress) || this._defaultSrcIP;\n  var srcPort = (options && options.localPort) || 0;\n  var dstIP = options.host;\n  var dstPort = options.port;\n\n  if (Client === undefined)\n    Client = __webpack_require__(/*! ./client */ \"./node_modules/ssh2/lib/client.js\").Client;\n\n  var client = new Client();\n  var triedForward = false;\n  client.on('ready', () => {\n    client.forwardOut(srcIP, srcPort, dstIP, dstPort, (err, stream) => {\n      triedForward = true;\n      if (err) {\n        client.end();\n        return cb(err);\n      }\n      stream.once('close', () => {\n        client.end();\n      });\n      cb(null, decorateStream(stream));\n    });\n  }).on('error', cb).on('close', () => {\n    if (!triedForward)\n      cb(new Error('Unexpected connection loss'));\n  }).connect(this._connectCfg);\n}\n\nfunction noop() {}\n\nfunction decorateStream(stream) {\n  stream.setKeepAlive = noop;\n  stream.setNoDelay = noop;\n  stream.setTimeout = noop;\n  stream.ref = noop;\n  stream.unref = noop;\n  stream.destroySoon = stream.destroy;\n  return stream;\n}\n\n\n//# sourceURL=webpack:///./node_modules/ssh2/lib/http-agents.js?");

/***/ }),

/***/ "./node_modules/ssh2/lib/keepalivemgr.js":
/*!***********************************************!*\
  !*** ./node_modules/ssh2/lib/keepalivemgr.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("function spliceOne(list, index) {\n  for (var i = index, k = i + 1, n = list.length; k < n; i += 1, k += 1)\n    list[i] = list[k];\n  list.pop();\n}\n\nfunction Manager(interval, streamInterval, kaCountMax) {\n  var streams = this._streams = [];\n  this._timer = undefined;\n  this._timerInterval = interval;\n  this._timerfn = function() {\n    var now = Date.now();\n    for (var i = 0, len = streams.length, s, last; i < len; ++i) {\n      s = streams[i];\n      last = s._kalast;\n      if (last && (now - last) >= streamInterval) {\n        if (++s._kacnt > kaCountMax) {\n          var err = new Error('Keepalive timeout');\n          err.level = 'client-timeout';\n          s.emit('error', err);\n          s.disconnect();\n          spliceOne(streams, i);\n          --i;\n          len = streams.length;\n        } else {\n          s._kalast = now;\n          // XXX: if the server ever starts sending real global requests to the\n          //      client, we will need to add a dummy callback here to keep the\n          //      correct reply order\n          s.ping();\n        }\n      }\n    }\n  };\n}\n\nManager.prototype.start = function() {\n  if (this._timer)\n    this.stop();\n  this._timer = setInterval(this._timerfn, this._timerInterval);\n};\n\nManager.prototype.stop = function() {\n  if (this._timer) {\n    clearInterval(this._timer);\n    this._timer = undefined;\n  }\n};\n\nManager.prototype.add = function(stream) {\n  var streams = this._streams,\n      self = this;\n\n  stream.once('end', function() {\n    self.remove(stream);\n  }).on('packet', resetKA);\n\n  streams[streams.length] = stream;\n\n  resetKA();\n\n  if (!this._timer)\n    this.start();\n\n  function resetKA() {\n    stream._kalast = Date.now();\n    stream._kacnt = 0;\n  }\n};\n\nManager.prototype.remove = function(stream) {\n  var streams = this._streams,\n      index = streams.indexOf(stream);\n  if (index > -1)\n    spliceOne(streams, index);\n  if (!streams.length)\n    this.stop();\n};\n\nmodule.exports = Manager;\n\n\n//# sourceURL=webpack:///./node_modules/ssh2/lib/keepalivemgr.js?");

/***/ }),

/***/ "./node_modules/ssh2/lib/server.js":
/*!*****************************************!*\
  !*** ./node_modules/ssh2/lib/server.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var net = __webpack_require__(/*! net */ \"net\");\nvar EventEmitter = __webpack_require__(/*! events */ \"events\").EventEmitter;\nvar listenerCount = EventEmitter.listenerCount;\nvar inherits = __webpack_require__(/*! util */ \"util\").inherits;\n\nvar ssh2_streams = __webpack_require__(/*! ssh2-streams */ \"./node_modules/ssh2-streams/index.js\");\nvar parseKey = ssh2_streams.utils.parseKey;\nvar SSH2Stream = ssh2_streams.SSH2Stream;\nvar SFTPStream = ssh2_streams.SFTPStream;\nvar consts = ssh2_streams.constants;\nvar DISCONNECT_REASON = consts.DISCONNECT_REASON;\nvar CHANNEL_OPEN_FAILURE = consts.CHANNEL_OPEN_FAILURE;\nvar ALGORITHMS = consts.ALGORITHMS;\n\nvar Channel = __webpack_require__(/*! ./Channel */ \"./node_modules/ssh2/lib/Channel.js\");\nvar KeepaliveManager = __webpack_require__(/*! ./keepalivemgr */ \"./node_modules/ssh2/lib/keepalivemgr.js\");\nvar writeUInt32BE = __webpack_require__(/*! ./buffer-helpers */ \"./node_modules/ssh2/lib/buffer-helpers.js\").writeUInt32BE;\n\nvar MAX_CHANNEL = Math.pow(2, 32) - 1;\nvar MAX_PENDING_AUTHS = 10;\n\nvar kaMgr;\n\nfunction Server(cfg, listener) {\n  if (!(this instanceof Server))\n    return new Server(cfg, listener);\n\n  var hostKeys = {\n    'ssh-rsa': null,\n    'ssh-dss': null,\n    'ssh-ed25519': null,\n    'ecdsa-sha2-nistp256': null,\n    'ecdsa-sha2-nistp384': null,\n    'ecdsa-sha2-nistp521': null\n  };\n\n  var hostKeys_ = cfg.hostKeys;\n  if (!Array.isArray(hostKeys_))\n    throw new Error('hostKeys must be an array');\n\n  var i;\n  for (i = 0; i < hostKeys_.length; ++i) {\n    var privateKey;\n    if (Buffer.isBuffer(hostKeys_[i]) || typeof hostKeys_[i] === 'string')\n      privateKey = parseKey(hostKeys_[i]);\n    else\n      privateKey = parseKey(hostKeys_[i].key, hostKeys_[i].passphrase);\n    if (privateKey instanceof Error)\n      throw new Error('Cannot parse privateKey: ' + privateKey.message);\n    if (Array.isArray(privateKey))\n      privateKey = privateKey[0]; // OpenSSH's newer format only stores 1 key for now\n    if (privateKey.getPrivatePEM() === null)\n      throw new Error('privateKey value contains an invalid private key');\n    if (hostKeys[privateKey.type])\n      continue;\n    hostKeys[privateKey.type] = privateKey;\n  }\n\n  var algorithms = {\n    kex: undefined,\n    kexBuf: undefined,\n    cipher: undefined,\n    cipherBuf: undefined,\n    serverHostKey: undefined,\n    serverHostKeyBuf: undefined,\n    hmac: undefined,\n    hmacBuf: undefined,\n    compress: undefined,\n    compressBuf: undefined\n  };\n  if (typeof cfg.algorithms === 'object' && cfg.algorithms !== null) {\n    var algosSupported;\n    var algoList;\n\n    algoList = cfg.algorithms.kex;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_KEX;\n      for (i = 0; i < algoList.length; ++i) {\n        if (algosSupported.indexOf(algoList[i]) === -1)\n          throw new Error('Unsupported key exchange algorithm: ' + algoList[i]);\n      }\n      algorithms.kex = algoList;\n    }\n\n    algoList = cfg.algorithms.cipher;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_CIPHER;\n      for (i = 0; i < algoList.length; ++i) {\n        if (algosSupported.indexOf(algoList[i]) === -1)\n          throw new Error('Unsupported cipher algorithm: ' + algoList[i]);\n      }\n      algorithms.cipher = algoList;\n    }\n\n    algoList = cfg.algorithms.serverHostKey;\n    var copied = false;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_SERVER_HOST_KEY;\n      for (i = algoList.length - 1; i >= 0; --i) {\n        if (algosSupported.indexOf(algoList[i]) === -1) {\n          throw new Error('Unsupported server host key algorithm: '\n                           + algoList[i]);\n        }\n        if (!hostKeys[algoList[i]]) {\n          // Silently discard for now\n          if (!copied) {\n            algoList = algoList.slice();\n            copied = true;\n          }\n          algoList.splice(i, 1);\n        }\n      }\n      if (algoList.length > 0)\n        algorithms.serverHostKey = algoList;\n    }\n\n    algoList = cfg.algorithms.hmac;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_HMAC;\n      for (i = 0; i < algoList.length; ++i) {\n        if (algosSupported.indexOf(algoList[i]) === -1)\n          throw new Error('Unsupported HMAC algorithm: ' + algoList[i]);\n      }\n      algorithms.hmac = algoList;\n    }\n\n    algoList = cfg.algorithms.compress;\n    if (Array.isArray(algoList) && algoList.length > 0) {\n      algosSupported = ALGORITHMS.SUPPORTED_COMPRESS;\n      for (i = 0; i < algoList.length; ++i) {\n        if (algosSupported.indexOf(algoList[i]) === -1)\n          throw new Error('Unsupported compression algorithm: ' + algoList[i]);\n      }\n      algorithms.compress = algoList;\n    }\n  }\n\n  // Make sure we at least have some kind of valid list of support key\n  // formats\n  if (algorithms.serverHostKey === undefined) {\n    var hostKeyAlgos = Object.keys(hostKeys);\n    for (i = hostKeyAlgos.length - 1; i >= 0; --i) {\n      if (!hostKeys[hostKeyAlgos[i]])\n        hostKeyAlgos.splice(i, 1);\n    }\n    algorithms.serverHostKey = hostKeyAlgos;\n  }\n\n  if (!kaMgr\n      && Server.KEEPALIVE_INTERVAL > 0\n      && Server.KEEPALIVE_CLIENT_INTERVAL > 0\n      && Server.KEEPALIVE_CLIENT_COUNT_MAX >= 0) {\n    kaMgr = new KeepaliveManager(Server.KEEPALIVE_INTERVAL,\n                                 Server.KEEPALIVE_CLIENT_INTERVAL,\n                                 Server.KEEPALIVE_CLIENT_COUNT_MAX);\n  }\n\n  var self = this;\n\n  EventEmitter.call(this);\n\n  if (typeof listener === 'function')\n    self.on('connection', listener);\n\n  var streamcfg = {\n    algorithms: algorithms,\n    hostKeys: hostKeys,\n    server: true\n  };\n  var keys;\n  var len;\n  for (i = 0, keys = Object.keys(cfg), len = keys.length; i < len; ++i) {\n    var key = keys[i];\n    if (key === 'privateKey'\n        || key === 'publicKey'\n        || key === 'passphrase'\n        || key === 'algorithms'\n        || key === 'hostKeys'\n        || key === 'server') {\n      continue;\n    }\n    streamcfg[key] = cfg[key];\n  }\n\n  if (typeof streamcfg.debug === 'function') {\n    var oldDebug = streamcfg.debug;\n    var cfgKeys = Object.keys(streamcfg);\n  }\n\n  this._srv = new net.Server(function(socket) {\n    if (self._connections >= self.maxConnections) {\n      socket.destroy();\n      return;\n    }\n    ++self._connections;\n    socket.once('close', function(had_err) {\n      --self._connections;\n\n      // since joyent/node#993bb93e0a, we have to \"read past EOF\" in order to\n      // get an `end` event on streams. thankfully adding this does not\n      // negatively affect node versions pre-joyent/node#993bb93e0a.\n      sshstream.read();\n    }).on('error', function(err) {\n      sshstream.reset();\n      sshstream.emit('error', err);\n    });\n\n    var conncfg = streamcfg;\n\n    // prepend debug output with a unique identifier in case there are multiple\n    // clients connected at the same time\n    if (oldDebug) {\n      conncfg = {};\n      for (var i = 0, key; i < cfgKeys.length; ++i) {\n        key = cfgKeys[i];\n        conncfg[key] = streamcfg[key];\n      }\n      var debugPrefix = '[' + process.hrtime().join('.') + '] ';\n      conncfg.debug = function(msg) {\n        oldDebug(debugPrefix + msg);\n      };\n    }\n\n    var sshstream = new SSH2Stream(conncfg);\n    var client = new Client(sshstream, socket);\n\n    socket.pipe(sshstream).pipe(socket);\n\n    // silence pre-header errors\n    function onClientPreHeaderError(err) {}\n    client.on('error', onClientPreHeaderError);\n\n    sshstream.once('header', function(header) {\n      if (sshstream._readableState.ended) {\n        // already disconnected internally in SSH2Stream due to incompatible\n        // protocol version\n        return;\n      } else if (!listenerCount(self, 'connection')) {\n        // auto reject\n        return sshstream.disconnect(DISCONNECT_REASON.BY_APPLICATION);\n      }\n\n      client.removeListener('error', onClientPreHeaderError);\n\n      self.emit('connection',\n                client,\n                { ip: socket.remoteAddress,\n                  family: socket.remoteFamily,\n                  port: socket.remotePort,\n                  header: header });\n    });\n  }).on('error', function(err) {\n    self.emit('error', err);\n  }).on('listening', function() {\n    self.emit('listening');\n  }).on('close', function() {\n    self.emit('close');\n  });\n  this._connections = 0;\n  this.maxConnections = Infinity;\n}\ninherits(Server, EventEmitter);\n\nServer.prototype.listen = function() {\n  this._srv.listen.apply(this._srv, arguments);\n  return this;\n};\n\nServer.prototype.address = function() {\n  return this._srv.address();\n};\n\nServer.prototype.getConnections = function(cb) {\n  this._srv.getConnections(cb);\n};\n\nServer.prototype.close = function(cb) {\n  this._srv.close(cb);\n  return this;\n};\n\nServer.prototype.ref = function() {\n  this._srv.ref();\n};\n\nServer.prototype.unref = function() {\n  this._srv.unref();\n};\n\n\nfunction Client(stream, socket) {\n  EventEmitter.call(this);\n\n  var self = this;\n\n  this._sshstream = stream;\n  var channels = this._channels = {};\n  this._curChan = -1;\n  this._sock = socket;\n  this.noMoreSessions = false;\n  this.authenticated = false;\n\n  stream.on('end', function() {\n    socket.resume();\n    self.emit('end');\n  }).on('close', function(hasErr) {\n    self.emit('close', hasErr);\n  }).on('error', function(err) {\n    self.emit('error', err);\n  }).on('drain', function() {\n    self.emit('drain');\n  }).on('continue', function() {\n    self.emit('continue');\n  });\n\n  var exchanges = 0;\n  var acceptedAuthSvc = false;\n  var pendingAuths = [];\n  var authCtx;\n\n  // begin service/auth-related ================================================\n  stream.on('SERVICE_REQUEST', function(service) {\n    if (exchanges === 0\n        || acceptedAuthSvc\n        || self.authenticated\n        || service !== 'ssh-userauth')\n      return stream.disconnect(DISCONNECT_REASON.SERVICE_NOT_AVAILABLE);\n\n    acceptedAuthSvc = true;\n    stream.serviceAccept(service);\n  }).on('USERAUTH_REQUEST', onUSERAUTH_REQUEST);\n  function onUSERAUTH_REQUEST(username, service, method, methodData) {\n    if (exchanges === 0\n        || (authCtx\n            && (authCtx.username !== username || authCtx.service !== service))\n          // TODO: support hostbased auth\n        || (method !== 'password'\n            && method !== 'publickey'\n            && method !== 'hostbased'\n            && method !== 'keyboard-interactive'\n            && method !== 'none')\n        || pendingAuths.length === MAX_PENDING_AUTHS)\n      return stream.disconnect(DISCONNECT_REASON.PROTOCOL_ERROR);\n    else if (service !== 'ssh-connection')\n      return stream.disconnect(DISCONNECT_REASON.SERVICE_NOT_AVAILABLE);\n\n    // XXX: this really shouldn't be reaching into private state ...\n    stream._state.authMethod = method;\n\n    var ctx;\n    if (method === 'keyboard-interactive') {\n      ctx = new KeyboardAuthContext(stream, username, service, method,\n                                    methodData, onAuthDecide);\n    } else if (method === 'publickey') {\n      ctx = new PKAuthContext(stream, username, service, method, methodData,\n                              onAuthDecide);\n    } else if (method === 'hostbased') {\n      ctx = new HostbasedAuthContext(stream, username, service, method,\n                                     methodData, onAuthDecide);\n    } else if (method === 'password') {\n      ctx = new PwdAuthContext(stream, username, service, method, methodData,\n                               onAuthDecide);\n    } else if (method === 'none')\n      ctx = new AuthContext(stream, username, service, method, onAuthDecide);\n\n    if (authCtx) {\n      if (!authCtx._initialResponse)\n        return pendingAuths.push(ctx);\n      else if (authCtx._multistep && !this._finalResponse) {\n        // RFC 4252 says to silently abort the current auth request if a new\n        // auth request comes in before the final response from an auth method\n        // that requires additional request/response exchanges -- this means\n        // keyboard-interactive for now ...\n        authCtx._cleanup && authCtx._cleanup();\n        authCtx.emit('abort');\n      }\n    }\n\n    authCtx = ctx;\n\n    if (listenerCount(self, 'authentication'))\n      self.emit('authentication', authCtx);\n    else\n      authCtx.reject();\n  }\n  function onAuthDecide(ctx, allowed, methodsLeft, isPartial) {\n    if (authCtx === ctx && !self.authenticated) {\n      if (allowed) {\n        stream.removeListener('USERAUTH_REQUEST', onUSERAUTH_REQUEST);\n        authCtx = undefined;\n        self.authenticated = true;\n        stream.authSuccess();\n        pendingAuths = [];\n        self.emit('ready');\n      } else {\n        stream.authFailure(methodsLeft, isPartial);\n        if (pendingAuths.length) {\n          authCtx = pendingAuths.pop();\n          if (listenerCount(self, 'authentication'))\n            self.emit('authentication', authCtx);\n          else\n            authCtx.reject();\n        }\n      }\n    }\n  }\n  // end service/auth-related ==================================================\n\n  var unsentGlobalRequestsReplies = [];\n\n  function sendReplies() {\n    var reply;\n    while (unsentGlobalRequestsReplies.length > 0\n           && unsentGlobalRequestsReplies[0].type) {\n      reply = unsentGlobalRequestsReplies.shift();\n      if (reply.type === 'SUCCESS')\n        stream.requestSuccess(reply.buf);\n      if (reply.type === 'FAILURE')\n        stream.requestFailure();\n    }\n  }\n\n  stream.on('GLOBAL_REQUEST', function(name, wantReply, data) {\n    var reply = {\n      type: null,\n      buf: null\n    };\n\n    function setReply(type, buf) {\n      reply.type = type;\n      reply.buf = buf;\n      sendReplies();\n    }\n\n    if (wantReply)\n      unsentGlobalRequestsReplies.push(reply);\n\n    if ((name === 'tcpip-forward'\n         || name === 'cancel-tcpip-forward'\n         || name === 'no-more-sessions@openssh.com'\n         || name === 'streamlocal-forward@openssh.com'\n         || name === 'cancel-streamlocal-forward@openssh.com')\n        && listenerCount(self, 'request')\n        && self.authenticated) {\n      var accept;\n      var reject;\n\n      if (wantReply) {\n        var replied = false;\n        accept = function(chosenPort) {\n          if (replied)\n            return;\n          replied = true;\n          var bufPort;\n          if (name === 'tcpip-forward'\n              && data.bindPort === 0\n              && typeof chosenPort === 'number') {\n            bufPort = Buffer.allocUnsafe(4);\n            writeUInt32BE(bufPort, chosenPort, 0);\n          }\n          setReply('SUCCESS', bufPort);\n        };\n        reject = function() {\n          if (replied)\n            return;\n          replied = true;\n          setReply('FAILURE');\n        };\n      }\n\n      if (name === 'no-more-sessions@openssh.com') {\n        self.noMoreSessions = true;\n        accept && accept();\n        return;\n      }\n\n      self.emit('request', accept, reject, name, data);\n    } else if (wantReply)\n      setReply('FAILURE');\n  });\n\n  stream.on('CHANNEL_OPEN', function(info) {\n    // do early reject in some cases to prevent wasteful channel allocation\n    if ((info.type === 'session' && self.noMoreSessions)\n        || !self.authenticated) {\n      var reasonCode = CHANNEL_OPEN_FAILURE.ADMINISTRATIVELY_PROHIBITED;\n      return stream.channelOpenFail(info.sender, reasonCode);\n    }\n\n    var localChan = nextChannel(self);\n    var accept;\n    var reject;\n    var replied = false;\n    if (localChan === false) {\n      // auto-reject due to no channels available\n      return stream.channelOpenFail(info.sender,\n                                    CHANNEL_OPEN_FAILURE.RESOURCE_SHORTAGE);\n    }\n\n    // be optimistic, reserve channel to prevent another request from trying to\n    // take the same channel\n    channels[localChan] = true;\n\n    reject = function() {\n      if (replied)\n        return;\n\n      replied = true;\n\n      delete channels[localChan];\n\n      var reasonCode = CHANNEL_OPEN_FAILURE.ADMINISTRATIVELY_PROHIBITED;\n      return stream.channelOpenFail(info.sender, reasonCode);\n    };\n\n    switch (info.type) {\n      case 'session':\n        if (listenerCount(self, 'session')) {\n          accept = function() {\n            if (replied)\n              return;\n\n            replied = true;\n\n            stream.channelOpenConfirm(info.sender,\n                                      localChan,\n                                      Channel.MAX_WINDOW,\n                                      Channel.PACKET_SIZE);\n\n            return new Session(self, info, localChan);\n          };\n\n          self.emit('session', accept, reject);\n        } else\n          reject();\n      break;\n      case 'direct-tcpip':\n        if (listenerCount(self, 'tcpip')) {\n          accept = function() {\n            if (replied)\n              return;\n\n            replied = true;\n\n            stream.channelOpenConfirm(info.sender,\n                                      localChan,\n                                      Channel.MAX_WINDOW,\n                                      Channel.PACKET_SIZE);\n\n            var chaninfo = {\n              type: undefined,\n              incoming: {\n                id: localChan,\n                window: Channel.MAX_WINDOW,\n                packetSize: Channel.PACKET_SIZE,\n                state: 'open'\n              },\n              outgoing: {\n                id: info.sender,\n                window: info.window,\n                packetSize: info.packetSize,\n                state: 'open'\n              }\n            };\n\n            return new Channel(chaninfo, self);\n          };\n\n          self.emit('tcpip', accept, reject, info.data);\n        } else\n          reject();\n      break;\n      case 'direct-streamlocal@openssh.com':\n        if (listenerCount(self, 'openssh.streamlocal')) {\n          accept = function() {\n            if (replied)\n              return;\n\n            replied = true;\n\n            stream.channelOpenConfirm(info.sender,\n                                      localChan,\n                                      Channel.MAX_WINDOW,\n                                      Channel.PACKET_SIZE);\n\n            var chaninfo = {\n              type: undefined,\n              incoming: {\n                id: localChan,\n                window: Channel.MAX_WINDOW,\n                packetSize: Channel.PACKET_SIZE,\n                state: 'open'\n              },\n              outgoing: {\n                id: info.sender,\n                window: info.window,\n                packetSize: info.packetSize,\n                state: 'open'\n              }\n            };\n\n            return new Channel(chaninfo, self);\n          };\n\n          self.emit('openssh.streamlocal', accept, reject, info.data);\n        } else\n          reject();\n      break;\n      default:\n        // auto-reject unsupported channel types\n        reject();\n    }\n  });\n\n  stream.on('NEWKEYS', function() {\n    if (++exchanges > 1)\n      self.emit('rekey');\n  });\n\n  if (kaMgr) {\n    this.once('ready', function() {\n      kaMgr.add(stream);\n    });\n  }\n}\ninherits(Client, EventEmitter);\n\nClient.prototype.end = function() {\n  return this._sshstream.disconnect(DISCONNECT_REASON.BY_APPLICATION);\n};\n\nClient.prototype.x11 = function(originAddr, originPort, cb) {\n  var opts = {\n    originAddr: originAddr,\n    originPort: originPort\n  };\n  return openChannel(this, 'x11', opts, cb);\n};\n\nClient.prototype.forwardOut = function(boundAddr, boundPort, remoteAddr,\n                                       remotePort, cb) {\n  var opts = {\n    boundAddr: boundAddr,\n    boundPort: boundPort,\n    remoteAddr: remoteAddr,\n    remotePort: remotePort\n  };\n  return openChannel(this, 'forwarded-tcpip', opts, cb);\n};\n\nClient.prototype.openssh_forwardOutStreamLocal = function(socketPath, cb) {\n  var opts = {\n    socketPath: socketPath\n  };\n  return openChannel(this, 'forwarded-streamlocal@openssh.com', opts, cb);\n};\n\nClient.prototype.rekey = function(cb) {\n  var stream = this._sshstream;\n  var ret = true;\n  var error;\n\n  try {\n    ret = stream.rekey();\n  } catch (ex) {\n    error = ex;\n  }\n\n  // TODO: re-throw error if no callback?\n\n  if (typeof cb === 'function') {\n    if (error) {\n      process.nextTick(function() {\n        cb(error);\n      });\n    } else\n      this.once('rekey', cb);\n  }\n\n  return ret;\n};\n\nfunction Session(client, info, localChan) {\n  this.subtype = undefined;\n\n  var ending = false;\n  var self = this;\n  var outgoingId = info.sender;\n  var channel;\n\n  var chaninfo = {\n    type: 'session',\n    incoming: {\n      id: localChan,\n      window: Channel.MAX_WINDOW,\n      packetSize: Channel.PACKET_SIZE,\n      state: 'open'\n    },\n    outgoing: {\n      id: info.sender,\n      window: info.window,\n      packetSize: info.packetSize,\n      state: 'open'\n    }\n  };\n\n  function onREQUEST(info) {\n    var replied = false;\n    var accept;\n    var reject;\n\n    if (info.wantReply) {\n      // \"real session\" requests will have custom accept behaviors\n      if (info.request !== 'shell'\n          && info.request !== 'exec'\n          && info.request !== 'subsystem') {\n        accept = function() {\n          if (replied || ending || channel)\n            return;\n\n          replied = true;\n\n          return client._sshstream.channelSuccess(outgoingId);\n        };\n      }\n\n      reject = function() {\n        if (replied || ending || channel)\n          return;\n\n        replied = true;\n\n        return client._sshstream.channelFailure(outgoingId);\n      };\n    }\n\n    if (ending) {\n      reject && reject();\n      return;\n    }\n\n    switch (info.request) {\n      // \"pre-real session start\" requests\n      case 'env':\n        if (listenerCount(self, 'env')) {\n          self.emit('env', accept, reject, {\n            key: info.key,\n            val: info.val\n          });\n        } else\n          reject && reject();\n      break;\n      case 'pty-req':\n        if (listenerCount(self, 'pty')) {\n          self.emit('pty', accept, reject, {\n            cols: info.cols,\n            rows: info.rows,\n            width: info.width,\n            height: info.height,\n            term: info.term,\n            modes: info.modes,\n          });\n        } else\n          reject && reject();\n      break;\n      case 'window-change':\n        if (listenerCount(self, 'window-change')) {\n          self.emit('window-change', accept, reject, {\n            cols: info.cols,\n            rows: info.rows,\n            width: info.width,\n            height: info.height\n          });\n        } else\n          reject && reject();\n      break;\n      case 'x11-req':\n        if (listenerCount(self, 'x11')) {\n          self.emit('x11', accept, reject, {\n            single: info.single,\n            protocol: info.protocol,\n            cookie: info.cookie,\n            screen: info.screen\n          });\n        } else\n          reject && reject();\n      break;\n      // \"post-real session start\" requests\n      case 'signal':\n        if (listenerCount(self, 'signal')) {\n          self.emit('signal', accept, reject, {\n            name: info.signal\n          });\n        } else\n          reject && reject();\n      break;\n      // XXX: is `auth-agent-req@openssh.com` really \"post-real session start\"?\n      case 'auth-agent-req@openssh.com':\n        if (listenerCount(self, 'auth-agent'))\n          self.emit('auth-agent', accept, reject);\n        else\n          reject && reject();\n      break;\n      // \"real session start\" requests\n      case 'shell':\n        if (listenerCount(self, 'shell')) {\n          accept = function() {\n            if (replied || ending || channel)\n              return;\n\n            replied = true;\n\n            if (info.wantReply)\n              client._sshstream.channelSuccess(outgoingId);\n\n            channel = new Channel(chaninfo, client, { server: true });\n\n            channel.subtype = self.subtype = info.request;\n\n            return channel;\n          };\n\n          self.emit('shell', accept, reject);\n        } else\n          reject && reject();\n      break;\n      case 'exec':\n        if (listenerCount(self, 'exec')) {\n          accept = function() {\n            if (replied || ending || channel)\n              return;\n\n            replied = true;\n\n            if (info.wantReply)\n              client._sshstream.channelSuccess(outgoingId);\n\n            channel = new Channel(chaninfo, client, { server: true });\n\n            channel.subtype = self.subtype = info.request;\n\n            return channel;\n          };\n\n          self.emit('exec', accept, reject, {\n            command: info.command\n          });\n        } else\n          reject && reject();\n      break;\n      case 'subsystem':\n        accept = function() {\n          if (replied || ending || channel)\n            return;\n\n          replied = true;\n\n          if (info.wantReply)\n            client._sshstream.channelSuccess(outgoingId);\n\n          channel = new Channel(chaninfo, client, { server: true });\n\n          channel.subtype = self.subtype = (info.request + ':' + info.subsystem);\n\n          if (info.subsystem === 'sftp') {\n            var sftp = new SFTPStream({\n              server: true,\n              debug: client._sshstream.debug\n            });\n            channel.pipe(sftp).pipe(channel);\n\n            return sftp;\n          } else\n            return channel;\n        };\n\n        if (info.subsystem === 'sftp' && listenerCount(self, 'sftp'))\n          self.emit('sftp', accept, reject);\n        else if (info.subsystem !== 'sftp' && listenerCount(self, 'subsystem')) {\n          self.emit('subsystem', accept, reject, {\n            name: info.subsystem\n          });\n        } else\n          reject && reject();\n      break;\n      default:\n        reject && reject();\n    }\n  }\n  function onEOF() {\n    ending = true;\n    self.emit('eof');\n    self.emit('end');\n  }\n  function onCLOSE() {\n    ending = true;\n    self.emit('close');\n  }\n  client._sshstream\n        .on('CHANNEL_REQUEST:' + localChan, onREQUEST)\n        .once('CHANNEL_EOF:' + localChan, onEOF)\n        .once('CHANNEL_CLOSE:' + localChan, onCLOSE);\n}\ninherits(Session, EventEmitter);\n\n\nfunction AuthContext(stream, username, service, method, cb) {\n  EventEmitter.call(this);\n\n  var self = this;\n\n  this.username = this.user = username;\n  this.service = service;\n  this.method = method;\n  this._initialResponse = false;\n  this._finalResponse = false;\n  this._multistep = false;\n  this._cbfinal = function(allowed, methodsLeft, isPartial) {\n    if (!self._finalResponse) {\n      self._finalResponse = true;\n      cb(self, allowed, methodsLeft, isPartial);\n    }\n  };\n  this._stream = stream;\n}\ninherits(AuthContext, EventEmitter);\nAuthContext.prototype.accept = function() {\n  this._cleanup && this._cleanup();\n  this._initialResponse = true;\n  this._cbfinal(true);\n};\nAuthContext.prototype.reject = function(methodsLeft, isPartial) {\n  this._cleanup && this._cleanup();\n  this._initialResponse = true;\n  this._cbfinal(false, methodsLeft, isPartial);\n};\n\nvar RE_KBINT_SUBMETHODS = /[ \\t\\r\\n]*,[ \\t\\r\\n]*/g;\nfunction KeyboardAuthContext(stream, username, service, method, submethods, cb) {\n  AuthContext.call(this, stream, username, service, method, cb);\n  this._multistep = true;\n\n  var self = this;\n\n  this._cb = undefined;\n  this._onInfoResponse = function(responses) {\n    if (self._cb) {\n      var callback = self._cb;\n      self._cb = undefined;\n      callback(responses);\n    }\n  };\n  this.submethods = submethods.split(RE_KBINT_SUBMETHODS);\n  this.on('abort', function() {\n    self._cb && self._cb(new Error('Authentication request aborted'));\n  });\n}\ninherits(KeyboardAuthContext, AuthContext);\nKeyboardAuthContext.prototype._cleanup = function() {\n  this._stream.removeListener('USERAUTH_INFO_RESPONSE', this._onInfoResponse);\n};\nKeyboardAuthContext.prototype.prompt = function(prompts, title, instructions,\n                                                cb) {\n  if (!Array.isArray(prompts))\n    prompts = [ prompts ];\n\n  if (typeof title === 'function') {\n    cb = title;\n    title = instructions = undefined;\n  } else if (typeof instructions === 'function') {\n    cb = instructions;\n    instructions = undefined;\n  }\n\n  for (var i = 0; i < prompts.length; ++i) {\n    if (typeof prompts[i] === 'string') {\n      prompts[i] = {\n        prompt: prompts[i],\n        echo: true\n      };\n    }\n  }\n\n  this._cb = cb;\n  this._initialResponse = true;\n  this._stream.once('USERAUTH_INFO_RESPONSE', this._onInfoResponse);\n\n  return this._stream.authInfoReq(title, instructions, prompts);\n};\n\nfunction PKAuthContext(stream, username, service, method, pkInfo, cb) {\n  AuthContext.call(this, stream, username, service, method, cb);\n\n  this.key = { algo: pkInfo.keyAlgo, data: pkInfo.key };\n  this.signature = pkInfo.signature;\n  var sigAlgo;\n  if (this.signature) {\n    // TODO: move key type checking logic to ssh2-streams\n    switch (pkInfo.keyAlgo) {\n      case 'ssh-rsa':\n      case 'ssh-dss':\n        sigAlgo = 'sha1';\n        break;\n      case 'ssh-ed25519':\n        sigAlgo = null;\n        break;\n      case 'ecdsa-sha2-nistp256':\n        sigAlgo = 'sha256';\n        break;\n      case 'ecdsa-sha2-nistp384':\n        sigAlgo = 'sha384';\n        break;\n      case 'ecdsa-sha2-nistp521':\n        sigAlgo = 'sha512';\n        break;\n    }\n  }\n  this.sigAlgo = sigAlgo;\n  this.blob = pkInfo.blob;\n}\ninherits(PKAuthContext, AuthContext);\nPKAuthContext.prototype.accept = function() {\n  if (!this.signature) {\n    this._initialResponse = true;\n    this._stream.authPKOK(this.key.algo, this.key.data);\n  } else {\n    AuthContext.prototype.accept.call(this);\n  }\n};\n\nfunction HostbasedAuthContext(stream, username, service, method, pkInfo, cb) {\n  AuthContext.call(this, stream, username, service, method, cb);\n\n  this.key = { algo: pkInfo.keyAlgo, data: pkInfo.key };\n  this.signature = pkInfo.signature;\n  var sigAlgo;\n  if (this.signature) {\n    // TODO: move key type checking logic to ssh2-streams\n    switch (pkInfo.keyAlgo) {\n      case 'ssh-rsa':\n      case 'ssh-dss':\n        sigAlgo = 'sha1';\n        break;\n      case 'ssh-ed25519':\n        sigAlgo = null;\n        break;\n      case 'ecdsa-sha2-nistp256':\n        sigAlgo = 'sha256';\n        break;\n      case 'ecdsa-sha2-nistp384':\n        sigAlgo = 'sha384';\n        break;\n      case 'ecdsa-sha2-nistp521':\n        sigAlgo = 'sha512';\n        break;\n    }\n  }\n  this.sigAlgo = sigAlgo;\n  this.blob = pkInfo.blob;\n  this.localHostname = pkInfo.localHostname;\n  this.localUsername = pkInfo.localUsername;\n}\ninherits(HostbasedAuthContext, AuthContext);\n\nfunction PwdAuthContext(stream, username, service, method, password, cb) {\n  AuthContext.call(this, stream, username, service, method, cb);\n\n  this.password = password;\n}\ninherits(PwdAuthContext, AuthContext);\n\n\nfunction openChannel(self, type, opts, cb) {\n  // ask the client to open a channel for some purpose\n  // (e.g. a forwarded TCP connection)\n  var localChan = nextChannel(self);\n  var initWindow = Channel.MAX_WINDOW;\n  var maxPacket = Channel.PACKET_SIZE;\n  var ret = true;\n\n  if (localChan === false)\n    return cb(new Error('No free channels available'));\n\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n\n  self._channels[localChan] = true;\n\n  var sshstream = self._sshstream;\n  sshstream.once('CHANNEL_OPEN_CONFIRMATION:' + localChan, function(info) {\n    sshstream.removeAllListeners('CHANNEL_OPEN_FAILURE:' + localChan);\n\n    var chaninfo = {\n      type: type,\n      incoming: {\n        id: localChan,\n        window: initWindow,\n        packetSize: maxPacket,\n        state: 'open'\n      },\n      outgoing: {\n        id: info.sender,\n        window: info.window,\n        packetSize: info.packetSize,\n        state: 'open'\n      }\n    };\n    cb(undefined, new Channel(chaninfo, self, { server: true }));\n  }).once('CHANNEL_OPEN_FAILURE:' + localChan, function(info) {\n    sshstream.removeAllListeners('CHANNEL_OPEN_CONFIRMATION:' + localChan);\n\n    delete self._channels[localChan];\n\n    var err = new Error('(SSH) Channel open failure: ' + info.description);\n    err.reason = info.reason;\n    err.lang = info.lang;\n    cb(err);\n  });\n\n  if (type === 'forwarded-tcpip')\n    ret = sshstream.forwardedTcpip(localChan, initWindow, maxPacket, opts);\n  else if (type === 'x11')\n    ret = sshstream.x11(localChan, initWindow, maxPacket, opts);\n  else if (type === 'forwarded-streamlocal@openssh.com') {\n    ret = sshstream.openssh_forwardedStreamLocal(localChan,\n                                                 initWindow,\n                                                 maxPacket,\n                                                 opts);\n  }\n\n  return ret;\n}\n\nfunction nextChannel(self) {\n  // get the next available channel number\n\n  // fast path\n  if (self._curChan < MAX_CHANNEL)\n    return ++self._curChan;\n\n  // slower lookup path\n  for (var i = 0, channels = self._channels; i < MAX_CHANNEL; ++i)\n    if (!channels[i])\n      return i;\n\n  return false;\n}\n\n\nServer.createServer = function(cfg, listener) {\n  return new Server(cfg, listener);\n};\nServer.KEEPALIVE_INTERVAL = 1000;\nServer.KEEPALIVE_CLIENT_INTERVAL = 15000;\nServer.KEEPALIVE_CLIENT_COUNT_MAX = 3;\n\nmodule.exports = Server;\nmodule.exports.IncomingClient = Client;\n\n\n//# sourceURL=webpack:///./node_modules/ssh2/lib/server.js?");

/***/ }),

/***/ "./node_modules/streamsearch/lib/sbmh.js":
/*!***********************************************!*\
  !*** ./node_modules/streamsearch/lib/sbmh.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/*\n  Based heavily on the Streaming Boyer-Moore-Horspool C++ implementation\n  by Hongli Lai at: https://github.com/FooBarWidget/boyer-moore-horspool\n*/\nvar EventEmitter = __webpack_require__(/*! events */ \"events\").EventEmitter,\n    inherits = __webpack_require__(/*! util */ \"util\").inherits;\n\nfunction jsmemcmp(buf1, pos1, buf2, pos2, num) {\n  for (var i = 0; i < num; ++i, ++pos1, ++pos2)\n    if (buf1[pos1] !== buf2[pos2])\n      return false;\n  return true;\n}\n\nfunction SBMH(needle) {\n  if (typeof needle === 'string')\n    needle = new Buffer(needle);\n  var i, j, needle_len = needle.length;\n\n  this.maxMatches = Infinity;\n  this.matches = 0;\n\n  this._occ = new Array(256);\n  this._lookbehind_size = 0;\n  this._needle = needle;\n  this._bufpos = 0;\n\n  this._lookbehind = new Buffer(needle_len);\n\n  // Initialize occurrence table.\n  for (j = 0; j < 256; ++j)\n    this._occ[j] = needle_len;\n\n  // Populate occurrence table with analysis of the needle,\n  // ignoring last letter.\n  if (needle_len >= 1) {\n    for (i = 0; i < needle_len - 1; ++i)\n      this._occ[needle[i]] = needle_len - 1 - i;\n  }\n}\ninherits(SBMH, EventEmitter);\n\nSBMH.prototype.reset = function() {\n  this._lookbehind_size = 0;\n  this.matches = 0;\n  this._bufpos = 0;\n};\n\nSBMH.prototype.push = function(chunk, pos) {\n  var r, chlen;\n  if (!Buffer.isBuffer(chunk))\n    chunk = new Buffer(chunk, 'binary');\n  chlen = chunk.length;\n  this._bufpos = pos || 0;\n  while (r !== chlen && this.matches < this.maxMatches)\n    r = this._sbmh_feed(chunk);\n  return r;\n};\n\nSBMH.prototype._sbmh_feed = function(data) {\n  var len = data.length, needle = this._needle, needle_len = needle.length;\n\n  // Positive: points to a position in `data`\n  //           pos == 3 points to data[3]\n  // Negative: points to a position in the lookbehind buffer\n  //           pos == -2 points to lookbehind[lookbehind_size - 2]\n  var pos = -this._lookbehind_size,\n      last_needle_char = needle[needle_len - 1],\n      occ = this._occ,\n      lookbehind = this._lookbehind;\n\n  if (pos < 0) {\n    // Lookbehind buffer is not empty. Perform Boyer-Moore-Horspool\n    // search with character lookup code that considers both the\n    // lookbehind buffer and the current round's haystack data.\n    //\n    // Loop until\n    //   there is a match.\n    // or until\n    //   we've moved past the position that requires the\n    //   lookbehind buffer. In this case we switch to the\n    //   optimized loop.\n    // or until\n    //   the character to look at lies outside the haystack.\n    while (pos < 0 && pos <= len - needle_len) {\n       var ch = this._sbmh_lookup_char(data, pos + needle_len - 1);\n\n      if (ch === last_needle_char\n          && this._sbmh_memcmp(data, pos, needle_len - 1)) {\n        this._lookbehind_size = 0;\n        ++this.matches;\n        if (pos > -this._lookbehind_size)\n          this.emit('info', true, lookbehind, 0, this._lookbehind_size + pos);\n        else\n          this.emit('info', true);\n\n        this._bufpos = pos + needle_len;\n        return pos + needle_len;\n      } else\n        pos += occ[ch];\n    }\n\n    // No match.\n\n    if (pos < 0) {\n      // There's too few data for Boyer-Moore-Horspool to run,\n      // so let's use a different algorithm to skip as much as\n      // we can.\n      // Forward pos until\n      //   the trailing part of lookbehind + data\n      //   looks like the beginning of the needle\n      // or until\n      //   pos == 0\n      while (pos < 0 && !this._sbmh_memcmp(data, pos, len - pos))\n        pos++;\n    }\n\n    if (pos >= 0) {\n      // Discard lookbehind buffer.\n      this.emit('info', false, lookbehind, 0, this._lookbehind_size);\n      this._lookbehind_size = 0;\n    } else {\n      // Cut off part of the lookbehind buffer that has\n      // been processed and append the entire haystack\n      // into it.\n      var bytesToCutOff = this._lookbehind_size + pos;\n\n      if (bytesToCutOff > 0) {\n        // The cut off data is guaranteed not to contain the needle.\n        this.emit('info', false, lookbehind, 0, bytesToCutOff);\n      }\n\n      lookbehind.copy(lookbehind, 0, bytesToCutOff,\n                      this._lookbehind_size - bytesToCutOff);\n      this._lookbehind_size -= bytesToCutOff;\n\n      data.copy(lookbehind, this._lookbehind_size);\n      this._lookbehind_size += len;\n\n      this._bufpos = len;\n      return len;\n    }\n  }\n\n  if (pos >= 0)\n    pos += this._bufpos;\n\n  // Lookbehind buffer is now empty. Perform Boyer-Moore-Horspool\n  // search with optimized character lookup code that only considers\n  // the current round's haystack data.\n  while (pos <= len - needle_len) {\n    var ch = data[pos + needle_len - 1];\n\n    if (ch === last_needle_char\n        && data[pos] === needle[0]\n        && jsmemcmp(needle, 0, data, pos, needle_len - 1)) {\n      ++this.matches;\n      if (pos > 0)\n        this.emit('info', true, data, this._bufpos, pos);\n      else\n        this.emit('info', true);\n\n      this._bufpos = pos + needle_len;\n      return pos + needle_len;\n    } else\n      pos += occ[ch];\n  }\n\n  // There was no match. If there's trailing haystack data that we cannot\n  // match yet using the Boyer-Moore-Horspool algorithm (because the trailing\n  // data is less than the needle size) then match using a modified\n  // algorithm that starts matching from the beginning instead of the end.\n  // Whatever trailing data is left after running this algorithm is added to\n  // the lookbehind buffer.\n  if (pos < len) {\n    while (pos < len && (data[pos] !== needle[0]\n                         || !jsmemcmp(data, pos, needle, 0, len - pos))) {\n      ++pos;\n    }\n    if (pos < len) {\n      data.copy(lookbehind, 0, pos, pos + (len - pos));\n      this._lookbehind_size = len - pos;\n    }\n  }\n\n  // Everything until pos is guaranteed not to contain needle data.\n  if (pos > 0)\n    this.emit('info', false, data, this._bufpos, pos < len ? pos : len);\n\n  this._bufpos = len;\n  return len;\n};\n\nSBMH.prototype._sbmh_lookup_char = function(data, pos) {\n  if (pos < 0)\n    return this._lookbehind[this._lookbehind_size + pos];\n  else\n    return data[pos];\n}\n\nSBMH.prototype._sbmh_memcmp = function(data, pos, len) {\n  var i = 0;\n\n  while (i < len) {\n    if (this._sbmh_lookup_char(data, pos + i) === this._needle[i])\n      ++i;\n    else\n      return false;\n  }\n  return true;\n}\n\nmodule.exports = SBMH;\n\n\n//# sourceURL=webpack:///./node_modules/streamsearch/lib/sbmh.js?");

/***/ }),

/***/ "./node_modules/tweetnacl/nacl-fast.js":
/*!*********************************************!*\
  !*** ./node_modules/tweetnacl/nacl-fast.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("(function(nacl) {\n'use strict';\n\n// Ported in 2014 by Dmitry Chestnykh and Devi Mandiri.\n// Public domain.\n//\n// Implementation derived from TweetNaCl version 20140427.\n// See for details: http://tweetnacl.cr.yp.to/\n\nvar gf = function(init) {\n  var i, r = new Float64Array(16);\n  if (init) for (i = 0; i < init.length; i++) r[i] = init[i];\n  return r;\n};\n\n//  Pluggable, initialized in high-level API below.\nvar randombytes = function(/* x, n */) { throw new Error('no PRNG'); };\n\nvar _0 = new Uint8Array(16);\nvar _9 = new Uint8Array(32); _9[0] = 9;\n\nvar gf0 = gf(),\n    gf1 = gf([1]),\n    _121665 = gf([0xdb41, 1]),\n    D = gf([0x78a3, 0x1359, 0x4dca, 0x75eb, 0xd8ab, 0x4141, 0x0a4d, 0x0070, 0xe898, 0x7779, 0x4079, 0x8cc7, 0xfe73, 0x2b6f, 0x6cee, 0x5203]),\n    D2 = gf([0xf159, 0x26b2, 0x9b94, 0xebd6, 0xb156, 0x8283, 0x149a, 0x00e0, 0xd130, 0xeef3, 0x80f2, 0x198e, 0xfce7, 0x56df, 0xd9dc, 0x2406]),\n    X = gf([0xd51a, 0x8f25, 0x2d60, 0xc956, 0xa7b2, 0x9525, 0xc760, 0x692c, 0xdc5c, 0xfdd6, 0xe231, 0xc0a4, 0x53fe, 0xcd6e, 0x36d3, 0x2169]),\n    Y = gf([0x6658, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666, 0x6666]),\n    I = gf([0xa0b0, 0x4a0e, 0x1b27, 0xc4ee, 0xe478, 0xad2f, 0x1806, 0x2f43, 0xd7a7, 0x3dfb, 0x0099, 0x2b4d, 0xdf0b, 0x4fc1, 0x2480, 0x2b83]);\n\nfunction ts64(x, i, h, l) {\n  x[i]   = (h >> 24) & 0xff;\n  x[i+1] = (h >> 16) & 0xff;\n  x[i+2] = (h >>  8) & 0xff;\n  x[i+3] = h & 0xff;\n  x[i+4] = (l >> 24)  & 0xff;\n  x[i+5] = (l >> 16)  & 0xff;\n  x[i+6] = (l >>  8)  & 0xff;\n  x[i+7] = l & 0xff;\n}\n\nfunction vn(x, xi, y, yi, n) {\n  var i,d = 0;\n  for (i = 0; i < n; i++) d |= x[xi+i]^y[yi+i];\n  return (1 & ((d - 1) >>> 8)) - 1;\n}\n\nfunction crypto_verify_16(x, xi, y, yi) {\n  return vn(x,xi,y,yi,16);\n}\n\nfunction crypto_verify_32(x, xi, y, yi) {\n  return vn(x,xi,y,yi,32);\n}\n\nfunction core_salsa20(o, p, k, c) {\n  var j0  = c[ 0] & 0xff | (c[ 1] & 0xff)<<8 | (c[ 2] & 0xff)<<16 | (c[ 3] & 0xff)<<24,\n      j1  = k[ 0] & 0xff | (k[ 1] & 0xff)<<8 | (k[ 2] & 0xff)<<16 | (k[ 3] & 0xff)<<24,\n      j2  = k[ 4] & 0xff | (k[ 5] & 0xff)<<8 | (k[ 6] & 0xff)<<16 | (k[ 7] & 0xff)<<24,\n      j3  = k[ 8] & 0xff | (k[ 9] & 0xff)<<8 | (k[10] & 0xff)<<16 | (k[11] & 0xff)<<24,\n      j4  = k[12] & 0xff | (k[13] & 0xff)<<8 | (k[14] & 0xff)<<16 | (k[15] & 0xff)<<24,\n      j5  = c[ 4] & 0xff | (c[ 5] & 0xff)<<8 | (c[ 6] & 0xff)<<16 | (c[ 7] & 0xff)<<24,\n      j6  = p[ 0] & 0xff | (p[ 1] & 0xff)<<8 | (p[ 2] & 0xff)<<16 | (p[ 3] & 0xff)<<24,\n      j7  = p[ 4] & 0xff | (p[ 5] & 0xff)<<8 | (p[ 6] & 0xff)<<16 | (p[ 7] & 0xff)<<24,\n      j8  = p[ 8] & 0xff | (p[ 9] & 0xff)<<8 | (p[10] & 0xff)<<16 | (p[11] & 0xff)<<24,\n      j9  = p[12] & 0xff | (p[13] & 0xff)<<8 | (p[14] & 0xff)<<16 | (p[15] & 0xff)<<24,\n      j10 = c[ 8] & 0xff | (c[ 9] & 0xff)<<8 | (c[10] & 0xff)<<16 | (c[11] & 0xff)<<24,\n      j11 = k[16] & 0xff | (k[17] & 0xff)<<8 | (k[18] & 0xff)<<16 | (k[19] & 0xff)<<24,\n      j12 = k[20] & 0xff | (k[21] & 0xff)<<8 | (k[22] & 0xff)<<16 | (k[23] & 0xff)<<24,\n      j13 = k[24] & 0xff | (k[25] & 0xff)<<8 | (k[26] & 0xff)<<16 | (k[27] & 0xff)<<24,\n      j14 = k[28] & 0xff | (k[29] & 0xff)<<8 | (k[30] & 0xff)<<16 | (k[31] & 0xff)<<24,\n      j15 = c[12] & 0xff | (c[13] & 0xff)<<8 | (c[14] & 0xff)<<16 | (c[15] & 0xff)<<24;\n\n  var x0 = j0, x1 = j1, x2 = j2, x3 = j3, x4 = j4, x5 = j5, x6 = j6, x7 = j7,\n      x8 = j8, x9 = j9, x10 = j10, x11 = j11, x12 = j12, x13 = j13, x14 = j14,\n      x15 = j15, u;\n\n  for (var i = 0; i < 20; i += 2) {\n    u = x0 + x12 | 0;\n    x4 ^= u<<7 | u>>>(32-7);\n    u = x4 + x0 | 0;\n    x8 ^= u<<9 | u>>>(32-9);\n    u = x8 + x4 | 0;\n    x12 ^= u<<13 | u>>>(32-13);\n    u = x12 + x8 | 0;\n    x0 ^= u<<18 | u>>>(32-18);\n\n    u = x5 + x1 | 0;\n    x9 ^= u<<7 | u>>>(32-7);\n    u = x9 + x5 | 0;\n    x13 ^= u<<9 | u>>>(32-9);\n    u = x13 + x9 | 0;\n    x1 ^= u<<13 | u>>>(32-13);\n    u = x1 + x13 | 0;\n    x5 ^= u<<18 | u>>>(32-18);\n\n    u = x10 + x6 | 0;\n    x14 ^= u<<7 | u>>>(32-7);\n    u = x14 + x10 | 0;\n    x2 ^= u<<9 | u>>>(32-9);\n    u = x2 + x14 | 0;\n    x6 ^= u<<13 | u>>>(32-13);\n    u = x6 + x2 | 0;\n    x10 ^= u<<18 | u>>>(32-18);\n\n    u = x15 + x11 | 0;\n    x3 ^= u<<7 | u>>>(32-7);\n    u = x3 + x15 | 0;\n    x7 ^= u<<9 | u>>>(32-9);\n    u = x7 + x3 | 0;\n    x11 ^= u<<13 | u>>>(32-13);\n    u = x11 + x7 | 0;\n    x15 ^= u<<18 | u>>>(32-18);\n\n    u = x0 + x3 | 0;\n    x1 ^= u<<7 | u>>>(32-7);\n    u = x1 + x0 | 0;\n    x2 ^= u<<9 | u>>>(32-9);\n    u = x2 + x1 | 0;\n    x3 ^= u<<13 | u>>>(32-13);\n    u = x3 + x2 | 0;\n    x0 ^= u<<18 | u>>>(32-18);\n\n    u = x5 + x4 | 0;\n    x6 ^= u<<7 | u>>>(32-7);\n    u = x6 + x5 | 0;\n    x7 ^= u<<9 | u>>>(32-9);\n    u = x7 + x6 | 0;\n    x4 ^= u<<13 | u>>>(32-13);\n    u = x4 + x7 | 0;\n    x5 ^= u<<18 | u>>>(32-18);\n\n    u = x10 + x9 | 0;\n    x11 ^= u<<7 | u>>>(32-7);\n    u = x11 + x10 | 0;\n    x8 ^= u<<9 | u>>>(32-9);\n    u = x8 + x11 | 0;\n    x9 ^= u<<13 | u>>>(32-13);\n    u = x9 + x8 | 0;\n    x10 ^= u<<18 | u>>>(32-18);\n\n    u = x15 + x14 | 0;\n    x12 ^= u<<7 | u>>>(32-7);\n    u = x12 + x15 | 0;\n    x13 ^= u<<9 | u>>>(32-9);\n    u = x13 + x12 | 0;\n    x14 ^= u<<13 | u>>>(32-13);\n    u = x14 + x13 | 0;\n    x15 ^= u<<18 | u>>>(32-18);\n  }\n   x0 =  x0 +  j0 | 0;\n   x1 =  x1 +  j1 | 0;\n   x2 =  x2 +  j2 | 0;\n   x3 =  x3 +  j3 | 0;\n   x4 =  x4 +  j4 | 0;\n   x5 =  x5 +  j5 | 0;\n   x6 =  x6 +  j6 | 0;\n   x7 =  x7 +  j7 | 0;\n   x8 =  x8 +  j8 | 0;\n   x9 =  x9 +  j9 | 0;\n  x10 = x10 + j10 | 0;\n  x11 = x11 + j11 | 0;\n  x12 = x12 + j12 | 0;\n  x13 = x13 + j13 | 0;\n  x14 = x14 + j14 | 0;\n  x15 = x15 + j15 | 0;\n\n  o[ 0] = x0 >>>  0 & 0xff;\n  o[ 1] = x0 >>>  8 & 0xff;\n  o[ 2] = x0 >>> 16 & 0xff;\n  o[ 3] = x0 >>> 24 & 0xff;\n\n  o[ 4] = x1 >>>  0 & 0xff;\n  o[ 5] = x1 >>>  8 & 0xff;\n  o[ 6] = x1 >>> 16 & 0xff;\n  o[ 7] = x1 >>> 24 & 0xff;\n\n  o[ 8] = x2 >>>  0 & 0xff;\n  o[ 9] = x2 >>>  8 & 0xff;\n  o[10] = x2 >>> 16 & 0xff;\n  o[11] = x2 >>> 24 & 0xff;\n\n  o[12] = x3 >>>  0 & 0xff;\n  o[13] = x3 >>>  8 & 0xff;\n  o[14] = x3 >>> 16 & 0xff;\n  o[15] = x3 >>> 24 & 0xff;\n\n  o[16] = x4 >>>  0 & 0xff;\n  o[17] = x4 >>>  8 & 0xff;\n  o[18] = x4 >>> 16 & 0xff;\n  o[19] = x4 >>> 24 & 0xff;\n\n  o[20] = x5 >>>  0 & 0xff;\n  o[21] = x5 >>>  8 & 0xff;\n  o[22] = x5 >>> 16 & 0xff;\n  o[23] = x5 >>> 24 & 0xff;\n\n  o[24] = x6 >>>  0 & 0xff;\n  o[25] = x6 >>>  8 & 0xff;\n  o[26] = x6 >>> 16 & 0xff;\n  o[27] = x6 >>> 24 & 0xff;\n\n  o[28] = x7 >>>  0 & 0xff;\n  o[29] = x7 >>>  8 & 0xff;\n  o[30] = x7 >>> 16 & 0xff;\n  o[31] = x7 >>> 24 & 0xff;\n\n  o[32] = x8 >>>  0 & 0xff;\n  o[33] = x8 >>>  8 & 0xff;\n  o[34] = x8 >>> 16 & 0xff;\n  o[35] = x8 >>> 24 & 0xff;\n\n  o[36] = x9 >>>  0 & 0xff;\n  o[37] = x9 >>>  8 & 0xff;\n  o[38] = x9 >>> 16 & 0xff;\n  o[39] = x9 >>> 24 & 0xff;\n\n  o[40] = x10 >>>  0 & 0xff;\n  o[41] = x10 >>>  8 & 0xff;\n  o[42] = x10 >>> 16 & 0xff;\n  o[43] = x10 >>> 24 & 0xff;\n\n  o[44] = x11 >>>  0 & 0xff;\n  o[45] = x11 >>>  8 & 0xff;\n  o[46] = x11 >>> 16 & 0xff;\n  o[47] = x11 >>> 24 & 0xff;\n\n  o[48] = x12 >>>  0 & 0xff;\n  o[49] = x12 >>>  8 & 0xff;\n  o[50] = x12 >>> 16 & 0xff;\n  o[51] = x12 >>> 24 & 0xff;\n\n  o[52] = x13 >>>  0 & 0xff;\n  o[53] = x13 >>>  8 & 0xff;\n  o[54] = x13 >>> 16 & 0xff;\n  o[55] = x13 >>> 24 & 0xff;\n\n  o[56] = x14 >>>  0 & 0xff;\n  o[57] = x14 >>>  8 & 0xff;\n  o[58] = x14 >>> 16 & 0xff;\n  o[59] = x14 >>> 24 & 0xff;\n\n  o[60] = x15 >>>  0 & 0xff;\n  o[61] = x15 >>>  8 & 0xff;\n  o[62] = x15 >>> 16 & 0xff;\n  o[63] = x15 >>> 24 & 0xff;\n}\n\nfunction core_hsalsa20(o,p,k,c) {\n  var j0  = c[ 0] & 0xff | (c[ 1] & 0xff)<<8 | (c[ 2] & 0xff)<<16 | (c[ 3] & 0xff)<<24,\n      j1  = k[ 0] & 0xff | (k[ 1] & 0xff)<<8 | (k[ 2] & 0xff)<<16 | (k[ 3] & 0xff)<<24,\n      j2  = k[ 4] & 0xff | (k[ 5] & 0xff)<<8 | (k[ 6] & 0xff)<<16 | (k[ 7] & 0xff)<<24,\n      j3  = k[ 8] & 0xff | (k[ 9] & 0xff)<<8 | (k[10] & 0xff)<<16 | (k[11] & 0xff)<<24,\n      j4  = k[12] & 0xff | (k[13] & 0xff)<<8 | (k[14] & 0xff)<<16 | (k[15] & 0xff)<<24,\n      j5  = c[ 4] & 0xff | (c[ 5] & 0xff)<<8 | (c[ 6] & 0xff)<<16 | (c[ 7] & 0xff)<<24,\n      j6  = p[ 0] & 0xff | (p[ 1] & 0xff)<<8 | (p[ 2] & 0xff)<<16 | (p[ 3] & 0xff)<<24,\n      j7  = p[ 4] & 0xff | (p[ 5] & 0xff)<<8 | (p[ 6] & 0xff)<<16 | (p[ 7] & 0xff)<<24,\n      j8  = p[ 8] & 0xff | (p[ 9] & 0xff)<<8 | (p[10] & 0xff)<<16 | (p[11] & 0xff)<<24,\n      j9  = p[12] & 0xff | (p[13] & 0xff)<<8 | (p[14] & 0xff)<<16 | (p[15] & 0xff)<<24,\n      j10 = c[ 8] & 0xff | (c[ 9] & 0xff)<<8 | (c[10] & 0xff)<<16 | (c[11] & 0xff)<<24,\n      j11 = k[16] & 0xff | (k[17] & 0xff)<<8 | (k[18] & 0xff)<<16 | (k[19] & 0xff)<<24,\n      j12 = k[20] & 0xff | (k[21] & 0xff)<<8 | (k[22] & 0xff)<<16 | (k[23] & 0xff)<<24,\n      j13 = k[24] & 0xff | (k[25] & 0xff)<<8 | (k[26] & 0xff)<<16 | (k[27] & 0xff)<<24,\n      j14 = k[28] & 0xff | (k[29] & 0xff)<<8 | (k[30] & 0xff)<<16 | (k[31] & 0xff)<<24,\n      j15 = c[12] & 0xff | (c[13] & 0xff)<<8 | (c[14] & 0xff)<<16 | (c[15] & 0xff)<<24;\n\n  var x0 = j0, x1 = j1, x2 = j2, x3 = j3, x4 = j4, x5 = j5, x6 = j6, x7 = j7,\n      x8 = j8, x9 = j9, x10 = j10, x11 = j11, x12 = j12, x13 = j13, x14 = j14,\n      x15 = j15, u;\n\n  for (var i = 0; i < 20; i += 2) {\n    u = x0 + x12 | 0;\n    x4 ^= u<<7 | u>>>(32-7);\n    u = x4 + x0 | 0;\n    x8 ^= u<<9 | u>>>(32-9);\n    u = x8 + x4 | 0;\n    x12 ^= u<<13 | u>>>(32-13);\n    u = x12 + x8 | 0;\n    x0 ^= u<<18 | u>>>(32-18);\n\n    u = x5 + x1 | 0;\n    x9 ^= u<<7 | u>>>(32-7);\n    u = x9 + x5 | 0;\n    x13 ^= u<<9 | u>>>(32-9);\n    u = x13 + x9 | 0;\n    x1 ^= u<<13 | u>>>(32-13);\n    u = x1 + x13 | 0;\n    x5 ^= u<<18 | u>>>(32-18);\n\n    u = x10 + x6 | 0;\n    x14 ^= u<<7 | u>>>(32-7);\n    u = x14 + x10 | 0;\n    x2 ^= u<<9 | u>>>(32-9);\n    u = x2 + x14 | 0;\n    x6 ^= u<<13 | u>>>(32-13);\n    u = x6 + x2 | 0;\n    x10 ^= u<<18 | u>>>(32-18);\n\n    u = x15 + x11 | 0;\n    x3 ^= u<<7 | u>>>(32-7);\n    u = x3 + x15 | 0;\n    x7 ^= u<<9 | u>>>(32-9);\n    u = x7 + x3 | 0;\n    x11 ^= u<<13 | u>>>(32-13);\n    u = x11 + x7 | 0;\n    x15 ^= u<<18 | u>>>(32-18);\n\n    u = x0 + x3 | 0;\n    x1 ^= u<<7 | u>>>(32-7);\n    u = x1 + x0 | 0;\n    x2 ^= u<<9 | u>>>(32-9);\n    u = x2 + x1 | 0;\n    x3 ^= u<<13 | u>>>(32-13);\n    u = x3 + x2 | 0;\n    x0 ^= u<<18 | u>>>(32-18);\n\n    u = x5 + x4 | 0;\n    x6 ^= u<<7 | u>>>(32-7);\n    u = x6 + x5 | 0;\n    x7 ^= u<<9 | u>>>(32-9);\n    u = x7 + x6 | 0;\n    x4 ^= u<<13 | u>>>(32-13);\n    u = x4 + x7 | 0;\n    x5 ^= u<<18 | u>>>(32-18);\n\n    u = x10 + x9 | 0;\n    x11 ^= u<<7 | u>>>(32-7);\n    u = x11 + x10 | 0;\n    x8 ^= u<<9 | u>>>(32-9);\n    u = x8 + x11 | 0;\n    x9 ^= u<<13 | u>>>(32-13);\n    u = x9 + x8 | 0;\n    x10 ^= u<<18 | u>>>(32-18);\n\n    u = x15 + x14 | 0;\n    x12 ^= u<<7 | u>>>(32-7);\n    u = x12 + x15 | 0;\n    x13 ^= u<<9 | u>>>(32-9);\n    u = x13 + x12 | 0;\n    x14 ^= u<<13 | u>>>(32-13);\n    u = x14 + x13 | 0;\n    x15 ^= u<<18 | u>>>(32-18);\n  }\n\n  o[ 0] = x0 >>>  0 & 0xff;\n  o[ 1] = x0 >>>  8 & 0xff;\n  o[ 2] = x0 >>> 16 & 0xff;\n  o[ 3] = x0 >>> 24 & 0xff;\n\n  o[ 4] = x5 >>>  0 & 0xff;\n  o[ 5] = x5 >>>  8 & 0xff;\n  o[ 6] = x5 >>> 16 & 0xff;\n  o[ 7] = x5 >>> 24 & 0xff;\n\n  o[ 8] = x10 >>>  0 & 0xff;\n  o[ 9] = x10 >>>  8 & 0xff;\n  o[10] = x10 >>> 16 & 0xff;\n  o[11] = x10 >>> 24 & 0xff;\n\n  o[12] = x15 >>>  0 & 0xff;\n  o[13] = x15 >>>  8 & 0xff;\n  o[14] = x15 >>> 16 & 0xff;\n  o[15] = x15 >>> 24 & 0xff;\n\n  o[16] = x6 >>>  0 & 0xff;\n  o[17] = x6 >>>  8 & 0xff;\n  o[18] = x6 >>> 16 & 0xff;\n  o[19] = x6 >>> 24 & 0xff;\n\n  o[20] = x7 >>>  0 & 0xff;\n  o[21] = x7 >>>  8 & 0xff;\n  o[22] = x7 >>> 16 & 0xff;\n  o[23] = x7 >>> 24 & 0xff;\n\n  o[24] = x8 >>>  0 & 0xff;\n  o[25] = x8 >>>  8 & 0xff;\n  o[26] = x8 >>> 16 & 0xff;\n  o[27] = x8 >>> 24 & 0xff;\n\n  o[28] = x9 >>>  0 & 0xff;\n  o[29] = x9 >>>  8 & 0xff;\n  o[30] = x9 >>> 16 & 0xff;\n  o[31] = x9 >>> 24 & 0xff;\n}\n\nfunction crypto_core_salsa20(out,inp,k,c) {\n  core_salsa20(out,inp,k,c);\n}\n\nfunction crypto_core_hsalsa20(out,inp,k,c) {\n  core_hsalsa20(out,inp,k,c);\n}\n\nvar sigma = new Uint8Array([101, 120, 112, 97, 110, 100, 32, 51, 50, 45, 98, 121, 116, 101, 32, 107]);\n            // \"expand 32-byte k\"\n\nfunction crypto_stream_salsa20_xor(c,cpos,m,mpos,b,n,k) {\n  var z = new Uint8Array(16), x = new Uint8Array(64);\n  var u, i;\n  for (i = 0; i < 16; i++) z[i] = 0;\n  for (i = 0; i < 8; i++) z[i] = n[i];\n  while (b >= 64) {\n    crypto_core_salsa20(x,z,k,sigma);\n    for (i = 0; i < 64; i++) c[cpos+i] = m[mpos+i] ^ x[i];\n    u = 1;\n    for (i = 8; i < 16; i++) {\n      u = u + (z[i] & 0xff) | 0;\n      z[i] = u & 0xff;\n      u >>>= 8;\n    }\n    b -= 64;\n    cpos += 64;\n    mpos += 64;\n  }\n  if (b > 0) {\n    crypto_core_salsa20(x,z,k,sigma);\n    for (i = 0; i < b; i++) c[cpos+i] = m[mpos+i] ^ x[i];\n  }\n  return 0;\n}\n\nfunction crypto_stream_salsa20(c,cpos,b,n,k) {\n  var z = new Uint8Array(16), x = new Uint8Array(64);\n  var u, i;\n  for (i = 0; i < 16; i++) z[i] = 0;\n  for (i = 0; i < 8; i++) z[i] = n[i];\n  while (b >= 64) {\n    crypto_core_salsa20(x,z,k,sigma);\n    for (i = 0; i < 64; i++) c[cpos+i] = x[i];\n    u = 1;\n    for (i = 8; i < 16; i++) {\n      u = u + (z[i] & 0xff) | 0;\n      z[i] = u & 0xff;\n      u >>>= 8;\n    }\n    b -= 64;\n    cpos += 64;\n  }\n  if (b > 0) {\n    crypto_core_salsa20(x,z,k,sigma);\n    for (i = 0; i < b; i++) c[cpos+i] = x[i];\n  }\n  return 0;\n}\n\nfunction crypto_stream(c,cpos,d,n,k) {\n  var s = new Uint8Array(32);\n  crypto_core_hsalsa20(s,n,k,sigma);\n  var sn = new Uint8Array(8);\n  for (var i = 0; i < 8; i++) sn[i] = n[i+16];\n  return crypto_stream_salsa20(c,cpos,d,sn,s);\n}\n\nfunction crypto_stream_xor(c,cpos,m,mpos,d,n,k) {\n  var s = new Uint8Array(32);\n  crypto_core_hsalsa20(s,n,k,sigma);\n  var sn = new Uint8Array(8);\n  for (var i = 0; i < 8; i++) sn[i] = n[i+16];\n  return crypto_stream_salsa20_xor(c,cpos,m,mpos,d,sn,s);\n}\n\n/*\n* Port of Andrew Moon's Poly1305-donna-16. Public domain.\n* https://github.com/floodyberry/poly1305-donna\n*/\n\nvar poly1305 = function(key) {\n  this.buffer = new Uint8Array(16);\n  this.r = new Uint16Array(10);\n  this.h = new Uint16Array(10);\n  this.pad = new Uint16Array(8);\n  this.leftover = 0;\n  this.fin = 0;\n\n  var t0, t1, t2, t3, t4, t5, t6, t7;\n\n  t0 = key[ 0] & 0xff | (key[ 1] & 0xff) << 8; this.r[0] = ( t0                     ) & 0x1fff;\n  t1 = key[ 2] & 0xff | (key[ 3] & 0xff) << 8; this.r[1] = ((t0 >>> 13) | (t1 <<  3)) & 0x1fff;\n  t2 = key[ 4] & 0xff | (key[ 5] & 0xff) << 8; this.r[2] = ((t1 >>> 10) | (t2 <<  6)) & 0x1f03;\n  t3 = key[ 6] & 0xff | (key[ 7] & 0xff) << 8; this.r[3] = ((t2 >>>  7) | (t3 <<  9)) & 0x1fff;\n  t4 = key[ 8] & 0xff | (key[ 9] & 0xff) << 8; this.r[4] = ((t3 >>>  4) | (t4 << 12)) & 0x00ff;\n  this.r[5] = ((t4 >>>  1)) & 0x1ffe;\n  t5 = key[10] & 0xff | (key[11] & 0xff) << 8; this.r[6] = ((t4 >>> 14) | (t5 <<  2)) & 0x1fff;\n  t6 = key[12] & 0xff | (key[13] & 0xff) << 8; this.r[7] = ((t5 >>> 11) | (t6 <<  5)) & 0x1f81;\n  t7 = key[14] & 0xff | (key[15] & 0xff) << 8; this.r[8] = ((t6 >>>  8) | (t7 <<  8)) & 0x1fff;\n  this.r[9] = ((t7 >>>  5)) & 0x007f;\n\n  this.pad[0] = key[16] & 0xff | (key[17] & 0xff) << 8;\n  this.pad[1] = key[18] & 0xff | (key[19] & 0xff) << 8;\n  this.pad[2] = key[20] & 0xff | (key[21] & 0xff) << 8;\n  this.pad[3] = key[22] & 0xff | (key[23] & 0xff) << 8;\n  this.pad[4] = key[24] & 0xff | (key[25] & 0xff) << 8;\n  this.pad[5] = key[26] & 0xff | (key[27] & 0xff) << 8;\n  this.pad[6] = key[28] & 0xff | (key[29] & 0xff) << 8;\n  this.pad[7] = key[30] & 0xff | (key[31] & 0xff) << 8;\n};\n\npoly1305.prototype.blocks = function(m, mpos, bytes) {\n  var hibit = this.fin ? 0 : (1 << 11);\n  var t0, t1, t2, t3, t4, t5, t6, t7, c;\n  var d0, d1, d2, d3, d4, d5, d6, d7, d8, d9;\n\n  var h0 = this.h[0],\n      h1 = this.h[1],\n      h2 = this.h[2],\n      h3 = this.h[3],\n      h4 = this.h[4],\n      h5 = this.h[5],\n      h6 = this.h[6],\n      h7 = this.h[7],\n      h8 = this.h[8],\n      h9 = this.h[9];\n\n  var r0 = this.r[0],\n      r1 = this.r[1],\n      r2 = this.r[2],\n      r3 = this.r[3],\n      r4 = this.r[4],\n      r5 = this.r[5],\n      r6 = this.r[6],\n      r7 = this.r[7],\n      r8 = this.r[8],\n      r9 = this.r[9];\n\n  while (bytes >= 16) {\n    t0 = m[mpos+ 0] & 0xff | (m[mpos+ 1] & 0xff) << 8; h0 += ( t0                     ) & 0x1fff;\n    t1 = m[mpos+ 2] & 0xff | (m[mpos+ 3] & 0xff) << 8; h1 += ((t0 >>> 13) | (t1 <<  3)) & 0x1fff;\n    t2 = m[mpos+ 4] & 0xff | (m[mpos+ 5] & 0xff) << 8; h2 += ((t1 >>> 10) | (t2 <<  6)) & 0x1fff;\n    t3 = m[mpos+ 6] & 0xff | (m[mpos+ 7] & 0xff) << 8; h3 += ((t2 >>>  7) | (t3 <<  9)) & 0x1fff;\n    t4 = m[mpos+ 8] & 0xff | (m[mpos+ 9] & 0xff) << 8; h4 += ((t3 >>>  4) | (t4 << 12)) & 0x1fff;\n    h5 += ((t4 >>>  1)) & 0x1fff;\n    t5 = m[mpos+10] & 0xff | (m[mpos+11] & 0xff) << 8; h6 += ((t4 >>> 14) | (t5 <<  2)) & 0x1fff;\n    t6 = m[mpos+12] & 0xff | (m[mpos+13] & 0xff) << 8; h7 += ((t5 >>> 11) | (t6 <<  5)) & 0x1fff;\n    t7 = m[mpos+14] & 0xff | (m[mpos+15] & 0xff) << 8; h8 += ((t6 >>>  8) | (t7 <<  8)) & 0x1fff;\n    h9 += ((t7 >>> 5)) | hibit;\n\n    c = 0;\n\n    d0 = c;\n    d0 += h0 * r0;\n    d0 += h1 * (5 * r9);\n    d0 += h2 * (5 * r8);\n    d0 += h3 * (5 * r7);\n    d0 += h4 * (5 * r6);\n    c = (d0 >>> 13); d0 &= 0x1fff;\n    d0 += h5 * (5 * r5);\n    d0 += h6 * (5 * r4);\n    d0 += h7 * (5 * r3);\n    d0 += h8 * (5 * r2);\n    d0 += h9 * (5 * r1);\n    c += (d0 >>> 13); d0 &= 0x1fff;\n\n    d1 = c;\n    d1 += h0 * r1;\n    d1 += h1 * r0;\n    d1 += h2 * (5 * r9);\n    d1 += h3 * (5 * r8);\n    d1 += h4 * (5 * r7);\n    c = (d1 >>> 13); d1 &= 0x1fff;\n    d1 += h5 * (5 * r6);\n    d1 += h6 * (5 * r5);\n    d1 += h7 * (5 * r4);\n    d1 += h8 * (5 * r3);\n    d1 += h9 * (5 * r2);\n    c += (d1 >>> 13); d1 &= 0x1fff;\n\n    d2 = c;\n    d2 += h0 * r2;\n    d2 += h1 * r1;\n    d2 += h2 * r0;\n    d2 += h3 * (5 * r9);\n    d2 += h4 * (5 * r8);\n    c = (d2 >>> 13); d2 &= 0x1fff;\n    d2 += h5 * (5 * r7);\n    d2 += h6 * (5 * r6);\n    d2 += h7 * (5 * r5);\n    d2 += h8 * (5 * r4);\n    d2 += h9 * (5 * r3);\n    c += (d2 >>> 13); d2 &= 0x1fff;\n\n    d3 = c;\n    d3 += h0 * r3;\n    d3 += h1 * r2;\n    d3 += h2 * r1;\n    d3 += h3 * r0;\n    d3 += h4 * (5 * r9);\n    c = (d3 >>> 13); d3 &= 0x1fff;\n    d3 += h5 * (5 * r8);\n    d3 += h6 * (5 * r7);\n    d3 += h7 * (5 * r6);\n    d3 += h8 * (5 * r5);\n    d3 += h9 * (5 * r4);\n    c += (d3 >>> 13); d3 &= 0x1fff;\n\n    d4 = c;\n    d4 += h0 * r4;\n    d4 += h1 * r3;\n    d4 += h2 * r2;\n    d4 += h3 * r1;\n    d4 += h4 * r0;\n    c = (d4 >>> 13); d4 &= 0x1fff;\n    d4 += h5 * (5 * r9);\n    d4 += h6 * (5 * r8);\n    d4 += h7 * (5 * r7);\n    d4 += h8 * (5 * r6);\n    d4 += h9 * (5 * r5);\n    c += (d4 >>> 13); d4 &= 0x1fff;\n\n    d5 = c;\n    d5 += h0 * r5;\n    d5 += h1 * r4;\n    d5 += h2 * r3;\n    d5 += h3 * r2;\n    d5 += h4 * r1;\n    c = (d5 >>> 13); d5 &= 0x1fff;\n    d5 += h5 * r0;\n    d5 += h6 * (5 * r9);\n    d5 += h7 * (5 * r8);\n    d5 += h8 * (5 * r7);\n    d5 += h9 * (5 * r6);\n    c += (d5 >>> 13); d5 &= 0x1fff;\n\n    d6 = c;\n    d6 += h0 * r6;\n    d6 += h1 * r5;\n    d6 += h2 * r4;\n    d6 += h3 * r3;\n    d6 += h4 * r2;\n    c = (d6 >>> 13); d6 &= 0x1fff;\n    d6 += h5 * r1;\n    d6 += h6 * r0;\n    d6 += h7 * (5 * r9);\n    d6 += h8 * (5 * r8);\n    d6 += h9 * (5 * r7);\n    c += (d6 >>> 13); d6 &= 0x1fff;\n\n    d7 = c;\n    d7 += h0 * r7;\n    d7 += h1 * r6;\n    d7 += h2 * r5;\n    d7 += h3 * r4;\n    d7 += h4 * r3;\n    c = (d7 >>> 13); d7 &= 0x1fff;\n    d7 += h5 * r2;\n    d7 += h6 * r1;\n    d7 += h7 * r0;\n    d7 += h8 * (5 * r9);\n    d7 += h9 * (5 * r8);\n    c += (d7 >>> 13); d7 &= 0x1fff;\n\n    d8 = c;\n    d8 += h0 * r8;\n    d8 += h1 * r7;\n    d8 += h2 * r6;\n    d8 += h3 * r5;\n    d8 += h4 * r4;\n    c = (d8 >>> 13); d8 &= 0x1fff;\n    d8 += h5 * r3;\n    d8 += h6 * r2;\n    d8 += h7 * r1;\n    d8 += h8 * r0;\n    d8 += h9 * (5 * r9);\n    c += (d8 >>> 13); d8 &= 0x1fff;\n\n    d9 = c;\n    d9 += h0 * r9;\n    d9 += h1 * r8;\n    d9 += h2 * r7;\n    d9 += h3 * r6;\n    d9 += h4 * r5;\n    c = (d9 >>> 13); d9 &= 0x1fff;\n    d9 += h5 * r4;\n    d9 += h6 * r3;\n    d9 += h7 * r2;\n    d9 += h8 * r1;\n    d9 += h9 * r0;\n    c += (d9 >>> 13); d9 &= 0x1fff;\n\n    c = (((c << 2) + c)) | 0;\n    c = (c + d0) | 0;\n    d0 = c & 0x1fff;\n    c = (c >>> 13);\n    d1 += c;\n\n    h0 = d0;\n    h1 = d1;\n    h2 = d2;\n    h3 = d3;\n    h4 = d4;\n    h5 = d5;\n    h6 = d6;\n    h7 = d7;\n    h8 = d8;\n    h9 = d9;\n\n    mpos += 16;\n    bytes -= 16;\n  }\n  this.h[0] = h0;\n  this.h[1] = h1;\n  this.h[2] = h2;\n  this.h[3] = h3;\n  this.h[4] = h4;\n  this.h[5] = h5;\n  this.h[6] = h6;\n  this.h[7] = h7;\n  this.h[8] = h8;\n  this.h[9] = h9;\n};\n\npoly1305.prototype.finish = function(mac, macpos) {\n  var g = new Uint16Array(10);\n  var c, mask, f, i;\n\n  if (this.leftover) {\n    i = this.leftover;\n    this.buffer[i++] = 1;\n    for (; i < 16; i++) this.buffer[i] = 0;\n    this.fin = 1;\n    this.blocks(this.buffer, 0, 16);\n  }\n\n  c = this.h[1] >>> 13;\n  this.h[1] &= 0x1fff;\n  for (i = 2; i < 10; i++) {\n    this.h[i] += c;\n    c = this.h[i] >>> 13;\n    this.h[i] &= 0x1fff;\n  }\n  this.h[0] += (c * 5);\n  c = this.h[0] >>> 13;\n  this.h[0] &= 0x1fff;\n  this.h[1] += c;\n  c = this.h[1] >>> 13;\n  this.h[1] &= 0x1fff;\n  this.h[2] += c;\n\n  g[0] = this.h[0] + 5;\n  c = g[0] >>> 13;\n  g[0] &= 0x1fff;\n  for (i = 1; i < 10; i++) {\n    g[i] = this.h[i] + c;\n    c = g[i] >>> 13;\n    g[i] &= 0x1fff;\n  }\n  g[9] -= (1 << 13);\n\n  mask = (c ^ 1) - 1;\n  for (i = 0; i < 10; i++) g[i] &= mask;\n  mask = ~mask;\n  for (i = 0; i < 10; i++) this.h[i] = (this.h[i] & mask) | g[i];\n\n  this.h[0] = ((this.h[0]       ) | (this.h[1] << 13)                    ) & 0xffff;\n  this.h[1] = ((this.h[1] >>>  3) | (this.h[2] << 10)                    ) & 0xffff;\n  this.h[2] = ((this.h[2] >>>  6) | (this.h[3] <<  7)                    ) & 0xffff;\n  this.h[3] = ((this.h[3] >>>  9) | (this.h[4] <<  4)                    ) & 0xffff;\n  this.h[4] = ((this.h[4] >>> 12) | (this.h[5] <<  1) | (this.h[6] << 14)) & 0xffff;\n  this.h[5] = ((this.h[6] >>>  2) | (this.h[7] << 11)                    ) & 0xffff;\n  this.h[6] = ((this.h[7] >>>  5) | (this.h[8] <<  8)                    ) & 0xffff;\n  this.h[7] = ((this.h[8] >>>  8) | (this.h[9] <<  5)                    ) & 0xffff;\n\n  f = this.h[0] + this.pad[0];\n  this.h[0] = f & 0xffff;\n  for (i = 1; i < 8; i++) {\n    f = (((this.h[i] + this.pad[i]) | 0) + (f >>> 16)) | 0;\n    this.h[i] = f & 0xffff;\n  }\n\n  mac[macpos+ 0] = (this.h[0] >>> 0) & 0xff;\n  mac[macpos+ 1] = (this.h[0] >>> 8) & 0xff;\n  mac[macpos+ 2] = (this.h[1] >>> 0) & 0xff;\n  mac[macpos+ 3] = (this.h[1] >>> 8) & 0xff;\n  mac[macpos+ 4] = (this.h[2] >>> 0) & 0xff;\n  mac[macpos+ 5] = (this.h[2] >>> 8) & 0xff;\n  mac[macpos+ 6] = (this.h[3] >>> 0) & 0xff;\n  mac[macpos+ 7] = (this.h[3] >>> 8) & 0xff;\n  mac[macpos+ 8] = (this.h[4] >>> 0) & 0xff;\n  mac[macpos+ 9] = (this.h[4] >>> 8) & 0xff;\n  mac[macpos+10] = (this.h[5] >>> 0) & 0xff;\n  mac[macpos+11] = (this.h[5] >>> 8) & 0xff;\n  mac[macpos+12] = (this.h[6] >>> 0) & 0xff;\n  mac[macpos+13] = (this.h[6] >>> 8) & 0xff;\n  mac[macpos+14] = (this.h[7] >>> 0) & 0xff;\n  mac[macpos+15] = (this.h[7] >>> 8) & 0xff;\n};\n\npoly1305.prototype.update = function(m, mpos, bytes) {\n  var i, want;\n\n  if (this.leftover) {\n    want = (16 - this.leftover);\n    if (want > bytes)\n      want = bytes;\n    for (i = 0; i < want; i++)\n      this.buffer[this.leftover + i] = m[mpos+i];\n    bytes -= want;\n    mpos += want;\n    this.leftover += want;\n    if (this.leftover < 16)\n      return;\n    this.blocks(this.buffer, 0, 16);\n    this.leftover = 0;\n  }\n\n  if (bytes >= 16) {\n    want = bytes - (bytes % 16);\n    this.blocks(m, mpos, want);\n    mpos += want;\n    bytes -= want;\n  }\n\n  if (bytes) {\n    for (i = 0; i < bytes; i++)\n      this.buffer[this.leftover + i] = m[mpos+i];\n    this.leftover += bytes;\n  }\n};\n\nfunction crypto_onetimeauth(out, outpos, m, mpos, n, k) {\n  var s = new poly1305(k);\n  s.update(m, mpos, n);\n  s.finish(out, outpos);\n  return 0;\n}\n\nfunction crypto_onetimeauth_verify(h, hpos, m, mpos, n, k) {\n  var x = new Uint8Array(16);\n  crypto_onetimeauth(x,0,m,mpos,n,k);\n  return crypto_verify_16(h,hpos,x,0);\n}\n\nfunction crypto_secretbox(c,m,d,n,k) {\n  var i;\n  if (d < 32) return -1;\n  crypto_stream_xor(c,0,m,0,d,n,k);\n  crypto_onetimeauth(c, 16, c, 32, d - 32, c);\n  for (i = 0; i < 16; i++) c[i] = 0;\n  return 0;\n}\n\nfunction crypto_secretbox_open(m,c,d,n,k) {\n  var i;\n  var x = new Uint8Array(32);\n  if (d < 32) return -1;\n  crypto_stream(x,0,32,n,k);\n  if (crypto_onetimeauth_verify(c, 16,c, 32,d - 32,x) !== 0) return -1;\n  crypto_stream_xor(m,0,c,0,d,n,k);\n  for (i = 0; i < 32; i++) m[i] = 0;\n  return 0;\n}\n\nfunction set25519(r, a) {\n  var i;\n  for (i = 0; i < 16; i++) r[i] = a[i]|0;\n}\n\nfunction car25519(o) {\n  var i, v, c = 1;\n  for (i = 0; i < 16; i++) {\n    v = o[i] + c + 65535;\n    c = Math.floor(v / 65536);\n    o[i] = v - c * 65536;\n  }\n  o[0] += c-1 + 37 * (c-1);\n}\n\nfunction sel25519(p, q, b) {\n  var t, c = ~(b-1);\n  for (var i = 0; i < 16; i++) {\n    t = c & (p[i] ^ q[i]);\n    p[i] ^= t;\n    q[i] ^= t;\n  }\n}\n\nfunction pack25519(o, n) {\n  var i, j, b;\n  var m = gf(), t = gf();\n  for (i = 0; i < 16; i++) t[i] = n[i];\n  car25519(t);\n  car25519(t);\n  car25519(t);\n  for (j = 0; j < 2; j++) {\n    m[0] = t[0] - 0xffed;\n    for (i = 1; i < 15; i++) {\n      m[i] = t[i] - 0xffff - ((m[i-1]>>16) & 1);\n      m[i-1] &= 0xffff;\n    }\n    m[15] = t[15] - 0x7fff - ((m[14]>>16) & 1);\n    b = (m[15]>>16) & 1;\n    m[14] &= 0xffff;\n    sel25519(t, m, 1-b);\n  }\n  for (i = 0; i < 16; i++) {\n    o[2*i] = t[i] & 0xff;\n    o[2*i+1] = t[i]>>8;\n  }\n}\n\nfunction neq25519(a, b) {\n  var c = new Uint8Array(32), d = new Uint8Array(32);\n  pack25519(c, a);\n  pack25519(d, b);\n  return crypto_verify_32(c, 0, d, 0);\n}\n\nfunction par25519(a) {\n  var d = new Uint8Array(32);\n  pack25519(d, a);\n  return d[0] & 1;\n}\n\nfunction unpack25519(o, n) {\n  var i;\n  for (i = 0; i < 16; i++) o[i] = n[2*i] + (n[2*i+1] << 8);\n  o[15] &= 0x7fff;\n}\n\nfunction A(o, a, b) {\n  for (var i = 0; i < 16; i++) o[i] = a[i] + b[i];\n}\n\nfunction Z(o, a, b) {\n  for (var i = 0; i < 16; i++) o[i] = a[i] - b[i];\n}\n\nfunction M(o, a, b) {\n  var v, c,\n     t0 = 0,  t1 = 0,  t2 = 0,  t3 = 0,  t4 = 0,  t5 = 0,  t6 = 0,  t7 = 0,\n     t8 = 0,  t9 = 0, t10 = 0, t11 = 0, t12 = 0, t13 = 0, t14 = 0, t15 = 0,\n    t16 = 0, t17 = 0, t18 = 0, t19 = 0, t20 = 0, t21 = 0, t22 = 0, t23 = 0,\n    t24 = 0, t25 = 0, t26 = 0, t27 = 0, t28 = 0, t29 = 0, t30 = 0,\n    b0 = b[0],\n    b1 = b[1],\n    b2 = b[2],\n    b3 = b[3],\n    b4 = b[4],\n    b5 = b[5],\n    b6 = b[6],\n    b7 = b[7],\n    b8 = b[8],\n    b9 = b[9],\n    b10 = b[10],\n    b11 = b[11],\n    b12 = b[12],\n    b13 = b[13],\n    b14 = b[14],\n    b15 = b[15];\n\n  v = a[0];\n  t0 += v * b0;\n  t1 += v * b1;\n  t2 += v * b2;\n  t3 += v * b3;\n  t4 += v * b4;\n  t5 += v * b5;\n  t6 += v * b6;\n  t7 += v * b7;\n  t8 += v * b8;\n  t9 += v * b9;\n  t10 += v * b10;\n  t11 += v * b11;\n  t12 += v * b12;\n  t13 += v * b13;\n  t14 += v * b14;\n  t15 += v * b15;\n  v = a[1];\n  t1 += v * b0;\n  t2 += v * b1;\n  t3 += v * b2;\n  t4 += v * b3;\n  t5 += v * b4;\n  t6 += v * b5;\n  t7 += v * b6;\n  t8 += v * b7;\n  t9 += v * b8;\n  t10 += v * b9;\n  t11 += v * b10;\n  t12 += v * b11;\n  t13 += v * b12;\n  t14 += v * b13;\n  t15 += v * b14;\n  t16 += v * b15;\n  v = a[2];\n  t2 += v * b0;\n  t3 += v * b1;\n  t4 += v * b2;\n  t5 += v * b3;\n  t6 += v * b4;\n  t7 += v * b5;\n  t8 += v * b6;\n  t9 += v * b7;\n  t10 += v * b8;\n  t11 += v * b9;\n  t12 += v * b10;\n  t13 += v * b11;\n  t14 += v * b12;\n  t15 += v * b13;\n  t16 += v * b14;\n  t17 += v * b15;\n  v = a[3];\n  t3 += v * b0;\n  t4 += v * b1;\n  t5 += v * b2;\n  t6 += v * b3;\n  t7 += v * b4;\n  t8 += v * b5;\n  t9 += v * b6;\n  t10 += v * b7;\n  t11 += v * b8;\n  t12 += v * b9;\n  t13 += v * b10;\n  t14 += v * b11;\n  t15 += v * b12;\n  t16 += v * b13;\n  t17 += v * b14;\n  t18 += v * b15;\n  v = a[4];\n  t4 += v * b0;\n  t5 += v * b1;\n  t6 += v * b2;\n  t7 += v * b3;\n  t8 += v * b4;\n  t9 += v * b5;\n  t10 += v * b6;\n  t11 += v * b7;\n  t12 += v * b8;\n  t13 += v * b9;\n  t14 += v * b10;\n  t15 += v * b11;\n  t16 += v * b12;\n  t17 += v * b13;\n  t18 += v * b14;\n  t19 += v * b15;\n  v = a[5];\n  t5 += v * b0;\n  t6 += v * b1;\n  t7 += v * b2;\n  t8 += v * b3;\n  t9 += v * b4;\n  t10 += v * b5;\n  t11 += v * b6;\n  t12 += v * b7;\n  t13 += v * b8;\n  t14 += v * b9;\n  t15 += v * b10;\n  t16 += v * b11;\n  t17 += v * b12;\n  t18 += v * b13;\n  t19 += v * b14;\n  t20 += v * b15;\n  v = a[6];\n  t6 += v * b0;\n  t7 += v * b1;\n  t8 += v * b2;\n  t9 += v * b3;\n  t10 += v * b4;\n  t11 += v * b5;\n  t12 += v * b6;\n  t13 += v * b7;\n  t14 += v * b8;\n  t15 += v * b9;\n  t16 += v * b10;\n  t17 += v * b11;\n  t18 += v * b12;\n  t19 += v * b13;\n  t20 += v * b14;\n  t21 += v * b15;\n  v = a[7];\n  t7 += v * b0;\n  t8 += v * b1;\n  t9 += v * b2;\n  t10 += v * b3;\n  t11 += v * b4;\n  t12 += v * b5;\n  t13 += v * b6;\n  t14 += v * b7;\n  t15 += v * b8;\n  t16 += v * b9;\n  t17 += v * b10;\n  t18 += v * b11;\n  t19 += v * b12;\n  t20 += v * b13;\n  t21 += v * b14;\n  t22 += v * b15;\n  v = a[8];\n  t8 += v * b0;\n  t9 += v * b1;\n  t10 += v * b2;\n  t11 += v * b3;\n  t12 += v * b4;\n  t13 += v * b5;\n  t14 += v * b6;\n  t15 += v * b7;\n  t16 += v * b8;\n  t17 += v * b9;\n  t18 += v * b10;\n  t19 += v * b11;\n  t20 += v * b12;\n  t21 += v * b13;\n  t22 += v * b14;\n  t23 += v * b15;\n  v = a[9];\n  t9 += v * b0;\n  t10 += v * b1;\n  t11 += v * b2;\n  t12 += v * b3;\n  t13 += v * b4;\n  t14 += v * b5;\n  t15 += v * b6;\n  t16 += v * b7;\n  t17 += v * b8;\n  t18 += v * b9;\n  t19 += v * b10;\n  t20 += v * b11;\n  t21 += v * b12;\n  t22 += v * b13;\n  t23 += v * b14;\n  t24 += v * b15;\n  v = a[10];\n  t10 += v * b0;\n  t11 += v * b1;\n  t12 += v * b2;\n  t13 += v * b3;\n  t14 += v * b4;\n  t15 += v * b5;\n  t16 += v * b6;\n  t17 += v * b7;\n  t18 += v * b8;\n  t19 += v * b9;\n  t20 += v * b10;\n  t21 += v * b11;\n  t22 += v * b12;\n  t23 += v * b13;\n  t24 += v * b14;\n  t25 += v * b15;\n  v = a[11];\n  t11 += v * b0;\n  t12 += v * b1;\n  t13 += v * b2;\n  t14 += v * b3;\n  t15 += v * b4;\n  t16 += v * b5;\n  t17 += v * b6;\n  t18 += v * b7;\n  t19 += v * b8;\n  t20 += v * b9;\n  t21 += v * b10;\n  t22 += v * b11;\n  t23 += v * b12;\n  t24 += v * b13;\n  t25 += v * b14;\n  t26 += v * b15;\n  v = a[12];\n  t12 += v * b0;\n  t13 += v * b1;\n  t14 += v * b2;\n  t15 += v * b3;\n  t16 += v * b4;\n  t17 += v * b5;\n  t18 += v * b6;\n  t19 += v * b7;\n  t20 += v * b8;\n  t21 += v * b9;\n  t22 += v * b10;\n  t23 += v * b11;\n  t24 += v * b12;\n  t25 += v * b13;\n  t26 += v * b14;\n  t27 += v * b15;\n  v = a[13];\n  t13 += v * b0;\n  t14 += v * b1;\n  t15 += v * b2;\n  t16 += v * b3;\n  t17 += v * b4;\n  t18 += v * b5;\n  t19 += v * b6;\n  t20 += v * b7;\n  t21 += v * b8;\n  t22 += v * b9;\n  t23 += v * b10;\n  t24 += v * b11;\n  t25 += v * b12;\n  t26 += v * b13;\n  t27 += v * b14;\n  t28 += v * b15;\n  v = a[14];\n  t14 += v * b0;\n  t15 += v * b1;\n  t16 += v * b2;\n  t17 += v * b3;\n  t18 += v * b4;\n  t19 += v * b5;\n  t20 += v * b6;\n  t21 += v * b7;\n  t22 += v * b8;\n  t23 += v * b9;\n  t24 += v * b10;\n  t25 += v * b11;\n  t26 += v * b12;\n  t27 += v * b13;\n  t28 += v * b14;\n  t29 += v * b15;\n  v = a[15];\n  t15 += v * b0;\n  t16 += v * b1;\n  t17 += v * b2;\n  t18 += v * b3;\n  t19 += v * b4;\n  t20 += v * b5;\n  t21 += v * b6;\n  t22 += v * b7;\n  t23 += v * b8;\n  t24 += v * b9;\n  t25 += v * b10;\n  t26 += v * b11;\n  t27 += v * b12;\n  t28 += v * b13;\n  t29 += v * b14;\n  t30 += v * b15;\n\n  t0  += 38 * t16;\n  t1  += 38 * t17;\n  t2  += 38 * t18;\n  t3  += 38 * t19;\n  t4  += 38 * t20;\n  t5  += 38 * t21;\n  t6  += 38 * t22;\n  t7  += 38 * t23;\n  t8  += 38 * t24;\n  t9  += 38 * t25;\n  t10 += 38 * t26;\n  t11 += 38 * t27;\n  t12 += 38 * t28;\n  t13 += 38 * t29;\n  t14 += 38 * t30;\n  // t15 left as is\n\n  // first car\n  c = 1;\n  v =  t0 + c + 65535; c = Math.floor(v / 65536);  t0 = v - c * 65536;\n  v =  t1 + c + 65535; c = Math.floor(v / 65536);  t1 = v - c * 65536;\n  v =  t2 + c + 65535; c = Math.floor(v / 65536);  t2 = v - c * 65536;\n  v =  t3 + c + 65535; c = Math.floor(v / 65536);  t3 = v - c * 65536;\n  v =  t4 + c + 65535; c = Math.floor(v / 65536);  t4 = v - c * 65536;\n  v =  t5 + c + 65535; c = Math.floor(v / 65536);  t5 = v - c * 65536;\n  v =  t6 + c + 65535; c = Math.floor(v / 65536);  t6 = v - c * 65536;\n  v =  t7 + c + 65535; c = Math.floor(v / 65536);  t7 = v - c * 65536;\n  v =  t8 + c + 65535; c = Math.floor(v / 65536);  t8 = v - c * 65536;\n  v =  t9 + c + 65535; c = Math.floor(v / 65536);  t9 = v - c * 65536;\n  v = t10 + c + 65535; c = Math.floor(v / 65536); t10 = v - c * 65536;\n  v = t11 + c + 65535; c = Math.floor(v / 65536); t11 = v - c * 65536;\n  v = t12 + c + 65535; c = Math.floor(v / 65536); t12 = v - c * 65536;\n  v = t13 + c + 65535; c = Math.floor(v / 65536); t13 = v - c * 65536;\n  v = t14 + c + 65535; c = Math.floor(v / 65536); t14 = v - c * 65536;\n  v = t15 + c + 65535; c = Math.floor(v / 65536); t15 = v - c * 65536;\n  t0 += c-1 + 37 * (c-1);\n\n  // second car\n  c = 1;\n  v =  t0 + c + 65535; c = Math.floor(v / 65536);  t0 = v - c * 65536;\n  v =  t1 + c + 65535; c = Math.floor(v / 65536);  t1 = v - c * 65536;\n  v =  t2 + c + 65535; c = Math.floor(v / 65536);  t2 = v - c * 65536;\n  v =  t3 + c + 65535; c = Math.floor(v / 65536);  t3 = v - c * 65536;\n  v =  t4 + c + 65535; c = Math.floor(v / 65536);  t4 = v - c * 65536;\n  v =  t5 + c + 65535; c = Math.floor(v / 65536);  t5 = v - c * 65536;\n  v =  t6 + c + 65535; c = Math.floor(v / 65536);  t6 = v - c * 65536;\n  v =  t7 + c + 65535; c = Math.floor(v / 65536);  t7 = v - c * 65536;\n  v =  t8 + c + 65535; c = Math.floor(v / 65536);  t8 = v - c * 65536;\n  v =  t9 + c + 65535; c = Math.floor(v / 65536);  t9 = v - c * 65536;\n  v = t10 + c + 65535; c = Math.floor(v / 65536); t10 = v - c * 65536;\n  v = t11 + c + 65535; c = Math.floor(v / 65536); t11 = v - c * 65536;\n  v = t12 + c + 65535; c = Math.floor(v / 65536); t12 = v - c * 65536;\n  v = t13 + c + 65535; c = Math.floor(v / 65536); t13 = v - c * 65536;\n  v = t14 + c + 65535; c = Math.floor(v / 65536); t14 = v - c * 65536;\n  v = t15 + c + 65535; c = Math.floor(v / 65536); t15 = v - c * 65536;\n  t0 += c-1 + 37 * (c-1);\n\n  o[ 0] = t0;\n  o[ 1] = t1;\n  o[ 2] = t2;\n  o[ 3] = t3;\n  o[ 4] = t4;\n  o[ 5] = t5;\n  o[ 6] = t6;\n  o[ 7] = t7;\n  o[ 8] = t8;\n  o[ 9] = t9;\n  o[10] = t10;\n  o[11] = t11;\n  o[12] = t12;\n  o[13] = t13;\n  o[14] = t14;\n  o[15] = t15;\n}\n\nfunction S(o, a) {\n  M(o, a, a);\n}\n\nfunction inv25519(o, i) {\n  var c = gf();\n  var a;\n  for (a = 0; a < 16; a++) c[a] = i[a];\n  for (a = 253; a >= 0; a--) {\n    S(c, c);\n    if(a !== 2 && a !== 4) M(c, c, i);\n  }\n  for (a = 0; a < 16; a++) o[a] = c[a];\n}\n\nfunction pow2523(o, i) {\n  var c = gf();\n  var a;\n  for (a = 0; a < 16; a++) c[a] = i[a];\n  for (a = 250; a >= 0; a--) {\n      S(c, c);\n      if(a !== 1) M(c, c, i);\n  }\n  for (a = 0; a < 16; a++) o[a] = c[a];\n}\n\nfunction crypto_scalarmult(q, n, p) {\n  var z = new Uint8Array(32);\n  var x = new Float64Array(80), r, i;\n  var a = gf(), b = gf(), c = gf(),\n      d = gf(), e = gf(), f = gf();\n  for (i = 0; i < 31; i++) z[i] = n[i];\n  z[31]=(n[31]&127)|64;\n  z[0]&=248;\n  unpack25519(x,p);\n  for (i = 0; i < 16; i++) {\n    b[i]=x[i];\n    d[i]=a[i]=c[i]=0;\n  }\n  a[0]=d[0]=1;\n  for (i=254; i>=0; --i) {\n    r=(z[i>>>3]>>>(i&7))&1;\n    sel25519(a,b,r);\n    sel25519(c,d,r);\n    A(e,a,c);\n    Z(a,a,c);\n    A(c,b,d);\n    Z(b,b,d);\n    S(d,e);\n    S(f,a);\n    M(a,c,a);\n    M(c,b,e);\n    A(e,a,c);\n    Z(a,a,c);\n    S(b,a);\n    Z(c,d,f);\n    M(a,c,_121665);\n    A(a,a,d);\n    M(c,c,a);\n    M(a,d,f);\n    M(d,b,x);\n    S(b,e);\n    sel25519(a,b,r);\n    sel25519(c,d,r);\n  }\n  for (i = 0; i < 16; i++) {\n    x[i+16]=a[i];\n    x[i+32]=c[i];\n    x[i+48]=b[i];\n    x[i+64]=d[i];\n  }\n  var x32 = x.subarray(32);\n  var x16 = x.subarray(16);\n  inv25519(x32,x32);\n  M(x16,x16,x32);\n  pack25519(q,x16);\n  return 0;\n}\n\nfunction crypto_scalarmult_base(q, n) {\n  return crypto_scalarmult(q, n, _9);\n}\n\nfunction crypto_box_keypair(y, x) {\n  randombytes(x, 32);\n  return crypto_scalarmult_base(y, x);\n}\n\nfunction crypto_box_beforenm(k, y, x) {\n  var s = new Uint8Array(32);\n  crypto_scalarmult(s, x, y);\n  return crypto_core_hsalsa20(k, _0, s, sigma);\n}\n\nvar crypto_box_afternm = crypto_secretbox;\nvar crypto_box_open_afternm = crypto_secretbox_open;\n\nfunction crypto_box(c, m, d, n, y, x) {\n  var k = new Uint8Array(32);\n  crypto_box_beforenm(k, y, x);\n  return crypto_box_afternm(c, m, d, n, k);\n}\n\nfunction crypto_box_open(m, c, d, n, y, x) {\n  var k = new Uint8Array(32);\n  crypto_box_beforenm(k, y, x);\n  return crypto_box_open_afternm(m, c, d, n, k);\n}\n\nvar K = [\n  0x428a2f98, 0xd728ae22, 0x71374491, 0x23ef65cd,\n  0xb5c0fbcf, 0xec4d3b2f, 0xe9b5dba5, 0x8189dbbc,\n  0x3956c25b, 0xf348b538, 0x59f111f1, 0xb605d019,\n  0x923f82a4, 0xaf194f9b, 0xab1c5ed5, 0xda6d8118,\n  0xd807aa98, 0xa3030242, 0x12835b01, 0x45706fbe,\n  0x243185be, 0x4ee4b28c, 0x550c7dc3, 0xd5ffb4e2,\n  0x72be5d74, 0xf27b896f, 0x80deb1fe, 0x3b1696b1,\n  0x9bdc06a7, 0x25c71235, 0xc19bf174, 0xcf692694,\n  0xe49b69c1, 0x9ef14ad2, 0xefbe4786, 0x384f25e3,\n  0x0fc19dc6, 0x8b8cd5b5, 0x240ca1cc, 0x77ac9c65,\n  0x2de92c6f, 0x592b0275, 0x4a7484aa, 0x6ea6e483,\n  0x5cb0a9dc, 0xbd41fbd4, 0x76f988da, 0x831153b5,\n  0x983e5152, 0xee66dfab, 0xa831c66d, 0x2db43210,\n  0xb00327c8, 0x98fb213f, 0xbf597fc7, 0xbeef0ee4,\n  0xc6e00bf3, 0x3da88fc2, 0xd5a79147, 0x930aa725,\n  0x06ca6351, 0xe003826f, 0x14292967, 0x0a0e6e70,\n  0x27b70a85, 0x46d22ffc, 0x2e1b2138, 0x5c26c926,\n  0x4d2c6dfc, 0x5ac42aed, 0x53380d13, 0x9d95b3df,\n  0x650a7354, 0x8baf63de, 0x766a0abb, 0x3c77b2a8,\n  0x81c2c92e, 0x47edaee6, 0x92722c85, 0x1482353b,\n  0xa2bfe8a1, 0x4cf10364, 0xa81a664b, 0xbc423001,\n  0xc24b8b70, 0xd0f89791, 0xc76c51a3, 0x0654be30,\n  0xd192e819, 0xd6ef5218, 0xd6990624, 0x5565a910,\n  0xf40e3585, 0x5771202a, 0x106aa070, 0x32bbd1b8,\n  0x19a4c116, 0xb8d2d0c8, 0x1e376c08, 0x5141ab53,\n  0x2748774c, 0xdf8eeb99, 0x34b0bcb5, 0xe19b48a8,\n  0x391c0cb3, 0xc5c95a63, 0x4ed8aa4a, 0xe3418acb,\n  0x5b9cca4f, 0x7763e373, 0x682e6ff3, 0xd6b2b8a3,\n  0x748f82ee, 0x5defb2fc, 0x78a5636f, 0x43172f60,\n  0x84c87814, 0xa1f0ab72, 0x8cc70208, 0x1a6439ec,\n  0x90befffa, 0x23631e28, 0xa4506ceb, 0xde82bde9,\n  0xbef9a3f7, 0xb2c67915, 0xc67178f2, 0xe372532b,\n  0xca273ece, 0xea26619c, 0xd186b8c7, 0x21c0c207,\n  0xeada7dd6, 0xcde0eb1e, 0xf57d4f7f, 0xee6ed178,\n  0x06f067aa, 0x72176fba, 0x0a637dc5, 0xa2c898a6,\n  0x113f9804, 0xbef90dae, 0x1b710b35, 0x131c471b,\n  0x28db77f5, 0x23047d84, 0x32caab7b, 0x40c72493,\n  0x3c9ebe0a, 0x15c9bebc, 0x431d67c4, 0x9c100d4c,\n  0x4cc5d4be, 0xcb3e42b6, 0x597f299c, 0xfc657e2a,\n  0x5fcb6fab, 0x3ad6faec, 0x6c44198c, 0x4a475817\n];\n\nfunction crypto_hashblocks_hl(hh, hl, m, n) {\n  var wh = new Int32Array(16), wl = new Int32Array(16),\n      bh0, bh1, bh2, bh3, bh4, bh5, bh6, bh7,\n      bl0, bl1, bl2, bl3, bl4, bl5, bl6, bl7,\n      th, tl, i, j, h, l, a, b, c, d;\n\n  var ah0 = hh[0],\n      ah1 = hh[1],\n      ah2 = hh[2],\n      ah3 = hh[3],\n      ah4 = hh[4],\n      ah5 = hh[5],\n      ah6 = hh[6],\n      ah7 = hh[7],\n\n      al0 = hl[0],\n      al1 = hl[1],\n      al2 = hl[2],\n      al3 = hl[3],\n      al4 = hl[4],\n      al5 = hl[5],\n      al6 = hl[6],\n      al7 = hl[7];\n\n  var pos = 0;\n  while (n >= 128) {\n    for (i = 0; i < 16; i++) {\n      j = 8 * i + pos;\n      wh[i] = (m[j+0] << 24) | (m[j+1] << 16) | (m[j+2] << 8) | m[j+3];\n      wl[i] = (m[j+4] << 24) | (m[j+5] << 16) | (m[j+6] << 8) | m[j+7];\n    }\n    for (i = 0; i < 80; i++) {\n      bh0 = ah0;\n      bh1 = ah1;\n      bh2 = ah2;\n      bh3 = ah3;\n      bh4 = ah4;\n      bh5 = ah5;\n      bh6 = ah6;\n      bh7 = ah7;\n\n      bl0 = al0;\n      bl1 = al1;\n      bl2 = al2;\n      bl3 = al3;\n      bl4 = al4;\n      bl5 = al5;\n      bl6 = al6;\n      bl7 = al7;\n\n      // add\n      h = ah7;\n      l = al7;\n\n      a = l & 0xffff; b = l >>> 16;\n      c = h & 0xffff; d = h >>> 16;\n\n      // Sigma1\n      h = ((ah4 >>> 14) | (al4 << (32-14))) ^ ((ah4 >>> 18) | (al4 << (32-18))) ^ ((al4 >>> (41-32)) | (ah4 << (32-(41-32))));\n      l = ((al4 >>> 14) | (ah4 << (32-14))) ^ ((al4 >>> 18) | (ah4 << (32-18))) ^ ((ah4 >>> (41-32)) | (al4 << (32-(41-32))));\n\n      a += l & 0xffff; b += l >>> 16;\n      c += h & 0xffff; d += h >>> 16;\n\n      // Ch\n      h = (ah4 & ah5) ^ (~ah4 & ah6);\n      l = (al4 & al5) ^ (~al4 & al6);\n\n      a += l & 0xffff; b += l >>> 16;\n      c += h & 0xffff; d += h >>> 16;\n\n      // K\n      h = K[i*2];\n      l = K[i*2+1];\n\n      a += l & 0xffff; b += l >>> 16;\n      c += h & 0xffff; d += h >>> 16;\n\n      // w\n      h = wh[i%16];\n      l = wl[i%16];\n\n      a += l & 0xffff; b += l >>> 16;\n      c += h & 0xffff; d += h >>> 16;\n\n      b += a >>> 16;\n      c += b >>> 16;\n      d += c >>> 16;\n\n      th = c & 0xffff | d << 16;\n      tl = a & 0xffff | b << 16;\n\n      // add\n      h = th;\n      l = tl;\n\n      a = l & 0xffff; b = l >>> 16;\n      c = h & 0xffff; d = h >>> 16;\n\n      // Sigma0\n      h = ((ah0 >>> 28) | (al0 << (32-28))) ^ ((al0 >>> (34-32)) | (ah0 << (32-(34-32)))) ^ ((al0 >>> (39-32)) | (ah0 << (32-(39-32))));\n      l = ((al0 >>> 28) | (ah0 << (32-28))) ^ ((ah0 >>> (34-32)) | (al0 << (32-(34-32)))) ^ ((ah0 >>> (39-32)) | (al0 << (32-(39-32))));\n\n      a += l & 0xffff; b += l >>> 16;\n      c += h & 0xffff; d += h >>> 16;\n\n      // Maj\n      h = (ah0 & ah1) ^ (ah0 & ah2) ^ (ah1 & ah2);\n      l = (al0 & al1) ^ (al0 & al2) ^ (al1 & al2);\n\n      a += l & 0xffff; b += l >>> 16;\n      c += h & 0xffff; d += h >>> 16;\n\n      b += a >>> 16;\n      c += b >>> 16;\n      d += c >>> 16;\n\n      bh7 = (c & 0xffff) | (d << 16);\n      bl7 = (a & 0xffff) | (b << 16);\n\n      // add\n      h = bh3;\n      l = bl3;\n\n      a = l & 0xffff; b = l >>> 16;\n      c = h & 0xffff; d = h >>> 16;\n\n      h = th;\n      l = tl;\n\n      a += l & 0xffff; b += l >>> 16;\n      c += h & 0xffff; d += h >>> 16;\n\n      b += a >>> 16;\n      c += b >>> 16;\n      d += c >>> 16;\n\n      bh3 = (c & 0xffff) | (d << 16);\n      bl3 = (a & 0xffff) | (b << 16);\n\n      ah1 = bh0;\n      ah2 = bh1;\n      ah3 = bh2;\n      ah4 = bh3;\n      ah5 = bh4;\n      ah6 = bh5;\n      ah7 = bh6;\n      ah0 = bh7;\n\n      al1 = bl0;\n      al2 = bl1;\n      al3 = bl2;\n      al4 = bl3;\n      al5 = bl4;\n      al6 = bl5;\n      al7 = bl6;\n      al0 = bl7;\n\n      if (i%16 === 15) {\n        for (j = 0; j < 16; j++) {\n          // add\n          h = wh[j];\n          l = wl[j];\n\n          a = l & 0xffff; b = l >>> 16;\n          c = h & 0xffff; d = h >>> 16;\n\n          h = wh[(j+9)%16];\n          l = wl[(j+9)%16];\n\n          a += l & 0xffff; b += l >>> 16;\n          c += h & 0xffff; d += h >>> 16;\n\n          // sigma0\n          th = wh[(j+1)%16];\n          tl = wl[(j+1)%16];\n          h = ((th >>> 1) | (tl << (32-1))) ^ ((th >>> 8) | (tl << (32-8))) ^ (th >>> 7);\n          l = ((tl >>> 1) | (th << (32-1))) ^ ((tl >>> 8) | (th << (32-8))) ^ ((tl >>> 7) | (th << (32-7)));\n\n          a += l & 0xffff; b += l >>> 16;\n          c += h & 0xffff; d += h >>> 16;\n\n          // sigma1\n          th = wh[(j+14)%16];\n          tl = wl[(j+14)%16];\n          h = ((th >>> 19) | (tl << (32-19))) ^ ((tl >>> (61-32)) | (th << (32-(61-32)))) ^ (th >>> 6);\n          l = ((tl >>> 19) | (th << (32-19))) ^ ((th >>> (61-32)) | (tl << (32-(61-32)))) ^ ((tl >>> 6) | (th << (32-6)));\n\n          a += l & 0xffff; b += l >>> 16;\n          c += h & 0xffff; d += h >>> 16;\n\n          b += a >>> 16;\n          c += b >>> 16;\n          d += c >>> 16;\n\n          wh[j] = (c & 0xffff) | (d << 16);\n          wl[j] = (a & 0xffff) | (b << 16);\n        }\n      }\n    }\n\n    // add\n    h = ah0;\n    l = al0;\n\n    a = l & 0xffff; b = l >>> 16;\n    c = h & 0xffff; d = h >>> 16;\n\n    h = hh[0];\n    l = hl[0];\n\n    a += l & 0xffff; b += l >>> 16;\n    c += h & 0xffff; d += h >>> 16;\n\n    b += a >>> 16;\n    c += b >>> 16;\n    d += c >>> 16;\n\n    hh[0] = ah0 = (c & 0xffff) | (d << 16);\n    hl[0] = al0 = (a & 0xffff) | (b << 16);\n\n    h = ah1;\n    l = al1;\n\n    a = l & 0xffff; b = l >>> 16;\n    c = h & 0xffff; d = h >>> 16;\n\n    h = hh[1];\n    l = hl[1];\n\n    a += l & 0xffff; b += l >>> 16;\n    c += h & 0xffff; d += h >>> 16;\n\n    b += a >>> 16;\n    c += b >>> 16;\n    d += c >>> 16;\n\n    hh[1] = ah1 = (c & 0xffff) | (d << 16);\n    hl[1] = al1 = (a & 0xffff) | (b << 16);\n\n    h = ah2;\n    l = al2;\n\n    a = l & 0xffff; b = l >>> 16;\n    c = h & 0xffff; d = h >>> 16;\n\n    h = hh[2];\n    l = hl[2];\n\n    a += l & 0xffff; b += l >>> 16;\n    c += h & 0xffff; d += h >>> 16;\n\n    b += a >>> 16;\n    c += b >>> 16;\n    d += c >>> 16;\n\n    hh[2] = ah2 = (c & 0xffff) | (d << 16);\n    hl[2] = al2 = (a & 0xffff) | (b << 16);\n\n    h = ah3;\n    l = al3;\n\n    a = l & 0xffff; b = l >>> 16;\n    c = h & 0xffff; d = h >>> 16;\n\n    h = hh[3];\n    l = hl[3];\n\n    a += l & 0xffff; b += l >>> 16;\n    c += h & 0xffff; d += h >>> 16;\n\n    b += a >>> 16;\n    c += b >>> 16;\n    d += c >>> 16;\n\n    hh[3] = ah3 = (c & 0xffff) | (d << 16);\n    hl[3] = al3 = (a & 0xffff) | (b << 16);\n\n    h = ah4;\n    l = al4;\n\n    a = l & 0xffff; b = l >>> 16;\n    c = h & 0xffff; d = h >>> 16;\n\n    h = hh[4];\n    l = hl[4];\n\n    a += l & 0xffff; b += l >>> 16;\n    c += h & 0xffff; d += h >>> 16;\n\n    b += a >>> 16;\n    c += b >>> 16;\n    d += c >>> 16;\n\n    hh[4] = ah4 = (c & 0xffff) | (d << 16);\n    hl[4] = al4 = (a & 0xffff) | (b << 16);\n\n    h = ah5;\n    l = al5;\n\n    a = l & 0xffff; b = l >>> 16;\n    c = h & 0xffff; d = h >>> 16;\n\n    h = hh[5];\n    l = hl[5];\n\n    a += l & 0xffff; b += l >>> 16;\n    c += h & 0xffff; d += h >>> 16;\n\n    b += a >>> 16;\n    c += b >>> 16;\n    d += c >>> 16;\n\n    hh[5] = ah5 = (c & 0xffff) | (d << 16);\n    hl[5] = al5 = (a & 0xffff) | (b << 16);\n\n    h = ah6;\n    l = al6;\n\n    a = l & 0xffff; b = l >>> 16;\n    c = h & 0xffff; d = h >>> 16;\n\n    h = hh[6];\n    l = hl[6];\n\n    a += l & 0xffff; b += l >>> 16;\n    c += h & 0xffff; d += h >>> 16;\n\n    b += a >>> 16;\n    c += b >>> 16;\n    d += c >>> 16;\n\n    hh[6] = ah6 = (c & 0xffff) | (d << 16);\n    hl[6] = al6 = (a & 0xffff) | (b << 16);\n\n    h = ah7;\n    l = al7;\n\n    a = l & 0xffff; b = l >>> 16;\n    c = h & 0xffff; d = h >>> 16;\n\n    h = hh[7];\n    l = hl[7];\n\n    a += l & 0xffff; b += l >>> 16;\n    c += h & 0xffff; d += h >>> 16;\n\n    b += a >>> 16;\n    c += b >>> 16;\n    d += c >>> 16;\n\n    hh[7] = ah7 = (c & 0xffff) | (d << 16);\n    hl[7] = al7 = (a & 0xffff) | (b << 16);\n\n    pos += 128;\n    n -= 128;\n  }\n\n  return n;\n}\n\nfunction crypto_hash(out, m, n) {\n  var hh = new Int32Array(8),\n      hl = new Int32Array(8),\n      x = new Uint8Array(256),\n      i, b = n;\n\n  hh[0] = 0x6a09e667;\n  hh[1] = 0xbb67ae85;\n  hh[2] = 0x3c6ef372;\n  hh[3] = 0xa54ff53a;\n  hh[4] = 0x510e527f;\n  hh[5] = 0x9b05688c;\n  hh[6] = 0x1f83d9ab;\n  hh[7] = 0x5be0cd19;\n\n  hl[0] = 0xf3bcc908;\n  hl[1] = 0x84caa73b;\n  hl[2] = 0xfe94f82b;\n  hl[3] = 0x5f1d36f1;\n  hl[4] = 0xade682d1;\n  hl[5] = 0x2b3e6c1f;\n  hl[6] = 0xfb41bd6b;\n  hl[7] = 0x137e2179;\n\n  crypto_hashblocks_hl(hh, hl, m, n);\n  n %= 128;\n\n  for (i = 0; i < n; i++) x[i] = m[b-n+i];\n  x[n] = 128;\n\n  n = 256-128*(n<112?1:0);\n  x[n-9] = 0;\n  ts64(x, n-8,  (b / 0x20000000) | 0, b << 3);\n  crypto_hashblocks_hl(hh, hl, x, n);\n\n  for (i = 0; i < 8; i++) ts64(out, 8*i, hh[i], hl[i]);\n\n  return 0;\n}\n\nfunction add(p, q) {\n  var a = gf(), b = gf(), c = gf(),\n      d = gf(), e = gf(), f = gf(),\n      g = gf(), h = gf(), t = gf();\n\n  Z(a, p[1], p[0]);\n  Z(t, q[1], q[0]);\n  M(a, a, t);\n  A(b, p[0], p[1]);\n  A(t, q[0], q[1]);\n  M(b, b, t);\n  M(c, p[3], q[3]);\n  M(c, c, D2);\n  M(d, p[2], q[2]);\n  A(d, d, d);\n  Z(e, b, a);\n  Z(f, d, c);\n  A(g, d, c);\n  A(h, b, a);\n\n  M(p[0], e, f);\n  M(p[1], h, g);\n  M(p[2], g, f);\n  M(p[3], e, h);\n}\n\nfunction cswap(p, q, b) {\n  var i;\n  for (i = 0; i < 4; i++) {\n    sel25519(p[i], q[i], b);\n  }\n}\n\nfunction pack(r, p) {\n  var tx = gf(), ty = gf(), zi = gf();\n  inv25519(zi, p[2]);\n  M(tx, p[0], zi);\n  M(ty, p[1], zi);\n  pack25519(r, ty);\n  r[31] ^= par25519(tx) << 7;\n}\n\nfunction scalarmult(p, q, s) {\n  var b, i;\n  set25519(p[0], gf0);\n  set25519(p[1], gf1);\n  set25519(p[2], gf1);\n  set25519(p[3], gf0);\n  for (i = 255; i >= 0; --i) {\n    b = (s[(i/8)|0] >> (i&7)) & 1;\n    cswap(p, q, b);\n    add(q, p);\n    add(p, p);\n    cswap(p, q, b);\n  }\n}\n\nfunction scalarbase(p, s) {\n  var q = [gf(), gf(), gf(), gf()];\n  set25519(q[0], X);\n  set25519(q[1], Y);\n  set25519(q[2], gf1);\n  M(q[3], X, Y);\n  scalarmult(p, q, s);\n}\n\nfunction crypto_sign_keypair(pk, sk, seeded) {\n  var d = new Uint8Array(64);\n  var p = [gf(), gf(), gf(), gf()];\n  var i;\n\n  if (!seeded) randombytes(sk, 32);\n  crypto_hash(d, sk, 32);\n  d[0] &= 248;\n  d[31] &= 127;\n  d[31] |= 64;\n\n  scalarbase(p, d);\n  pack(pk, p);\n\n  for (i = 0; i < 32; i++) sk[i+32] = pk[i];\n  return 0;\n}\n\nvar L = new Float64Array([0xed, 0xd3, 0xf5, 0x5c, 0x1a, 0x63, 0x12, 0x58, 0xd6, 0x9c, 0xf7, 0xa2, 0xde, 0xf9, 0xde, 0x14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0x10]);\n\nfunction modL(r, x) {\n  var carry, i, j, k;\n  for (i = 63; i >= 32; --i) {\n    carry = 0;\n    for (j = i - 32, k = i - 12; j < k; ++j) {\n      x[j] += carry - 16 * x[i] * L[j - (i - 32)];\n      carry = (x[j] + 128) >> 8;\n      x[j] -= carry * 256;\n    }\n    x[j] += carry;\n    x[i] = 0;\n  }\n  carry = 0;\n  for (j = 0; j < 32; j++) {\n    x[j] += carry - (x[31] >> 4) * L[j];\n    carry = x[j] >> 8;\n    x[j] &= 255;\n  }\n  for (j = 0; j < 32; j++) x[j] -= carry * L[j];\n  for (i = 0; i < 32; i++) {\n    x[i+1] += x[i] >> 8;\n    r[i] = x[i] & 255;\n  }\n}\n\nfunction reduce(r) {\n  var x = new Float64Array(64), i;\n  for (i = 0; i < 64; i++) x[i] = r[i];\n  for (i = 0; i < 64; i++) r[i] = 0;\n  modL(r, x);\n}\n\n// Note: difference from C - smlen returned, not passed as argument.\nfunction crypto_sign(sm, m, n, sk) {\n  var d = new Uint8Array(64), h = new Uint8Array(64), r = new Uint8Array(64);\n  var i, j, x = new Float64Array(64);\n  var p = [gf(), gf(), gf(), gf()];\n\n  crypto_hash(d, sk, 32);\n  d[0] &= 248;\n  d[31] &= 127;\n  d[31] |= 64;\n\n  var smlen = n + 64;\n  for (i = 0; i < n; i++) sm[64 + i] = m[i];\n  for (i = 0; i < 32; i++) sm[32 + i] = d[32 + i];\n\n  crypto_hash(r, sm.subarray(32), n+32);\n  reduce(r);\n  scalarbase(p, r);\n  pack(sm, p);\n\n  for (i = 32; i < 64; i++) sm[i] = sk[i];\n  crypto_hash(h, sm, n + 64);\n  reduce(h);\n\n  for (i = 0; i < 64; i++) x[i] = 0;\n  for (i = 0; i < 32; i++) x[i] = r[i];\n  for (i = 0; i < 32; i++) {\n    for (j = 0; j < 32; j++) {\n      x[i+j] += h[i] * d[j];\n    }\n  }\n\n  modL(sm.subarray(32), x);\n  return smlen;\n}\n\nfunction unpackneg(r, p) {\n  var t = gf(), chk = gf(), num = gf(),\n      den = gf(), den2 = gf(), den4 = gf(),\n      den6 = gf();\n\n  set25519(r[2], gf1);\n  unpack25519(r[1], p);\n  S(num, r[1]);\n  M(den, num, D);\n  Z(num, num, r[2]);\n  A(den, r[2], den);\n\n  S(den2, den);\n  S(den4, den2);\n  M(den6, den4, den2);\n  M(t, den6, num);\n  M(t, t, den);\n\n  pow2523(t, t);\n  M(t, t, num);\n  M(t, t, den);\n  M(t, t, den);\n  M(r[0], t, den);\n\n  S(chk, r[0]);\n  M(chk, chk, den);\n  if (neq25519(chk, num)) M(r[0], r[0], I);\n\n  S(chk, r[0]);\n  M(chk, chk, den);\n  if (neq25519(chk, num)) return -1;\n\n  if (par25519(r[0]) === (p[31]>>7)) Z(r[0], gf0, r[0]);\n\n  M(r[3], r[0], r[1]);\n  return 0;\n}\n\nfunction crypto_sign_open(m, sm, n, pk) {\n  var i, mlen;\n  var t = new Uint8Array(32), h = new Uint8Array(64);\n  var p = [gf(), gf(), gf(), gf()],\n      q = [gf(), gf(), gf(), gf()];\n\n  mlen = -1;\n  if (n < 64) return -1;\n\n  if (unpackneg(q, pk)) return -1;\n\n  for (i = 0; i < n; i++) m[i] = sm[i];\n  for (i = 0; i < 32; i++) m[i+32] = pk[i];\n  crypto_hash(h, m, n);\n  reduce(h);\n  scalarmult(p, q, h);\n\n  scalarbase(q, sm.subarray(32));\n  add(p, q);\n  pack(t, p);\n\n  n -= 64;\n  if (crypto_verify_32(sm, 0, t, 0)) {\n    for (i = 0; i < n; i++) m[i] = 0;\n    return -1;\n  }\n\n  for (i = 0; i < n; i++) m[i] = sm[i + 64];\n  mlen = n;\n  return mlen;\n}\n\nvar crypto_secretbox_KEYBYTES = 32,\n    crypto_secretbox_NONCEBYTES = 24,\n    crypto_secretbox_ZEROBYTES = 32,\n    crypto_secretbox_BOXZEROBYTES = 16,\n    crypto_scalarmult_BYTES = 32,\n    crypto_scalarmult_SCALARBYTES = 32,\n    crypto_box_PUBLICKEYBYTES = 32,\n    crypto_box_SECRETKEYBYTES = 32,\n    crypto_box_BEFORENMBYTES = 32,\n    crypto_box_NONCEBYTES = crypto_secretbox_NONCEBYTES,\n    crypto_box_ZEROBYTES = crypto_secretbox_ZEROBYTES,\n    crypto_box_BOXZEROBYTES = crypto_secretbox_BOXZEROBYTES,\n    crypto_sign_BYTES = 64,\n    crypto_sign_PUBLICKEYBYTES = 32,\n    crypto_sign_SECRETKEYBYTES = 64,\n    crypto_sign_SEEDBYTES = 32,\n    crypto_hash_BYTES = 64;\n\nnacl.lowlevel = {\n  crypto_core_hsalsa20: crypto_core_hsalsa20,\n  crypto_stream_xor: crypto_stream_xor,\n  crypto_stream: crypto_stream,\n  crypto_stream_salsa20_xor: crypto_stream_salsa20_xor,\n  crypto_stream_salsa20: crypto_stream_salsa20,\n  crypto_onetimeauth: crypto_onetimeauth,\n  crypto_onetimeauth_verify: crypto_onetimeauth_verify,\n  crypto_verify_16: crypto_verify_16,\n  crypto_verify_32: crypto_verify_32,\n  crypto_secretbox: crypto_secretbox,\n  crypto_secretbox_open: crypto_secretbox_open,\n  crypto_scalarmult: crypto_scalarmult,\n  crypto_scalarmult_base: crypto_scalarmult_base,\n  crypto_box_beforenm: crypto_box_beforenm,\n  crypto_box_afternm: crypto_box_afternm,\n  crypto_box: crypto_box,\n  crypto_box_open: crypto_box_open,\n  crypto_box_keypair: crypto_box_keypair,\n  crypto_hash: crypto_hash,\n  crypto_sign: crypto_sign,\n  crypto_sign_keypair: crypto_sign_keypair,\n  crypto_sign_open: crypto_sign_open,\n\n  crypto_secretbox_KEYBYTES: crypto_secretbox_KEYBYTES,\n  crypto_secretbox_NONCEBYTES: crypto_secretbox_NONCEBYTES,\n  crypto_secretbox_ZEROBYTES: crypto_secretbox_ZEROBYTES,\n  crypto_secretbox_BOXZEROBYTES: crypto_secretbox_BOXZEROBYTES,\n  crypto_scalarmult_BYTES: crypto_scalarmult_BYTES,\n  crypto_scalarmult_SCALARBYTES: crypto_scalarmult_SCALARBYTES,\n  crypto_box_PUBLICKEYBYTES: crypto_box_PUBLICKEYBYTES,\n  crypto_box_SECRETKEYBYTES: crypto_box_SECRETKEYBYTES,\n  crypto_box_BEFORENMBYTES: crypto_box_BEFORENMBYTES,\n  crypto_box_NONCEBYTES: crypto_box_NONCEBYTES,\n  crypto_box_ZEROBYTES: crypto_box_ZEROBYTES,\n  crypto_box_BOXZEROBYTES: crypto_box_BOXZEROBYTES,\n  crypto_sign_BYTES: crypto_sign_BYTES,\n  crypto_sign_PUBLICKEYBYTES: crypto_sign_PUBLICKEYBYTES,\n  crypto_sign_SECRETKEYBYTES: crypto_sign_SECRETKEYBYTES,\n  crypto_sign_SEEDBYTES: crypto_sign_SEEDBYTES,\n  crypto_hash_BYTES: crypto_hash_BYTES\n};\n\n/* High-level API */\n\nfunction checkLengths(k, n) {\n  if (k.length !== crypto_secretbox_KEYBYTES) throw new Error('bad key size');\n  if (n.length !== crypto_secretbox_NONCEBYTES) throw new Error('bad nonce size');\n}\n\nfunction checkBoxLengths(pk, sk) {\n  if (pk.length !== crypto_box_PUBLICKEYBYTES) throw new Error('bad public key size');\n  if (sk.length !== crypto_box_SECRETKEYBYTES) throw new Error('bad secret key size');\n}\n\nfunction checkArrayTypes() {\n  var t, i;\n  for (i = 0; i < arguments.length; i++) {\n     if ((t = Object.prototype.toString.call(arguments[i])) !== '[object Uint8Array]')\n       throw new TypeError('unexpected type ' + t + ', use Uint8Array');\n  }\n}\n\nfunction cleanup(arr) {\n  for (var i = 0; i < arr.length; i++) arr[i] = 0;\n}\n\n// TODO: Completely remove this in v0.15.\nif (!nacl.util) {\n  nacl.util = {};\n  nacl.util.decodeUTF8 = nacl.util.encodeUTF8 = nacl.util.encodeBase64 = nacl.util.decodeBase64 = function() {\n    throw new Error('nacl.util moved into separate package: https://github.com/dchest/tweetnacl-util-js');\n  };\n}\n\nnacl.randomBytes = function(n) {\n  var b = new Uint8Array(n);\n  randombytes(b, n);\n  return b;\n};\n\nnacl.secretbox = function(msg, nonce, key) {\n  checkArrayTypes(msg, nonce, key);\n  checkLengths(key, nonce);\n  var m = new Uint8Array(crypto_secretbox_ZEROBYTES + msg.length);\n  var c = new Uint8Array(m.length);\n  for (var i = 0; i < msg.length; i++) m[i+crypto_secretbox_ZEROBYTES] = msg[i];\n  crypto_secretbox(c, m, m.length, nonce, key);\n  return c.subarray(crypto_secretbox_BOXZEROBYTES);\n};\n\nnacl.secretbox.open = function(box, nonce, key) {\n  checkArrayTypes(box, nonce, key);\n  checkLengths(key, nonce);\n  var c = new Uint8Array(crypto_secretbox_BOXZEROBYTES + box.length);\n  var m = new Uint8Array(c.length);\n  for (var i = 0; i < box.length; i++) c[i+crypto_secretbox_BOXZEROBYTES] = box[i];\n  if (c.length < 32) return false;\n  if (crypto_secretbox_open(m, c, c.length, nonce, key) !== 0) return false;\n  return m.subarray(crypto_secretbox_ZEROBYTES);\n};\n\nnacl.secretbox.keyLength = crypto_secretbox_KEYBYTES;\nnacl.secretbox.nonceLength = crypto_secretbox_NONCEBYTES;\nnacl.secretbox.overheadLength = crypto_secretbox_BOXZEROBYTES;\n\nnacl.scalarMult = function(n, p) {\n  checkArrayTypes(n, p);\n  if (n.length !== crypto_scalarmult_SCALARBYTES) throw new Error('bad n size');\n  if (p.length !== crypto_scalarmult_BYTES) throw new Error('bad p size');\n  var q = new Uint8Array(crypto_scalarmult_BYTES);\n  crypto_scalarmult(q, n, p);\n  return q;\n};\n\nnacl.scalarMult.base = function(n) {\n  checkArrayTypes(n);\n  if (n.length !== crypto_scalarmult_SCALARBYTES) throw new Error('bad n size');\n  var q = new Uint8Array(crypto_scalarmult_BYTES);\n  crypto_scalarmult_base(q, n);\n  return q;\n};\n\nnacl.scalarMult.scalarLength = crypto_scalarmult_SCALARBYTES;\nnacl.scalarMult.groupElementLength = crypto_scalarmult_BYTES;\n\nnacl.box = function(msg, nonce, publicKey, secretKey) {\n  var k = nacl.box.before(publicKey, secretKey);\n  return nacl.secretbox(msg, nonce, k);\n};\n\nnacl.box.before = function(publicKey, secretKey) {\n  checkArrayTypes(publicKey, secretKey);\n  checkBoxLengths(publicKey, secretKey);\n  var k = new Uint8Array(crypto_box_BEFORENMBYTES);\n  crypto_box_beforenm(k, publicKey, secretKey);\n  return k;\n};\n\nnacl.box.after = nacl.secretbox;\n\nnacl.box.open = function(msg, nonce, publicKey, secretKey) {\n  var k = nacl.box.before(publicKey, secretKey);\n  return nacl.secretbox.open(msg, nonce, k);\n};\n\nnacl.box.open.after = nacl.secretbox.open;\n\nnacl.box.keyPair = function() {\n  var pk = new Uint8Array(crypto_box_PUBLICKEYBYTES);\n  var sk = new Uint8Array(crypto_box_SECRETKEYBYTES);\n  crypto_box_keypair(pk, sk);\n  return {publicKey: pk, secretKey: sk};\n};\n\nnacl.box.keyPair.fromSecretKey = function(secretKey) {\n  checkArrayTypes(secretKey);\n  if (secretKey.length !== crypto_box_SECRETKEYBYTES)\n    throw new Error('bad secret key size');\n  var pk = new Uint8Array(crypto_box_PUBLICKEYBYTES);\n  crypto_scalarmult_base(pk, secretKey);\n  return {publicKey: pk, secretKey: new Uint8Array(secretKey)};\n};\n\nnacl.box.publicKeyLength = crypto_box_PUBLICKEYBYTES;\nnacl.box.secretKeyLength = crypto_box_SECRETKEYBYTES;\nnacl.box.sharedKeyLength = crypto_box_BEFORENMBYTES;\nnacl.box.nonceLength = crypto_box_NONCEBYTES;\nnacl.box.overheadLength = nacl.secretbox.overheadLength;\n\nnacl.sign = function(msg, secretKey) {\n  checkArrayTypes(msg, secretKey);\n  if (secretKey.length !== crypto_sign_SECRETKEYBYTES)\n    throw new Error('bad secret key size');\n  var signedMsg = new Uint8Array(crypto_sign_BYTES+msg.length);\n  crypto_sign(signedMsg, msg, msg.length, secretKey);\n  return signedMsg;\n};\n\nnacl.sign.open = function(signedMsg, publicKey) {\n  if (arguments.length !== 2)\n    throw new Error('nacl.sign.open accepts 2 arguments; did you mean to use nacl.sign.detached.verify?');\n  checkArrayTypes(signedMsg, publicKey);\n  if (publicKey.length !== crypto_sign_PUBLICKEYBYTES)\n    throw new Error('bad public key size');\n  var tmp = new Uint8Array(signedMsg.length);\n  var mlen = crypto_sign_open(tmp, signedMsg, signedMsg.length, publicKey);\n  if (mlen < 0) return null;\n  var m = new Uint8Array(mlen);\n  for (var i = 0; i < m.length; i++) m[i] = tmp[i];\n  return m;\n};\n\nnacl.sign.detached = function(msg, secretKey) {\n  var signedMsg = nacl.sign(msg, secretKey);\n  var sig = new Uint8Array(crypto_sign_BYTES);\n  for (var i = 0; i < sig.length; i++) sig[i] = signedMsg[i];\n  return sig;\n};\n\nnacl.sign.detached.verify = function(msg, sig, publicKey) {\n  checkArrayTypes(msg, sig, publicKey);\n  if (sig.length !== crypto_sign_BYTES)\n    throw new Error('bad signature size');\n  if (publicKey.length !== crypto_sign_PUBLICKEYBYTES)\n    throw new Error('bad public key size');\n  var sm = new Uint8Array(crypto_sign_BYTES + msg.length);\n  var m = new Uint8Array(crypto_sign_BYTES + msg.length);\n  var i;\n  for (i = 0; i < crypto_sign_BYTES; i++) sm[i] = sig[i];\n  for (i = 0; i < msg.length; i++) sm[i+crypto_sign_BYTES] = msg[i];\n  return (crypto_sign_open(m, sm, sm.length, publicKey) >= 0);\n};\n\nnacl.sign.keyPair = function() {\n  var pk = new Uint8Array(crypto_sign_PUBLICKEYBYTES);\n  var sk = new Uint8Array(crypto_sign_SECRETKEYBYTES);\n  crypto_sign_keypair(pk, sk);\n  return {publicKey: pk, secretKey: sk};\n};\n\nnacl.sign.keyPair.fromSecretKey = function(secretKey) {\n  checkArrayTypes(secretKey);\n  if (secretKey.length !== crypto_sign_SECRETKEYBYTES)\n    throw new Error('bad secret key size');\n  var pk = new Uint8Array(crypto_sign_PUBLICKEYBYTES);\n  for (var i = 0; i < pk.length; i++) pk[i] = secretKey[32+i];\n  return {publicKey: pk, secretKey: new Uint8Array(secretKey)};\n};\n\nnacl.sign.keyPair.fromSeed = function(seed) {\n  checkArrayTypes(seed);\n  if (seed.length !== crypto_sign_SEEDBYTES)\n    throw new Error('bad seed size');\n  var pk = new Uint8Array(crypto_sign_PUBLICKEYBYTES);\n  var sk = new Uint8Array(crypto_sign_SECRETKEYBYTES);\n  for (var i = 0; i < 32; i++) sk[i] = seed[i];\n  crypto_sign_keypair(pk, sk, true);\n  return {publicKey: pk, secretKey: sk};\n};\n\nnacl.sign.publicKeyLength = crypto_sign_PUBLICKEYBYTES;\nnacl.sign.secretKeyLength = crypto_sign_SECRETKEYBYTES;\nnacl.sign.seedLength = crypto_sign_SEEDBYTES;\nnacl.sign.signatureLength = crypto_sign_BYTES;\n\nnacl.hash = function(msg) {\n  checkArrayTypes(msg);\n  var h = new Uint8Array(crypto_hash_BYTES);\n  crypto_hash(h, msg, msg.length);\n  return h;\n};\n\nnacl.hash.hashLength = crypto_hash_BYTES;\n\nnacl.verify = function(x, y) {\n  checkArrayTypes(x, y);\n  // Zero length arguments are considered not equal.\n  if (x.length === 0 || y.length === 0) return false;\n  if (x.length !== y.length) return false;\n  return (vn(x, 0, y, 0, x.length) === 0) ? true : false;\n};\n\nnacl.setPRNG = function(fn) {\n  randombytes = fn;\n};\n\n(function() {\n  // Initialize PRNG if environment provides CSPRNG.\n  // If not, methods calling randombytes will throw.\n  var crypto = typeof self !== 'undefined' ? (self.crypto || self.msCrypto) : null;\n  if (crypto && crypto.getRandomValues) {\n    // Browsers.\n    var QUOTA = 65536;\n    nacl.setPRNG(function(x, n) {\n      var i, v = new Uint8Array(n);\n      for (i = 0; i < n; i += QUOTA) {\n        crypto.getRandomValues(v.subarray(i, i + Math.min(n - i, QUOTA)));\n      }\n      for (i = 0; i < n; i++) x[i] = v[i];\n      cleanup(v);\n    });\n  } else if (true) {\n    // Node.js.\n    crypto = __webpack_require__(/*! crypto */ \"crypto\");\n    if (crypto && crypto.randomBytes) {\n      nacl.setPRNG(function(x, n) {\n        var i, v = crypto.randomBytes(n);\n        for (i = 0; i < n; i++) x[i] = v[i];\n        cleanup(v);\n      });\n    }\n  }\n})();\n\n})( true && module.exports ? module.exports : (self.nacl = self.nacl || {}));\n\n\n//# sourceURL=webpack:///./node_modules/tweetnacl/nacl-fast.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/dist/index.js":
/*!**********************************************!*\
  !*** ./node_modules/unzip-crx/dist/index.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar jszip = __webpack_require__(/*! jszip */ \"./node_modules/unzip-crx/node_modules/jszip/lib/index.js\");\nvar mkdirp = __webpack_require__(/*! mkdirp */ \"./node_modules/mkdirp/index.js\");\nvar promisify = __webpack_require__(/*! yaku/lib/promisify */ \"./node_modules/yaku/lib/promisify.js\");\n\nvar writeFile = promisify(fs.writeFile);\nvar readFile = promisify(fs.readFile);\nvar mkdir = promisify(mkdirp);\n\nfunction crxToZip(buf) {\n    function calcLength(a, b, c, d) {\n        var length = 0;\n\n        length += a;\n        length += b << 8;\n        length += c << 16;\n        length += d << 24;\n        return length;\n    }\n\n    // 50 4b 03 04\n    // This is actually a zip file\n    if (buf[0] === 80 && buf[1] === 75 && buf[2] === 3 && buf[3] === 4) {\n        return buf;\n    }\n\n    // 43 72 32 34 (Cr24)\n    if (buf[0] !== 67 || buf[1] !== 114 || buf[2] !== 50 || buf[3] !== 52) {\n        throw new Error(\"Invalid header: Does not start with Cr24\");\n    }\n\n    // 02 00 00 00\n    if (buf[4] !== 2 || buf[5] || buf[6] || buf[7]) {\n        throw new Error(\"Unexpected crx format version number.\");\n    }\n\n    var publicKeyLength = calcLength(buf[8], buf[9], buf[10], buf[11]);\n    var signatureLength = calcLength(buf[12], buf[13], buf[14], buf[15]);\n\n    // 16 = Magic number (4), CRX format version (4), lengths (2x4)\n    var zipStartOffset = 16 + publicKeyLength + signatureLength;\n\n    return buf.slice(zipStartOffset, buf.length);\n}\n\nfunction unzip(crxFilePath, destination) {\n    var filePath = path.resolve(crxFilePath);\n    var extname = path.extname(crxFilePath);\n    var basename = path.basename(crxFilePath, extname);\n    var dirname = path.dirname(crxFilePath);\n\n    destination = destination || path.resolve(dirname, basename);\n    return readFile(filePath).then(function (buf) {\n        return jszip.loadAsync(crxToZip(buf));\n    }).then(function (zip) {\n        var zipFileKeys = Object.keys(zip.files);\n\n        return Promise.all(zipFileKeys.map(function (filename) {\n            var isFile = !zip.files[filename].dir;\n            var fullPath = path.join(destination, filename);\n            var directory = isFile && path.dirname(fullPath) || fullPath;\n            var content = zip.files[filename].async(\"nodebuffer\");\n\n            return mkdir(directory).then(function () {\n                return isFile ? content : false;\n            }).then(function (data) {\n                return data ? writeFile(fullPath, data) : true;\n            });\n        }));\n    });\n}\n\nmodule.exports = unzip;\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/dist/index.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/base64.js":
/*!*****************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/base64.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/unzip-crx/node_modules/jszip/lib/support.js\");\n// private property\nvar _keyStr = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\";\n\n\n// public method for encoding\nexports.encode = function(input) {\n    var output = [];\n    var chr1, chr2, chr3, enc1, enc2, enc3, enc4;\n    var i = 0, len = input.length, remainingBytes = len;\n\n    var isArray = utils.getTypeOf(input) !== \"string\";\n    while (i < input.length) {\n        remainingBytes = len - i;\n\n        if (!isArray) {\n            chr1 = input.charCodeAt(i++);\n            chr2 = i < len ? input.charCodeAt(i++) : 0;\n            chr3 = i < len ? input.charCodeAt(i++) : 0;\n        } else {\n            chr1 = input[i++];\n            chr2 = i < len ? input[i++] : 0;\n            chr3 = i < len ? input[i++] : 0;\n        }\n\n        enc1 = chr1 >> 2;\n        enc2 = ((chr1 & 3) << 4) | (chr2 >> 4);\n        enc3 = remainingBytes > 1 ? (((chr2 & 15) << 2) | (chr3 >> 6)) : 64;\n        enc4 = remainingBytes > 2 ? (chr3 & 63) : 64;\n\n        output.push(_keyStr.charAt(enc1) + _keyStr.charAt(enc2) + _keyStr.charAt(enc3) + _keyStr.charAt(enc4));\n\n    }\n\n    return output.join(\"\");\n};\n\n// public method for decoding\nexports.decode = function(input) {\n    var chr1, chr2, chr3;\n    var enc1, enc2, enc3, enc4;\n    var i = 0, resultIndex = 0;\n\n    var dataUrlPrefix = \"data:\";\n\n    if (input.substr(0, dataUrlPrefix.length) === dataUrlPrefix) {\n        // This is a common error: people give a data url\n        // (data:image/png;base64,iVBOR...) with a {base64: true} and\n        // wonders why things don't work.\n        // We can detect that the string input looks like a data url but we\n        // *can't* be sure it is one: removing everything up to the comma would\n        // be too dangerous.\n        throw new Error(\"Invalid base64 input, it looks like a data url.\");\n    }\n\n    input = input.replace(/[^A-Za-z0-9\\+\\/\\=]/g, \"\");\n\n    var totalLength = input.length * 3 / 4;\n    if(input.charAt(input.length - 1) === _keyStr.charAt(64)) {\n        totalLength--;\n    }\n    if(input.charAt(input.length - 2) === _keyStr.charAt(64)) {\n        totalLength--;\n    }\n    if (totalLength % 1 !== 0) {\n        // totalLength is not an integer, the length does not match a valid\n        // base64 content. That can happen if:\n        // - the input is not a base64 content\n        // - the input is *almost* a base64 content, with a extra chars at the\n        //   beginning or at the end\n        // - the input uses a base64 variant (base64url for example)\n        throw new Error(\"Invalid base64 input, bad content length.\");\n    }\n    var output;\n    if (support.uint8array) {\n        output = new Uint8Array(totalLength|0);\n    } else {\n        output = new Array(totalLength|0);\n    }\n\n    while (i < input.length) {\n\n        enc1 = _keyStr.indexOf(input.charAt(i++));\n        enc2 = _keyStr.indexOf(input.charAt(i++));\n        enc3 = _keyStr.indexOf(input.charAt(i++));\n        enc4 = _keyStr.indexOf(input.charAt(i++));\n\n        chr1 = (enc1 << 2) | (enc2 >> 4);\n        chr2 = ((enc2 & 15) << 4) | (enc3 >> 2);\n        chr3 = ((enc3 & 3) << 6) | enc4;\n\n        output[resultIndex++] = chr1;\n\n        if (enc3 !== 64) {\n            output[resultIndex++] = chr2;\n        }\n        if (enc4 !== 64) {\n            output[resultIndex++] = chr3;\n        }\n\n    }\n\n    return output;\n};\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/base64.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/compressedObject.js":
/*!***************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/compressedObject.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar external = __webpack_require__(/*! ./external */ \"./node_modules/unzip-crx/node_modules/jszip/lib/external.js\");\nvar DataWorker = __webpack_require__(/*! ./stream/DataWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataWorker.js\");\nvar DataLengthProbe = __webpack_require__(/*! ./stream/DataLengthProbe */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataLengthProbe.js\");\nvar Crc32Probe = __webpack_require__(/*! ./stream/Crc32Probe */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/Crc32Probe.js\");\nvar DataLengthProbe = __webpack_require__(/*! ./stream/DataLengthProbe */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataLengthProbe.js\");\n\n/**\n * Represent a compressed object, with everything needed to decompress it.\n * @constructor\n * @param {number} compressedSize the size of the data compressed.\n * @param {number} uncompressedSize the size of the data after decompression.\n * @param {number} crc32 the crc32 of the decompressed file.\n * @param {object} compression the type of compression, see lib/compressions.js.\n * @param {String|ArrayBuffer|Uint8Array|Buffer} data the compressed data.\n */\nfunction CompressedObject(compressedSize, uncompressedSize, crc32, compression, data) {\n    this.compressedSize = compressedSize;\n    this.uncompressedSize = uncompressedSize;\n    this.crc32 = crc32;\n    this.compression = compression;\n    this.compressedContent = data;\n}\n\nCompressedObject.prototype = {\n    /**\n     * Create a worker to get the uncompressed content.\n     * @return {GenericWorker} the worker.\n     */\n    getContentWorker : function () {\n        var worker = new DataWorker(external.Promise.resolve(this.compressedContent))\n        .pipe(this.compression.uncompressWorker())\n        .pipe(new DataLengthProbe(\"data_length\"));\n\n        var that = this;\n        worker.on(\"end\", function () {\n            if(this.streamInfo['data_length'] !== that.uncompressedSize) {\n                throw new Error(\"Bug : uncompressed data size mismatch\");\n            }\n        });\n        return worker;\n    },\n    /**\n     * Create a worker to get the compressed content.\n     * @return {GenericWorker} the worker.\n     */\n    getCompressedWorker : function () {\n        return new DataWorker(external.Promise.resolve(this.compressedContent))\n        .withStreamInfo(\"compressedSize\", this.compressedSize)\n        .withStreamInfo(\"uncompressedSize\", this.uncompressedSize)\n        .withStreamInfo(\"crc32\", this.crc32)\n        .withStreamInfo(\"compression\", this.compression)\n        ;\n    }\n};\n\n/**\n * Chain the given worker with other workers to compress the content with the\n * given compresion.\n * @param {GenericWorker} uncompressedWorker the worker to pipe.\n * @param {Object} compression the compression object.\n * @param {Object} compressionOptions the options to use when compressing.\n * @return {GenericWorker} the new worker compressing the content.\n */\nCompressedObject.createWorkerFrom = function (uncompressedWorker, compression, compressionOptions) {\n    return uncompressedWorker\n    .pipe(new Crc32Probe())\n    .pipe(new DataLengthProbe(\"uncompressedSize\"))\n    .pipe(compression.compressWorker(compressionOptions))\n    .pipe(new DataLengthProbe(\"compressedSize\"))\n    .withStreamInfo(\"compression\", compression);\n};\n\nmodule.exports = CompressedObject;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/compressedObject.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/compressions.js":
/*!***********************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/compressions.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar GenericWorker = __webpack_require__(/*! ./stream/GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\n\nexports.STORE = {\n    magic: \"\\x00\\x00\",\n    compressWorker : function (compressionOptions) {\n        return new GenericWorker(\"STORE compression\");\n    },\n    uncompressWorker : function () {\n        return new GenericWorker(\"STORE decompression\");\n    }\n};\nexports.DEFLATE = __webpack_require__(/*! ./flate */ \"./node_modules/unzip-crx/node_modules/jszip/lib/flate.js\");\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/compressions.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/crc32.js":
/*!****************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/crc32.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\n\n/**\n * The following functions come from pako, from pako/lib/zlib/crc32.js\n * released under the MIT license, see pako https://github.com/nodeca/pako/\n */\n\n// Use ordinary array, since untyped makes no boost here\nfunction makeTable() {\n    var c, table = [];\n\n    for(var n =0; n < 256; n++){\n        c = n;\n        for(var k =0; k < 8; k++){\n            c = ((c&1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));\n        }\n        table[n] = c;\n    }\n\n    return table;\n}\n\n// Create table on load. Just 255 signed longs. Not a problem.\nvar crcTable = makeTable();\n\n\nfunction crc32(crc, buf, len, pos) {\n    var t = crcTable, end = pos + len;\n\n    crc = crc ^ (-1);\n\n    for (var i = pos; i < end; i++ ) {\n        crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];\n    }\n\n    return (crc ^ (-1)); // >>> 0;\n}\n\n// That's all for the pako functions.\n\n/**\n * Compute the crc32 of a string.\n * This is almost the same as the function crc32, but for strings. Using the\n * same function for the two use cases leads to horrible performances.\n * @param {Number} crc the starting value of the crc.\n * @param {String} str the string to use.\n * @param {Number} len the length of the string.\n * @param {Number} pos the starting position for the crc32 computation.\n * @return {Number} the computed crc32.\n */\nfunction crc32str(crc, str, len, pos) {\n    var t = crcTable, end = pos + len;\n\n    crc = crc ^ (-1);\n\n    for (var i = pos; i < end; i++ ) {\n        crc = (crc >>> 8) ^ t[(crc ^ str.charCodeAt(i)) & 0xFF];\n    }\n\n    return (crc ^ (-1)); // >>> 0;\n}\n\nmodule.exports = function crc32wrapper(input, crc) {\n    if (typeof input === \"undefined\" || !input.length) {\n        return 0;\n    }\n\n    var isArray = utils.getTypeOf(input) !== \"string\";\n\n    if(isArray) {\n        return crc32(crc|0, input, input.length, 0);\n    } else {\n        return crc32str(crc|0, input, input.length, 0);\n    }\n};\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/crc32.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/defaults.js":
/*!*******************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/defaults.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nexports.base64 = false;\nexports.binary = false;\nexports.dir = false;\nexports.createFolders = true;\nexports.date = null;\nexports.compression = null;\nexports.compressionOptions = null;\nexports.comment = null;\nexports.unixPermissions = null;\nexports.dosPermissions = null;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/defaults.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/external.js":
/*!*******************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/external.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* global Promise */\n\n\n// load the global object first:\n// - it should be better integrated in the system (unhandledRejection in node)\n// - the environment may have a custom Promise implementation (see zone.js)\nvar ES6Promise = null;\nif (typeof Promise !== \"undefined\") {\n    ES6Promise = Promise;\n} else {\n    ES6Promise = __webpack_require__(/*! lie */ \"./node_modules/lie/lib/index.js\");\n}\n\n/**\n * Let the user use/change some implementations.\n */\nmodule.exports = {\n    Promise: ES6Promise\n};\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/external.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/flate.js":
/*!****************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/flate.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar USE_TYPEDARRAY = (typeof Uint8Array !== 'undefined') && (typeof Uint16Array !== 'undefined') && (typeof Uint32Array !== 'undefined');\n\nvar pako = __webpack_require__(/*! pako */ \"./node_modules/pako/index.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar GenericWorker = __webpack_require__(/*! ./stream/GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\n\nvar ARRAY_TYPE = USE_TYPEDARRAY ? \"uint8array\" : \"array\";\n\nexports.magic = \"\\x08\\x00\";\n\n/**\n * Create a worker that uses pako to inflate/deflate.\n * @constructor\n * @param {String} action the name of the pako function to call : either \"Deflate\" or \"Inflate\".\n * @param {Object} options the options to use when (de)compressing.\n */\nfunction FlateWorker(action, options) {\n    GenericWorker.call(this, \"FlateWorker/\" + action);\n\n    this._pako = null;\n    this._pakoAction = action;\n    this._pakoOptions = options;\n    // the `meta` object from the last chunk received\n    // this allow this worker to pass around metadata\n    this.meta = {};\n}\n\nutils.inherits(FlateWorker, GenericWorker);\n\n/**\n * @see GenericWorker.processChunk\n */\nFlateWorker.prototype.processChunk = function (chunk) {\n    this.meta = chunk.meta;\n    if (this._pako === null) {\n        this._createPako();\n    }\n    this._pako.push(utils.transformTo(ARRAY_TYPE, chunk.data), false);\n};\n\n/**\n * @see GenericWorker.flush\n */\nFlateWorker.prototype.flush = function () {\n    GenericWorker.prototype.flush.call(this);\n    if (this._pako === null) {\n        this._createPako();\n    }\n    this._pako.push([], true);\n};\n/**\n * @see GenericWorker.cleanUp\n */\nFlateWorker.prototype.cleanUp = function () {\n    GenericWorker.prototype.cleanUp.call(this);\n    this._pako = null;\n};\n\n/**\n * Create the _pako object.\n * TODO: lazy-loading this object isn't the best solution but it's the\n * quickest. The best solution is to lazy-load the worker list. See also the\n * issue #446.\n */\nFlateWorker.prototype._createPako = function () {\n    this._pako = new pako[this._pakoAction]({\n        raw: true,\n        level: this._pakoOptions.level || -1 // default compression\n    });\n    var self = this;\n    this._pako.onData = function(data) {\n        self.push({\n            data : data,\n            meta : self.meta\n        });\n    };\n};\n\nexports.compressWorker = function (compressionOptions) {\n    return new FlateWorker(\"Deflate\", compressionOptions);\n};\nexports.uncompressWorker = function () {\n    return new FlateWorker(\"Inflate\", {});\n};\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/flate.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/generate/ZipFileWorker.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/generate/ZipFileWorker.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar GenericWorker = __webpack_require__(/*! ../stream/GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\nvar utf8 = __webpack_require__(/*! ../utf8 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utf8.js\");\nvar crc32 = __webpack_require__(/*! ../crc32 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/crc32.js\");\nvar signature = __webpack_require__(/*! ../signature */ \"./node_modules/unzip-crx/node_modules/jszip/lib/signature.js\");\n\n/**\n * Transform an integer into a string in hexadecimal.\n * @private\n * @param {number} dec the number to convert.\n * @param {number} bytes the number of bytes to generate.\n * @returns {string} the result.\n */\nvar decToHex = function(dec, bytes) {\n    var hex = \"\", i;\n    for (i = 0; i < bytes; i++) {\n        hex += String.fromCharCode(dec & 0xff);\n        dec = dec >>> 8;\n    }\n    return hex;\n};\n\n/**\n * Generate the UNIX part of the external file attributes.\n * @param {Object} unixPermissions the unix permissions or null.\n * @param {Boolean} isDir true if the entry is a directory, false otherwise.\n * @return {Number} a 32 bit integer.\n *\n * adapted from http://unix.stackexchange.com/questions/14705/the-zip-formats-external-file-attribute :\n *\n * TTTTsstrwxrwxrwx0000000000ADVSHR\n * ^^^^____________________________ file type, see zipinfo.c (UNX_*)\n *     ^^^_________________________ setuid, setgid, sticky\n *        ^^^^^^^^^________________ permissions\n *                 ^^^^^^^^^^______ not used ?\n *                           ^^^^^^ DOS attribute bits : Archive, Directory, Volume label, System file, Hidden, Read only\n */\nvar generateUnixExternalFileAttr = function (unixPermissions, isDir) {\n\n    var result = unixPermissions;\n    if (!unixPermissions) {\n        // I can't use octal values in strict mode, hence the hexa.\n        //  040775 => 0x41fd\n        // 0100664 => 0x81b4\n        result = isDir ? 0x41fd : 0x81b4;\n    }\n    return (result & 0xFFFF) << 16;\n};\n\n/**\n * Generate the DOS part of the external file attributes.\n * @param {Object} dosPermissions the dos permissions or null.\n * @param {Boolean} isDir true if the entry is a directory, false otherwise.\n * @return {Number} a 32 bit integer.\n *\n * Bit 0     Read-Only\n * Bit 1     Hidden\n * Bit 2     System\n * Bit 3     Volume Label\n * Bit 4     Directory\n * Bit 5     Archive\n */\nvar generateDosExternalFileAttr = function (dosPermissions, isDir) {\n\n    // the dir flag is already set for compatibility\n    return (dosPermissions || 0)  & 0x3F;\n};\n\n/**\n * Generate the various parts used in the construction of the final zip file.\n * @param {Object} streamInfo the hash with informations about the compressed file.\n * @param {Boolean} streamedContent is the content streamed ?\n * @param {Boolean} streamingEnded is the stream finished ?\n * @param {number} offset the current offset from the start of the zip file.\n * @param {String} platform let's pretend we are this platform (change platform dependents fields)\n * @param {Function} encodeFileName the function to encode the file name / comment.\n * @return {Object} the zip parts.\n */\nvar generateZipParts = function(streamInfo, streamedContent, streamingEnded, offset, platform, encodeFileName) {\n    var file = streamInfo['file'],\n    compression = streamInfo['compression'],\n    useCustomEncoding = encodeFileName !== utf8.utf8encode,\n    encodedFileName = utils.transformTo(\"string\", encodeFileName(file.name)),\n    utfEncodedFileName = utils.transformTo(\"string\", utf8.utf8encode(file.name)),\n    comment = file.comment,\n    encodedComment = utils.transformTo(\"string\", encodeFileName(comment)),\n    utfEncodedComment = utils.transformTo(\"string\", utf8.utf8encode(comment)),\n    useUTF8ForFileName = utfEncodedFileName.length !== file.name.length,\n    useUTF8ForComment = utfEncodedComment.length !== comment.length,\n    dosTime,\n    dosDate,\n    extraFields = \"\",\n    unicodePathExtraField = \"\",\n    unicodeCommentExtraField = \"\",\n    dir = file.dir,\n    date = file.date;\n\n\n    var dataInfo = {\n        crc32 : 0,\n        compressedSize : 0,\n        uncompressedSize : 0\n    };\n\n    // if the content is streamed, the sizes/crc32 are only available AFTER\n    // the end of the stream.\n    if (!streamedContent || streamingEnded) {\n        dataInfo.crc32 = streamInfo['crc32'];\n        dataInfo.compressedSize = streamInfo['compressedSize'];\n        dataInfo.uncompressedSize = streamInfo['uncompressedSize'];\n    }\n\n    var bitflag = 0;\n    if (streamedContent) {\n        // Bit 3: the sizes/crc32 are set to zero in the local header.\n        // The correct values are put in the data descriptor immediately\n        // following the compressed data.\n        bitflag |= 0x0008;\n    }\n    if (!useCustomEncoding && (useUTF8ForFileName || useUTF8ForComment)) {\n        // Bit 11: Language encoding flag (EFS).\n        bitflag |= 0x0800;\n    }\n\n\n    var extFileAttr = 0;\n    var versionMadeBy = 0;\n    if (dir) {\n        // dos or unix, we set the dos dir flag\n        extFileAttr |= 0x00010;\n    }\n    if(platform === \"UNIX\") {\n        versionMadeBy = 0x031E; // UNIX, version 3.0\n        extFileAttr |= generateUnixExternalFileAttr(file.unixPermissions, dir);\n    } else { // DOS or other, fallback to DOS\n        versionMadeBy = 0x0014; // DOS, version 2.0\n        extFileAttr |= generateDosExternalFileAttr(file.dosPermissions, dir);\n    }\n\n    // date\n    // @see http://www.delorie.com/djgpp/doc/rbinter/it/52/13.html\n    // @see http://www.delorie.com/djgpp/doc/rbinter/it/65/16.html\n    // @see http://www.delorie.com/djgpp/doc/rbinter/it/66/16.html\n\n    dosTime = date.getUTCHours();\n    dosTime = dosTime << 6;\n    dosTime = dosTime | date.getUTCMinutes();\n    dosTime = dosTime << 5;\n    dosTime = dosTime | date.getUTCSeconds() / 2;\n\n    dosDate = date.getUTCFullYear() - 1980;\n    dosDate = dosDate << 4;\n    dosDate = dosDate | (date.getUTCMonth() + 1);\n    dosDate = dosDate << 5;\n    dosDate = dosDate | date.getUTCDate();\n\n    if (useUTF8ForFileName) {\n        // set the unicode path extra field. unzip needs at least one extra\n        // field to correctly handle unicode path, so using the path is as good\n        // as any other information. This could improve the situation with\n        // other archive managers too.\n        // This field is usually used without the utf8 flag, with a non\n        // unicode path in the header (winrar, winzip). This helps (a bit)\n        // with the messy Windows' default compressed folders feature but\n        // breaks on p7zip which doesn't seek the unicode path extra field.\n        // So for now, UTF-8 everywhere !\n        unicodePathExtraField =\n            // Version\n            decToHex(1, 1) +\n            // NameCRC32\n            decToHex(crc32(encodedFileName), 4) +\n            // UnicodeName\n            utfEncodedFileName;\n\n        extraFields +=\n            // Info-ZIP Unicode Path Extra Field\n            \"\\x75\\x70\" +\n            // size\n            decToHex(unicodePathExtraField.length, 2) +\n            // content\n            unicodePathExtraField;\n    }\n\n    if(useUTF8ForComment) {\n\n        unicodeCommentExtraField =\n            // Version\n            decToHex(1, 1) +\n            // CommentCRC32\n            decToHex(crc32(encodedComment), 4) +\n            // UnicodeName\n            utfEncodedComment;\n\n        extraFields +=\n            // Info-ZIP Unicode Path Extra Field\n            \"\\x75\\x63\" +\n            // size\n            decToHex(unicodeCommentExtraField.length, 2) +\n            // content\n            unicodeCommentExtraField;\n    }\n\n    var header = \"\";\n\n    // version needed to extract\n    header += \"\\x0A\\x00\";\n    // general purpose bit flag\n    header += decToHex(bitflag, 2);\n    // compression method\n    header += compression.magic;\n    // last mod file time\n    header += decToHex(dosTime, 2);\n    // last mod file date\n    header += decToHex(dosDate, 2);\n    // crc-32\n    header += decToHex(dataInfo.crc32, 4);\n    // compressed size\n    header += decToHex(dataInfo.compressedSize, 4);\n    // uncompressed size\n    header += decToHex(dataInfo.uncompressedSize, 4);\n    // file name length\n    header += decToHex(encodedFileName.length, 2);\n    // extra field length\n    header += decToHex(extraFields.length, 2);\n\n\n    var fileRecord = signature.LOCAL_FILE_HEADER + header + encodedFileName + extraFields;\n\n    var dirRecord = signature.CENTRAL_FILE_HEADER +\n        // version made by (00: DOS)\n        decToHex(versionMadeBy, 2) +\n        // file header (common to file and central directory)\n        header +\n        // file comment length\n        decToHex(encodedComment.length, 2) +\n        // disk number start\n        \"\\x00\\x00\" +\n        // internal file attributes TODO\n        \"\\x00\\x00\" +\n        // external file attributes\n        decToHex(extFileAttr, 4) +\n        // relative offset of local header\n        decToHex(offset, 4) +\n        // file name\n        encodedFileName +\n        // extra field\n        extraFields +\n        // file comment\n        encodedComment;\n\n    return {\n        fileRecord: fileRecord,\n        dirRecord: dirRecord\n    };\n};\n\n/**\n * Generate the EOCD record.\n * @param {Number} entriesCount the number of entries in the zip file.\n * @param {Number} centralDirLength the length (in bytes) of the central dir.\n * @param {Number} localDirLength the length (in bytes) of the local dir.\n * @param {String} comment the zip file comment as a binary string.\n * @param {Function} encodeFileName the function to encode the comment.\n * @return {String} the EOCD record.\n */\nvar generateCentralDirectoryEnd = function (entriesCount, centralDirLength, localDirLength, comment, encodeFileName) {\n    var dirEnd = \"\";\n    var encodedComment = utils.transformTo(\"string\", encodeFileName(comment));\n\n    // end of central dir signature\n    dirEnd = signature.CENTRAL_DIRECTORY_END +\n        // number of this disk\n        \"\\x00\\x00\" +\n        // number of the disk with the start of the central directory\n        \"\\x00\\x00\" +\n        // total number of entries in the central directory on this disk\n        decToHex(entriesCount, 2) +\n        // total number of entries in the central directory\n        decToHex(entriesCount, 2) +\n        // size of the central directory   4 bytes\n        decToHex(centralDirLength, 4) +\n        // offset of start of central directory with respect to the starting disk number\n        decToHex(localDirLength, 4) +\n        // .ZIP file comment length\n        decToHex(encodedComment.length, 2) +\n        // .ZIP file comment\n        encodedComment;\n\n    return dirEnd;\n};\n\n/**\n * Generate data descriptors for a file entry.\n * @param {Object} streamInfo the hash generated by a worker, containing informations\n * on the file entry.\n * @return {String} the data descriptors.\n */\nvar generateDataDescriptors = function (streamInfo) {\n    var descriptor = \"\";\n    descriptor = signature.DATA_DESCRIPTOR +\n        // crc-32                          4 bytes\n        decToHex(streamInfo['crc32'], 4) +\n        // compressed size                 4 bytes\n        decToHex(streamInfo['compressedSize'], 4) +\n        // uncompressed size               4 bytes\n        decToHex(streamInfo['uncompressedSize'], 4);\n\n    return descriptor;\n};\n\n\n/**\n * A worker to concatenate other workers to create a zip file.\n * @param {Boolean} streamFiles `true` to stream the content of the files,\n * `false` to accumulate it.\n * @param {String} comment the comment to use.\n * @param {String} platform the platform to use, \"UNIX\" or \"DOS\".\n * @param {Function} encodeFileName the function to encode file names and comments.\n */\nfunction ZipFileWorker(streamFiles, comment, platform, encodeFileName) {\n    GenericWorker.call(this, \"ZipFileWorker\");\n    // The number of bytes written so far. This doesn't count accumulated chunks.\n    this.bytesWritten = 0;\n    // The comment of the zip file\n    this.zipComment = comment;\n    // The platform \"generating\" the zip file.\n    this.zipPlatform = platform;\n    // the function to encode file names and comments.\n    this.encodeFileName = encodeFileName;\n    // Should we stream the content of the files ?\n    this.streamFiles = streamFiles;\n    // If `streamFiles` is false, we will need to accumulate the content of the\n    // files to calculate sizes / crc32 (and write them *before* the content).\n    // This boolean indicates if we are accumulating chunks (it will change a lot\n    // during the lifetime of this worker).\n    this.accumulate = false;\n    // The buffer receiving chunks when accumulating content.\n    this.contentBuffer = [];\n    // The list of generated directory records.\n    this.dirRecords = [];\n    // The offset (in bytes) from the beginning of the zip file for the current source.\n    this.currentSourceOffset = 0;\n    // The total number of entries in this zip file.\n    this.entriesCount = 0;\n    // the name of the file currently being added, null when handling the end of the zip file.\n    // Used for the emited metadata.\n    this.currentFile = null;\n\n\n\n    this._sources = [];\n}\nutils.inherits(ZipFileWorker, GenericWorker);\n\n/**\n * @see GenericWorker.push\n */\nZipFileWorker.prototype.push = function (chunk) {\n\n    var currentFilePercent = chunk.meta.percent || 0;\n    var entriesCount = this.entriesCount;\n    var remainingFiles = this._sources.length;\n\n    if(this.accumulate) {\n        this.contentBuffer.push(chunk);\n    } else {\n        this.bytesWritten += chunk.data.length;\n\n        GenericWorker.prototype.push.call(this, {\n            data : chunk.data,\n            meta : {\n                currentFile : this.currentFile,\n                percent : entriesCount ? (currentFilePercent + 100 * (entriesCount - remainingFiles - 1)) / entriesCount : 100\n            }\n        });\n    }\n};\n\n/**\n * The worker started a new source (an other worker).\n * @param {Object} streamInfo the streamInfo object from the new source.\n */\nZipFileWorker.prototype.openedSource = function (streamInfo) {\n    this.currentSourceOffset = this.bytesWritten;\n    this.currentFile = streamInfo['file'].name;\n\n    var streamedContent = this.streamFiles && !streamInfo['file'].dir;\n\n    // don't stream folders (because they don't have any content)\n    if(streamedContent) {\n        var record = generateZipParts(streamInfo, streamedContent, false, this.currentSourceOffset, this.zipPlatform, this.encodeFileName);\n        this.push({\n            data : record.fileRecord,\n            meta : {percent:0}\n        });\n    } else {\n        // we need to wait for the whole file before pushing anything\n        this.accumulate = true;\n    }\n};\n\n/**\n * The worker finished a source (an other worker).\n * @param {Object} streamInfo the streamInfo object from the finished source.\n */\nZipFileWorker.prototype.closedSource = function (streamInfo) {\n    this.accumulate = false;\n    var streamedContent = this.streamFiles && !streamInfo['file'].dir;\n    var record = generateZipParts(streamInfo, streamedContent, true, this.currentSourceOffset, this.zipPlatform, this.encodeFileName);\n\n    this.dirRecords.push(record.dirRecord);\n    if(streamedContent) {\n        // after the streamed file, we put data descriptors\n        this.push({\n            data : generateDataDescriptors(streamInfo),\n            meta : {percent:100}\n        });\n    } else {\n        // the content wasn't streamed, we need to push everything now\n        // first the file record, then the content\n        this.push({\n            data : record.fileRecord,\n            meta : {percent:0}\n        });\n        while(this.contentBuffer.length) {\n            this.push(this.contentBuffer.shift());\n        }\n    }\n    this.currentFile = null;\n};\n\n/**\n * @see GenericWorker.flush\n */\nZipFileWorker.prototype.flush = function () {\n\n    var localDirLength = this.bytesWritten;\n    for(var i = 0; i < this.dirRecords.length; i++) {\n        this.push({\n            data : this.dirRecords[i],\n            meta : {percent:100}\n        });\n    }\n    var centralDirLength = this.bytesWritten - localDirLength;\n\n    var dirEnd = generateCentralDirectoryEnd(this.dirRecords.length, centralDirLength, localDirLength, this.zipComment, this.encodeFileName);\n\n    this.push({\n        data : dirEnd,\n        meta : {percent:100}\n    });\n};\n\n/**\n * Prepare the next source to be read.\n */\nZipFileWorker.prototype.prepareNextSource = function () {\n    this.previous = this._sources.shift();\n    this.openedSource(this.previous.streamInfo);\n    if (this.isPaused) {\n        this.previous.pause();\n    } else {\n        this.previous.resume();\n    }\n};\n\n/**\n * @see GenericWorker.registerPrevious\n */\nZipFileWorker.prototype.registerPrevious = function (previous) {\n    this._sources.push(previous);\n    var self = this;\n\n    previous.on('data', function (chunk) {\n        self.processChunk(chunk);\n    });\n    previous.on('end', function () {\n        self.closedSource(self.previous.streamInfo);\n        if(self._sources.length) {\n            self.prepareNextSource();\n        } else {\n            self.end();\n        }\n    });\n    previous.on('error', function (e) {\n        self.error(e);\n    });\n    return this;\n};\n\n/**\n * @see GenericWorker.resume\n */\nZipFileWorker.prototype.resume = function () {\n    if(!GenericWorker.prototype.resume.call(this)) {\n        return false;\n    }\n\n    if (!this.previous && this._sources.length) {\n        this.prepareNextSource();\n        return true;\n    }\n    if (!this.previous && !this._sources.length && !this.generatedError) {\n        this.end();\n        return true;\n    }\n};\n\n/**\n * @see GenericWorker.error\n */\nZipFileWorker.prototype.error = function (e) {\n    var sources = this._sources;\n    if(!GenericWorker.prototype.error.call(this, e)) {\n        return false;\n    }\n    for(var i = 0; i < sources.length; i++) {\n        try {\n            sources[i].error(e);\n        } catch(e) {\n            // the `error` exploded, nothing to do\n        }\n    }\n    return true;\n};\n\n/**\n * @see GenericWorker.lock\n */\nZipFileWorker.prototype.lock = function () {\n    GenericWorker.prototype.lock.call(this);\n    var sources = this._sources;\n    for(var i = 0; i < sources.length; i++) {\n        sources[i].lock();\n    }\n};\n\nmodule.exports = ZipFileWorker;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/generate/ZipFileWorker.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/generate/index.js":
/*!*************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/generate/index.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar compressions = __webpack_require__(/*! ../compressions */ \"./node_modules/unzip-crx/node_modules/jszip/lib/compressions.js\");\nvar ZipFileWorker = __webpack_require__(/*! ./ZipFileWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/generate/ZipFileWorker.js\");\n\n/**\n * Find the compression to use.\n * @param {String} fileCompression the compression defined at the file level, if any.\n * @param {String} zipCompression the compression defined at the load() level.\n * @return {Object} the compression object to use.\n */\nvar getCompression = function (fileCompression, zipCompression) {\n\n    var compressionName = fileCompression || zipCompression;\n    var compression = compressions[compressionName];\n    if (!compression) {\n        throw new Error(compressionName + \" is not a valid compression method !\");\n    }\n    return compression;\n};\n\n/**\n * Create a worker to generate a zip file.\n * @param {JSZip} zip the JSZip instance at the right root level.\n * @param {Object} options to generate the zip file.\n * @param {String} comment the comment to use.\n */\nexports.generateWorker = function (zip, options, comment) {\n\n    var zipFileWorker = new ZipFileWorker(options.streamFiles, comment, options.platform, options.encodeFileName);\n    var entriesCount = 0;\n    try {\n\n        zip.forEach(function (relativePath, file) {\n            entriesCount++;\n            var compression = getCompression(file.options.compression, options.compression);\n            var compressionOptions = file.options.compressionOptions || options.compressionOptions || {};\n            var dir = file.dir, date = file.date;\n\n            file._compressWorker(compression, compressionOptions)\n            .withStreamInfo(\"file\", {\n                name : relativePath,\n                dir : dir,\n                date : date,\n                comment : file.comment || \"\",\n                unixPermissions : file.unixPermissions,\n                dosPermissions : file.dosPermissions\n            })\n            .pipe(zipFileWorker);\n        });\n        zipFileWorker.entriesCount = entriesCount;\n    } catch (e) {\n        zipFileWorker.error(e);\n    }\n\n    return zipFileWorker;\n};\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/generate/index.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/index.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n/**\n * Representation a of zip file in js\n * @constructor\n */\nfunction JSZip() {\n    // if this constructor isused without`new`, itadds `new` beforeitself:\n    if(!(this instanceof JSZip)) {\n        return new JSZip();\n    }\n\n    if(arguments.length) {\n        throw new Error(\"The constructor with parameters has been removed in JSZip 3.0, please check the upgrade guide.\");\n    }\n\n    // object containing the files :\n    // {\n    //   \"folder/\" : {...},\n    //   \"folder/data.txt\" : {...}\n    // }\n    this.files = {};\n\n    this.comment = null;\n\n    // Where we are in the hierarchy\n    this.root = \"\";\n    this.clone = function() {\n        var newObj = new JSZip();\n        for (var i in this) {\n            if (typeof this[i] !== \"function\") {\n                newObj[i] = this[i];\n            }\n        }\n        return newObj;\n    };\n}\nJSZip.prototype = __webpack_require__(/*! ./object */ \"./node_modules/unzip-crx/node_modules/jszip/lib/object.js\");\nJSZip.prototype.loadAsync = __webpack_require__(/*! ./load */ \"./node_modules/unzip-crx/node_modules/jszip/lib/load.js\");\nJSZip.support = __webpack_require__(/*! ./support */ \"./node_modules/unzip-crx/node_modules/jszip/lib/support.js\");\nJSZip.defaults = __webpack_require__(/*! ./defaults */ \"./node_modules/unzip-crx/node_modules/jszip/lib/defaults.js\");\n\n// TODO find a better way to handle this version,\n// a require('package.json').version doesn't work with webpack, see #327\nJSZip.version = \"3.2.0\";\n\nJSZip.loadAsync = function (content, options) {\n    return new JSZip().loadAsync(content, options);\n};\n\nJSZip.external = __webpack_require__(/*! ./external */ \"./node_modules/unzip-crx/node_modules/jszip/lib/external.js\");\nmodule.exports = JSZip;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/index.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/load.js":
/*!***************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/load.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar external = __webpack_require__(/*! ./external */ \"./node_modules/unzip-crx/node_modules/jszip/lib/external.js\");\nvar utf8 = __webpack_require__(/*! ./utf8 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utf8.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar ZipEntries = __webpack_require__(/*! ./zipEntries */ \"./node_modules/unzip-crx/node_modules/jszip/lib/zipEntries.js\");\nvar Crc32Probe = __webpack_require__(/*! ./stream/Crc32Probe */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/Crc32Probe.js\");\nvar nodejsUtils = __webpack_require__(/*! ./nodejsUtils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/nodejsUtils.js\");\n\n/**\n * Check the CRC32 of an entry.\n * @param {ZipEntry} zipEntry the zip entry to check.\n * @return {Promise} the result.\n */\nfunction checkEntryCRC32(zipEntry) {\n    return new external.Promise(function (resolve, reject) {\n        var worker = zipEntry.decompressed.getContentWorker().pipe(new Crc32Probe());\n        worker.on(\"error\", function (e) {\n            reject(e);\n        })\n        .on(\"end\", function () {\n            if (worker.streamInfo.crc32 !== zipEntry.decompressed.crc32) {\n                reject(new Error(\"Corrupted zip : CRC32 mismatch\"));\n            } else {\n                resolve();\n            }\n        })\n        .resume();\n    });\n}\n\nmodule.exports = function(data, options) {\n    var zip = this;\n    options = utils.extend(options || {}, {\n        base64: false,\n        checkCRC32: false,\n        optimizedBinaryString: false,\n        createFolders: false,\n        decodeFileName: utf8.utf8decode\n    });\n\n    if (nodejsUtils.isNode && nodejsUtils.isStream(data)) {\n        return external.Promise.reject(new Error(\"JSZip can't accept a stream when loading a zip file.\"));\n    }\n\n    return utils.prepareContent(\"the loaded zip file\", data, true, options.optimizedBinaryString, options.base64)\n    .then(function(data) {\n        var zipEntries = new ZipEntries(options);\n        zipEntries.load(data);\n        return zipEntries;\n    }).then(function checkCRC32(zipEntries) {\n        var promises = [external.Promise.resolve(zipEntries)];\n        var files = zipEntries.files;\n        if (options.checkCRC32) {\n            for (var i = 0; i < files.length; i++) {\n                promises.push(checkEntryCRC32(files[i]));\n            }\n        }\n        return external.Promise.all(promises);\n    }).then(function addFiles(results) {\n        var zipEntries = results.shift();\n        var files = zipEntries.files;\n        for (var i = 0; i < files.length; i++) {\n            var input = files[i];\n            zip.file(input.fileNameStr, input.decompressed, {\n                binary: true,\n                optimizedBinaryString: true,\n                date: input.date,\n                dir: input.dir,\n                comment : input.fileCommentStr.length ? input.fileCommentStr : null,\n                unixPermissions : input.unixPermissions,\n                dosPermissions : input.dosPermissions,\n                createFolders: options.createFolders\n            });\n        }\n        if (zipEntries.zipComment.length) {\n            zip.comment = zipEntries.zipComment;\n        }\n\n        return zip;\n    });\n};\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/load.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/nodejs/NodejsStreamInputAdapter.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/nodejs/NodejsStreamInputAdapter.js ***!
  \******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar GenericWorker = __webpack_require__(/*! ../stream/GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\n\n/**\n * A worker that use a nodejs stream as source.\n * @constructor\n * @param {String} filename the name of the file entry for this stream.\n * @param {Readable} stream the nodejs stream.\n */\nfunction NodejsStreamInputAdapter(filename, stream) {\n    GenericWorker.call(this, \"Nodejs stream input adapter for \" + filename);\n    this._upstreamEnded = false;\n    this._bindStream(stream);\n}\n\nutils.inherits(NodejsStreamInputAdapter, GenericWorker);\n\n/**\n * Prepare the stream and bind the callbacks on it.\n * Do this ASAP on node 0.10 ! A lazy binding doesn't always work.\n * @param {Stream} stream the nodejs stream to use.\n */\nNodejsStreamInputAdapter.prototype._bindStream = function (stream) {\n    var self = this;\n    this._stream = stream;\n    stream.pause();\n    stream\n    .on(\"data\", function (chunk) {\n        self.push({\n            data: chunk,\n            meta : {\n                percent : 0\n            }\n        });\n    })\n    .on(\"error\", function (e) {\n        if(self.isPaused) {\n            this.generatedError = e;\n        } else {\n            self.error(e);\n        }\n    })\n    .on(\"end\", function () {\n        if(self.isPaused) {\n            self._upstreamEnded = true;\n        } else {\n            self.end();\n        }\n    });\n};\nNodejsStreamInputAdapter.prototype.pause = function () {\n    if(!GenericWorker.prototype.pause.call(this)) {\n        return false;\n    }\n    this._stream.pause();\n    return true;\n};\nNodejsStreamInputAdapter.prototype.resume = function () {\n    if(!GenericWorker.prototype.resume.call(this)) {\n        return false;\n    }\n\n    if(this._upstreamEnded) {\n        this.end();\n    } else {\n        this._stream.resume();\n    }\n\n    return true;\n};\n\nmodule.exports = NodejsStreamInputAdapter;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/nodejs/NodejsStreamInputAdapter.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/nodejs/NodejsStreamOutputAdapter.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/nodejs/NodejsStreamOutputAdapter.js ***!
  \*******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar Readable = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/readable.js\").Readable;\n\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nutils.inherits(NodejsStreamOutputAdapter, Readable);\n\n/**\n* A nodejs stream using a worker as source.\n* @see the SourceWrapper in http://nodejs.org/api/stream.html\n* @constructor\n* @param {StreamHelper} helper the helper wrapping the worker\n* @param {Object} options the nodejs stream options\n* @param {Function} updateCb the update callback.\n*/\nfunction NodejsStreamOutputAdapter(helper, options, updateCb) {\n    Readable.call(this, options);\n    this._helper = helper;\n\n    var self = this;\n    helper.on(\"data\", function (data, meta) {\n        if (!self.push(data)) {\n            self._helper.pause();\n        }\n        if(updateCb) {\n            updateCb(meta);\n        }\n    })\n    .on(\"error\", function(e) {\n        self.emit('error', e);\n    })\n    .on(\"end\", function () {\n        self.push(null);\n    });\n}\n\n\nNodejsStreamOutputAdapter.prototype._read = function() {\n    this._helper.resume();\n};\n\nmodule.exports = NodejsStreamOutputAdapter;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/nodejs/NodejsStreamOutputAdapter.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/nodejsUtils.js":
/*!**********************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/nodejsUtils.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nmodule.exports = {\n    /**\n     * True if this is running in Nodejs, will be undefined in a browser.\n     * In a browser, browserify won't include this file and the whole module\n     * will be resolved an empty object.\n     */\n    isNode : typeof Buffer !== \"undefined\",\n    /**\n     * Create a new nodejs Buffer from an existing content.\n     * @param {Object} data the data to pass to the constructor.\n     * @param {String} encoding the encoding to use.\n     * @return {Buffer} a new Buffer.\n     */\n    newBufferFrom: function(data, encoding) {\n        if (Buffer.from && Buffer.from !== Uint8Array.from) {\n            return Buffer.from(data, encoding);\n        } else {\n            if (typeof data === \"number\") {\n                // Safeguard for old Node.js versions. On newer versions,\n                // Buffer.from(number) / Buffer(number, encoding) already throw.\n                throw new Error(\"The \\\"data\\\" argument must not be a number\");\n            }\n            return new Buffer(data, encoding);\n        }\n    },\n    /**\n     * Create a new nodejs Buffer with the specified size.\n     * @param {Integer} size the size of the buffer.\n     * @return {Buffer} a new Buffer.\n     */\n    allocBuffer: function (size) {\n        if (Buffer.alloc) {\n            return Buffer.alloc(size);\n        } else {\n            var buf = new Buffer(size);\n            buf.fill(0);\n            return buf;\n        }\n    },\n    /**\n     * Find out if an object is a Buffer.\n     * @param {Object} b the object to test.\n     * @return {Boolean} true if the object is a Buffer, false otherwise.\n     */\n    isBuffer : function(b){\n        return Buffer.isBuffer(b);\n    },\n\n    isStream : function (obj) {\n        return obj &&\n            typeof obj.on === \"function\" &&\n            typeof obj.pause === \"function\" &&\n            typeof obj.resume === \"function\";\n    }\n};\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/nodejsUtils.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/object.js":
/*!*****************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/object.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar utf8 = __webpack_require__(/*! ./utf8 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utf8.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar GenericWorker = __webpack_require__(/*! ./stream/GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\nvar StreamHelper = __webpack_require__(/*! ./stream/StreamHelper */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/StreamHelper.js\");\nvar defaults = __webpack_require__(/*! ./defaults */ \"./node_modules/unzip-crx/node_modules/jszip/lib/defaults.js\");\nvar CompressedObject = __webpack_require__(/*! ./compressedObject */ \"./node_modules/unzip-crx/node_modules/jszip/lib/compressedObject.js\");\nvar ZipObject = __webpack_require__(/*! ./zipObject */ \"./node_modules/unzip-crx/node_modules/jszip/lib/zipObject.js\");\nvar generate = __webpack_require__(/*! ./generate */ \"./node_modules/unzip-crx/node_modules/jszip/lib/generate/index.js\");\nvar nodejsUtils = __webpack_require__(/*! ./nodejsUtils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/nodejsUtils.js\");\nvar NodejsStreamInputAdapter = __webpack_require__(/*! ./nodejs/NodejsStreamInputAdapter */ \"./node_modules/unzip-crx/node_modules/jszip/lib/nodejs/NodejsStreamInputAdapter.js\");\n\n\n/**\n * Add a file in the current folder.\n * @private\n * @param {string} name the name of the file\n * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data of the file\n * @param {Object} originalOptions the options of the file\n * @return {Object} the new file.\n */\nvar fileAdd = function(name, data, originalOptions) {\n    // be sure sub folders exist\n    var dataType = utils.getTypeOf(data),\n        parent;\n\n\n    /*\n     * Correct options.\n     */\n\n    var o = utils.extend(originalOptions || {}, defaults);\n    o.date = o.date || new Date();\n    if (o.compression !== null) {\n        o.compression = o.compression.toUpperCase();\n    }\n\n    if (typeof o.unixPermissions === \"string\") {\n        o.unixPermissions = parseInt(o.unixPermissions, 8);\n    }\n\n    // UNX_IFDIR  0040000 see zipinfo.c\n    if (o.unixPermissions && (o.unixPermissions & 0x4000)) {\n        o.dir = true;\n    }\n    // Bit 4    Directory\n    if (o.dosPermissions && (o.dosPermissions & 0x0010)) {\n        o.dir = true;\n    }\n\n    if (o.dir) {\n        name = forceTrailingSlash(name);\n    }\n    if (o.createFolders && (parent = parentFolder(name))) {\n        folderAdd.call(this, parent, true);\n    }\n\n    var isUnicodeString = dataType === \"string\" && o.binary === false && o.base64 === false;\n    if (!originalOptions || typeof originalOptions.binary === \"undefined\") {\n        o.binary = !isUnicodeString;\n    }\n\n\n    var isCompressedEmpty = (data instanceof CompressedObject) && data.uncompressedSize === 0;\n\n    if (isCompressedEmpty || o.dir || !data || data.length === 0) {\n        o.base64 = false;\n        o.binary = true;\n        data = \"\";\n        o.compression = \"STORE\";\n        dataType = \"string\";\n    }\n\n    /*\n     * Convert content to fit.\n     */\n\n    var zipObjectContent = null;\n    if (data instanceof CompressedObject || data instanceof GenericWorker) {\n        zipObjectContent = data;\n    } else if (nodejsUtils.isNode && nodejsUtils.isStream(data)) {\n        zipObjectContent = new NodejsStreamInputAdapter(name, data);\n    } else {\n        zipObjectContent = utils.prepareContent(name, data, o.binary, o.optimizedBinaryString, o.base64);\n    }\n\n    var object = new ZipObject(name, zipObjectContent, o);\n    this.files[name] = object;\n    /*\n    TODO: we can't throw an exception because we have async promises\n    (we can have a promise of a Date() for example) but returning a\n    promise is useless because file(name, data) returns the JSZip\n    object for chaining. Should we break that to allow the user\n    to catch the error ?\n\n    return external.Promise.resolve(zipObjectContent)\n    .then(function () {\n        return object;\n    });\n    */\n};\n\n/**\n * Find the parent folder of the path.\n * @private\n * @param {string} path the path to use\n * @return {string} the parent folder, or \"\"\n */\nvar parentFolder = function (path) {\n    if (path.slice(-1) === '/') {\n        path = path.substring(0, path.length - 1);\n    }\n    var lastSlash = path.lastIndexOf('/');\n    return (lastSlash > 0) ? path.substring(0, lastSlash) : \"\";\n};\n\n/**\n * Returns the path with a slash at the end.\n * @private\n * @param {String} path the path to check.\n * @return {String} the path with a trailing slash.\n */\nvar forceTrailingSlash = function(path) {\n    // Check the name ends with a /\n    if (path.slice(-1) !== \"/\") {\n        path += \"/\"; // IE doesn't like substr(-1)\n    }\n    return path;\n};\n\n/**\n * Add a (sub) folder in the current folder.\n * @private\n * @param {string} name the folder's name\n * @param {boolean=} [createFolders] If true, automatically create sub\n *  folders. Defaults to false.\n * @return {Object} the new folder.\n */\nvar folderAdd = function(name, createFolders) {\n    createFolders = (typeof createFolders !== 'undefined') ? createFolders : defaults.createFolders;\n\n    name = forceTrailingSlash(name);\n\n    // Does this folder already exist?\n    if (!this.files[name]) {\n        fileAdd.call(this, name, null, {\n            dir: true,\n            createFolders: createFolders\n        });\n    }\n    return this.files[name];\n};\n\n/**\n* Cross-window, cross-Node-context regular expression detection\n* @param  {Object}  object Anything\n* @return {Boolean}        true if the object is a regular expression,\n* false otherwise\n*/\nfunction isRegExp(object) {\n    return Object.prototype.toString.call(object) === \"[object RegExp]\";\n}\n\n// return the actual prototype of JSZip\nvar out = {\n    /**\n     * @see loadAsync\n     */\n    load: function() {\n        throw new Error(\"This method has been removed in JSZip 3.0, please check the upgrade guide.\");\n    },\n\n\n    /**\n     * Call a callback function for each entry at this folder level.\n     * @param {Function} cb the callback function:\n     * function (relativePath, file) {...}\n     * It takes 2 arguments : the relative path and the file.\n     */\n    forEach: function(cb) {\n        var filename, relativePath, file;\n        for (filename in this.files) {\n            if (!this.files.hasOwnProperty(filename)) {\n                continue;\n            }\n            file = this.files[filename];\n            relativePath = filename.slice(this.root.length, filename.length);\n            if (relativePath && filename.slice(0, this.root.length) === this.root) { // the file is in the current root\n                cb(relativePath, file); // TODO reverse the parameters ? need to be clean AND consistent with the filter search fn...\n            }\n        }\n    },\n\n    /**\n     * Filter nested files/folders with the specified function.\n     * @param {Function} search the predicate to use :\n     * function (relativePath, file) {...}\n     * It takes 2 arguments : the relative path and the file.\n     * @return {Array} An array of matching elements.\n     */\n    filter: function(search) {\n        var result = [];\n        this.forEach(function (relativePath, entry) {\n            if (search(relativePath, entry)) { // the file matches the function\n                result.push(entry);\n            }\n\n        });\n        return result;\n    },\n\n    /**\n     * Add a file to the zip file, or search a file.\n     * @param   {string|RegExp} name The name of the file to add (if data is defined),\n     * the name of the file to find (if no data) or a regex to match files.\n     * @param   {String|ArrayBuffer|Uint8Array|Buffer} data  The file data, either raw or base64 encoded\n     * @param   {Object} o     File options\n     * @return  {JSZip|Object|Array} this JSZip object (when adding a file),\n     * a file (when searching by string) or an array of files (when searching by regex).\n     */\n    file: function(name, data, o) {\n        if (arguments.length === 1) {\n            if (isRegExp(name)) {\n                var regexp = name;\n                return this.filter(function(relativePath, file) {\n                    return !file.dir && regexp.test(relativePath);\n                });\n            }\n            else { // text\n                var obj = this.files[this.root + name];\n                if (obj && !obj.dir) {\n                    return obj;\n                } else {\n                    return null;\n                }\n            }\n        }\n        else { // more than one argument : we have data !\n            name = this.root + name;\n            fileAdd.call(this, name, data, o);\n        }\n        return this;\n    },\n\n    /**\n     * Add a directory to the zip file, or search.\n     * @param   {String|RegExp} arg The name of the directory to add, or a regex to search folders.\n     * @return  {JSZip} an object with the new directory as the root, or an array containing matching folders.\n     */\n    folder: function(arg) {\n        if (!arg) {\n            return this;\n        }\n\n        if (isRegExp(arg)) {\n            return this.filter(function(relativePath, file) {\n                return file.dir && arg.test(relativePath);\n            });\n        }\n\n        // else, name is a new folder\n        var name = this.root + arg;\n        var newFolder = folderAdd.call(this, name);\n\n        // Allow chaining by returning a new object with this folder as the root\n        var ret = this.clone();\n        ret.root = newFolder.name;\n        return ret;\n    },\n\n    /**\n     * Delete a file, or a directory and all sub-files, from the zip\n     * @param {string} name the name of the file to delete\n     * @return {JSZip} this JSZip object\n     */\n    remove: function(name) {\n        name = this.root + name;\n        var file = this.files[name];\n        if (!file) {\n            // Look for any folders\n            if (name.slice(-1) !== \"/\") {\n                name += \"/\";\n            }\n            file = this.files[name];\n        }\n\n        if (file && !file.dir) {\n            // file\n            delete this.files[name];\n        } else {\n            // maybe a folder, delete recursively\n            var kids = this.filter(function(relativePath, file) {\n                return file.name.slice(0, name.length) === name;\n            });\n            for (var i = 0; i < kids.length; i++) {\n                delete this.files[kids[i].name];\n            }\n        }\n\n        return this;\n    },\n\n    /**\n     * Generate the complete zip file\n     * @param {Object} options the options to generate the zip file :\n     * - compression, \"STORE\" by default.\n     * - type, \"base64\" by default. Values are : string, base64, uint8array, arraybuffer, blob.\n     * @return {String|Uint8Array|ArrayBuffer|Buffer|Blob} the zip file\n     */\n    generate: function(options) {\n        throw new Error(\"This method has been removed in JSZip 3.0, please check the upgrade guide.\");\n    },\n\n    /**\n     * Generate the complete zip file as an internal stream.\n     * @param {Object} options the options to generate the zip file :\n     * - compression, \"STORE\" by default.\n     * - type, \"base64\" by default. Values are : string, base64, uint8array, arraybuffer, blob.\n     * @return {StreamHelper} the streamed zip file.\n     */\n    generateInternalStream: function(options) {\n      var worker, opts = {};\n      try {\n          opts = utils.extend(options || {}, {\n              streamFiles: false,\n              compression: \"STORE\",\n              compressionOptions : null,\n              type: \"\",\n              platform: \"DOS\",\n              comment: null,\n              mimeType: 'application/zip',\n              encodeFileName: utf8.utf8encode\n          });\n\n          opts.type = opts.type.toLowerCase();\n          opts.compression = opts.compression.toUpperCase();\n\n          // \"binarystring\" is prefered but the internals use \"string\".\n          if(opts.type === \"binarystring\") {\n            opts.type = \"string\";\n          }\n\n          if (!opts.type) {\n            throw new Error(\"No output type specified.\");\n          }\n\n          utils.checkSupport(opts.type);\n\n          // accept nodejs `process.platform`\n          if(\n              opts.platform === 'darwin' ||\n              opts.platform === 'freebsd' ||\n              opts.platform === 'linux' ||\n              opts.platform === 'sunos'\n          ) {\n              opts.platform = \"UNIX\";\n          }\n          if (opts.platform === 'win32') {\n              opts.platform = \"DOS\";\n          }\n\n          var comment = opts.comment || this.comment || \"\";\n          worker = generate.generateWorker(this, opts, comment);\n      } catch (e) {\n        worker = new GenericWorker(\"error\");\n        worker.error(e);\n      }\n      return new StreamHelper(worker, opts.type || \"string\", opts.mimeType);\n    },\n    /**\n     * Generate the complete zip file asynchronously.\n     * @see generateInternalStream\n     */\n    generateAsync: function(options, onUpdate) {\n        return this.generateInternalStream(options).accumulate(onUpdate);\n    },\n    /**\n     * Generate the complete zip file asynchronously.\n     * @see generateInternalStream\n     */\n    generateNodeStream: function(options, onUpdate) {\n        options = options || {};\n        if (!options.type) {\n            options.type = \"nodebuffer\";\n        }\n        return this.generateInternalStream(options).toNodejsStream(onUpdate);\n    }\n};\nmodule.exports = out;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/object.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/reader/ArrayReader.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/reader/ArrayReader.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar DataReader = __webpack_require__(/*! ./DataReader */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/DataReader.js\");\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\n\nfunction ArrayReader(data) {\n    DataReader.call(this, data);\n\tfor(var i = 0; i < this.data.length; i++) {\n\t\tdata[i] = data[i] & 0xFF;\n\t}\n}\nutils.inherits(ArrayReader, DataReader);\n/**\n * @see DataReader.byteAt\n */\nArrayReader.prototype.byteAt = function(i) {\n    return this.data[this.zero + i];\n};\n/**\n * @see DataReader.lastIndexOfSignature\n */\nArrayReader.prototype.lastIndexOfSignature = function(sig) {\n    var sig0 = sig.charCodeAt(0),\n        sig1 = sig.charCodeAt(1),\n        sig2 = sig.charCodeAt(2),\n        sig3 = sig.charCodeAt(3);\n    for (var i = this.length - 4; i >= 0; --i) {\n        if (this.data[i] === sig0 && this.data[i + 1] === sig1 && this.data[i + 2] === sig2 && this.data[i + 3] === sig3) {\n            return i - this.zero;\n        }\n    }\n\n    return -1;\n};\n/**\n * @see DataReader.readAndCheckSignature\n */\nArrayReader.prototype.readAndCheckSignature = function (sig) {\n    var sig0 = sig.charCodeAt(0),\n        sig1 = sig.charCodeAt(1),\n        sig2 = sig.charCodeAt(2),\n        sig3 = sig.charCodeAt(3),\n        data = this.readData(4);\n    return sig0 === data[0] && sig1 === data[1] && sig2 === data[2] && sig3 === data[3];\n};\n/**\n * @see DataReader.readData\n */\nArrayReader.prototype.readData = function(size) {\n    this.checkOffset(size);\n    if(size === 0) {\n        return [];\n    }\n    var result = this.data.slice(this.zero + this.index, this.zero + this.index + size);\n    this.index += size;\n    return result;\n};\nmodule.exports = ArrayReader;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/reader/ArrayReader.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/reader/DataReader.js":
/*!****************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/reader/DataReader.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\n\nfunction DataReader(data) {\n    this.data = data; // type : see implementation\n    this.length = data.length;\n    this.index = 0;\n    this.zero = 0;\n}\nDataReader.prototype = {\n    /**\n     * Check that the offset will not go too far.\n     * @param {string} offset the additional offset to check.\n     * @throws {Error} an Error if the offset is out of bounds.\n     */\n    checkOffset: function(offset) {\n        this.checkIndex(this.index + offset);\n    },\n    /**\n     * Check that the specified index will not be too far.\n     * @param {string} newIndex the index to check.\n     * @throws {Error} an Error if the index is out of bounds.\n     */\n    checkIndex: function(newIndex) {\n        if (this.length < this.zero + newIndex || newIndex < 0) {\n            throw new Error(\"End of data reached (data length = \" + this.length + \", asked index = \" + (newIndex) + \"). Corrupted zip ?\");\n        }\n    },\n    /**\n     * Change the index.\n     * @param {number} newIndex The new index.\n     * @throws {Error} if the new index is out of the data.\n     */\n    setIndex: function(newIndex) {\n        this.checkIndex(newIndex);\n        this.index = newIndex;\n    },\n    /**\n     * Skip the next n bytes.\n     * @param {number} n the number of bytes to skip.\n     * @throws {Error} if the new index is out of the data.\n     */\n    skip: function(n) {\n        this.setIndex(this.index + n);\n    },\n    /**\n     * Get the byte at the specified index.\n     * @param {number} i the index to use.\n     * @return {number} a byte.\n     */\n    byteAt: function(i) {\n        // see implementations\n    },\n    /**\n     * Get the next number with a given byte size.\n     * @param {number} size the number of bytes to read.\n     * @return {number} the corresponding number.\n     */\n    readInt: function(size) {\n        var result = 0,\n            i;\n        this.checkOffset(size);\n        for (i = this.index + size - 1; i >= this.index; i--) {\n            result = (result << 8) + this.byteAt(i);\n        }\n        this.index += size;\n        return result;\n    },\n    /**\n     * Get the next string with a given byte size.\n     * @param {number} size the number of bytes to read.\n     * @return {string} the corresponding string.\n     */\n    readString: function(size) {\n        return utils.transformTo(\"string\", this.readData(size));\n    },\n    /**\n     * Get raw data without conversion, <size> bytes.\n     * @param {number} size the number of bytes to read.\n     * @return {Object} the raw data, implementation specific.\n     */\n    readData: function(size) {\n        // see implementations\n    },\n    /**\n     * Find the last occurence of a zip signature (4 bytes).\n     * @param {string} sig the signature to find.\n     * @return {number} the index of the last occurence, -1 if not found.\n     */\n    lastIndexOfSignature: function(sig) {\n        // see implementations\n    },\n    /**\n     * Read the signature (4 bytes) at the current position and compare it with sig.\n     * @param {string} sig the expected signature\n     * @return {boolean} true if the signature matches, false otherwise.\n     */\n    readAndCheckSignature: function(sig) {\n        // see implementations\n    },\n    /**\n     * Get the next date.\n     * @return {Date} the date.\n     */\n    readDate: function() {\n        var dostime = this.readInt(4);\n        return new Date(Date.UTC(\n        ((dostime >> 25) & 0x7f) + 1980, // year\n        ((dostime >> 21) & 0x0f) - 1, // month\n        (dostime >> 16) & 0x1f, // day\n        (dostime >> 11) & 0x1f, // hour\n        (dostime >> 5) & 0x3f, // minute\n        (dostime & 0x1f) << 1)); // second\n    }\n};\nmodule.exports = DataReader;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/reader/DataReader.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/reader/NodeBufferReader.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/reader/NodeBufferReader.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar Uint8ArrayReader = __webpack_require__(/*! ./Uint8ArrayReader */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/Uint8ArrayReader.js\");\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\n\nfunction NodeBufferReader(data) {\n    Uint8ArrayReader.call(this, data);\n}\nutils.inherits(NodeBufferReader, Uint8ArrayReader);\n\n/**\n * @see DataReader.readData\n */\nNodeBufferReader.prototype.readData = function(size) {\n    this.checkOffset(size);\n    var result = this.data.slice(this.zero + this.index, this.zero + this.index + size);\n    this.index += size;\n    return result;\n};\nmodule.exports = NodeBufferReader;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/reader/NodeBufferReader.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/reader/StringReader.js":
/*!******************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/reader/StringReader.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar DataReader = __webpack_require__(/*! ./DataReader */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/DataReader.js\");\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\n\nfunction StringReader(data) {\n    DataReader.call(this, data);\n}\nutils.inherits(StringReader, DataReader);\n/**\n * @see DataReader.byteAt\n */\nStringReader.prototype.byteAt = function(i) {\n    return this.data.charCodeAt(this.zero + i);\n};\n/**\n * @see DataReader.lastIndexOfSignature\n */\nStringReader.prototype.lastIndexOfSignature = function(sig) {\n    return this.data.lastIndexOf(sig) - this.zero;\n};\n/**\n * @see DataReader.readAndCheckSignature\n */\nStringReader.prototype.readAndCheckSignature = function (sig) {\n    var data = this.readData(4);\n    return sig === data;\n};\n/**\n * @see DataReader.readData\n */\nStringReader.prototype.readData = function(size) {\n    this.checkOffset(size);\n    // this will work because the constructor applied the \"& 0xff\" mask.\n    var result = this.data.slice(this.zero + this.index, this.zero + this.index + size);\n    this.index += size;\n    return result;\n};\nmodule.exports = StringReader;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/reader/StringReader.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/reader/Uint8ArrayReader.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/reader/Uint8ArrayReader.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar ArrayReader = __webpack_require__(/*! ./ArrayReader */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/ArrayReader.js\");\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\n\nfunction Uint8ArrayReader(data) {\n    ArrayReader.call(this, data);\n}\nutils.inherits(Uint8ArrayReader, ArrayReader);\n/**\n * @see DataReader.readData\n */\nUint8ArrayReader.prototype.readData = function(size) {\n    this.checkOffset(size);\n    if(size === 0) {\n        // in IE10, when using subarray(idx, idx), we get the array [0x00] instead of [].\n        return new Uint8Array(0);\n    }\n    var result = this.data.subarray(this.zero + this.index, this.zero + this.index + size);\n    this.index += size;\n    return result;\n};\nmodule.exports = Uint8ArrayReader;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/reader/Uint8ArrayReader.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/reader/readerFor.js":
/*!***************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/reader/readerFor.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar support = __webpack_require__(/*! ../support */ \"./node_modules/unzip-crx/node_modules/jszip/lib/support.js\");\nvar ArrayReader = __webpack_require__(/*! ./ArrayReader */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/ArrayReader.js\");\nvar StringReader = __webpack_require__(/*! ./StringReader */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/StringReader.js\");\nvar NodeBufferReader = __webpack_require__(/*! ./NodeBufferReader */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/NodeBufferReader.js\");\nvar Uint8ArrayReader = __webpack_require__(/*! ./Uint8ArrayReader */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/Uint8ArrayReader.js\");\n\n/**\n * Create a reader adapted to the data.\n * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data to read.\n * @return {DataReader} the data reader.\n */\nmodule.exports = function (data) {\n    var type = utils.getTypeOf(data);\n    utils.checkSupport(type);\n    if (type === \"string\" && !support.uint8array) {\n        return new StringReader(data);\n    }\n    if (type === \"nodebuffer\") {\n        return new NodeBufferReader(data);\n    }\n    if (support.uint8array) {\n        return new Uint8ArrayReader(utils.transformTo(\"uint8array\", data));\n    }\n    return new ArrayReader(utils.transformTo(\"array\", data));\n};\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/reader/readerFor.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/signature.js":
/*!********************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/signature.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nexports.LOCAL_FILE_HEADER = \"PK\\x03\\x04\";\nexports.CENTRAL_FILE_HEADER = \"PK\\x01\\x02\";\nexports.CENTRAL_DIRECTORY_END = \"PK\\x05\\x06\";\nexports.ZIP64_CENTRAL_DIRECTORY_LOCATOR = \"PK\\x06\\x07\";\nexports.ZIP64_CENTRAL_DIRECTORY_END = \"PK\\x06\\x06\";\nexports.DATA_DESCRIPTOR = \"PK\\x07\\x08\";\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/signature.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/stream/ConvertWorker.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/stream/ConvertWorker.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar GenericWorker = __webpack_require__(/*! ./GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\n\n/**\n * A worker which convert chunks to a specified type.\n * @constructor\n * @param {String} destType the destination type.\n */\nfunction ConvertWorker(destType) {\n    GenericWorker.call(this, \"ConvertWorker to \" + destType);\n    this.destType = destType;\n}\nutils.inherits(ConvertWorker, GenericWorker);\n\n/**\n * @see GenericWorker.processChunk\n */\nConvertWorker.prototype.processChunk = function (chunk) {\n    this.push({\n        data : utils.transformTo(this.destType, chunk.data),\n        meta : chunk.meta\n    });\n};\nmodule.exports = ConvertWorker;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/stream/ConvertWorker.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/stream/Crc32Probe.js":
/*!****************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/stream/Crc32Probe.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar GenericWorker = __webpack_require__(/*! ./GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\nvar crc32 = __webpack_require__(/*! ../crc32 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/crc32.js\");\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\n\n/**\n * A worker which calculate the crc32 of the data flowing through.\n * @constructor\n */\nfunction Crc32Probe() {\n    GenericWorker.call(this, \"Crc32Probe\");\n    this.withStreamInfo(\"crc32\", 0);\n}\nutils.inherits(Crc32Probe, GenericWorker);\n\n/**\n * @see GenericWorker.processChunk\n */\nCrc32Probe.prototype.processChunk = function (chunk) {\n    this.streamInfo.crc32 = crc32(chunk.data, this.streamInfo.crc32 || 0);\n    this.push(chunk);\n};\nmodule.exports = Crc32Probe;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/stream/Crc32Probe.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataLengthProbe.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataLengthProbe.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar GenericWorker = __webpack_require__(/*! ./GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\n\n/**\n * A worker which calculate the total length of the data flowing through.\n * @constructor\n * @param {String} propName the name used to expose the length\n */\nfunction DataLengthProbe(propName) {\n    GenericWorker.call(this, \"DataLengthProbe for \" + propName);\n    this.propName = propName;\n    this.withStreamInfo(propName, 0);\n}\nutils.inherits(DataLengthProbe, GenericWorker);\n\n/**\n * @see GenericWorker.processChunk\n */\nDataLengthProbe.prototype.processChunk = function (chunk) {\n    if(chunk) {\n        var length = this.streamInfo[this.propName] || 0;\n        this.streamInfo[this.propName] = length + chunk.data.length;\n    }\n    GenericWorker.prototype.processChunk.call(this, chunk);\n};\nmodule.exports = DataLengthProbe;\n\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataLengthProbe.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataWorker.js":
/*!****************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataWorker.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar GenericWorker = __webpack_require__(/*! ./GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\n\n// the size of the generated chunks\n// TODO expose this as a public variable\nvar DEFAULT_BLOCK_SIZE = 16 * 1024;\n\n/**\n * A worker that reads a content and emits chunks.\n * @constructor\n * @param {Promise} dataP the promise of the data to split\n */\nfunction DataWorker(dataP) {\n    GenericWorker.call(this, \"DataWorker\");\n    var self = this;\n    this.dataIsReady = false;\n    this.index = 0;\n    this.max = 0;\n    this.data = null;\n    this.type = \"\";\n\n    this._tickScheduled = false;\n\n    dataP.then(function (data) {\n        self.dataIsReady = true;\n        self.data = data;\n        self.max = data && data.length || 0;\n        self.type = utils.getTypeOf(data);\n        if(!self.isPaused) {\n            self._tickAndRepeat();\n        }\n    }, function (e) {\n        self.error(e);\n    });\n}\n\nutils.inherits(DataWorker, GenericWorker);\n\n/**\n * @see GenericWorker.cleanUp\n */\nDataWorker.prototype.cleanUp = function () {\n    GenericWorker.prototype.cleanUp.call(this);\n    this.data = null;\n};\n\n/**\n * @see GenericWorker.resume\n */\nDataWorker.prototype.resume = function () {\n    if(!GenericWorker.prototype.resume.call(this)) {\n        return false;\n    }\n\n    if (!this._tickScheduled && this.dataIsReady) {\n        this._tickScheduled = true;\n        utils.delay(this._tickAndRepeat, [], this);\n    }\n    return true;\n};\n\n/**\n * Trigger a tick a schedule an other call to this function.\n */\nDataWorker.prototype._tickAndRepeat = function() {\n    this._tickScheduled = false;\n    if(this.isPaused || this.isFinished) {\n        return;\n    }\n    this._tick();\n    if(!this.isFinished) {\n        utils.delay(this._tickAndRepeat, [], this);\n        this._tickScheduled = true;\n    }\n};\n\n/**\n * Read and push a chunk.\n */\nDataWorker.prototype._tick = function() {\n\n    if(this.isPaused || this.isFinished) {\n        return false;\n    }\n\n    var size = DEFAULT_BLOCK_SIZE;\n    var data = null, nextIndex = Math.min(this.max, this.index + size);\n    if (this.index >= this.max) {\n        // EOF\n        return this.end();\n    } else {\n        switch(this.type) {\n            case \"string\":\n                data = this.data.substring(this.index, nextIndex);\n            break;\n            case \"uint8array\":\n                data = this.data.subarray(this.index, nextIndex);\n            break;\n            case \"array\":\n            case \"nodebuffer\":\n                data = this.data.slice(this.index, nextIndex);\n            break;\n        }\n        this.index = nextIndex;\n        return this.push({\n            data : data,\n            meta : {\n                percent : this.max ? this.index / this.max * 100 : 0\n            }\n        });\n    }\n};\n\nmodule.exports = DataWorker;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataWorker.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n/**\n * A worker that does nothing but passing chunks to the next one. This is like\n * a nodejs stream but with some differences. On the good side :\n * - it works on IE 6-9 without any issue / polyfill\n * - it weights less than the full dependencies bundled with browserify\n * - it forwards errors (no need to declare an error handler EVERYWHERE)\n *\n * A chunk is an object with 2 attributes : `meta` and `data`. The former is an\n * object containing anything (`percent` for example), see each worker for more\n * details. The latter is the real data (String, Uint8Array, etc).\n *\n * @constructor\n * @param {String} name the name of the stream (mainly used for debugging purposes)\n */\nfunction GenericWorker(name) {\n    // the name of the worker\n    this.name = name || \"default\";\n    // an object containing metadata about the workers chain\n    this.streamInfo = {};\n    // an error which happened when the worker was paused\n    this.generatedError = null;\n    // an object containing metadata to be merged by this worker into the general metadata\n    this.extraStreamInfo = {};\n    // true if the stream is paused (and should not do anything), false otherwise\n    this.isPaused = true;\n    // true if the stream is finished (and should not do anything), false otherwise\n    this.isFinished = false;\n    // true if the stream is locked to prevent further structure updates (pipe), false otherwise\n    this.isLocked = false;\n    // the event listeners\n    this._listeners = {\n        'data':[],\n        'end':[],\n        'error':[]\n    };\n    // the previous worker, if any\n    this.previous = null;\n}\n\nGenericWorker.prototype = {\n    /**\n     * Push a chunk to the next workers.\n     * @param {Object} chunk the chunk to push\n     */\n    push : function (chunk) {\n        this.emit(\"data\", chunk);\n    },\n    /**\n     * End the stream.\n     * @return {Boolean} true if this call ended the worker, false otherwise.\n     */\n    end : function () {\n        if (this.isFinished) {\n            return false;\n        }\n\n        this.flush();\n        try {\n            this.emit(\"end\");\n            this.cleanUp();\n            this.isFinished = true;\n        } catch (e) {\n            this.emit(\"error\", e);\n        }\n        return true;\n    },\n    /**\n     * End the stream with an error.\n     * @param {Error} e the error which caused the premature end.\n     * @return {Boolean} true if this call ended the worker with an error, false otherwise.\n     */\n    error : function (e) {\n        if (this.isFinished) {\n            return false;\n        }\n\n        if(this.isPaused) {\n            this.generatedError = e;\n        } else {\n            this.isFinished = true;\n\n            this.emit(\"error\", e);\n\n            // in the workers chain exploded in the middle of the chain,\n            // the error event will go downward but we also need to notify\n            // workers upward that there has been an error.\n            if(this.previous) {\n                this.previous.error(e);\n            }\n\n            this.cleanUp();\n        }\n        return true;\n    },\n    /**\n     * Add a callback on an event.\n     * @param {String} name the name of the event (data, end, error)\n     * @param {Function} listener the function to call when the event is triggered\n     * @return {GenericWorker} the current object for chainability\n     */\n    on : function (name, listener) {\n        this._listeners[name].push(listener);\n        return this;\n    },\n    /**\n     * Clean any references when a worker is ending.\n     */\n    cleanUp : function () {\n        this.streamInfo = this.generatedError = this.extraStreamInfo = null;\n        this._listeners = [];\n    },\n    /**\n     * Trigger an event. This will call registered callback with the provided arg.\n     * @param {String} name the name of the event (data, end, error)\n     * @param {Object} arg the argument to call the callback with.\n     */\n    emit : function (name, arg) {\n        if (this._listeners[name]) {\n            for(var i = 0; i < this._listeners[name].length; i++) {\n                this._listeners[name][i].call(this, arg);\n            }\n        }\n    },\n    /**\n     * Chain a worker with an other.\n     * @param {Worker} next the worker receiving events from the current one.\n     * @return {worker} the next worker for chainability\n     */\n    pipe : function (next) {\n        return next.registerPrevious(this);\n    },\n    /**\n     * Same as `pipe` in the other direction.\n     * Using an API with `pipe(next)` is very easy.\n     * Implementing the API with the point of view of the next one registering\n     * a source is easier, see the ZipFileWorker.\n     * @param {Worker} previous the previous worker, sending events to this one\n     * @return {Worker} the current worker for chainability\n     */\n    registerPrevious : function (previous) {\n        if (this.isLocked) {\n            throw new Error(\"The stream '\" + this + \"' has already been used.\");\n        }\n\n        // sharing the streamInfo...\n        this.streamInfo = previous.streamInfo;\n        // ... and adding our own bits\n        this.mergeStreamInfo();\n        this.previous =  previous;\n        var self = this;\n        previous.on('data', function (chunk) {\n            self.processChunk(chunk);\n        });\n        previous.on('end', function () {\n            self.end();\n        });\n        previous.on('error', function (e) {\n            self.error(e);\n        });\n        return this;\n    },\n    /**\n     * Pause the stream so it doesn't send events anymore.\n     * @return {Boolean} true if this call paused the worker, false otherwise.\n     */\n    pause : function () {\n        if(this.isPaused || this.isFinished) {\n            return false;\n        }\n        this.isPaused = true;\n\n        if(this.previous) {\n            this.previous.pause();\n        }\n        return true;\n    },\n    /**\n     * Resume a paused stream.\n     * @return {Boolean} true if this call resumed the worker, false otherwise.\n     */\n    resume : function () {\n        if(!this.isPaused || this.isFinished) {\n            return false;\n        }\n        this.isPaused = false;\n\n        // if true, the worker tried to resume but failed\n        var withError = false;\n        if(this.generatedError) {\n            this.error(this.generatedError);\n            withError = true;\n        }\n        if(this.previous) {\n            this.previous.resume();\n        }\n\n        return !withError;\n    },\n    /**\n     * Flush any remaining bytes as the stream is ending.\n     */\n    flush : function () {},\n    /**\n     * Process a chunk. This is usually the method overridden.\n     * @param {Object} chunk the chunk to process.\n     */\n    processChunk : function(chunk) {\n        this.push(chunk);\n    },\n    /**\n     * Add a key/value to be added in the workers chain streamInfo once activated.\n     * @param {String} key the key to use\n     * @param {Object} value the associated value\n     * @return {Worker} the current worker for chainability\n     */\n    withStreamInfo : function (key, value) {\n        this.extraStreamInfo[key] = value;\n        this.mergeStreamInfo();\n        return this;\n    },\n    /**\n     * Merge this worker's streamInfo into the chain's streamInfo.\n     */\n    mergeStreamInfo : function () {\n        for(var key in this.extraStreamInfo) {\n            if (!this.extraStreamInfo.hasOwnProperty(key)) {\n                continue;\n            }\n            this.streamInfo[key] = this.extraStreamInfo[key];\n        }\n    },\n\n    /**\n     * Lock the stream to prevent further updates on the workers chain.\n     * After calling this method, all calls to pipe will fail.\n     */\n    lock: function () {\n        if (this.isLocked) {\n            throw new Error(\"The stream '\" + this + \"' has already been used.\");\n        }\n        this.isLocked = true;\n        if (this.previous) {\n            this.previous.lock();\n        }\n    },\n\n    /**\n     *\n     * Pretty print the workers chain.\n     */\n    toString : function () {\n        var me = \"Worker \" + this.name;\n        if (this.previous) {\n            return this.previous + \" -> \" + me;\n        } else {\n            return me;\n        }\n    }\n};\n\nmodule.exports = GenericWorker;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/stream/StreamHelper.js":
/*!******************************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/stream/StreamHelper.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ../utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar ConvertWorker = __webpack_require__(/*! ./ConvertWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/ConvertWorker.js\");\nvar GenericWorker = __webpack_require__(/*! ./GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\nvar base64 = __webpack_require__(/*! ../base64 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/base64.js\");\nvar support = __webpack_require__(/*! ../support */ \"./node_modules/unzip-crx/node_modules/jszip/lib/support.js\");\nvar external = __webpack_require__(/*! ../external */ \"./node_modules/unzip-crx/node_modules/jszip/lib/external.js\");\n\nvar NodejsStreamOutputAdapter = null;\nif (support.nodestream) {\n    try {\n        NodejsStreamOutputAdapter = __webpack_require__(/*! ../nodejs/NodejsStreamOutputAdapter */ \"./node_modules/unzip-crx/node_modules/jszip/lib/nodejs/NodejsStreamOutputAdapter.js\");\n    } catch(e) {}\n}\n\n/**\n * Apply the final transformation of the data. If the user wants a Blob for\n * example, it's easier to work with an U8intArray and finally do the\n * ArrayBuffer/Blob conversion.\n * @param {String} type the name of the final type\n * @param {String|Uint8Array|Buffer} content the content to transform\n * @param {String} mimeType the mime type of the content, if applicable.\n * @return {String|Uint8Array|ArrayBuffer|Buffer|Blob} the content in the right format.\n */\nfunction transformZipOutput(type, content, mimeType) {\n    switch(type) {\n        case \"blob\" :\n            return utils.newBlob(utils.transformTo(\"arraybuffer\", content), mimeType);\n        case \"base64\" :\n            return base64.encode(content);\n        default :\n            return utils.transformTo(type, content);\n    }\n}\n\n/**\n * Concatenate an array of data of the given type.\n * @param {String} type the type of the data in the given array.\n * @param {Array} dataArray the array containing the data chunks to concatenate\n * @return {String|Uint8Array|Buffer} the concatenated data\n * @throws Error if the asked type is unsupported\n */\nfunction concat (type, dataArray) {\n    var i, index = 0, res = null, totalLength = 0;\n    for(i = 0; i < dataArray.length; i++) {\n        totalLength += dataArray[i].length;\n    }\n    switch(type) {\n        case \"string\":\n            return dataArray.join(\"\");\n          case \"array\":\n            return Array.prototype.concat.apply([], dataArray);\n        case \"uint8array\":\n            res = new Uint8Array(totalLength);\n            for(i = 0; i < dataArray.length; i++) {\n                res.set(dataArray[i], index);\n                index += dataArray[i].length;\n            }\n            return res;\n        case \"nodebuffer\":\n            return Buffer.concat(dataArray);\n        default:\n            throw new Error(\"concat : unsupported type '\"  + type + \"'\");\n    }\n}\n\n/**\n * Listen a StreamHelper, accumulate its content and concatenate it into a\n * complete block.\n * @param {StreamHelper} helper the helper to use.\n * @param {Function} updateCallback a callback called on each update. Called\n * with one arg :\n * - the metadata linked to the update received.\n * @return Promise the promise for the accumulation.\n */\nfunction accumulate(helper, updateCallback) {\n    return new external.Promise(function (resolve, reject){\n        var dataArray = [];\n        var chunkType = helper._internalType,\n            resultType = helper._outputType,\n            mimeType = helper._mimeType;\n        helper\n        .on('data', function (data, meta) {\n            dataArray.push(data);\n            if(updateCallback) {\n                updateCallback(meta);\n            }\n        })\n        .on('error', function(err) {\n            dataArray = [];\n            reject(err);\n        })\n        .on('end', function (){\n            try {\n                var result = transformZipOutput(resultType, concat(chunkType, dataArray), mimeType);\n                resolve(result);\n            } catch (e) {\n                reject(e);\n            }\n            dataArray = [];\n        })\n        .resume();\n    });\n}\n\n/**\n * An helper to easily use workers outside of JSZip.\n * @constructor\n * @param {Worker} worker the worker to wrap\n * @param {String} outputType the type of data expected by the use\n * @param {String} mimeType the mime type of the content, if applicable.\n */\nfunction StreamHelper(worker, outputType, mimeType) {\n    var internalType = outputType;\n    switch(outputType) {\n        case \"blob\":\n        case \"arraybuffer\":\n            internalType = \"uint8array\";\n        break;\n        case \"base64\":\n            internalType = \"string\";\n        break;\n    }\n\n    try {\n        // the type used internally\n        this._internalType = internalType;\n        // the type used to output results\n        this._outputType = outputType;\n        // the mime type\n        this._mimeType = mimeType;\n        utils.checkSupport(internalType);\n        this._worker = worker.pipe(new ConvertWorker(internalType));\n        // the last workers can be rewired without issues but we need to\n        // prevent any updates on previous workers.\n        worker.lock();\n    } catch(e) {\n        this._worker = new GenericWorker(\"error\");\n        this._worker.error(e);\n    }\n}\n\nStreamHelper.prototype = {\n    /**\n     * Listen a StreamHelper, accumulate its content and concatenate it into a\n     * complete block.\n     * @param {Function} updateCb the update callback.\n     * @return Promise the promise for the accumulation.\n     */\n    accumulate : function (updateCb) {\n        return accumulate(this, updateCb);\n    },\n    /**\n     * Add a listener on an event triggered on a stream.\n     * @param {String} evt the name of the event\n     * @param {Function} fn the listener\n     * @return {StreamHelper} the current helper.\n     */\n    on : function (evt, fn) {\n        var self = this;\n\n        if(evt === \"data\") {\n            this._worker.on(evt, function (chunk) {\n                fn.call(self, chunk.data, chunk.meta);\n            });\n        } else {\n            this._worker.on(evt, function () {\n                utils.delay(fn, arguments, self);\n            });\n        }\n        return this;\n    },\n    /**\n     * Resume the flow of chunks.\n     * @return {StreamHelper} the current helper.\n     */\n    resume : function () {\n        utils.delay(this._worker.resume, [], this._worker);\n        return this;\n    },\n    /**\n     * Pause the flow of chunks.\n     * @return {StreamHelper} the current helper.\n     */\n    pause : function () {\n        this._worker.pause();\n        return this;\n    },\n    /**\n     * Return a nodejs stream for this helper.\n     * @param {Function} updateCb the update callback.\n     * @return {NodejsStreamOutputAdapter} the nodejs stream.\n     */\n    toNodejsStream : function (updateCb) {\n        utils.checkSupport(\"nodestream\");\n        if (this._outputType !== \"nodebuffer\") {\n            // an object stream containing blob/arraybuffer/uint8array/string\n            // is strange and I don't know if it would be useful.\n            // I you find this comment and have a good usecase, please open a\n            // bug report !\n            throw new Error(this._outputType + \" is not supported by this method\");\n        }\n\n        return new NodejsStreamOutputAdapter(this, {\n            objectMode : this._outputType !== \"nodebuffer\"\n        }, updateCb);\n    }\n};\n\n\nmodule.exports = StreamHelper;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/stream/StreamHelper.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/support.js":
/*!******************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/support.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nexports.base64 = true;\nexports.array = true;\nexports.string = true;\nexports.arraybuffer = typeof ArrayBuffer !== \"undefined\" && typeof Uint8Array !== \"undefined\";\nexports.nodebuffer = typeof Buffer !== \"undefined\";\n// contains true if JSZip can read/generate Uint8Array, false otherwise.\nexports.uint8array = typeof Uint8Array !== \"undefined\";\n\nif (typeof ArrayBuffer === \"undefined\") {\n    exports.blob = false;\n}\nelse {\n    var buffer = new ArrayBuffer(0);\n    try {\n        exports.blob = new Blob([buffer], {\n            type: \"application/zip\"\n        }).size === 0;\n    }\n    catch (e) {\n        try {\n            var Builder = self.BlobBuilder || self.WebKitBlobBuilder || self.MozBlobBuilder || self.MSBlobBuilder;\n            var builder = new Builder();\n            builder.append(buffer);\n            exports.blob = builder.getBlob('application/zip').size === 0;\n        }\n        catch (e) {\n            exports.blob = false;\n        }\n    }\n}\n\ntry {\n    exports.nodestream = !!__webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/readable.js\").Readable;\n} catch(e) {\n    exports.nodestream = false;\n}\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/support.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/utf8.js":
/*!***************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/utf8.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/unzip-crx/node_modules/jszip/lib/support.js\");\nvar nodejsUtils = __webpack_require__(/*! ./nodejsUtils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/nodejsUtils.js\");\nvar GenericWorker = __webpack_require__(/*! ./stream/GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\n\n/**\n * The following functions come from pako, from pako/lib/utils/strings\n * released under the MIT license, see pako https://github.com/nodeca/pako/\n */\n\n// Table with utf8 lengths (calculated by first byte of sequence)\n// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,\n// because max possible codepoint is 0x10ffff\nvar _utf8len = new Array(256);\nfor (var i=0; i<256; i++) {\n  _utf8len[i] = (i >= 252 ? 6 : i >= 248 ? 5 : i >= 240 ? 4 : i >= 224 ? 3 : i >= 192 ? 2 : 1);\n}\n_utf8len[254]=_utf8len[254]=1; // Invalid sequence start\n\n// convert string to array (typed, when possible)\nvar string2buf = function (str) {\n    var buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;\n\n    // count binary size\n    for (m_pos = 0; m_pos < str_len; m_pos++) {\n        c = str.charCodeAt(m_pos);\n        if ((c & 0xfc00) === 0xd800 && (m_pos+1 < str_len)) {\n            c2 = str.charCodeAt(m_pos+1);\n            if ((c2 & 0xfc00) === 0xdc00) {\n                c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n                m_pos++;\n            }\n        }\n        buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;\n    }\n\n    // allocate buffer\n    if (support.uint8array) {\n        buf = new Uint8Array(buf_len);\n    } else {\n        buf = new Array(buf_len);\n    }\n\n    // convert\n    for (i=0, m_pos = 0; i < buf_len; m_pos++) {\n        c = str.charCodeAt(m_pos);\n        if ((c & 0xfc00) === 0xd800 && (m_pos+1 < str_len)) {\n            c2 = str.charCodeAt(m_pos+1);\n            if ((c2 & 0xfc00) === 0xdc00) {\n                c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n                m_pos++;\n            }\n        }\n        if (c < 0x80) {\n            /* one byte */\n            buf[i++] = c;\n        } else if (c < 0x800) {\n            /* two bytes */\n            buf[i++] = 0xC0 | (c >>> 6);\n            buf[i++] = 0x80 | (c & 0x3f);\n        } else if (c < 0x10000) {\n            /* three bytes */\n            buf[i++] = 0xE0 | (c >>> 12);\n            buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n            buf[i++] = 0x80 | (c & 0x3f);\n        } else {\n            /* four bytes */\n            buf[i++] = 0xf0 | (c >>> 18);\n            buf[i++] = 0x80 | (c >>> 12 & 0x3f);\n            buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n            buf[i++] = 0x80 | (c & 0x3f);\n        }\n    }\n\n    return buf;\n};\n\n// Calculate max possible position in utf8 buffer,\n// that will not break sequence. If that's not possible\n// - (very small limits) return max size as is.\n//\n// buf[] - utf8 bytes array\n// max   - length limit (mandatory);\nvar utf8border = function(buf, max) {\n    var pos;\n\n    max = max || buf.length;\n    if (max > buf.length) { max = buf.length; }\n\n    // go back from last position, until start of sequence found\n    pos = max-1;\n    while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }\n\n    // Fuckup - very small and broken sequence,\n    // return max, because we should return something anyway.\n    if (pos < 0) { return max; }\n\n    // If we came to start of buffer - that means vuffer is too small,\n    // return max too.\n    if (pos === 0) { return max; }\n\n    return (pos + _utf8len[buf[pos]] > max) ? pos : max;\n};\n\n// convert array to string\nvar buf2string = function (buf) {\n    var str, i, out, c, c_len;\n    var len = buf.length;\n\n    // Reserve max possible length (2 words per char)\n    // NB: by unknown reasons, Array is significantly faster for\n    //     String.fromCharCode.apply than Uint16Array.\n    var utf16buf = new Array(len*2);\n\n    for (out=0, i=0; i<len;) {\n        c = buf[i++];\n        // quick process ascii\n        if (c < 0x80) { utf16buf[out++] = c; continue; }\n\n        c_len = _utf8len[c];\n        // skip 5 & 6 byte codes\n        if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len-1; continue; }\n\n        // apply mask on first byte\n        c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;\n        // join the rest\n        while (c_len > 1 && i < len) {\n            c = (c << 6) | (buf[i++] & 0x3f);\n            c_len--;\n        }\n\n        // terminated by end of string?\n        if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }\n\n        if (c < 0x10000) {\n            utf16buf[out++] = c;\n        } else {\n            c -= 0x10000;\n            utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);\n            utf16buf[out++] = 0xdc00 | (c & 0x3ff);\n        }\n    }\n\n    // shrinkBuf(utf16buf, out)\n    if (utf16buf.length !== out) {\n        if(utf16buf.subarray) {\n            utf16buf = utf16buf.subarray(0, out);\n        } else {\n            utf16buf.length = out;\n        }\n    }\n\n    // return String.fromCharCode.apply(null, utf16buf);\n    return utils.applyFromCharCode(utf16buf);\n};\n\n\n// That's all for the pako functions.\n\n\n/**\n * Transform a javascript string into an array (typed if possible) of bytes,\n * UTF-8 encoded.\n * @param {String} str the string to encode\n * @return {Array|Uint8Array|Buffer} the UTF-8 encoded string.\n */\nexports.utf8encode = function utf8encode(str) {\n    if (support.nodebuffer) {\n        return nodejsUtils.newBufferFrom(str, \"utf-8\");\n    }\n\n    return string2buf(str);\n};\n\n\n/**\n * Transform a bytes array (or a representation) representing an UTF-8 encoded\n * string into a javascript string.\n * @param {Array|Uint8Array|Buffer} buf the data de decode\n * @return {String} the decoded string.\n */\nexports.utf8decode = function utf8decode(buf) {\n    if (support.nodebuffer) {\n        return utils.transformTo(\"nodebuffer\", buf).toString(\"utf-8\");\n    }\n\n    buf = utils.transformTo(support.uint8array ? \"uint8array\" : \"array\", buf);\n\n    return buf2string(buf);\n};\n\n/**\n * A worker to decode utf8 encoded binary chunks into string chunks.\n * @constructor\n */\nfunction Utf8DecodeWorker() {\n    GenericWorker.call(this, \"utf-8 decode\");\n    // the last bytes if a chunk didn't end with a complete codepoint.\n    this.leftOver = null;\n}\nutils.inherits(Utf8DecodeWorker, GenericWorker);\n\n/**\n * @see GenericWorker.processChunk\n */\nUtf8DecodeWorker.prototype.processChunk = function (chunk) {\n\n    var data = utils.transformTo(support.uint8array ? \"uint8array\" : \"array\", chunk.data);\n\n    // 1st step, re-use what's left of the previous chunk\n    if (this.leftOver && this.leftOver.length) {\n        if(support.uint8array) {\n            var previousData = data;\n            data = new Uint8Array(previousData.length + this.leftOver.length);\n            data.set(this.leftOver, 0);\n            data.set(previousData, this.leftOver.length);\n        } else {\n            data = this.leftOver.concat(data);\n        }\n        this.leftOver = null;\n    }\n\n    var nextBoundary = utf8border(data);\n    var usableData = data;\n    if (nextBoundary !== data.length) {\n        if (support.uint8array) {\n            usableData = data.subarray(0, nextBoundary);\n            this.leftOver = data.subarray(nextBoundary, data.length);\n        } else {\n            usableData = data.slice(0, nextBoundary);\n            this.leftOver = data.slice(nextBoundary, data.length);\n        }\n    }\n\n    this.push({\n        data : exports.utf8decode(usableData),\n        meta : chunk.meta\n    });\n};\n\n/**\n * @see GenericWorker.flush\n */\nUtf8DecodeWorker.prototype.flush = function () {\n    if(this.leftOver && this.leftOver.length) {\n        this.push({\n            data : exports.utf8decode(this.leftOver),\n            meta : {}\n        });\n        this.leftOver = null;\n    }\n};\nexports.Utf8DecodeWorker = Utf8DecodeWorker;\n\n/**\n * A worker to endcode string chunks into utf8 encoded binary chunks.\n * @constructor\n */\nfunction Utf8EncodeWorker() {\n    GenericWorker.call(this, \"utf-8 encode\");\n}\nutils.inherits(Utf8EncodeWorker, GenericWorker);\n\n/**\n * @see GenericWorker.processChunk\n */\nUtf8EncodeWorker.prototype.processChunk = function (chunk) {\n    this.push({\n        data : exports.utf8encode(chunk.data),\n        meta : chunk.meta\n    });\n};\nexports.Utf8EncodeWorker = Utf8EncodeWorker;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/utf8.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/utils.js":
/*!****************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/utils.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/unzip-crx/node_modules/jszip/lib/support.js\");\nvar base64 = __webpack_require__(/*! ./base64 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/base64.js\");\nvar nodejsUtils = __webpack_require__(/*! ./nodejsUtils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/nodejsUtils.js\");\nvar setImmediate = __webpack_require__(/*! set-immediate-shim */ \"./node_modules/set-immediate-shim/index.js\");\nvar external = __webpack_require__(/*! ./external */ \"./node_modules/unzip-crx/node_modules/jszip/lib/external.js\");\n\n\n/**\n * Convert a string that pass as a \"binary string\": it should represent a byte\n * array but may have > 255 char codes. Be sure to take only the first byte\n * and returns the byte array.\n * @param {String} str the string to transform.\n * @return {Array|Uint8Array} the string in a binary format.\n */\nfunction string2binary(str) {\n    var result = null;\n    if (support.uint8array) {\n      result = new Uint8Array(str.length);\n    } else {\n      result = new Array(str.length);\n    }\n    return stringToArrayLike(str, result);\n}\n\n/**\n * Create a new blob with the given content and the given type.\n * @param {String|ArrayBuffer} part the content to put in the blob. DO NOT use\n * an Uint8Array because the stock browser of android 4 won't accept it (it\n * will be silently converted to a string, \"[object Uint8Array]\").\n *\n * Use only ONE part to build the blob to avoid a memory leak in IE11 / Edge:\n * when a large amount of Array is used to create the Blob, the amount of\n * memory consumed is nearly 100 times the original data amount.\n *\n * @param {String} type the mime type of the blob.\n * @return {Blob} the created blob.\n */\nexports.newBlob = function(part, type) {\n    exports.checkSupport(\"blob\");\n\n    try {\n        // Blob constructor\n        return new Blob([part], {\n            type: type\n        });\n    }\n    catch (e) {\n\n        try {\n            // deprecated, browser only, old way\n            var Builder = self.BlobBuilder || self.WebKitBlobBuilder || self.MozBlobBuilder || self.MSBlobBuilder;\n            var builder = new Builder();\n            builder.append(part);\n            return builder.getBlob(type);\n        }\n        catch (e) {\n\n            // well, fuck ?!\n            throw new Error(\"Bug : can't construct the Blob.\");\n        }\n    }\n\n\n};\n/**\n * The identity function.\n * @param {Object} input the input.\n * @return {Object} the same input.\n */\nfunction identity(input) {\n    return input;\n}\n\n/**\n * Fill in an array with a string.\n * @param {String} str the string to use.\n * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to fill in (will be mutated).\n * @return {Array|ArrayBuffer|Uint8Array|Buffer} the updated array.\n */\nfunction stringToArrayLike(str, array) {\n    for (var i = 0; i < str.length; ++i) {\n        array[i] = str.charCodeAt(i) & 0xFF;\n    }\n    return array;\n}\n\n/**\n * An helper for the function arrayLikeToString.\n * This contains static informations and functions that\n * can be optimized by the browser JIT compiler.\n */\nvar arrayToStringHelper = {\n    /**\n     * Transform an array of int into a string, chunk by chunk.\n     * See the performances notes on arrayLikeToString.\n     * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.\n     * @param {String} type the type of the array.\n     * @param {Integer} chunk the chunk size.\n     * @return {String} the resulting string.\n     * @throws Error if the chunk is too big for the stack.\n     */\n    stringifyByChunk: function(array, type, chunk) {\n        var result = [], k = 0, len = array.length;\n        // shortcut\n        if (len <= chunk) {\n            return String.fromCharCode.apply(null, array);\n        }\n        while (k < len) {\n            if (type === \"array\" || type === \"nodebuffer\") {\n                result.push(String.fromCharCode.apply(null, array.slice(k, Math.min(k + chunk, len))));\n            }\n            else {\n                result.push(String.fromCharCode.apply(null, array.subarray(k, Math.min(k + chunk, len))));\n            }\n            k += chunk;\n        }\n        return result.join(\"\");\n    },\n    /**\n     * Call String.fromCharCode on every item in the array.\n     * This is the naive implementation, which generate A LOT of intermediate string.\n     * This should be used when everything else fail.\n     * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.\n     * @return {String} the result.\n     */\n    stringifyByChar: function(array){\n        var resultStr = \"\";\n        for(var i = 0; i < array.length; i++) {\n            resultStr += String.fromCharCode(array[i]);\n        }\n        return resultStr;\n    },\n    applyCanBeUsed : {\n        /**\n         * true if the browser accepts to use String.fromCharCode on Uint8Array\n         */\n        uint8array : (function () {\n            try {\n                return support.uint8array && String.fromCharCode.apply(null, new Uint8Array(1)).length === 1;\n            } catch (e) {\n                return false;\n            }\n        })(),\n        /**\n         * true if the browser accepts to use String.fromCharCode on nodejs Buffer.\n         */\n        nodebuffer : (function () {\n            try {\n                return support.nodebuffer && String.fromCharCode.apply(null, nodejsUtils.allocBuffer(1)).length === 1;\n            } catch (e) {\n                return false;\n            }\n        })()\n    }\n};\n\n/**\n * Transform an array-like object to a string.\n * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.\n * @return {String} the result.\n */\nfunction arrayLikeToString(array) {\n    // Performances notes :\n    // --------------------\n    // String.fromCharCode.apply(null, array) is the fastest, see\n    // see http://jsperf.com/converting-a-uint8array-to-a-string/2\n    // but the stack is limited (and we can get huge arrays !).\n    //\n    // result += String.fromCharCode(array[i]); generate too many strings !\n    //\n    // This code is inspired by http://jsperf.com/arraybuffer-to-string-apply-performance/2\n    // TODO : we now have workers that split the work. Do we still need that ?\n    var chunk = 65536,\n        type = exports.getTypeOf(array),\n        canUseApply = true;\n    if (type === \"uint8array\") {\n        canUseApply = arrayToStringHelper.applyCanBeUsed.uint8array;\n    } else if (type === \"nodebuffer\") {\n        canUseApply = arrayToStringHelper.applyCanBeUsed.nodebuffer;\n    }\n\n    if (canUseApply) {\n        while (chunk > 1) {\n            try {\n                return arrayToStringHelper.stringifyByChunk(array, type, chunk);\n            } catch (e) {\n                chunk = Math.floor(chunk / 2);\n            }\n        }\n    }\n\n    // no apply or chunk error : slow and painful algorithm\n    // default browser on android 4.*\n    return arrayToStringHelper.stringifyByChar(array);\n}\n\nexports.applyFromCharCode = arrayLikeToString;\n\n\n/**\n * Copy the data from an array-like to an other array-like.\n * @param {Array|ArrayBuffer|Uint8Array|Buffer} arrayFrom the origin array.\n * @param {Array|ArrayBuffer|Uint8Array|Buffer} arrayTo the destination array which will be mutated.\n * @return {Array|ArrayBuffer|Uint8Array|Buffer} the updated destination array.\n */\nfunction arrayLikeToArrayLike(arrayFrom, arrayTo) {\n    for (var i = 0; i < arrayFrom.length; i++) {\n        arrayTo[i] = arrayFrom[i];\n    }\n    return arrayTo;\n}\n\n// a matrix containing functions to transform everything into everything.\nvar transform = {};\n\n// string to ?\ntransform[\"string\"] = {\n    \"string\": identity,\n    \"array\": function(input) {\n        return stringToArrayLike(input, new Array(input.length));\n    },\n    \"arraybuffer\": function(input) {\n        return transform[\"string\"][\"uint8array\"](input).buffer;\n    },\n    \"uint8array\": function(input) {\n        return stringToArrayLike(input, new Uint8Array(input.length));\n    },\n    \"nodebuffer\": function(input) {\n        return stringToArrayLike(input, nodejsUtils.allocBuffer(input.length));\n    }\n};\n\n// array to ?\ntransform[\"array\"] = {\n    \"string\": arrayLikeToString,\n    \"array\": identity,\n    \"arraybuffer\": function(input) {\n        return (new Uint8Array(input)).buffer;\n    },\n    \"uint8array\": function(input) {\n        return new Uint8Array(input);\n    },\n    \"nodebuffer\": function(input) {\n        return nodejsUtils.newBufferFrom(input);\n    }\n};\n\n// arraybuffer to ?\ntransform[\"arraybuffer\"] = {\n    \"string\": function(input) {\n        return arrayLikeToString(new Uint8Array(input));\n    },\n    \"array\": function(input) {\n        return arrayLikeToArrayLike(new Uint8Array(input), new Array(input.byteLength));\n    },\n    \"arraybuffer\": identity,\n    \"uint8array\": function(input) {\n        return new Uint8Array(input);\n    },\n    \"nodebuffer\": function(input) {\n        return nodejsUtils.newBufferFrom(new Uint8Array(input));\n    }\n};\n\n// uint8array to ?\ntransform[\"uint8array\"] = {\n    \"string\": arrayLikeToString,\n    \"array\": function(input) {\n        return arrayLikeToArrayLike(input, new Array(input.length));\n    },\n    \"arraybuffer\": function(input) {\n        return input.buffer;\n    },\n    \"uint8array\": identity,\n    \"nodebuffer\": function(input) {\n        return nodejsUtils.newBufferFrom(input);\n    }\n};\n\n// nodebuffer to ?\ntransform[\"nodebuffer\"] = {\n    \"string\": arrayLikeToString,\n    \"array\": function(input) {\n        return arrayLikeToArrayLike(input, new Array(input.length));\n    },\n    \"arraybuffer\": function(input) {\n        return transform[\"nodebuffer\"][\"uint8array\"](input).buffer;\n    },\n    \"uint8array\": function(input) {\n        return arrayLikeToArrayLike(input, new Uint8Array(input.length));\n    },\n    \"nodebuffer\": identity\n};\n\n/**\n * Transform an input into any type.\n * The supported output type are : string, array, uint8array, arraybuffer, nodebuffer.\n * If no output type is specified, the unmodified input will be returned.\n * @param {String} outputType the output type.\n * @param {String|Array|ArrayBuffer|Uint8Array|Buffer} input the input to convert.\n * @throws {Error} an Error if the browser doesn't support the requested output type.\n */\nexports.transformTo = function(outputType, input) {\n    if (!input) {\n        // undefined, null, etc\n        // an empty string won't harm.\n        input = \"\";\n    }\n    if (!outputType) {\n        return input;\n    }\n    exports.checkSupport(outputType);\n    var inputType = exports.getTypeOf(input);\n    var result = transform[inputType][outputType](input);\n    return result;\n};\n\n/**\n * Return the type of the input.\n * The type will be in a format valid for JSZip.utils.transformTo : string, array, uint8array, arraybuffer.\n * @param {Object} input the input to identify.\n * @return {String} the (lowercase) type of the input.\n */\nexports.getTypeOf = function(input) {\n    if (typeof input === \"string\") {\n        return \"string\";\n    }\n    if (Object.prototype.toString.call(input) === \"[object Array]\") {\n        return \"array\";\n    }\n    if (support.nodebuffer && nodejsUtils.isBuffer(input)) {\n        return \"nodebuffer\";\n    }\n    if (support.uint8array && input instanceof Uint8Array) {\n        return \"uint8array\";\n    }\n    if (support.arraybuffer && input instanceof ArrayBuffer) {\n        return \"arraybuffer\";\n    }\n};\n\n/**\n * Throw an exception if the type is not supported.\n * @param {String} type the type to check.\n * @throws {Error} an Error if the browser doesn't support the requested type.\n */\nexports.checkSupport = function(type) {\n    var supported = support[type.toLowerCase()];\n    if (!supported) {\n        throw new Error(type + \" is not supported by this platform\");\n    }\n};\n\nexports.MAX_VALUE_16BITS = 65535;\nexports.MAX_VALUE_32BITS = -1; // well, \"\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\" is parsed as -1\n\n/**\n * Prettify a string read as binary.\n * @param {string} str the string to prettify.\n * @return {string} a pretty string.\n */\nexports.pretty = function(str) {\n    var res = '',\n        code, i;\n    for (i = 0; i < (str || \"\").length; i++) {\n        code = str.charCodeAt(i);\n        res += '\\\\x' + (code < 16 ? \"0\" : \"\") + code.toString(16).toUpperCase();\n    }\n    return res;\n};\n\n/**\n * Defer the call of a function.\n * @param {Function} callback the function to call asynchronously.\n * @param {Array} args the arguments to give to the callback.\n */\nexports.delay = function(callback, args, self) {\n    setImmediate(function () {\n        callback.apply(self || null, args || []);\n    });\n};\n\n/**\n * Extends a prototype with an other, without calling a constructor with\n * side effects. Inspired by nodejs' `utils.inherits`\n * @param {Function} ctor the constructor to augment\n * @param {Function} superCtor the parent constructor to use\n */\nexports.inherits = function (ctor, superCtor) {\n    var Obj = function() {};\n    Obj.prototype = superCtor.prototype;\n    ctor.prototype = new Obj();\n};\n\n/**\n * Merge the objects passed as parameters into a new one.\n * @private\n * @param {...Object} var_args All objects to merge.\n * @return {Object} a new object with the data of the others.\n */\nexports.extend = function() {\n    var result = {}, i, attr;\n    for (i = 0; i < arguments.length; i++) { // arguments is not enumerable in some browsers\n        for (attr in arguments[i]) {\n            if (arguments[i].hasOwnProperty(attr) && typeof result[attr] === \"undefined\") {\n                result[attr] = arguments[i][attr];\n            }\n        }\n    }\n    return result;\n};\n\n/**\n * Transform arbitrary content into a Promise.\n * @param {String} name a name for the content being processed.\n * @param {Object} inputData the content to process.\n * @param {Boolean} isBinary true if the content is not an unicode string\n * @param {Boolean} isOptimizedBinaryString true if the string content only has one byte per character.\n * @param {Boolean} isBase64 true if the string content is encoded with base64.\n * @return {Promise} a promise in a format usable by JSZip.\n */\nexports.prepareContent = function(name, inputData, isBinary, isOptimizedBinaryString, isBase64) {\n\n    // if inputData is already a promise, this flatten it.\n    var promise = external.Promise.resolve(inputData).then(function(data) {\n        \n        \n        var isBlob = support.blob && (data instanceof Blob || ['[object File]', '[object Blob]'].indexOf(Object.prototype.toString.call(data)) !== -1);\n\n        if (isBlob && typeof FileReader !== \"undefined\") {\n            return new external.Promise(function (resolve, reject) {\n                var reader = new FileReader();\n\n                reader.onload = function(e) {\n                    resolve(e.target.result);\n                };\n                reader.onerror = function(e) {\n                    reject(e.target.error);\n                };\n                reader.readAsArrayBuffer(data);\n            });\n        } else {\n            return data;\n        }\n    });\n\n    return promise.then(function(data) {\n        var dataType = exports.getTypeOf(data);\n\n        if (!dataType) {\n            return external.Promise.reject(\n                new Error(\"Can't read the data of '\" + name + \"'. Is it \" +\n                          \"in a supported JavaScript type (String, Blob, ArrayBuffer, etc) ?\")\n            );\n        }\n        // special case : it's way easier to work with Uint8Array than with ArrayBuffer\n        if (dataType === \"arraybuffer\") {\n            data = exports.transformTo(\"uint8array\", data);\n        } else if (dataType === \"string\") {\n            if (isBase64) {\n                data = base64.decode(data);\n            }\n            else if (isBinary) {\n                // optimizedBinaryString === true means that the file has already been filtered with a 0xFF mask\n                if (isOptimizedBinaryString !== true) {\n                    // this is a string, not in a base64 format.\n                    // Be sure that this is a correct \"binary string\"\n                    data = string2binary(data);\n                }\n            }\n        }\n        return data;\n    });\n};\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/utils.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/zipEntries.js":
/*!*********************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/zipEntries.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar readerFor = __webpack_require__(/*! ./reader/readerFor */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/readerFor.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar sig = __webpack_require__(/*! ./signature */ \"./node_modules/unzip-crx/node_modules/jszip/lib/signature.js\");\nvar ZipEntry = __webpack_require__(/*! ./zipEntry */ \"./node_modules/unzip-crx/node_modules/jszip/lib/zipEntry.js\");\nvar utf8 = __webpack_require__(/*! ./utf8 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utf8.js\");\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/unzip-crx/node_modules/jszip/lib/support.js\");\n//  class ZipEntries {{{\n/**\n * All the entries in the zip file.\n * @constructor\n * @param {Object} loadOptions Options for loading the stream.\n */\nfunction ZipEntries(loadOptions) {\n    this.files = [];\n    this.loadOptions = loadOptions;\n}\nZipEntries.prototype = {\n    /**\n     * Check that the reader is on the specified signature.\n     * @param {string} expectedSignature the expected signature.\n     * @throws {Error} if it is an other signature.\n     */\n    checkSignature: function(expectedSignature) {\n        if (!this.reader.readAndCheckSignature(expectedSignature)) {\n            this.reader.index -= 4;\n            var signature = this.reader.readString(4);\n            throw new Error(\"Corrupted zip or bug: unexpected signature \" + \"(\" + utils.pretty(signature) + \", expected \" + utils.pretty(expectedSignature) + \")\");\n        }\n    },\n    /**\n     * Check if the given signature is at the given index.\n     * @param {number} askedIndex the index to check.\n     * @param {string} expectedSignature the signature to expect.\n     * @return {boolean} true if the signature is here, false otherwise.\n     */\n    isSignature: function(askedIndex, expectedSignature) {\n        var currentIndex = this.reader.index;\n        this.reader.setIndex(askedIndex);\n        var signature = this.reader.readString(4);\n        var result = signature === expectedSignature;\n        this.reader.setIndex(currentIndex);\n        return result;\n    },\n    /**\n     * Read the end of the central directory.\n     */\n    readBlockEndOfCentral: function() {\n        this.diskNumber = this.reader.readInt(2);\n        this.diskWithCentralDirStart = this.reader.readInt(2);\n        this.centralDirRecordsOnThisDisk = this.reader.readInt(2);\n        this.centralDirRecords = this.reader.readInt(2);\n        this.centralDirSize = this.reader.readInt(4);\n        this.centralDirOffset = this.reader.readInt(4);\n\n        this.zipCommentLength = this.reader.readInt(2);\n        // warning : the encoding depends of the system locale\n        // On a linux machine with LANG=en_US.utf8, this field is utf8 encoded.\n        // On a windows machine, this field is encoded with the localized windows code page.\n        var zipComment = this.reader.readData(this.zipCommentLength);\n        var decodeParamType = support.uint8array ? \"uint8array\" : \"array\";\n        // To get consistent behavior with the generation part, we will assume that\n        // this is utf8 encoded unless specified otherwise.\n        var decodeContent = utils.transformTo(decodeParamType, zipComment);\n        this.zipComment = this.loadOptions.decodeFileName(decodeContent);\n    },\n    /**\n     * Read the end of the Zip 64 central directory.\n     * Not merged with the method readEndOfCentral :\n     * The end of central can coexist with its Zip64 brother,\n     * I don't want to read the wrong number of bytes !\n     */\n    readBlockZip64EndOfCentral: function() {\n        this.zip64EndOfCentralSize = this.reader.readInt(8);\n        this.reader.skip(4);\n        // this.versionMadeBy = this.reader.readString(2);\n        // this.versionNeeded = this.reader.readInt(2);\n        this.diskNumber = this.reader.readInt(4);\n        this.diskWithCentralDirStart = this.reader.readInt(4);\n        this.centralDirRecordsOnThisDisk = this.reader.readInt(8);\n        this.centralDirRecords = this.reader.readInt(8);\n        this.centralDirSize = this.reader.readInt(8);\n        this.centralDirOffset = this.reader.readInt(8);\n\n        this.zip64ExtensibleData = {};\n        var extraDataSize = this.zip64EndOfCentralSize - 44,\n            index = 0,\n            extraFieldId,\n            extraFieldLength,\n            extraFieldValue;\n        while (index < extraDataSize) {\n            extraFieldId = this.reader.readInt(2);\n            extraFieldLength = this.reader.readInt(4);\n            extraFieldValue = this.reader.readData(extraFieldLength);\n            this.zip64ExtensibleData[extraFieldId] = {\n                id: extraFieldId,\n                length: extraFieldLength,\n                value: extraFieldValue\n            };\n        }\n    },\n    /**\n     * Read the end of the Zip 64 central directory locator.\n     */\n    readBlockZip64EndOfCentralLocator: function() {\n        this.diskWithZip64CentralDirStart = this.reader.readInt(4);\n        this.relativeOffsetEndOfZip64CentralDir = this.reader.readInt(8);\n        this.disksCount = this.reader.readInt(4);\n        if (this.disksCount > 1) {\n            throw new Error(\"Multi-volumes zip are not supported\");\n        }\n    },\n    /**\n     * Read the local files, based on the offset read in the central part.\n     */\n    readLocalFiles: function() {\n        var i, file;\n        for (i = 0; i < this.files.length; i++) {\n            file = this.files[i];\n            this.reader.setIndex(file.localHeaderOffset);\n            this.checkSignature(sig.LOCAL_FILE_HEADER);\n            file.readLocalPart(this.reader);\n            file.handleUTF8();\n            file.processAttributes();\n        }\n    },\n    /**\n     * Read the central directory.\n     */\n    readCentralDir: function() {\n        var file;\n\n        this.reader.setIndex(this.centralDirOffset);\n        while (this.reader.readAndCheckSignature(sig.CENTRAL_FILE_HEADER)) {\n            file = new ZipEntry({\n                zip64: this.zip64\n            }, this.loadOptions);\n            file.readCentralPart(this.reader);\n            this.files.push(file);\n        }\n\n        if (this.centralDirRecords !== this.files.length) {\n            if (this.centralDirRecords !== 0 && this.files.length === 0) {\n                // We expected some records but couldn't find ANY.\n                // This is really suspicious, as if something went wrong.\n                throw new Error(\"Corrupted zip or bug: expected \" + this.centralDirRecords + \" records in central dir, got \" + this.files.length);\n            } else {\n                // We found some records but not all.\n                // Something is wrong but we got something for the user: no error here.\n                // console.warn(\"expected\", this.centralDirRecords, \"records in central dir, got\", this.files.length);\n            }\n        }\n    },\n    /**\n     * Read the end of central directory.\n     */\n    readEndOfCentral: function() {\n        var offset = this.reader.lastIndexOfSignature(sig.CENTRAL_DIRECTORY_END);\n        if (offset < 0) {\n            // Check if the content is a truncated zip or complete garbage.\n            // A \"LOCAL_FILE_HEADER\" is not required at the beginning (auto\n            // extractible zip for example) but it can give a good hint.\n            // If an ajax request was used without responseType, we will also\n            // get unreadable data.\n            var isGarbage = !this.isSignature(0, sig.LOCAL_FILE_HEADER);\n\n            if (isGarbage) {\n                throw new Error(\"Can't find end of central directory : is this a zip file ? \" +\n                                \"If it is, see https://stuk.github.io/jszip/documentation/howto/read_zip.html\");\n            } else {\n                throw new Error(\"Corrupted zip: can't find end of central directory\");\n            }\n\n        }\n        this.reader.setIndex(offset);\n        var endOfCentralDirOffset = offset;\n        this.checkSignature(sig.CENTRAL_DIRECTORY_END);\n        this.readBlockEndOfCentral();\n\n\n        /* extract from the zip spec :\n            4)  If one of the fields in the end of central directory\n                record is too small to hold required data, the field\n                should be set to -1 (0xFFFF or 0xFFFFFFFF) and the\n                ZIP64 format record should be created.\n            5)  The end of central directory record and the\n                Zip64 end of central directory locator record must\n                reside on the same disk when splitting or spanning\n                an archive.\n         */\n        if (this.diskNumber === utils.MAX_VALUE_16BITS || this.diskWithCentralDirStart === utils.MAX_VALUE_16BITS || this.centralDirRecordsOnThisDisk === utils.MAX_VALUE_16BITS || this.centralDirRecords === utils.MAX_VALUE_16BITS || this.centralDirSize === utils.MAX_VALUE_32BITS || this.centralDirOffset === utils.MAX_VALUE_32BITS) {\n            this.zip64 = true;\n\n            /*\n            Warning : the zip64 extension is supported, but ONLY if the 64bits integer read from\n            the zip file can fit into a 32bits integer. This cannot be solved : JavaScript represents\n            all numbers as 64-bit double precision IEEE 754 floating point numbers.\n            So, we have 53bits for integers and bitwise operations treat everything as 32bits.\n            see https://developer.mozilla.org/en-US/docs/JavaScript/Reference/Operators/Bitwise_Operators\n            and http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-262.pdf section 8.5\n            */\n\n            // should look for a zip64 EOCD locator\n            offset = this.reader.lastIndexOfSignature(sig.ZIP64_CENTRAL_DIRECTORY_LOCATOR);\n            if (offset < 0) {\n                throw new Error(\"Corrupted zip: can't find the ZIP64 end of central directory locator\");\n            }\n            this.reader.setIndex(offset);\n            this.checkSignature(sig.ZIP64_CENTRAL_DIRECTORY_LOCATOR);\n            this.readBlockZip64EndOfCentralLocator();\n\n            // now the zip64 EOCD record\n            if (!this.isSignature(this.relativeOffsetEndOfZip64CentralDir, sig.ZIP64_CENTRAL_DIRECTORY_END)) {\n                // console.warn(\"ZIP64 end of central directory not where expected.\");\n                this.relativeOffsetEndOfZip64CentralDir = this.reader.lastIndexOfSignature(sig.ZIP64_CENTRAL_DIRECTORY_END);\n                if (this.relativeOffsetEndOfZip64CentralDir < 0) {\n                    throw new Error(\"Corrupted zip: can't find the ZIP64 end of central directory\");\n                }\n            }\n            this.reader.setIndex(this.relativeOffsetEndOfZip64CentralDir);\n            this.checkSignature(sig.ZIP64_CENTRAL_DIRECTORY_END);\n            this.readBlockZip64EndOfCentral();\n        }\n\n        var expectedEndOfCentralDirOffset = this.centralDirOffset + this.centralDirSize;\n        if (this.zip64) {\n            expectedEndOfCentralDirOffset += 20; // end of central dir 64 locator\n            expectedEndOfCentralDirOffset += 12 /* should not include the leading 12 bytes */ + this.zip64EndOfCentralSize;\n        }\n\n        var extraBytes = endOfCentralDirOffset - expectedEndOfCentralDirOffset;\n\n        if (extraBytes > 0) {\n            // console.warn(extraBytes, \"extra bytes at beginning or within zipfile\");\n            if (this.isSignature(endOfCentralDirOffset, sig.CENTRAL_FILE_HEADER)) {\n                // The offsets seem wrong, but we have something at the specified offset.\n                // So we keep it.\n            } else {\n                // the offset is wrong, update the \"zero\" of the reader\n                // this happens if data has been prepended (crx files for example)\n                this.reader.zero = extraBytes;\n            }\n        } else if (extraBytes < 0) {\n            throw new Error(\"Corrupted zip: missing \" + Math.abs(extraBytes) + \" bytes.\");\n        }\n    },\n    prepareReader: function(data) {\n        this.reader = readerFor(data);\n    },\n    /**\n     * Read a zip file and create ZipEntries.\n     * @param {String|ArrayBuffer|Uint8Array|Buffer} data the binary string representing a zip file.\n     */\n    load: function(data) {\n        this.prepareReader(data);\n        this.readEndOfCentral();\n        this.readCentralDir();\n        this.readLocalFiles();\n    }\n};\n// }}} end of ZipEntries\nmodule.exports = ZipEntries;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/zipEntries.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/zipEntry.js":
/*!*******************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/zipEntry.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar readerFor = __webpack_require__(/*! ./reader/readerFor */ \"./node_modules/unzip-crx/node_modules/jszip/lib/reader/readerFor.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utils.js\");\nvar CompressedObject = __webpack_require__(/*! ./compressedObject */ \"./node_modules/unzip-crx/node_modules/jszip/lib/compressedObject.js\");\nvar crc32fn = __webpack_require__(/*! ./crc32 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/crc32.js\");\nvar utf8 = __webpack_require__(/*! ./utf8 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utf8.js\");\nvar compressions = __webpack_require__(/*! ./compressions */ \"./node_modules/unzip-crx/node_modules/jszip/lib/compressions.js\");\nvar support = __webpack_require__(/*! ./support */ \"./node_modules/unzip-crx/node_modules/jszip/lib/support.js\");\n\nvar MADE_BY_DOS = 0x00;\nvar MADE_BY_UNIX = 0x03;\n\n/**\n * Find a compression registered in JSZip.\n * @param {string} compressionMethod the method magic to find.\n * @return {Object|null} the JSZip compression object, null if none found.\n */\nvar findCompression = function(compressionMethod) {\n    for (var method in compressions) {\n        if (!compressions.hasOwnProperty(method)) {\n            continue;\n        }\n        if (compressions[method].magic === compressionMethod) {\n            return compressions[method];\n        }\n    }\n    return null;\n};\n\n// class ZipEntry {{{\n/**\n * An entry in the zip file.\n * @constructor\n * @param {Object} options Options of the current file.\n * @param {Object} loadOptions Options for loading the stream.\n */\nfunction ZipEntry(options, loadOptions) {\n    this.options = options;\n    this.loadOptions = loadOptions;\n}\nZipEntry.prototype = {\n    /**\n     * say if the file is encrypted.\n     * @return {boolean} true if the file is encrypted, false otherwise.\n     */\n    isEncrypted: function() {\n        // bit 1 is set\n        return (this.bitFlag & 0x0001) === 0x0001;\n    },\n    /**\n     * say if the file has utf-8 filename/comment.\n     * @return {boolean} true if the filename/comment is in utf-8, false otherwise.\n     */\n    useUTF8: function() {\n        // bit 11 is set\n        return (this.bitFlag & 0x0800) === 0x0800;\n    },\n    /**\n     * Read the local part of a zip file and add the info in this object.\n     * @param {DataReader} reader the reader to use.\n     */\n    readLocalPart: function(reader) {\n        var compression, localExtraFieldsLength;\n\n        // we already know everything from the central dir !\n        // If the central dir data are false, we are doomed.\n        // On the bright side, the local part is scary  : zip64, data descriptors, both, etc.\n        // The less data we get here, the more reliable this should be.\n        // Let's skip the whole header and dash to the data !\n        reader.skip(22);\n        // in some zip created on windows, the filename stored in the central dir contains \\ instead of /.\n        // Strangely, the filename here is OK.\n        // I would love to treat these zip files as corrupted (see http://www.info-zip.org/FAQ.html#backslashes\n        // or APPNOTE#4.4.17.1, \"All slashes MUST be forward slashes '/'\") but there are a lot of bad zip generators...\n        // Search \"unzip mismatching \"local\" filename continuing with \"central\" filename version\" on\n        // the internet.\n        //\n        // I think I see the logic here : the central directory is used to display\n        // content and the local directory is used to extract the files. Mixing / and \\\n        // may be used to display \\ to windows users and use / when extracting the files.\n        // Unfortunately, this lead also to some issues : http://seclists.org/fulldisclosure/2009/Sep/394\n        this.fileNameLength = reader.readInt(2);\n        localExtraFieldsLength = reader.readInt(2); // can't be sure this will be the same as the central dir\n        // the fileName is stored as binary data, the handleUTF8 method will take care of the encoding.\n        this.fileName = reader.readData(this.fileNameLength);\n        reader.skip(localExtraFieldsLength);\n\n        if (this.compressedSize === -1 || this.uncompressedSize === -1) {\n            throw new Error(\"Bug or corrupted zip : didn't get enough informations from the central directory \" + \"(compressedSize === -1 || uncompressedSize === -1)\");\n        }\n\n        compression = findCompression(this.compressionMethod);\n        if (compression === null) { // no compression found\n            throw new Error(\"Corrupted zip : compression \" + utils.pretty(this.compressionMethod) + \" unknown (inner file : \" + utils.transformTo(\"string\", this.fileName) + \")\");\n        }\n        this.decompressed = new CompressedObject(this.compressedSize, this.uncompressedSize, this.crc32, compression, reader.readData(this.compressedSize));\n    },\n\n    /**\n     * Read the central part of a zip file and add the info in this object.\n     * @param {DataReader} reader the reader to use.\n     */\n    readCentralPart: function(reader) {\n        this.versionMadeBy = reader.readInt(2);\n        reader.skip(2);\n        // this.versionNeeded = reader.readInt(2);\n        this.bitFlag = reader.readInt(2);\n        this.compressionMethod = reader.readString(2);\n        this.date = reader.readDate();\n        this.crc32 = reader.readInt(4);\n        this.compressedSize = reader.readInt(4);\n        this.uncompressedSize = reader.readInt(4);\n        var fileNameLength = reader.readInt(2);\n        this.extraFieldsLength = reader.readInt(2);\n        this.fileCommentLength = reader.readInt(2);\n        this.diskNumberStart = reader.readInt(2);\n        this.internalFileAttributes = reader.readInt(2);\n        this.externalFileAttributes = reader.readInt(4);\n        this.localHeaderOffset = reader.readInt(4);\n\n        if (this.isEncrypted()) {\n            throw new Error(\"Encrypted zip are not supported\");\n        }\n\n        // will be read in the local part, see the comments there\n        reader.skip(fileNameLength);\n        this.readExtraFields(reader);\n        this.parseZIP64ExtraField(reader);\n        this.fileComment = reader.readData(this.fileCommentLength);\n    },\n\n    /**\n     * Parse the external file attributes and get the unix/dos permissions.\n     */\n    processAttributes: function () {\n        this.unixPermissions = null;\n        this.dosPermissions = null;\n        var madeBy = this.versionMadeBy >> 8;\n\n        // Check if we have the DOS directory flag set.\n        // We look for it in the DOS and UNIX permissions\n        // but some unknown platform could set it as a compatibility flag.\n        this.dir = this.externalFileAttributes & 0x0010 ? true : false;\n\n        if(madeBy === MADE_BY_DOS) {\n            // first 6 bits (0 to 5)\n            this.dosPermissions = this.externalFileAttributes & 0x3F;\n        }\n\n        if(madeBy === MADE_BY_UNIX) {\n            this.unixPermissions = (this.externalFileAttributes >> 16) & 0xFFFF;\n            // the octal permissions are in (this.unixPermissions & 0x01FF).toString(8);\n        }\n\n        // fail safe : if the name ends with a / it probably means a folder\n        if (!this.dir && this.fileNameStr.slice(-1) === '/') {\n            this.dir = true;\n        }\n    },\n\n    /**\n     * Parse the ZIP64 extra field and merge the info in the current ZipEntry.\n     * @param {DataReader} reader the reader to use.\n     */\n    parseZIP64ExtraField: function(reader) {\n\n        if (!this.extraFields[0x0001]) {\n            return;\n        }\n\n        // should be something, preparing the extra reader\n        var extraReader = readerFor(this.extraFields[0x0001].value);\n\n        // I really hope that these 64bits integer can fit in 32 bits integer, because js\n        // won't let us have more.\n        if (this.uncompressedSize === utils.MAX_VALUE_32BITS) {\n            this.uncompressedSize = extraReader.readInt(8);\n        }\n        if (this.compressedSize === utils.MAX_VALUE_32BITS) {\n            this.compressedSize = extraReader.readInt(8);\n        }\n        if (this.localHeaderOffset === utils.MAX_VALUE_32BITS) {\n            this.localHeaderOffset = extraReader.readInt(8);\n        }\n        if (this.diskNumberStart === utils.MAX_VALUE_32BITS) {\n            this.diskNumberStart = extraReader.readInt(4);\n        }\n    },\n    /**\n     * Read the central part of a zip file and add the info in this object.\n     * @param {DataReader} reader the reader to use.\n     */\n    readExtraFields: function(reader) {\n        var end = reader.index + this.extraFieldsLength,\n            extraFieldId,\n            extraFieldLength,\n            extraFieldValue;\n\n        if (!this.extraFields) {\n            this.extraFields = {};\n        }\n\n        while (reader.index < end) {\n            extraFieldId = reader.readInt(2);\n            extraFieldLength = reader.readInt(2);\n            extraFieldValue = reader.readData(extraFieldLength);\n\n            this.extraFields[extraFieldId] = {\n                id: extraFieldId,\n                length: extraFieldLength,\n                value: extraFieldValue\n            };\n        }\n    },\n    /**\n     * Apply an UTF8 transformation if needed.\n     */\n    handleUTF8: function() {\n        var decodeParamType = support.uint8array ? \"uint8array\" : \"array\";\n        if (this.useUTF8()) {\n            this.fileNameStr = utf8.utf8decode(this.fileName);\n            this.fileCommentStr = utf8.utf8decode(this.fileComment);\n        } else {\n            var upath = this.findExtraFieldUnicodePath();\n            if (upath !== null) {\n                this.fileNameStr = upath;\n            } else {\n                // ASCII text or unsupported code page\n                var fileNameByteArray =  utils.transformTo(decodeParamType, this.fileName);\n                this.fileNameStr = this.loadOptions.decodeFileName(fileNameByteArray);\n            }\n\n            var ucomment = this.findExtraFieldUnicodeComment();\n            if (ucomment !== null) {\n                this.fileCommentStr = ucomment;\n            } else {\n                // ASCII text or unsupported code page\n                var commentByteArray =  utils.transformTo(decodeParamType, this.fileComment);\n                this.fileCommentStr = this.loadOptions.decodeFileName(commentByteArray);\n            }\n        }\n    },\n\n    /**\n     * Find the unicode path declared in the extra field, if any.\n     * @return {String} the unicode path, null otherwise.\n     */\n    findExtraFieldUnicodePath: function() {\n        var upathField = this.extraFields[0x7075];\n        if (upathField) {\n            var extraReader = readerFor(upathField.value);\n\n            // wrong version\n            if (extraReader.readInt(1) !== 1) {\n                return null;\n            }\n\n            // the crc of the filename changed, this field is out of date.\n            if (crc32fn(this.fileName) !== extraReader.readInt(4)) {\n                return null;\n            }\n\n            return utf8.utf8decode(extraReader.readData(upathField.length - 5));\n        }\n        return null;\n    },\n\n    /**\n     * Find the unicode comment declared in the extra field, if any.\n     * @return {String} the unicode comment, null otherwise.\n     */\n    findExtraFieldUnicodeComment: function() {\n        var ucommentField = this.extraFields[0x6375];\n        if (ucommentField) {\n            var extraReader = readerFor(ucommentField.value);\n\n            // wrong version\n            if (extraReader.readInt(1) !== 1) {\n                return null;\n            }\n\n            // the crc of the comment changed, this field is out of date.\n            if (crc32fn(this.fileComment) !== extraReader.readInt(4)) {\n                return null;\n            }\n\n            return utf8.utf8decode(extraReader.readData(ucommentField.length - 5));\n        }\n        return null;\n    }\n};\nmodule.exports = ZipEntry;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/zipEntry.js?");

/***/ }),

/***/ "./node_modules/unzip-crx/node_modules/jszip/lib/zipObject.js":
/*!********************************************************************!*\
  !*** ./node_modules/unzip-crx/node_modules/jszip/lib/zipObject.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar StreamHelper = __webpack_require__(/*! ./stream/StreamHelper */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/StreamHelper.js\");\nvar DataWorker = __webpack_require__(/*! ./stream/DataWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/DataWorker.js\");\nvar utf8 = __webpack_require__(/*! ./utf8 */ \"./node_modules/unzip-crx/node_modules/jszip/lib/utf8.js\");\nvar CompressedObject = __webpack_require__(/*! ./compressedObject */ \"./node_modules/unzip-crx/node_modules/jszip/lib/compressedObject.js\");\nvar GenericWorker = __webpack_require__(/*! ./stream/GenericWorker */ \"./node_modules/unzip-crx/node_modules/jszip/lib/stream/GenericWorker.js\");\n\n/**\n * A simple object representing a file in the zip file.\n * @constructor\n * @param {string} name the name of the file\n * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data\n * @param {Object} options the options of the file\n */\nvar ZipObject = function(name, data, options) {\n    this.name = name;\n    this.dir = options.dir;\n    this.date = options.date;\n    this.comment = options.comment;\n    this.unixPermissions = options.unixPermissions;\n    this.dosPermissions = options.dosPermissions;\n\n    this._data = data;\n    this._dataBinary = options.binary;\n    // keep only the compression\n    this.options = {\n        compression : options.compression,\n        compressionOptions : options.compressionOptions\n    };\n};\n\nZipObject.prototype = {\n    /**\n     * Create an internal stream for the content of this object.\n     * @param {String} type the type of each chunk.\n     * @return StreamHelper the stream.\n     */\n    internalStream: function (type) {\n        var result = null, outputType = \"string\";\n        try {\n            if (!type) {\n                throw new Error(\"No output type specified.\");\n            }\n            outputType = type.toLowerCase();\n            var askUnicodeString = outputType === \"string\" || outputType === \"text\";\n            if (outputType === \"binarystring\" || outputType === \"text\") {\n                outputType = \"string\";\n            }\n            result = this._decompressWorker();\n\n            var isUnicodeString = !this._dataBinary;\n\n            if (isUnicodeString && !askUnicodeString) {\n                result = result.pipe(new utf8.Utf8EncodeWorker());\n            }\n            if (!isUnicodeString && askUnicodeString) {\n                result = result.pipe(new utf8.Utf8DecodeWorker());\n            }\n        } catch (e) {\n            result = new GenericWorker(\"error\");\n            result.error(e);\n        }\n\n        return new StreamHelper(result, outputType, \"\");\n    },\n\n    /**\n     * Prepare the content in the asked type.\n     * @param {String} type the type of the result.\n     * @param {Function} onUpdate a function to call on each internal update.\n     * @return Promise the promise of the result.\n     */\n    async: function (type, onUpdate) {\n        return this.internalStream(type).accumulate(onUpdate);\n    },\n\n    /**\n     * Prepare the content as a nodejs stream.\n     * @param {String} type the type of each chunk.\n     * @param {Function} onUpdate a function to call on each internal update.\n     * @return Stream the stream.\n     */\n    nodeStream: function (type, onUpdate) {\n        return this.internalStream(type || \"nodebuffer\").toNodejsStream(onUpdate);\n    },\n\n    /**\n     * Return a worker for the compressed content.\n     * @private\n     * @param {Object} compression the compression object to use.\n     * @param {Object} compressionOptions the options to use when compressing.\n     * @return Worker the worker.\n     */\n    _compressWorker: function (compression, compressionOptions) {\n        if (\n            this._data instanceof CompressedObject &&\n            this._data.compression.magic === compression.magic\n        ) {\n            return this._data.getCompressedWorker();\n        } else {\n            var result = this._decompressWorker();\n            if(!this._dataBinary) {\n                result = result.pipe(new utf8.Utf8EncodeWorker());\n            }\n            return CompressedObject.createWorkerFrom(result, compression, compressionOptions);\n        }\n    },\n    /**\n     * Return a worker for the decompressed content.\n     * @private\n     * @return Worker the worker.\n     */\n    _decompressWorker : function () {\n        if (this._data instanceof CompressedObject) {\n            return this._data.getContentWorker();\n        } else if (this._data instanceof GenericWorker) {\n            return this._data;\n        } else {\n            return new DataWorker(this._data);\n        }\n    }\n};\n\nvar removedMethods = [\"asText\", \"asBinary\", \"asNodeBuffer\", \"asUint8Array\", \"asArrayBuffer\"];\nvar removedFn = function () {\n    throw new Error(\"This method has been removed in JSZip 3.0, please check the upgrade guide.\");\n};\n\nfor(var i = 0; i < removedMethods.length; i++) {\n    ZipObject.prototype[removedMethods[i]] = removedFn;\n}\nmodule.exports = ZipObject;\n\n\n//# sourceURL=webpack:///./node_modules/unzip-crx/node_modules/jszip/lib/zipObject.js?");

/***/ }),

/***/ "./node_modules/util-deprecate/node.js":
/*!*********************************************!*\
  !*** ./node_modules/util-deprecate/node.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nmodule.exports = __webpack_require__(/*! util */ \"util\").deprecate;\n\n\n//# sourceURL=webpack:///./node_modules/util-deprecate/node.js?");

/***/ }),

/***/ "./node_modules/vue-cli-plugin-electron-builder/lib/createProtocol.js":
/*!****************************************************************************!*\
  !*** ./node_modules/vue-cli-plugin-electron-builder/lib/createProtocol.js ***!
  \****************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! electron */ \"electron\");\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(electron__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ \"path\");\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! fs */ \"fs\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var url__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! url */ \"url\");\n/* harmony import */ var url__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(url__WEBPACK_IMPORTED_MODULE_3__);\n\n\n\n\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (scheme => {\n  electron__WEBPACK_IMPORTED_MODULE_0__[\"protocol\"].registerBufferProtocol(\n    scheme,\n    (request, respond) => {\n      let pathName = new url__WEBPACK_IMPORTED_MODULE_3__[\"URL\"](request.url).pathname\n      pathName = decodeURI(pathName) // Needed in case URL contains spaces\n\n      Object(fs__WEBPACK_IMPORTED_MODULE_2__[\"readFile\"])(path__WEBPACK_IMPORTED_MODULE_1__[\"join\"](__dirname, pathName), (error, data) => {\n        if (error) {\n          console.error(`Failed to register ${scheme} protocol`, error)\n        }\n        let extension = path__WEBPACK_IMPORTED_MODULE_1__[\"extname\"](pathName).toLowerCase()\n        let mimeType = ''\n\n        if (extension === '.js') {\n          mimeType = 'text/javascript'\n        } else if (extension === '.html') {\n          mimeType = 'text/html'\n        } else if (extension === '.css') {\n          mimeType = 'text/css'\n        } else if (extension === '.svg' || extension === '.svgz') {\n          mimeType = 'image/svg+xml'\n        } else if (extension === '.json') {\n          mimeType = 'application/json'\n        }\n\n        respond({ mimeType, data })\n      })\n    },\n    error => {\n      if (error) {\n        console.error(`Failed to register ${scheme} protocol`, error)\n      }\n    }\n  )\n});\n\n\n//# sourceURL=webpack:///./node_modules/vue-cli-plugin-electron-builder/lib/createProtocol.js?");

/***/ }),

/***/ "./node_modules/vue-cli-plugin-electron-builder/lib/index.js":
/*!*******************************************************************!*\
  !*** ./node_modules/vue-cli-plugin-electron-builder/lib/index.js ***!
  \*******************************************************************/
/*! exports provided: installVueDevtools, createProtocol */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _installVueDevtools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./installVueDevtools */ \"./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"installVueDevtools\", function() { return _installVueDevtools__WEBPACK_IMPORTED_MODULE_0__[\"default\"]; });\n\n/* harmony import */ var _createProtocol__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./createProtocol */ \"./node_modules/vue-cli-plugin-electron-builder/lib/createProtocol.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createProtocol\", function() { return _createProtocol__WEBPACK_IMPORTED_MODULE_1__[\"default\"]; });\n\n\n\n\n\n//# sourceURL=webpack:///./node_modules/vue-cli-plugin-electron-builder/lib/index.js?");

/***/ }),

/***/ "./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/downloadChromeExtension.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/downloadChromeExtension.js ***!
  \********************************************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ \"fs\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ \"path\");\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var rimraf__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! rimraf */ \"./node_modules/rimraf/rimraf.js\");\n/* harmony import */ var rimraf__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(rimraf__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var unzip_crx__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! unzip-crx */ \"./node_modules/unzip-crx/dist/index.js\");\n/* harmony import */ var unzip_crx__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(unzip_crx__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils */ \"./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/utils.js\");\n\n\n\n\n\n\n\nconst downloadChromeExtension = (\n  chromeStoreID,\n  forceDownload,\n  attempts = 5\n) => {\n  const extensionsStore = Object(_utils__WEBPACK_IMPORTED_MODULE_4__[\"getPath\"])()\n  if (!fs__WEBPACK_IMPORTED_MODULE_0___default.a.existsSync(extensionsStore)) {\n    fs__WEBPACK_IMPORTED_MODULE_0___default.a.mkdirSync(extensionsStore)\n  }\n  const extensionFolder = path__WEBPACK_IMPORTED_MODULE_1___default.a.resolve(`${extensionsStore}/${chromeStoreID}`)\n  return new Promise((resolve, reject) => {\n    if (!fs__WEBPACK_IMPORTED_MODULE_0___default.a.existsSync(extensionFolder) || forceDownload) {\n      if (fs__WEBPACK_IMPORTED_MODULE_0___default.a.existsSync(extensionFolder)) {\n        rimraf__WEBPACK_IMPORTED_MODULE_2___default.a.sync(extensionFolder)\n      }\n      const fileURL = `https://clients2.google.com/service/update2/crx?response=redirect&x=id%3D${chromeStoreID}%26uc&prodversion=32` // eslint-disable-line\n      const filePath = path__WEBPACK_IMPORTED_MODULE_1___default.a.resolve(`${extensionFolder}.crx`)\n      Object(_utils__WEBPACK_IMPORTED_MODULE_4__[\"downloadFile\"])(fileURL, filePath)\n        .then(() => {\n          unzip_crx__WEBPACK_IMPORTED_MODULE_3___default()(filePath, extensionFolder).then(err => {\n            if (\n              err &&\n              !fs__WEBPACK_IMPORTED_MODULE_0___default.a.existsSync(path__WEBPACK_IMPORTED_MODULE_1___default.a.resolve(extensionFolder, 'manifest.json'))\n            ) {\n              return reject(err)\n            }\n            Object(_utils__WEBPACK_IMPORTED_MODULE_4__[\"changePermissions\"])(extensionFolder, 755)\n            resolve(extensionFolder)\n          })\n        })\n        .catch(err => {\n          console.log(\n            `Failed to fetch extension, trying ${attempts - 1} more times`\n          ) // eslint-disable-line\n          if (attempts <= 1) {\n            return reject(err)\n          }\n          setTimeout(() => {\n            downloadChromeExtension(chromeStoreID, forceDownload, attempts - 1)\n              .then(resolve)\n              .catch(reject)\n          }, 200)\n        })\n    } else {\n      resolve(extensionFolder)\n    }\n  })\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (downloadChromeExtension);\n\n\n//# sourceURL=webpack:///./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/downloadChromeExtension.js?");

/***/ }),

/***/ "./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/index.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/index.js ***!
  \**************************************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! electron */ \"electron\");\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(electron__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! fs */ \"fs\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! path */ \"path\");\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var _downloadChromeExtension__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./downloadChromeExtension */ \"./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/downloadChromeExtension.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils */ \"./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/utils.js\");\n\n\n\n\n\n\n\nconst { BrowserWindow } = electron__WEBPACK_IMPORTED_MODULE_0__[\"remote\"] || electron__WEBPACK_IMPORTED_MODULE_0___default.a\n\nlet IDMap = {}\nconst getIDMapPath = () => path__WEBPACK_IMPORTED_MODULE_2___default.a.resolve(Object(_utils__WEBPACK_IMPORTED_MODULE_4__[\"getPath\"])(), 'IDMap.json')\nif (fs__WEBPACK_IMPORTED_MODULE_1___default.a.existsSync(getIDMapPath())) {\n  try {\n    IDMap = JSON.parse(fs__WEBPACK_IMPORTED_MODULE_1___default.a.readFileSync(getIDMapPath(), 'utf8'))\n  } catch (err) {\n    console.error(\n      'electron-devtools-installer: Invalid JSON present in the IDMap file'\n    )\n  }\n}\n\nconst install = (forceDownload = false) => {\n  // return new Promise(resolve => {\n  const chromeStoreID = 'nhdogjmejiglipccpnnnanhbledajbpd'\n  const extensionName = IDMap[chromeStoreID]\n  const extensionInstalled =\n    extensionName &&\n    BrowserWindow.getDevToolsExtensions &&\n    BrowserWindow.getDevToolsExtensions()[extensionName]\n  if (!forceDownload && extensionInstalled) {\n    return Promise.resolve(IDMap[chromeStoreID])\n  }\n  return Object(_downloadChromeExtension__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(chromeStoreID, forceDownload).then(\n    extensionFolder => {\n      // Use forceDownload, but already installed\n      if (extensionInstalled) {\n        BrowserWindow.removeDevToolsExtension(extensionName)\n      }\n      const name = BrowserWindow.addDevToolsExtension(extensionFolder) // eslint-disable-line\n      fs__WEBPACK_IMPORTED_MODULE_1___default.a.writeFileSync(\n        getIDMapPath(),\n        JSON.stringify(\n          Object.assign(IDMap, {\n            [chromeStoreID]: name\n          })\n        )\n      )\n      return Promise.resolve(name)\n    }\n  )\n  // })\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (install);\n\n\n//# sourceURL=webpack:///./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/index.js?");

/***/ }),

/***/ "./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/utils.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/utils.js ***!
  \**************************************************************************************/
/*! exports provided: getPath, downloadFile, changePermissions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getPath\", function() { return getPath; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"downloadFile\", function() { return downloadFile; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"changePermissions\", function() { return changePermissions; });\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! electron */ \"electron\");\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(electron__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! fs */ \"fs\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! path */ \"path\");\n/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var https__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! https */ \"https\");\n/* harmony import */ var https__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(https__WEBPACK_IMPORTED_MODULE_3__);\n\n\n\n\n\nconst getPath = () => {\n  const savePath = (electron__WEBPACK_IMPORTED_MODULE_0__[\"remote\"] || electron__WEBPACK_IMPORTED_MODULE_0___default.a).app.getPath('userData')\n  return path__WEBPACK_IMPORTED_MODULE_2___default.a.resolve(`${savePath}/extensions`)\n}\n\n// Use https.get fallback for Electron < 1.4.5\nconst { net } = electron__WEBPACK_IMPORTED_MODULE_0__[\"remote\"] || electron__WEBPACK_IMPORTED_MODULE_0___default.a\nconst request = net ? net.request : https__WEBPACK_IMPORTED_MODULE_3___default.a.get\n\nconst downloadFile = (from, to) =>\n  new Promise((resolve, reject) => {\n    const req = request(from)\n    req.on('response', res => {\n      // Shouldn't handle redirect with `electron.net`, this is for https.get fallback\n      if (\n        res.statusCode >= 300 &&\n        res.statusCode < 400 &&\n        res.headers.location\n      ) {\n        return downloadFile(res.headers.location, to)\n          .then(resolve)\n          .catch(reject)\n      }\n      res.pipe(fs__WEBPACK_IMPORTED_MODULE_1___default.a.createWriteStream(to)).on('close', resolve)\n    })\n    req.on('error', reject)\n    req.end()\n  })\n\nconst changePermissions = (dir, mode) => {\n  const files = fs__WEBPACK_IMPORTED_MODULE_1___default.a.readdirSync(dir)\n  files.forEach(file => {\n    const filePath = path__WEBPACK_IMPORTED_MODULE_2___default.a.join(dir, file)\n    fs__WEBPACK_IMPORTED_MODULE_1___default.a.chmodSync(filePath, parseInt(mode, 8))\n    if (fs__WEBPACK_IMPORTED_MODULE_1___default.a.statSync(filePath).isDirectory()) {\n      changePermissions(filePath, mode)\n    }\n  })\n}\n\n\n//# sourceURL=webpack:///./node_modules/vue-cli-plugin-electron-builder/lib/installVueDevtools/utils.js?");

/***/ }),

/***/ "./node_modules/vue/dist/vue.runtime.esm.js":
/*!**************************************************!*\
  !*** ./node_modules/vue/dist/vue.runtime.esm.js ***!
  \**************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/*!\n * Vue.js v2.6.10\n * (c) 2014-2019 Evan You\n * Released under the MIT License.\n */\n/*  */\n\nvar emptyObject = Object.freeze({});\n\n// These helpers produce better VM code in JS engines due to their\n// explicitness and function inlining.\nfunction isUndef (v) {\n  return v === undefined || v === null\n}\n\nfunction isDef (v) {\n  return v !== undefined && v !== null\n}\n\nfunction isTrue (v) {\n  return v === true\n}\n\nfunction isFalse (v) {\n  return v === false\n}\n\n/**\n * Check if value is primitive.\n */\nfunction isPrimitive (value) {\n  return (\n    typeof value === 'string' ||\n    typeof value === 'number' ||\n    // $flow-disable-line\n    typeof value === 'symbol' ||\n    typeof value === 'boolean'\n  )\n}\n\n/**\n * Quick object check - this is primarily used to tell\n * Objects from primitive values when we know the value\n * is a JSON-compliant type.\n */\nfunction isObject (obj) {\n  return obj !== null && typeof obj === 'object'\n}\n\n/**\n * Get the raw type string of a value, e.g., [object Object].\n */\nvar _toString = Object.prototype.toString;\n\nfunction toRawType (value) {\n  return _toString.call(value).slice(8, -1)\n}\n\n/**\n * Strict object type check. Only returns true\n * for plain JavaScript objects.\n */\nfunction isPlainObject (obj) {\n  return _toString.call(obj) === '[object Object]'\n}\n\nfunction isRegExp (v) {\n  return _toString.call(v) === '[object RegExp]'\n}\n\n/**\n * Check if val is a valid array index.\n */\nfunction isValidArrayIndex (val) {\n  var n = parseFloat(String(val));\n  return n >= 0 && Math.floor(n) === n && isFinite(val)\n}\n\nfunction isPromise (val) {\n  return (\n    isDef(val) &&\n    typeof val.then === 'function' &&\n    typeof val.catch === 'function'\n  )\n}\n\n/**\n * Convert a value to a string that is actually rendered.\n */\nfunction toString (val) {\n  return val == null\n    ? ''\n    : Array.isArray(val) || (isPlainObject(val) && val.toString === _toString)\n      ? JSON.stringify(val, null, 2)\n      : String(val)\n}\n\n/**\n * Convert an input value to a number for persistence.\n * If the conversion fails, return original string.\n */\nfunction toNumber (val) {\n  var n = parseFloat(val);\n  return isNaN(n) ? val : n\n}\n\n/**\n * Make a map and return a function for checking if a key\n * is in that map.\n */\nfunction makeMap (\n  str,\n  expectsLowerCase\n) {\n  var map = Object.create(null);\n  var list = str.split(',');\n  for (var i = 0; i < list.length; i++) {\n    map[list[i]] = true;\n  }\n  return expectsLowerCase\n    ? function (val) { return map[val.toLowerCase()]; }\n    : function (val) { return map[val]; }\n}\n\n/**\n * Check if a tag is a built-in tag.\n */\nvar isBuiltInTag = makeMap('slot,component', true);\n\n/**\n * Check if an attribute is a reserved attribute.\n */\nvar isReservedAttribute = makeMap('key,ref,slot,slot-scope,is');\n\n/**\n * Remove an item from an array.\n */\nfunction remove (arr, item) {\n  if (arr.length) {\n    var index = arr.indexOf(item);\n    if (index > -1) {\n      return arr.splice(index, 1)\n    }\n  }\n}\n\n/**\n * Check whether an object has the property.\n */\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nfunction hasOwn (obj, key) {\n  return hasOwnProperty.call(obj, key)\n}\n\n/**\n * Create a cached version of a pure function.\n */\nfunction cached (fn) {\n  var cache = Object.create(null);\n  return (function cachedFn (str) {\n    var hit = cache[str];\n    return hit || (cache[str] = fn(str))\n  })\n}\n\n/**\n * Camelize a hyphen-delimited string.\n */\nvar camelizeRE = /-(\\w)/g;\nvar camelize = cached(function (str) {\n  return str.replace(camelizeRE, function (_, c) { return c ? c.toUpperCase() : ''; })\n});\n\n/**\n * Capitalize a string.\n */\nvar capitalize = cached(function (str) {\n  return str.charAt(0).toUpperCase() + str.slice(1)\n});\n\n/**\n * Hyphenate a camelCase string.\n */\nvar hyphenateRE = /\\B([A-Z])/g;\nvar hyphenate = cached(function (str) {\n  return str.replace(hyphenateRE, '-$1').toLowerCase()\n});\n\n/**\n * Simple bind polyfill for environments that do not support it,\n * e.g., PhantomJS 1.x. Technically, we don't need this anymore\n * since native bind is now performant enough in most browsers.\n * But removing it would mean breaking code that was able to run in\n * PhantomJS 1.x, so this must be kept for backward compatibility.\n */\n\n/* istanbul ignore next */\nfunction polyfillBind (fn, ctx) {\n  function boundFn (a) {\n    var l = arguments.length;\n    return l\n      ? l > 1\n        ? fn.apply(ctx, arguments)\n        : fn.call(ctx, a)\n      : fn.call(ctx)\n  }\n\n  boundFn._length = fn.length;\n  return boundFn\n}\n\nfunction nativeBind (fn, ctx) {\n  return fn.bind(ctx)\n}\n\nvar bind = Function.prototype.bind\n  ? nativeBind\n  : polyfillBind;\n\n/**\n * Convert an Array-like object to a real Array.\n */\nfunction toArray (list, start) {\n  start = start || 0;\n  var i = list.length - start;\n  var ret = new Array(i);\n  while (i--) {\n    ret[i] = list[i + start];\n  }\n  return ret\n}\n\n/**\n * Mix properties into target object.\n */\nfunction extend (to, _from) {\n  for (var key in _from) {\n    to[key] = _from[key];\n  }\n  return to\n}\n\n/**\n * Merge an Array of Objects into a single Object.\n */\nfunction toObject (arr) {\n  var res = {};\n  for (var i = 0; i < arr.length; i++) {\n    if (arr[i]) {\n      extend(res, arr[i]);\n    }\n  }\n  return res\n}\n\n/* eslint-disable no-unused-vars */\n\n/**\n * Perform no operation.\n * Stubbing args to make Flow happy without leaving useless transpiled code\n * with ...rest (https://flow.org/blog/2017/05/07/Strict-Function-Call-Arity/).\n */\nfunction noop (a, b, c) {}\n\n/**\n * Always return false.\n */\nvar no = function (a, b, c) { return false; };\n\n/* eslint-enable no-unused-vars */\n\n/**\n * Return the same value.\n */\nvar identity = function (_) { return _; };\n\n/**\n * Check if two values are loosely equal - that is,\n * if they are plain objects, do they have the same shape?\n */\nfunction looseEqual (a, b) {\n  if (a === b) { return true }\n  var isObjectA = isObject(a);\n  var isObjectB = isObject(b);\n  if (isObjectA && isObjectB) {\n    try {\n      var isArrayA = Array.isArray(a);\n      var isArrayB = Array.isArray(b);\n      if (isArrayA && isArrayB) {\n        return a.length === b.length && a.every(function (e, i) {\n          return looseEqual(e, b[i])\n        })\n      } else if (a instanceof Date && b instanceof Date) {\n        return a.getTime() === b.getTime()\n      } else if (!isArrayA && !isArrayB) {\n        var keysA = Object.keys(a);\n        var keysB = Object.keys(b);\n        return keysA.length === keysB.length && keysA.every(function (key) {\n          return looseEqual(a[key], b[key])\n        })\n      } else {\n        /* istanbul ignore next */\n        return false\n      }\n    } catch (e) {\n      /* istanbul ignore next */\n      return false\n    }\n  } else if (!isObjectA && !isObjectB) {\n    return String(a) === String(b)\n  } else {\n    return false\n  }\n}\n\n/**\n * Return the first index at which a loosely equal value can be\n * found in the array (if value is a plain object, the array must\n * contain an object of the same shape), or -1 if it is not present.\n */\nfunction looseIndexOf (arr, val) {\n  for (var i = 0; i < arr.length; i++) {\n    if (looseEqual(arr[i], val)) { return i }\n  }\n  return -1\n}\n\n/**\n * Ensure a function is called only once.\n */\nfunction once (fn) {\n  var called = false;\n  return function () {\n    if (!called) {\n      called = true;\n      fn.apply(this, arguments);\n    }\n  }\n}\n\nvar SSR_ATTR = 'data-server-rendered';\n\nvar ASSET_TYPES = [\n  'component',\n  'directive',\n  'filter'\n];\n\nvar LIFECYCLE_HOOKS = [\n  'beforeCreate',\n  'created',\n  'beforeMount',\n  'mounted',\n  'beforeUpdate',\n  'updated',\n  'beforeDestroy',\n  'destroyed',\n  'activated',\n  'deactivated',\n  'errorCaptured',\n  'serverPrefetch'\n];\n\n/*  */\n\n\n\nvar config = ({\n  /**\n   * Option merge strategies (used in core/util/options)\n   */\n  // $flow-disable-line\n  optionMergeStrategies: Object.create(null),\n\n  /**\n   * Whether to suppress warnings.\n   */\n  silent: false,\n\n  /**\n   * Show production mode tip message on boot?\n   */\n  productionTip: \"development\" !== 'production',\n\n  /**\n   * Whether to enable devtools\n   */\n  devtools: \"development\" !== 'production',\n\n  /**\n   * Whether to record perf\n   */\n  performance: false,\n\n  /**\n   * Error handler for watcher errors\n   */\n  errorHandler: null,\n\n  /**\n   * Warn handler for watcher warns\n   */\n  warnHandler: null,\n\n  /**\n   * Ignore certain custom elements\n   */\n  ignoredElements: [],\n\n  /**\n   * Custom user key aliases for v-on\n   */\n  // $flow-disable-line\n  keyCodes: Object.create(null),\n\n  /**\n   * Check if a tag is reserved so that it cannot be registered as a\n   * component. This is platform-dependent and may be overwritten.\n   */\n  isReservedTag: no,\n\n  /**\n   * Check if an attribute is reserved so that it cannot be used as a component\n   * prop. This is platform-dependent and may be overwritten.\n   */\n  isReservedAttr: no,\n\n  /**\n   * Check if a tag is an unknown element.\n   * Platform-dependent.\n   */\n  isUnknownElement: no,\n\n  /**\n   * Get the namespace of an element\n   */\n  getTagNamespace: noop,\n\n  /**\n   * Parse the real tag name for the specific platform.\n   */\n  parsePlatformTagName: identity,\n\n  /**\n   * Check if an attribute must be bound using property, e.g. value\n   * Platform-dependent.\n   */\n  mustUseProp: no,\n\n  /**\n   * Perform updates asynchronously. Intended to be used by Vue Test Utils\n   * This will significantly reduce performance if set to false.\n   */\n  async: true,\n\n  /**\n   * Exposed for legacy reasons\n   */\n  _lifecycleHooks: LIFECYCLE_HOOKS\n});\n\n/*  */\n\n/**\n * unicode letters used for parsing html tags, component names and property paths.\n * using https://www.w3.org/TR/html53/semantics-scripting.html#potentialcustomelementname\n * skipping \\u10000-\\uEFFFF due to it freezing up PhantomJS\n */\nvar unicodeRegExp = /a-zA-Z\\u00B7\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u203F-\\u2040\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD/;\n\n/**\n * Check if a string starts with $ or _\n */\nfunction isReserved (str) {\n  var c = (str + '').charCodeAt(0);\n  return c === 0x24 || c === 0x5F\n}\n\n/**\n * Define a property.\n */\nfunction def (obj, key, val, enumerable) {\n  Object.defineProperty(obj, key, {\n    value: val,\n    enumerable: !!enumerable,\n    writable: true,\n    configurable: true\n  });\n}\n\n/**\n * Parse simple path.\n */\nvar bailRE = new RegExp((\"[^\" + (unicodeRegExp.source) + \".$_\\\\d]\"));\nfunction parsePath (path) {\n  if (bailRE.test(path)) {\n    return\n  }\n  var segments = path.split('.');\n  return function (obj) {\n    for (var i = 0; i < segments.length; i++) {\n      if (!obj) { return }\n      obj = obj[segments[i]];\n    }\n    return obj\n  }\n}\n\n/*  */\n\n// can we use __proto__?\nvar hasProto = '__proto__' in {};\n\n// Browser environment sniffing\nvar inBrowser = typeof window !== 'undefined';\nvar inWeex = typeof WXEnvironment !== 'undefined' && !!WXEnvironment.platform;\nvar weexPlatform = inWeex && WXEnvironment.platform.toLowerCase();\nvar UA = inBrowser && window.navigator.userAgent.toLowerCase();\nvar isIE = UA && /msie|trident/.test(UA);\nvar isIE9 = UA && UA.indexOf('msie 9.0') > 0;\nvar isEdge = UA && UA.indexOf('edge/') > 0;\nvar isAndroid = (UA && UA.indexOf('android') > 0) || (weexPlatform === 'android');\nvar isIOS = (UA && /iphone|ipad|ipod|ios/.test(UA)) || (weexPlatform === 'ios');\nvar isChrome = UA && /chrome\\/\\d+/.test(UA) && !isEdge;\nvar isPhantomJS = UA && /phantomjs/.test(UA);\nvar isFF = UA && UA.match(/firefox\\/(\\d+)/);\n\n// Firefox has a \"watch\" function on Object.prototype...\nvar nativeWatch = ({}).watch;\n\nvar supportsPassive = false;\nif (inBrowser) {\n  try {\n    var opts = {};\n    Object.defineProperty(opts, 'passive', ({\n      get: function get () {\n        /* istanbul ignore next */\n        supportsPassive = true;\n      }\n    })); // https://github.com/facebook/flow/issues/285\n    window.addEventListener('test-passive', null, opts);\n  } catch (e) {}\n}\n\n// this needs to be lazy-evaled because vue may be required before\n// vue-server-renderer can set VUE_ENV\nvar _isServer;\nvar isServerRendering = function () {\n  if (_isServer === undefined) {\n    /* istanbul ignore if */\n    if (!inBrowser && !inWeex && typeof global !== 'undefined') {\n      // detect presence of vue-server-renderer and avoid\n      // Webpack shimming the process\n      _isServer = global['process'] && global['process'].env.VUE_ENV === 'server';\n    } else {\n      _isServer = false;\n    }\n  }\n  return _isServer\n};\n\n// detect devtools\nvar devtools = inBrowser && window.__VUE_DEVTOOLS_GLOBAL_HOOK__;\n\n/* istanbul ignore next */\nfunction isNative (Ctor) {\n  return typeof Ctor === 'function' && /native code/.test(Ctor.toString())\n}\n\nvar hasSymbol =\n  typeof Symbol !== 'undefined' && isNative(Symbol) &&\n  typeof Reflect !== 'undefined' && isNative(Reflect.ownKeys);\n\nvar _Set;\n/* istanbul ignore if */ // $flow-disable-line\nif (typeof Set !== 'undefined' && isNative(Set)) {\n  // use native Set when available.\n  _Set = Set;\n} else {\n  // a non-standard Set polyfill that only works with primitive keys.\n  _Set = /*@__PURE__*/(function () {\n    function Set () {\n      this.set = Object.create(null);\n    }\n    Set.prototype.has = function has (key) {\n      return this.set[key] === true\n    };\n    Set.prototype.add = function add (key) {\n      this.set[key] = true;\n    };\n    Set.prototype.clear = function clear () {\n      this.set = Object.create(null);\n    };\n\n    return Set;\n  }());\n}\n\n/*  */\n\nvar warn = noop;\nvar tip = noop;\nvar generateComponentTrace = (noop); // work around flow check\nvar formatComponentName = (noop);\n\nif (true) {\n  var hasConsole = typeof console !== 'undefined';\n  var classifyRE = /(?:^|[-_])(\\w)/g;\n  var classify = function (str) { return str\n    .replace(classifyRE, function (c) { return c.toUpperCase(); })\n    .replace(/[-_]/g, ''); };\n\n  warn = function (msg, vm) {\n    var trace = vm ? generateComponentTrace(vm) : '';\n\n    if (config.warnHandler) {\n      config.warnHandler.call(null, msg, vm, trace);\n    } else if (hasConsole && (!config.silent)) {\n      console.error((\"[Vue warn]: \" + msg + trace));\n    }\n  };\n\n  tip = function (msg, vm) {\n    if (hasConsole && (!config.silent)) {\n      console.warn(\"[Vue tip]: \" + msg + (\n        vm ? generateComponentTrace(vm) : ''\n      ));\n    }\n  };\n\n  formatComponentName = function (vm, includeFile) {\n    if (vm.$root === vm) {\n      return '<Root>'\n    }\n    var options = typeof vm === 'function' && vm.cid != null\n      ? vm.options\n      : vm._isVue\n        ? vm.$options || vm.constructor.options\n        : vm;\n    var name = options.name || options._componentTag;\n    var file = options.__file;\n    if (!name && file) {\n      var match = file.match(/([^/\\\\]+)\\.vue$/);\n      name = match && match[1];\n    }\n\n    return (\n      (name ? (\"<\" + (classify(name)) + \">\") : \"<Anonymous>\") +\n      (file && includeFile !== false ? (\" at \" + file) : '')\n    )\n  };\n\n  var repeat = function (str, n) {\n    var res = '';\n    while (n) {\n      if (n % 2 === 1) { res += str; }\n      if (n > 1) { str += str; }\n      n >>= 1;\n    }\n    return res\n  };\n\n  generateComponentTrace = function (vm) {\n    if (vm._isVue && vm.$parent) {\n      var tree = [];\n      var currentRecursiveSequence = 0;\n      while (vm) {\n        if (tree.length > 0) {\n          var last = tree[tree.length - 1];\n          if (last.constructor === vm.constructor) {\n            currentRecursiveSequence++;\n            vm = vm.$parent;\n            continue\n          } else if (currentRecursiveSequence > 0) {\n            tree[tree.length - 1] = [last, currentRecursiveSequence];\n            currentRecursiveSequence = 0;\n          }\n        }\n        tree.push(vm);\n        vm = vm.$parent;\n      }\n      return '\\n\\nfound in\\n\\n' + tree\n        .map(function (vm, i) { return (\"\" + (i === 0 ? '---> ' : repeat(' ', 5 + i * 2)) + (Array.isArray(vm)\n            ? ((formatComponentName(vm[0])) + \"... (\" + (vm[1]) + \" recursive calls)\")\n            : formatComponentName(vm))); })\n        .join('\\n')\n    } else {\n      return (\"\\n\\n(found in \" + (formatComponentName(vm)) + \")\")\n    }\n  };\n}\n\n/*  */\n\nvar uid = 0;\n\n/**\n * A dep is an observable that can have multiple\n * directives subscribing to it.\n */\nvar Dep = function Dep () {\n  this.id = uid++;\n  this.subs = [];\n};\n\nDep.prototype.addSub = function addSub (sub) {\n  this.subs.push(sub);\n};\n\nDep.prototype.removeSub = function removeSub (sub) {\n  remove(this.subs, sub);\n};\n\nDep.prototype.depend = function depend () {\n  if (Dep.target) {\n    Dep.target.addDep(this);\n  }\n};\n\nDep.prototype.notify = function notify () {\n  // stabilize the subscriber list first\n  var subs = this.subs.slice();\n  if ( true && !config.async) {\n    // subs aren't sorted in scheduler if not running async\n    // we need to sort them now to make sure they fire in correct\n    // order\n    subs.sort(function (a, b) { return a.id - b.id; });\n  }\n  for (var i = 0, l = subs.length; i < l; i++) {\n    subs[i].update();\n  }\n};\n\n// The current target watcher being evaluated.\n// This is globally unique because only one watcher\n// can be evaluated at a time.\nDep.target = null;\nvar targetStack = [];\n\nfunction pushTarget (target) {\n  targetStack.push(target);\n  Dep.target = target;\n}\n\nfunction popTarget () {\n  targetStack.pop();\n  Dep.target = targetStack[targetStack.length - 1];\n}\n\n/*  */\n\nvar VNode = function VNode (\n  tag,\n  data,\n  children,\n  text,\n  elm,\n  context,\n  componentOptions,\n  asyncFactory\n) {\n  this.tag = tag;\n  this.data = data;\n  this.children = children;\n  this.text = text;\n  this.elm = elm;\n  this.ns = undefined;\n  this.context = context;\n  this.fnContext = undefined;\n  this.fnOptions = undefined;\n  this.fnScopeId = undefined;\n  this.key = data && data.key;\n  this.componentOptions = componentOptions;\n  this.componentInstance = undefined;\n  this.parent = undefined;\n  this.raw = false;\n  this.isStatic = false;\n  this.isRootInsert = true;\n  this.isComment = false;\n  this.isCloned = false;\n  this.isOnce = false;\n  this.asyncFactory = asyncFactory;\n  this.asyncMeta = undefined;\n  this.isAsyncPlaceholder = false;\n};\n\nvar prototypeAccessors = { child: { configurable: true } };\n\n// DEPRECATED: alias for componentInstance for backwards compat.\n/* istanbul ignore next */\nprototypeAccessors.child.get = function () {\n  return this.componentInstance\n};\n\nObject.defineProperties( VNode.prototype, prototypeAccessors );\n\nvar createEmptyVNode = function (text) {\n  if ( text === void 0 ) text = '';\n\n  var node = new VNode();\n  node.text = text;\n  node.isComment = true;\n  return node\n};\n\nfunction createTextVNode (val) {\n  return new VNode(undefined, undefined, undefined, String(val))\n}\n\n// optimized shallow clone\n// used for static nodes and slot nodes because they may be reused across\n// multiple renders, cloning them avoids errors when DOM manipulations rely\n// on their elm reference.\nfunction cloneVNode (vnode) {\n  var cloned = new VNode(\n    vnode.tag,\n    vnode.data,\n    // #7975\n    // clone children array to avoid mutating original in case of cloning\n    // a child.\n    vnode.children && vnode.children.slice(),\n    vnode.text,\n    vnode.elm,\n    vnode.context,\n    vnode.componentOptions,\n    vnode.asyncFactory\n  );\n  cloned.ns = vnode.ns;\n  cloned.isStatic = vnode.isStatic;\n  cloned.key = vnode.key;\n  cloned.isComment = vnode.isComment;\n  cloned.fnContext = vnode.fnContext;\n  cloned.fnOptions = vnode.fnOptions;\n  cloned.fnScopeId = vnode.fnScopeId;\n  cloned.asyncMeta = vnode.asyncMeta;\n  cloned.isCloned = true;\n  return cloned\n}\n\n/*\n * not type checking this file because flow doesn't play well with\n * dynamically accessing methods on Array prototype\n */\n\nvar arrayProto = Array.prototype;\nvar arrayMethods = Object.create(arrayProto);\n\nvar methodsToPatch = [\n  'push',\n  'pop',\n  'shift',\n  'unshift',\n  'splice',\n  'sort',\n  'reverse'\n];\n\n/**\n * Intercept mutating methods and emit events\n */\nmethodsToPatch.forEach(function (method) {\n  // cache original method\n  var original = arrayProto[method];\n  def(arrayMethods, method, function mutator () {\n    var args = [], len = arguments.length;\n    while ( len-- ) args[ len ] = arguments[ len ];\n\n    var result = original.apply(this, args);\n    var ob = this.__ob__;\n    var inserted;\n    switch (method) {\n      case 'push':\n      case 'unshift':\n        inserted = args;\n        break\n      case 'splice':\n        inserted = args.slice(2);\n        break\n    }\n    if (inserted) { ob.observeArray(inserted); }\n    // notify change\n    ob.dep.notify();\n    return result\n  });\n});\n\n/*  */\n\nvar arrayKeys = Object.getOwnPropertyNames(arrayMethods);\n\n/**\n * In some cases we may want to disable observation inside a component's\n * update computation.\n */\nvar shouldObserve = true;\n\nfunction toggleObserving (value) {\n  shouldObserve = value;\n}\n\n/**\n * Observer class that is attached to each observed\n * object. Once attached, the observer converts the target\n * object's property keys into getter/setters that\n * collect dependencies and dispatch updates.\n */\nvar Observer = function Observer (value) {\n  this.value = value;\n  this.dep = new Dep();\n  this.vmCount = 0;\n  def(value, '__ob__', this);\n  if (Array.isArray(value)) {\n    if (hasProto) {\n      protoAugment(value, arrayMethods);\n    } else {\n      copyAugment(value, arrayMethods, arrayKeys);\n    }\n    this.observeArray(value);\n  } else {\n    this.walk(value);\n  }\n};\n\n/**\n * Walk through all properties and convert them into\n * getter/setters. This method should only be called when\n * value type is Object.\n */\nObserver.prototype.walk = function walk (obj) {\n  var keys = Object.keys(obj);\n  for (var i = 0; i < keys.length; i++) {\n    defineReactive$$1(obj, keys[i]);\n  }\n};\n\n/**\n * Observe a list of Array items.\n */\nObserver.prototype.observeArray = function observeArray (items) {\n  for (var i = 0, l = items.length; i < l; i++) {\n    observe(items[i]);\n  }\n};\n\n// helpers\n\n/**\n * Augment a target Object or Array by intercepting\n * the prototype chain using __proto__\n */\nfunction protoAugment (target, src) {\n  /* eslint-disable no-proto */\n  target.__proto__ = src;\n  /* eslint-enable no-proto */\n}\n\n/**\n * Augment a target Object or Array by defining\n * hidden properties.\n */\n/* istanbul ignore next */\nfunction copyAugment (target, src, keys) {\n  for (var i = 0, l = keys.length; i < l; i++) {\n    var key = keys[i];\n    def(target, key, src[key]);\n  }\n}\n\n/**\n * Attempt to create an observer instance for a value,\n * returns the new observer if successfully observed,\n * or the existing observer if the value already has one.\n */\nfunction observe (value, asRootData) {\n  if (!isObject(value) || value instanceof VNode) {\n    return\n  }\n  var ob;\n  if (hasOwn(value, '__ob__') && value.__ob__ instanceof Observer) {\n    ob = value.__ob__;\n  } else if (\n    shouldObserve &&\n    !isServerRendering() &&\n    (Array.isArray(value) || isPlainObject(value)) &&\n    Object.isExtensible(value) &&\n    !value._isVue\n  ) {\n    ob = new Observer(value);\n  }\n  if (asRootData && ob) {\n    ob.vmCount++;\n  }\n  return ob\n}\n\n/**\n * Define a reactive property on an Object.\n */\nfunction defineReactive$$1 (\n  obj,\n  key,\n  val,\n  customSetter,\n  shallow\n) {\n  var dep = new Dep();\n\n  var property = Object.getOwnPropertyDescriptor(obj, key);\n  if (property && property.configurable === false) {\n    return\n  }\n\n  // cater for pre-defined getter/setters\n  var getter = property && property.get;\n  var setter = property && property.set;\n  if ((!getter || setter) && arguments.length === 2) {\n    val = obj[key];\n  }\n\n  var childOb = !shallow && observe(val);\n  Object.defineProperty(obj, key, {\n    enumerable: true,\n    configurable: true,\n    get: function reactiveGetter () {\n      var value = getter ? getter.call(obj) : val;\n      if (Dep.target) {\n        dep.depend();\n        if (childOb) {\n          childOb.dep.depend();\n          if (Array.isArray(value)) {\n            dependArray(value);\n          }\n        }\n      }\n      return value\n    },\n    set: function reactiveSetter (newVal) {\n      var value = getter ? getter.call(obj) : val;\n      /* eslint-disable no-self-compare */\n      if (newVal === value || (newVal !== newVal && value !== value)) {\n        return\n      }\n      /* eslint-enable no-self-compare */\n      if ( true && customSetter) {\n        customSetter();\n      }\n      // #7981: for accessor properties without setter\n      if (getter && !setter) { return }\n      if (setter) {\n        setter.call(obj, newVal);\n      } else {\n        val = newVal;\n      }\n      childOb = !shallow && observe(newVal);\n      dep.notify();\n    }\n  });\n}\n\n/**\n * Set a property on an object. Adds the new property and\n * triggers change notification if the property doesn't\n * already exist.\n */\nfunction set (target, key, val) {\n  if ( true &&\n    (isUndef(target) || isPrimitive(target))\n  ) {\n    warn((\"Cannot set reactive property on undefined, null, or primitive value: \" + ((target))));\n  }\n  if (Array.isArray(target) && isValidArrayIndex(key)) {\n    target.length = Math.max(target.length, key);\n    target.splice(key, 1, val);\n    return val\n  }\n  if (key in target && !(key in Object.prototype)) {\n    target[key] = val;\n    return val\n  }\n  var ob = (target).__ob__;\n  if (target._isVue || (ob && ob.vmCount)) {\n     true && warn(\n      'Avoid adding reactive properties to a Vue instance or its root $data ' +\n      'at runtime - declare it upfront in the data option.'\n    );\n    return val\n  }\n  if (!ob) {\n    target[key] = val;\n    return val\n  }\n  defineReactive$$1(ob.value, key, val);\n  ob.dep.notify();\n  return val\n}\n\n/**\n * Delete a property and trigger change if necessary.\n */\nfunction del (target, key) {\n  if ( true &&\n    (isUndef(target) || isPrimitive(target))\n  ) {\n    warn((\"Cannot delete reactive property on undefined, null, or primitive value: \" + ((target))));\n  }\n  if (Array.isArray(target) && isValidArrayIndex(key)) {\n    target.splice(key, 1);\n    return\n  }\n  var ob = (target).__ob__;\n  if (target._isVue || (ob && ob.vmCount)) {\n     true && warn(\n      'Avoid deleting properties on a Vue instance or its root $data ' +\n      '- just set it to null.'\n    );\n    return\n  }\n  if (!hasOwn(target, key)) {\n    return\n  }\n  delete target[key];\n  if (!ob) {\n    return\n  }\n  ob.dep.notify();\n}\n\n/**\n * Collect dependencies on array elements when the array is touched, since\n * we cannot intercept array element access like property getters.\n */\nfunction dependArray (value) {\n  for (var e = (void 0), i = 0, l = value.length; i < l; i++) {\n    e = value[i];\n    e && e.__ob__ && e.__ob__.dep.depend();\n    if (Array.isArray(e)) {\n      dependArray(e);\n    }\n  }\n}\n\n/*  */\n\n/**\n * Option overwriting strategies are functions that handle\n * how to merge a parent option value and a child option\n * value into the final value.\n */\nvar strats = config.optionMergeStrategies;\n\n/**\n * Options with restrictions\n */\nif (true) {\n  strats.el = strats.propsData = function (parent, child, vm, key) {\n    if (!vm) {\n      warn(\n        \"option \\\"\" + key + \"\\\" can only be used during instance \" +\n        'creation with the `new` keyword.'\n      );\n    }\n    return defaultStrat(parent, child)\n  };\n}\n\n/**\n * Helper that recursively merges two data objects together.\n */\nfunction mergeData (to, from) {\n  if (!from) { return to }\n  var key, toVal, fromVal;\n\n  var keys = hasSymbol\n    ? Reflect.ownKeys(from)\n    : Object.keys(from);\n\n  for (var i = 0; i < keys.length; i++) {\n    key = keys[i];\n    // in case the object is already observed...\n    if (key === '__ob__') { continue }\n    toVal = to[key];\n    fromVal = from[key];\n    if (!hasOwn(to, key)) {\n      set(to, key, fromVal);\n    } else if (\n      toVal !== fromVal &&\n      isPlainObject(toVal) &&\n      isPlainObject(fromVal)\n    ) {\n      mergeData(toVal, fromVal);\n    }\n  }\n  return to\n}\n\n/**\n * Data\n */\nfunction mergeDataOrFn (\n  parentVal,\n  childVal,\n  vm\n) {\n  if (!vm) {\n    // in a Vue.extend merge, both should be functions\n    if (!childVal) {\n      return parentVal\n    }\n    if (!parentVal) {\n      return childVal\n    }\n    // when parentVal & childVal are both present,\n    // we need to return a function that returns the\n    // merged result of both functions... no need to\n    // check if parentVal is a function here because\n    // it has to be a function to pass previous merges.\n    return function mergedDataFn () {\n      return mergeData(\n        typeof childVal === 'function' ? childVal.call(this, this) : childVal,\n        typeof parentVal === 'function' ? parentVal.call(this, this) : parentVal\n      )\n    }\n  } else {\n    return function mergedInstanceDataFn () {\n      // instance merge\n      var instanceData = typeof childVal === 'function'\n        ? childVal.call(vm, vm)\n        : childVal;\n      var defaultData = typeof parentVal === 'function'\n        ? parentVal.call(vm, vm)\n        : parentVal;\n      if (instanceData) {\n        return mergeData(instanceData, defaultData)\n      } else {\n        return defaultData\n      }\n    }\n  }\n}\n\nstrats.data = function (\n  parentVal,\n  childVal,\n  vm\n) {\n  if (!vm) {\n    if (childVal && typeof childVal !== 'function') {\n       true && warn(\n        'The \"data\" option should be a function ' +\n        'that returns a per-instance value in component ' +\n        'definitions.',\n        vm\n      );\n\n      return parentVal\n    }\n    return mergeDataOrFn(parentVal, childVal)\n  }\n\n  return mergeDataOrFn(parentVal, childVal, vm)\n};\n\n/**\n * Hooks and props are merged as arrays.\n */\nfunction mergeHook (\n  parentVal,\n  childVal\n) {\n  var res = childVal\n    ? parentVal\n      ? parentVal.concat(childVal)\n      : Array.isArray(childVal)\n        ? childVal\n        : [childVal]\n    : parentVal;\n  return res\n    ? dedupeHooks(res)\n    : res\n}\n\nfunction dedupeHooks (hooks) {\n  var res = [];\n  for (var i = 0; i < hooks.length; i++) {\n    if (res.indexOf(hooks[i]) === -1) {\n      res.push(hooks[i]);\n    }\n  }\n  return res\n}\n\nLIFECYCLE_HOOKS.forEach(function (hook) {\n  strats[hook] = mergeHook;\n});\n\n/**\n * Assets\n *\n * When a vm is present (instance creation), we need to do\n * a three-way merge between constructor options, instance\n * options and parent options.\n */\nfunction mergeAssets (\n  parentVal,\n  childVal,\n  vm,\n  key\n) {\n  var res = Object.create(parentVal || null);\n  if (childVal) {\n     true && assertObjectType(key, childVal, vm);\n    return extend(res, childVal)\n  } else {\n    return res\n  }\n}\n\nASSET_TYPES.forEach(function (type) {\n  strats[type + 's'] = mergeAssets;\n});\n\n/**\n * Watchers.\n *\n * Watchers hashes should not overwrite one\n * another, so we merge them as arrays.\n */\nstrats.watch = function (\n  parentVal,\n  childVal,\n  vm,\n  key\n) {\n  // work around Firefox's Object.prototype.watch...\n  if (parentVal === nativeWatch) { parentVal = undefined; }\n  if (childVal === nativeWatch) { childVal = undefined; }\n  /* istanbul ignore if */\n  if (!childVal) { return Object.create(parentVal || null) }\n  if (true) {\n    assertObjectType(key, childVal, vm);\n  }\n  if (!parentVal) { return childVal }\n  var ret = {};\n  extend(ret, parentVal);\n  for (var key$1 in childVal) {\n    var parent = ret[key$1];\n    var child = childVal[key$1];\n    if (parent && !Array.isArray(parent)) {\n      parent = [parent];\n    }\n    ret[key$1] = parent\n      ? parent.concat(child)\n      : Array.isArray(child) ? child : [child];\n  }\n  return ret\n};\n\n/**\n * Other object hashes.\n */\nstrats.props =\nstrats.methods =\nstrats.inject =\nstrats.computed = function (\n  parentVal,\n  childVal,\n  vm,\n  key\n) {\n  if (childVal && \"development\" !== 'production') {\n    assertObjectType(key, childVal, vm);\n  }\n  if (!parentVal) { return childVal }\n  var ret = Object.create(null);\n  extend(ret, parentVal);\n  if (childVal) { extend(ret, childVal); }\n  return ret\n};\nstrats.provide = mergeDataOrFn;\n\n/**\n * Default strategy.\n */\nvar defaultStrat = function (parentVal, childVal) {\n  return childVal === undefined\n    ? parentVal\n    : childVal\n};\n\n/**\n * Validate component names\n */\nfunction checkComponents (options) {\n  for (var key in options.components) {\n    validateComponentName(key);\n  }\n}\n\nfunction validateComponentName (name) {\n  if (!new RegExp((\"^[a-zA-Z][\\\\-\\\\.0-9_\" + (unicodeRegExp.source) + \"]*$\")).test(name)) {\n    warn(\n      'Invalid component name: \"' + name + '\". Component names ' +\n      'should conform to valid custom element name in html5 specification.'\n    );\n  }\n  if (isBuiltInTag(name) || config.isReservedTag(name)) {\n    warn(\n      'Do not use built-in or reserved HTML elements as component ' +\n      'id: ' + name\n    );\n  }\n}\n\n/**\n * Ensure all props option syntax are normalized into the\n * Object-based format.\n */\nfunction normalizeProps (options, vm) {\n  var props = options.props;\n  if (!props) { return }\n  var res = {};\n  var i, val, name;\n  if (Array.isArray(props)) {\n    i = props.length;\n    while (i--) {\n      val = props[i];\n      if (typeof val === 'string') {\n        name = camelize(val);\n        res[name] = { type: null };\n      } else if (true) {\n        warn('props must be strings when using array syntax.');\n      }\n    }\n  } else if (isPlainObject(props)) {\n    for (var key in props) {\n      val = props[key];\n      name = camelize(key);\n      res[name] = isPlainObject(val)\n        ? val\n        : { type: val };\n    }\n  } else if (true) {\n    warn(\n      \"Invalid value for option \\\"props\\\": expected an Array or an Object, \" +\n      \"but got \" + (toRawType(props)) + \".\",\n      vm\n    );\n  }\n  options.props = res;\n}\n\n/**\n * Normalize all injections into Object-based format\n */\nfunction normalizeInject (options, vm) {\n  var inject = options.inject;\n  if (!inject) { return }\n  var normalized = options.inject = {};\n  if (Array.isArray(inject)) {\n    for (var i = 0; i < inject.length; i++) {\n      normalized[inject[i]] = { from: inject[i] };\n    }\n  } else if (isPlainObject(inject)) {\n    for (var key in inject) {\n      var val = inject[key];\n      normalized[key] = isPlainObject(val)\n        ? extend({ from: key }, val)\n        : { from: val };\n    }\n  } else if (true) {\n    warn(\n      \"Invalid value for option \\\"inject\\\": expected an Array or an Object, \" +\n      \"but got \" + (toRawType(inject)) + \".\",\n      vm\n    );\n  }\n}\n\n/**\n * Normalize raw function directives into object format.\n */\nfunction normalizeDirectives (options) {\n  var dirs = options.directives;\n  if (dirs) {\n    for (var key in dirs) {\n      var def$$1 = dirs[key];\n      if (typeof def$$1 === 'function') {\n        dirs[key] = { bind: def$$1, update: def$$1 };\n      }\n    }\n  }\n}\n\nfunction assertObjectType (name, value, vm) {\n  if (!isPlainObject(value)) {\n    warn(\n      \"Invalid value for option \\\"\" + name + \"\\\": expected an Object, \" +\n      \"but got \" + (toRawType(value)) + \".\",\n      vm\n    );\n  }\n}\n\n/**\n * Merge two option objects into a new one.\n * Core utility used in both instantiation and inheritance.\n */\nfunction mergeOptions (\n  parent,\n  child,\n  vm\n) {\n  if (true) {\n    checkComponents(child);\n  }\n\n  if (typeof child === 'function') {\n    child = child.options;\n  }\n\n  normalizeProps(child, vm);\n  normalizeInject(child, vm);\n  normalizeDirectives(child);\n\n  // Apply extends and mixins on the child options,\n  // but only if it is a raw options object that isn't\n  // the result of another mergeOptions call.\n  // Only merged options has the _base property.\n  if (!child._base) {\n    if (child.extends) {\n      parent = mergeOptions(parent, child.extends, vm);\n    }\n    if (child.mixins) {\n      for (var i = 0, l = child.mixins.length; i < l; i++) {\n        parent = mergeOptions(parent, child.mixins[i], vm);\n      }\n    }\n  }\n\n  var options = {};\n  var key;\n  for (key in parent) {\n    mergeField(key);\n  }\n  for (key in child) {\n    if (!hasOwn(parent, key)) {\n      mergeField(key);\n    }\n  }\n  function mergeField (key) {\n    var strat = strats[key] || defaultStrat;\n    options[key] = strat(parent[key], child[key], vm, key);\n  }\n  return options\n}\n\n/**\n * Resolve an asset.\n * This function is used because child instances need access\n * to assets defined in its ancestor chain.\n */\nfunction resolveAsset (\n  options,\n  type,\n  id,\n  warnMissing\n) {\n  /* istanbul ignore if */\n  if (typeof id !== 'string') {\n    return\n  }\n  var assets = options[type];\n  // check local registration variations first\n  if (hasOwn(assets, id)) { return assets[id] }\n  var camelizedId = camelize(id);\n  if (hasOwn(assets, camelizedId)) { return assets[camelizedId] }\n  var PascalCaseId = capitalize(camelizedId);\n  if (hasOwn(assets, PascalCaseId)) { return assets[PascalCaseId] }\n  // fallback to prototype chain\n  var res = assets[id] || assets[camelizedId] || assets[PascalCaseId];\n  if ( true && warnMissing && !res) {\n    warn(\n      'Failed to resolve ' + type.slice(0, -1) + ': ' + id,\n      options\n    );\n  }\n  return res\n}\n\n/*  */\n\n\n\nfunction validateProp (\n  key,\n  propOptions,\n  propsData,\n  vm\n) {\n  var prop = propOptions[key];\n  var absent = !hasOwn(propsData, key);\n  var value = propsData[key];\n  // boolean casting\n  var booleanIndex = getTypeIndex(Boolean, prop.type);\n  if (booleanIndex > -1) {\n    if (absent && !hasOwn(prop, 'default')) {\n      value = false;\n    } else if (value === '' || value === hyphenate(key)) {\n      // only cast empty string / same name to boolean if\n      // boolean has higher priority\n      var stringIndex = getTypeIndex(String, prop.type);\n      if (stringIndex < 0 || booleanIndex < stringIndex) {\n        value = true;\n      }\n    }\n  }\n  // check default value\n  if (value === undefined) {\n    value = getPropDefaultValue(vm, prop, key);\n    // since the default value is a fresh copy,\n    // make sure to observe it.\n    var prevShouldObserve = shouldObserve;\n    toggleObserving(true);\n    observe(value);\n    toggleObserving(prevShouldObserve);\n  }\n  if (\n    true\n  ) {\n    assertProp(prop, key, value, vm, absent);\n  }\n  return value\n}\n\n/**\n * Get the default value of a prop.\n */\nfunction getPropDefaultValue (vm, prop, key) {\n  // no default, return undefined\n  if (!hasOwn(prop, 'default')) {\n    return undefined\n  }\n  var def = prop.default;\n  // warn against non-factory defaults for Object & Array\n  if ( true && isObject(def)) {\n    warn(\n      'Invalid default value for prop \"' + key + '\": ' +\n      'Props with type Object/Array must use a factory function ' +\n      'to return the default value.',\n      vm\n    );\n  }\n  // the raw prop value was also undefined from previous render,\n  // return previous default value to avoid unnecessary watcher trigger\n  if (vm && vm.$options.propsData &&\n    vm.$options.propsData[key] === undefined &&\n    vm._props[key] !== undefined\n  ) {\n    return vm._props[key]\n  }\n  // call factory function for non-Function types\n  // a value is Function if its prototype is function even across different execution context\n  return typeof def === 'function' && getType(prop.type) !== 'Function'\n    ? def.call(vm)\n    : def\n}\n\n/**\n * Assert whether a prop is valid.\n */\nfunction assertProp (\n  prop,\n  name,\n  value,\n  vm,\n  absent\n) {\n  if (prop.required && absent) {\n    warn(\n      'Missing required prop: \"' + name + '\"',\n      vm\n    );\n    return\n  }\n  if (value == null && !prop.required) {\n    return\n  }\n  var type = prop.type;\n  var valid = !type || type === true;\n  var expectedTypes = [];\n  if (type) {\n    if (!Array.isArray(type)) {\n      type = [type];\n    }\n    for (var i = 0; i < type.length && !valid; i++) {\n      var assertedType = assertType(value, type[i]);\n      expectedTypes.push(assertedType.expectedType || '');\n      valid = assertedType.valid;\n    }\n  }\n\n  if (!valid) {\n    warn(\n      getInvalidTypeMessage(name, value, expectedTypes),\n      vm\n    );\n    return\n  }\n  var validator = prop.validator;\n  if (validator) {\n    if (!validator(value)) {\n      warn(\n        'Invalid prop: custom validator check failed for prop \"' + name + '\".',\n        vm\n      );\n    }\n  }\n}\n\nvar simpleCheckRE = /^(String|Number|Boolean|Function|Symbol)$/;\n\nfunction assertType (value, type) {\n  var valid;\n  var expectedType = getType(type);\n  if (simpleCheckRE.test(expectedType)) {\n    var t = typeof value;\n    valid = t === expectedType.toLowerCase();\n    // for primitive wrapper objects\n    if (!valid && t === 'object') {\n      valid = value instanceof type;\n    }\n  } else if (expectedType === 'Object') {\n    valid = isPlainObject(value);\n  } else if (expectedType === 'Array') {\n    valid = Array.isArray(value);\n  } else {\n    valid = value instanceof type;\n  }\n  return {\n    valid: valid,\n    expectedType: expectedType\n  }\n}\n\n/**\n * Use function string name to check built-in types,\n * because a simple equality check will fail when running\n * across different vms / iframes.\n */\nfunction getType (fn) {\n  var match = fn && fn.toString().match(/^\\s*function (\\w+)/);\n  return match ? match[1] : ''\n}\n\nfunction isSameType (a, b) {\n  return getType(a) === getType(b)\n}\n\nfunction getTypeIndex (type, expectedTypes) {\n  if (!Array.isArray(expectedTypes)) {\n    return isSameType(expectedTypes, type) ? 0 : -1\n  }\n  for (var i = 0, len = expectedTypes.length; i < len; i++) {\n    if (isSameType(expectedTypes[i], type)) {\n      return i\n    }\n  }\n  return -1\n}\n\nfunction getInvalidTypeMessage (name, value, expectedTypes) {\n  var message = \"Invalid prop: type check failed for prop \\\"\" + name + \"\\\".\" +\n    \" Expected \" + (expectedTypes.map(capitalize).join(', '));\n  var expectedType = expectedTypes[0];\n  var receivedType = toRawType(value);\n  var expectedValue = styleValue(value, expectedType);\n  var receivedValue = styleValue(value, receivedType);\n  // check if we need to specify expected value\n  if (expectedTypes.length === 1 &&\n      isExplicable(expectedType) &&\n      !isBoolean(expectedType, receivedType)) {\n    message += \" with value \" + expectedValue;\n  }\n  message += \", got \" + receivedType + \" \";\n  // check if we need to specify received value\n  if (isExplicable(receivedType)) {\n    message += \"with value \" + receivedValue + \".\";\n  }\n  return message\n}\n\nfunction styleValue (value, type) {\n  if (type === 'String') {\n    return (\"\\\"\" + value + \"\\\"\")\n  } else if (type === 'Number') {\n    return (\"\" + (Number(value)))\n  } else {\n    return (\"\" + value)\n  }\n}\n\nfunction isExplicable (value) {\n  var explicitTypes = ['string', 'number', 'boolean'];\n  return explicitTypes.some(function (elem) { return value.toLowerCase() === elem; })\n}\n\nfunction isBoolean () {\n  var args = [], len = arguments.length;\n  while ( len-- ) args[ len ] = arguments[ len ];\n\n  return args.some(function (elem) { return elem.toLowerCase() === 'boolean'; })\n}\n\n/*  */\n\nfunction handleError (err, vm, info) {\n  // Deactivate deps tracking while processing error handler to avoid possible infinite rendering.\n  // See: https://github.com/vuejs/vuex/issues/1505\n  pushTarget();\n  try {\n    if (vm) {\n      var cur = vm;\n      while ((cur = cur.$parent)) {\n        var hooks = cur.$options.errorCaptured;\n        if (hooks) {\n          for (var i = 0; i < hooks.length; i++) {\n            try {\n              var capture = hooks[i].call(cur, err, vm, info) === false;\n              if (capture) { return }\n            } catch (e) {\n              globalHandleError(e, cur, 'errorCaptured hook');\n            }\n          }\n        }\n      }\n    }\n    globalHandleError(err, vm, info);\n  } finally {\n    popTarget();\n  }\n}\n\nfunction invokeWithErrorHandling (\n  handler,\n  context,\n  args,\n  vm,\n  info\n) {\n  var res;\n  try {\n    res = args ? handler.apply(context, args) : handler.call(context);\n    if (res && !res._isVue && isPromise(res) && !res._handled) {\n      res.catch(function (e) { return handleError(e, vm, info + \" (Promise/async)\"); });\n      // issue #9511\n      // avoid catch triggering multiple times when nested calls\n      res._handled = true;\n    }\n  } catch (e) {\n    handleError(e, vm, info);\n  }\n  return res\n}\n\nfunction globalHandleError (err, vm, info) {\n  if (config.errorHandler) {\n    try {\n      return config.errorHandler.call(null, err, vm, info)\n    } catch (e) {\n      // if the user intentionally throws the original error in the handler,\n      // do not log it twice\n      if (e !== err) {\n        logError(e, null, 'config.errorHandler');\n      }\n    }\n  }\n  logError(err, vm, info);\n}\n\nfunction logError (err, vm, info) {\n  if (true) {\n    warn((\"Error in \" + info + \": \\\"\" + (err.toString()) + \"\\\"\"), vm);\n  }\n  /* istanbul ignore else */\n  if ((inBrowser || inWeex) && typeof console !== 'undefined') {\n    console.error(err);\n  } else {\n    throw err\n  }\n}\n\n/*  */\n\nvar isUsingMicroTask = false;\n\nvar callbacks = [];\nvar pending = false;\n\nfunction flushCallbacks () {\n  pending = false;\n  var copies = callbacks.slice(0);\n  callbacks.length = 0;\n  for (var i = 0; i < copies.length; i++) {\n    copies[i]();\n  }\n}\n\n// Here we have async deferring wrappers using microtasks.\n// In 2.5 we used (macro) tasks (in combination with microtasks).\n// However, it has subtle problems when state is changed right before repaint\n// (e.g. #6813, out-in transitions).\n// Also, using (macro) tasks in event handler would cause some weird behaviors\n// that cannot be circumvented (e.g. #7109, #7153, #7546, #7834, #8109).\n// So we now use microtasks everywhere, again.\n// A major drawback of this tradeoff is that there are some scenarios\n// where microtasks have too high a priority and fire in between supposedly\n// sequential events (e.g. #4521, #6690, which have workarounds)\n// or even between bubbling of the same event (#6566).\nvar timerFunc;\n\n// The nextTick behavior leverages the microtask queue, which can be accessed\n// via either native Promise.then or MutationObserver.\n// MutationObserver has wider support, however it is seriously bugged in\n// UIWebView in iOS >= 9.3.3 when triggered in touch event handlers. It\n// completely stops working after triggering a few times... so, if native\n// Promise is available, we will use it:\n/* istanbul ignore next, $flow-disable-line */\nif (typeof Promise !== 'undefined' && isNative(Promise)) {\n  var p = Promise.resolve();\n  timerFunc = function () {\n    p.then(flushCallbacks);\n    // In problematic UIWebViews, Promise.then doesn't completely break, but\n    // it can get stuck in a weird state where callbacks are pushed into the\n    // microtask queue but the queue isn't being flushed, until the browser\n    // needs to do some other work, e.g. handle a timer. Therefore we can\n    // \"force\" the microtask queue to be flushed by adding an empty timer.\n    if (isIOS) { setTimeout(noop); }\n  };\n  isUsingMicroTask = true;\n} else if (!isIE && typeof MutationObserver !== 'undefined' && (\n  isNative(MutationObserver) ||\n  // PhantomJS and iOS 7.x\n  MutationObserver.toString() === '[object MutationObserverConstructor]'\n)) {\n  // Use MutationObserver where native Promise is not available,\n  // e.g. PhantomJS, iOS7, Android 4.4\n  // (#6466 MutationObserver is unreliable in IE11)\n  var counter = 1;\n  var observer = new MutationObserver(flushCallbacks);\n  var textNode = document.createTextNode(String(counter));\n  observer.observe(textNode, {\n    characterData: true\n  });\n  timerFunc = function () {\n    counter = (counter + 1) % 2;\n    textNode.data = String(counter);\n  };\n  isUsingMicroTask = true;\n} else if (typeof setImmediate !== 'undefined' && isNative(setImmediate)) {\n  // Fallback to setImmediate.\n  // Techinically it leverages the (macro) task queue,\n  // but it is still a better choice than setTimeout.\n  timerFunc = function () {\n    setImmediate(flushCallbacks);\n  };\n} else {\n  // Fallback to setTimeout.\n  timerFunc = function () {\n    setTimeout(flushCallbacks, 0);\n  };\n}\n\nfunction nextTick (cb, ctx) {\n  var _resolve;\n  callbacks.push(function () {\n    if (cb) {\n      try {\n        cb.call(ctx);\n      } catch (e) {\n        handleError(e, ctx, 'nextTick');\n      }\n    } else if (_resolve) {\n      _resolve(ctx);\n    }\n  });\n  if (!pending) {\n    pending = true;\n    timerFunc();\n  }\n  // $flow-disable-line\n  if (!cb && typeof Promise !== 'undefined') {\n    return new Promise(function (resolve) {\n      _resolve = resolve;\n    })\n  }\n}\n\n/*  */\n\n/* not type checking this file because flow doesn't play well with Proxy */\n\nvar initProxy;\n\nif (true) {\n  var allowedGlobals = makeMap(\n    'Infinity,undefined,NaN,isFinite,isNaN,' +\n    'parseFloat,parseInt,decodeURI,decodeURIComponent,encodeURI,encodeURIComponent,' +\n    'Math,Number,Date,Array,Object,Boolean,String,RegExp,Map,Set,JSON,Intl,' +\n    'require' // for Webpack/Browserify\n  );\n\n  var warnNonPresent = function (target, key) {\n    warn(\n      \"Property or method \\\"\" + key + \"\\\" is not defined on the instance but \" +\n      'referenced during render. Make sure that this property is reactive, ' +\n      'either in the data option, or for class-based components, by ' +\n      'initializing the property. ' +\n      'See: https://vuejs.org/v2/guide/reactivity.html#Declaring-Reactive-Properties.',\n      target\n    );\n  };\n\n  var warnReservedPrefix = function (target, key) {\n    warn(\n      \"Property \\\"\" + key + \"\\\" must be accessed with \\\"$data.\" + key + \"\\\" because \" +\n      'properties starting with \"$\" or \"_\" are not proxied in the Vue instance to ' +\n      'prevent conflicts with Vue internals' +\n      'See: https://vuejs.org/v2/api/#data',\n      target\n    );\n  };\n\n  var hasProxy =\n    typeof Proxy !== 'undefined' && isNative(Proxy);\n\n  if (hasProxy) {\n    var isBuiltInModifier = makeMap('stop,prevent,self,ctrl,shift,alt,meta,exact');\n    config.keyCodes = new Proxy(config.keyCodes, {\n      set: function set (target, key, value) {\n        if (isBuiltInModifier(key)) {\n          warn((\"Avoid overwriting built-in modifier in config.keyCodes: .\" + key));\n          return false\n        } else {\n          target[key] = value;\n          return true\n        }\n      }\n    });\n  }\n\n  var hasHandler = {\n    has: function has (target, key) {\n      var has = key in target;\n      var isAllowed = allowedGlobals(key) ||\n        (typeof key === 'string' && key.charAt(0) === '_' && !(key in target.$data));\n      if (!has && !isAllowed) {\n        if (key in target.$data) { warnReservedPrefix(target, key); }\n        else { warnNonPresent(target, key); }\n      }\n      return has || !isAllowed\n    }\n  };\n\n  var getHandler = {\n    get: function get (target, key) {\n      if (typeof key === 'string' && !(key in target)) {\n        if (key in target.$data) { warnReservedPrefix(target, key); }\n        else { warnNonPresent(target, key); }\n      }\n      return target[key]\n    }\n  };\n\n  initProxy = function initProxy (vm) {\n    if (hasProxy) {\n      // determine which proxy handler to use\n      var options = vm.$options;\n      var handlers = options.render && options.render._withStripped\n        ? getHandler\n        : hasHandler;\n      vm._renderProxy = new Proxy(vm, handlers);\n    } else {\n      vm._renderProxy = vm;\n    }\n  };\n}\n\n/*  */\n\nvar seenObjects = new _Set();\n\n/**\n * Recursively traverse an object to evoke all converted\n * getters, so that every nested property inside the object\n * is collected as a \"deep\" dependency.\n */\nfunction traverse (val) {\n  _traverse(val, seenObjects);\n  seenObjects.clear();\n}\n\nfunction _traverse (val, seen) {\n  var i, keys;\n  var isA = Array.isArray(val);\n  if ((!isA && !isObject(val)) || Object.isFrozen(val) || val instanceof VNode) {\n    return\n  }\n  if (val.__ob__) {\n    var depId = val.__ob__.dep.id;\n    if (seen.has(depId)) {\n      return\n    }\n    seen.add(depId);\n  }\n  if (isA) {\n    i = val.length;\n    while (i--) { _traverse(val[i], seen); }\n  } else {\n    keys = Object.keys(val);\n    i = keys.length;\n    while (i--) { _traverse(val[keys[i]], seen); }\n  }\n}\n\nvar mark;\nvar measure;\n\nif (true) {\n  var perf = inBrowser && window.performance;\n  /* istanbul ignore if */\n  if (\n    perf &&\n    perf.mark &&\n    perf.measure &&\n    perf.clearMarks &&\n    perf.clearMeasures\n  ) {\n    mark = function (tag) { return perf.mark(tag); };\n    measure = function (name, startTag, endTag) {\n      perf.measure(name, startTag, endTag);\n      perf.clearMarks(startTag);\n      perf.clearMarks(endTag);\n      // perf.clearMeasures(name)\n    };\n  }\n}\n\n/*  */\n\nvar normalizeEvent = cached(function (name) {\n  var passive = name.charAt(0) === '&';\n  name = passive ? name.slice(1) : name;\n  var once$$1 = name.charAt(0) === '~'; // Prefixed last, checked first\n  name = once$$1 ? name.slice(1) : name;\n  var capture = name.charAt(0) === '!';\n  name = capture ? name.slice(1) : name;\n  return {\n    name: name,\n    once: once$$1,\n    capture: capture,\n    passive: passive\n  }\n});\n\nfunction createFnInvoker (fns, vm) {\n  function invoker () {\n    var arguments$1 = arguments;\n\n    var fns = invoker.fns;\n    if (Array.isArray(fns)) {\n      var cloned = fns.slice();\n      for (var i = 0; i < cloned.length; i++) {\n        invokeWithErrorHandling(cloned[i], null, arguments$1, vm, \"v-on handler\");\n      }\n    } else {\n      // return handler return value for single handlers\n      return invokeWithErrorHandling(fns, null, arguments, vm, \"v-on handler\")\n    }\n  }\n  invoker.fns = fns;\n  return invoker\n}\n\nfunction updateListeners (\n  on,\n  oldOn,\n  add,\n  remove$$1,\n  createOnceHandler,\n  vm\n) {\n  var name, def$$1, cur, old, event;\n  for (name in on) {\n    def$$1 = cur = on[name];\n    old = oldOn[name];\n    event = normalizeEvent(name);\n    if (isUndef(cur)) {\n       true && warn(\n        \"Invalid handler for event \\\"\" + (event.name) + \"\\\": got \" + String(cur),\n        vm\n      );\n    } else if (isUndef(old)) {\n      if (isUndef(cur.fns)) {\n        cur = on[name] = createFnInvoker(cur, vm);\n      }\n      if (isTrue(event.once)) {\n        cur = on[name] = createOnceHandler(event.name, cur, event.capture);\n      }\n      add(event.name, cur, event.capture, event.passive, event.params);\n    } else if (cur !== old) {\n      old.fns = cur;\n      on[name] = old;\n    }\n  }\n  for (name in oldOn) {\n    if (isUndef(on[name])) {\n      event = normalizeEvent(name);\n      remove$$1(event.name, oldOn[name], event.capture);\n    }\n  }\n}\n\n/*  */\n\nfunction mergeVNodeHook (def, hookKey, hook) {\n  if (def instanceof VNode) {\n    def = def.data.hook || (def.data.hook = {});\n  }\n  var invoker;\n  var oldHook = def[hookKey];\n\n  function wrappedHook () {\n    hook.apply(this, arguments);\n    // important: remove merged hook to ensure it's called only once\n    // and prevent memory leak\n    remove(invoker.fns, wrappedHook);\n  }\n\n  if (isUndef(oldHook)) {\n    // no existing hook\n    invoker = createFnInvoker([wrappedHook]);\n  } else {\n    /* istanbul ignore if */\n    if (isDef(oldHook.fns) && isTrue(oldHook.merged)) {\n      // already a merged invoker\n      invoker = oldHook;\n      invoker.fns.push(wrappedHook);\n    } else {\n      // existing plain hook\n      invoker = createFnInvoker([oldHook, wrappedHook]);\n    }\n  }\n\n  invoker.merged = true;\n  def[hookKey] = invoker;\n}\n\n/*  */\n\nfunction extractPropsFromVNodeData (\n  data,\n  Ctor,\n  tag\n) {\n  // we are only extracting raw values here.\n  // validation and default values are handled in the child\n  // component itself.\n  var propOptions = Ctor.options.props;\n  if (isUndef(propOptions)) {\n    return\n  }\n  var res = {};\n  var attrs = data.attrs;\n  var props = data.props;\n  if (isDef(attrs) || isDef(props)) {\n    for (var key in propOptions) {\n      var altKey = hyphenate(key);\n      if (true) {\n        var keyInLowerCase = key.toLowerCase();\n        if (\n          key !== keyInLowerCase &&\n          attrs && hasOwn(attrs, keyInLowerCase)\n        ) {\n          tip(\n            \"Prop \\\"\" + keyInLowerCase + \"\\\" is passed to component \" +\n            (formatComponentName(tag || Ctor)) + \", but the declared prop name is\" +\n            \" \\\"\" + key + \"\\\". \" +\n            \"Note that HTML attributes are case-insensitive and camelCased \" +\n            \"props need to use their kebab-case equivalents when using in-DOM \" +\n            \"templates. You should probably use \\\"\" + altKey + \"\\\" instead of \\\"\" + key + \"\\\".\"\n          );\n        }\n      }\n      checkProp(res, props, key, altKey, true) ||\n      checkProp(res, attrs, key, altKey, false);\n    }\n  }\n  return res\n}\n\nfunction checkProp (\n  res,\n  hash,\n  key,\n  altKey,\n  preserve\n) {\n  if (isDef(hash)) {\n    if (hasOwn(hash, key)) {\n      res[key] = hash[key];\n      if (!preserve) {\n        delete hash[key];\n      }\n      return true\n    } else if (hasOwn(hash, altKey)) {\n      res[key] = hash[altKey];\n      if (!preserve) {\n        delete hash[altKey];\n      }\n      return true\n    }\n  }\n  return false\n}\n\n/*  */\n\n// The template compiler attempts to minimize the need for normalization by\n// statically analyzing the template at compile time.\n//\n// For plain HTML markup, normalization can be completely skipped because the\n// generated render function is guaranteed to return Array<VNode>. There are\n// two cases where extra normalization is needed:\n\n// 1. When the children contains components - because a functional component\n// may return an Array instead of a single root. In this case, just a simple\n// normalization is needed - if any child is an Array, we flatten the whole\n// thing with Array.prototype.concat. It is guaranteed to be only 1-level deep\n// because functional components already normalize their own children.\nfunction simpleNormalizeChildren (children) {\n  for (var i = 0; i < children.length; i++) {\n    if (Array.isArray(children[i])) {\n      return Array.prototype.concat.apply([], children)\n    }\n  }\n  return children\n}\n\n// 2. When the children contains constructs that always generated nested Arrays,\n// e.g. <template>, <slot>, v-for, or when the children is provided by user\n// with hand-written render functions / JSX. In such cases a full normalization\n// is needed to cater to all possible types of children values.\nfunction normalizeChildren (children) {\n  return isPrimitive(children)\n    ? [createTextVNode(children)]\n    : Array.isArray(children)\n      ? normalizeArrayChildren(children)\n      : undefined\n}\n\nfunction isTextNode (node) {\n  return isDef(node) && isDef(node.text) && isFalse(node.isComment)\n}\n\nfunction normalizeArrayChildren (children, nestedIndex) {\n  var res = [];\n  var i, c, lastIndex, last;\n  for (i = 0; i < children.length; i++) {\n    c = children[i];\n    if (isUndef(c) || typeof c === 'boolean') { continue }\n    lastIndex = res.length - 1;\n    last = res[lastIndex];\n    //  nested\n    if (Array.isArray(c)) {\n      if (c.length > 0) {\n        c = normalizeArrayChildren(c, ((nestedIndex || '') + \"_\" + i));\n        // merge adjacent text nodes\n        if (isTextNode(c[0]) && isTextNode(last)) {\n          res[lastIndex] = createTextVNode(last.text + (c[0]).text);\n          c.shift();\n        }\n        res.push.apply(res, c);\n      }\n    } else if (isPrimitive(c)) {\n      if (isTextNode(last)) {\n        // merge adjacent text nodes\n        // this is necessary for SSR hydration because text nodes are\n        // essentially merged when rendered to HTML strings\n        res[lastIndex] = createTextVNode(last.text + c);\n      } else if (c !== '') {\n        // convert primitive to vnode\n        res.push(createTextVNode(c));\n      }\n    } else {\n      if (isTextNode(c) && isTextNode(last)) {\n        // merge adjacent text nodes\n        res[lastIndex] = createTextVNode(last.text + c.text);\n      } else {\n        // default key for nested array children (likely generated by v-for)\n        if (isTrue(children._isVList) &&\n          isDef(c.tag) &&\n          isUndef(c.key) &&\n          isDef(nestedIndex)) {\n          c.key = \"__vlist\" + nestedIndex + \"_\" + i + \"__\";\n        }\n        res.push(c);\n      }\n    }\n  }\n  return res\n}\n\n/*  */\n\nfunction initProvide (vm) {\n  var provide = vm.$options.provide;\n  if (provide) {\n    vm._provided = typeof provide === 'function'\n      ? provide.call(vm)\n      : provide;\n  }\n}\n\nfunction initInjections (vm) {\n  var result = resolveInject(vm.$options.inject, vm);\n  if (result) {\n    toggleObserving(false);\n    Object.keys(result).forEach(function (key) {\n      /* istanbul ignore else */\n      if (true) {\n        defineReactive$$1(vm, key, result[key], function () {\n          warn(\n            \"Avoid mutating an injected value directly since the changes will be \" +\n            \"overwritten whenever the provided component re-renders. \" +\n            \"injection being mutated: \\\"\" + key + \"\\\"\",\n            vm\n          );\n        });\n      } else {}\n    });\n    toggleObserving(true);\n  }\n}\n\nfunction resolveInject (inject, vm) {\n  if (inject) {\n    // inject is :any because flow is not smart enough to figure out cached\n    var result = Object.create(null);\n    var keys = hasSymbol\n      ? Reflect.ownKeys(inject)\n      : Object.keys(inject);\n\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i];\n      // #6574 in case the inject object is observed...\n      if (key === '__ob__') { continue }\n      var provideKey = inject[key].from;\n      var source = vm;\n      while (source) {\n        if (source._provided && hasOwn(source._provided, provideKey)) {\n          result[key] = source._provided[provideKey];\n          break\n        }\n        source = source.$parent;\n      }\n      if (!source) {\n        if ('default' in inject[key]) {\n          var provideDefault = inject[key].default;\n          result[key] = typeof provideDefault === 'function'\n            ? provideDefault.call(vm)\n            : provideDefault;\n        } else if (true) {\n          warn((\"Injection \\\"\" + key + \"\\\" not found\"), vm);\n        }\n      }\n    }\n    return result\n  }\n}\n\n/*  */\n\n\n\n/**\n * Runtime helper for resolving raw children VNodes into a slot object.\n */\nfunction resolveSlots (\n  children,\n  context\n) {\n  if (!children || !children.length) {\n    return {}\n  }\n  var slots = {};\n  for (var i = 0, l = children.length; i < l; i++) {\n    var child = children[i];\n    var data = child.data;\n    // remove slot attribute if the node is resolved as a Vue slot node\n    if (data && data.attrs && data.attrs.slot) {\n      delete data.attrs.slot;\n    }\n    // named slots should only be respected if the vnode was rendered in the\n    // same context.\n    if ((child.context === context || child.fnContext === context) &&\n      data && data.slot != null\n    ) {\n      var name = data.slot;\n      var slot = (slots[name] || (slots[name] = []));\n      if (child.tag === 'template') {\n        slot.push.apply(slot, child.children || []);\n      } else {\n        slot.push(child);\n      }\n    } else {\n      (slots.default || (slots.default = [])).push(child);\n    }\n  }\n  // ignore slots that contains only whitespace\n  for (var name$1 in slots) {\n    if (slots[name$1].every(isWhitespace)) {\n      delete slots[name$1];\n    }\n  }\n  return slots\n}\n\nfunction isWhitespace (node) {\n  return (node.isComment && !node.asyncFactory) || node.text === ' '\n}\n\n/*  */\n\nfunction normalizeScopedSlots (\n  slots,\n  normalSlots,\n  prevSlots\n) {\n  var res;\n  var hasNormalSlots = Object.keys(normalSlots).length > 0;\n  var isStable = slots ? !!slots.$stable : !hasNormalSlots;\n  var key = slots && slots.$key;\n  if (!slots) {\n    res = {};\n  } else if (slots._normalized) {\n    // fast path 1: child component re-render only, parent did not change\n    return slots._normalized\n  } else if (\n    isStable &&\n    prevSlots &&\n    prevSlots !== emptyObject &&\n    key === prevSlots.$key &&\n    !hasNormalSlots &&\n    !prevSlots.$hasNormal\n  ) {\n    // fast path 2: stable scoped slots w/ no normal slots to proxy,\n    // only need to normalize once\n    return prevSlots\n  } else {\n    res = {};\n    for (var key$1 in slots) {\n      if (slots[key$1] && key$1[0] !== '$') {\n        res[key$1] = normalizeScopedSlot(normalSlots, key$1, slots[key$1]);\n      }\n    }\n  }\n  // expose normal slots on scopedSlots\n  for (var key$2 in normalSlots) {\n    if (!(key$2 in res)) {\n      res[key$2] = proxyNormalSlot(normalSlots, key$2);\n    }\n  }\n  // avoriaz seems to mock a non-extensible $scopedSlots object\n  // and when that is passed down this would cause an error\n  if (slots && Object.isExtensible(slots)) {\n    (slots)._normalized = res;\n  }\n  def(res, '$stable', isStable);\n  def(res, '$key', key);\n  def(res, '$hasNormal', hasNormalSlots);\n  return res\n}\n\nfunction normalizeScopedSlot(normalSlots, key, fn) {\n  var normalized = function () {\n    var res = arguments.length ? fn.apply(null, arguments) : fn({});\n    res = res && typeof res === 'object' && !Array.isArray(res)\n      ? [res] // single vnode\n      : normalizeChildren(res);\n    return res && (\n      res.length === 0 ||\n      (res.length === 1 && res[0].isComment) // #9658\n    ) ? undefined\n      : res\n  };\n  // this is a slot using the new v-slot syntax without scope. although it is\n  // compiled as a scoped slot, render fn users would expect it to be present\n  // on this.$slots because the usage is semantically a normal slot.\n  if (fn.proxy) {\n    Object.defineProperty(normalSlots, key, {\n      get: normalized,\n      enumerable: true,\n      configurable: true\n    });\n  }\n  return normalized\n}\n\nfunction proxyNormalSlot(slots, key) {\n  return function () { return slots[key]; }\n}\n\n/*  */\n\n/**\n * Runtime helper for rendering v-for lists.\n */\nfunction renderList (\n  val,\n  render\n) {\n  var ret, i, l, keys, key;\n  if (Array.isArray(val) || typeof val === 'string') {\n    ret = new Array(val.length);\n    for (i = 0, l = val.length; i < l; i++) {\n      ret[i] = render(val[i], i);\n    }\n  } else if (typeof val === 'number') {\n    ret = new Array(val);\n    for (i = 0; i < val; i++) {\n      ret[i] = render(i + 1, i);\n    }\n  } else if (isObject(val)) {\n    if (hasSymbol && val[Symbol.iterator]) {\n      ret = [];\n      var iterator = val[Symbol.iterator]();\n      var result = iterator.next();\n      while (!result.done) {\n        ret.push(render(result.value, ret.length));\n        result = iterator.next();\n      }\n    } else {\n      keys = Object.keys(val);\n      ret = new Array(keys.length);\n      for (i = 0, l = keys.length; i < l; i++) {\n        key = keys[i];\n        ret[i] = render(val[key], key, i);\n      }\n    }\n  }\n  if (!isDef(ret)) {\n    ret = [];\n  }\n  (ret)._isVList = true;\n  return ret\n}\n\n/*  */\n\n/**\n * Runtime helper for rendering <slot>\n */\nfunction renderSlot (\n  name,\n  fallback,\n  props,\n  bindObject\n) {\n  var scopedSlotFn = this.$scopedSlots[name];\n  var nodes;\n  if (scopedSlotFn) { // scoped slot\n    props = props || {};\n    if (bindObject) {\n      if ( true && !isObject(bindObject)) {\n        warn(\n          'slot v-bind without argument expects an Object',\n          this\n        );\n      }\n      props = extend(extend({}, bindObject), props);\n    }\n    nodes = scopedSlotFn(props) || fallback;\n  } else {\n    nodes = this.$slots[name] || fallback;\n  }\n\n  var target = props && props.slot;\n  if (target) {\n    return this.$createElement('template', { slot: target }, nodes)\n  } else {\n    return nodes\n  }\n}\n\n/*  */\n\n/**\n * Runtime helper for resolving filters\n */\nfunction resolveFilter (id) {\n  return resolveAsset(this.$options, 'filters', id, true) || identity\n}\n\n/*  */\n\nfunction isKeyNotMatch (expect, actual) {\n  if (Array.isArray(expect)) {\n    return expect.indexOf(actual) === -1\n  } else {\n    return expect !== actual\n  }\n}\n\n/**\n * Runtime helper for checking keyCodes from config.\n * exposed as Vue.prototype._k\n * passing in eventKeyName as last argument separately for backwards compat\n */\nfunction checkKeyCodes (\n  eventKeyCode,\n  key,\n  builtInKeyCode,\n  eventKeyName,\n  builtInKeyName\n) {\n  var mappedKeyCode = config.keyCodes[key] || builtInKeyCode;\n  if (builtInKeyName && eventKeyName && !config.keyCodes[key]) {\n    return isKeyNotMatch(builtInKeyName, eventKeyName)\n  } else if (mappedKeyCode) {\n    return isKeyNotMatch(mappedKeyCode, eventKeyCode)\n  } else if (eventKeyName) {\n    return hyphenate(eventKeyName) !== key\n  }\n}\n\n/*  */\n\n/**\n * Runtime helper for merging v-bind=\"object\" into a VNode's data.\n */\nfunction bindObjectProps (\n  data,\n  tag,\n  value,\n  asProp,\n  isSync\n) {\n  if (value) {\n    if (!isObject(value)) {\n       true && warn(\n        'v-bind without argument expects an Object or Array value',\n        this\n      );\n    } else {\n      if (Array.isArray(value)) {\n        value = toObject(value);\n      }\n      var hash;\n      var loop = function ( key ) {\n        if (\n          key === 'class' ||\n          key === 'style' ||\n          isReservedAttribute(key)\n        ) {\n          hash = data;\n        } else {\n          var type = data.attrs && data.attrs.type;\n          hash = asProp || config.mustUseProp(tag, type, key)\n            ? data.domProps || (data.domProps = {})\n            : data.attrs || (data.attrs = {});\n        }\n        var camelizedKey = camelize(key);\n        var hyphenatedKey = hyphenate(key);\n        if (!(camelizedKey in hash) && !(hyphenatedKey in hash)) {\n          hash[key] = value[key];\n\n          if (isSync) {\n            var on = data.on || (data.on = {});\n            on[(\"update:\" + key)] = function ($event) {\n              value[key] = $event;\n            };\n          }\n        }\n      };\n\n      for (var key in value) loop( key );\n    }\n  }\n  return data\n}\n\n/*  */\n\n/**\n * Runtime helper for rendering static trees.\n */\nfunction renderStatic (\n  index,\n  isInFor\n) {\n  var cached = this._staticTrees || (this._staticTrees = []);\n  var tree = cached[index];\n  // if has already-rendered static tree and not inside v-for,\n  // we can reuse the same tree.\n  if (tree && !isInFor) {\n    return tree\n  }\n  // otherwise, render a fresh tree.\n  tree = cached[index] = this.$options.staticRenderFns[index].call(\n    this._renderProxy,\n    null,\n    this // for render fns generated for functional component templates\n  );\n  markStatic(tree, (\"__static__\" + index), false);\n  return tree\n}\n\n/**\n * Runtime helper for v-once.\n * Effectively it means marking the node as static with a unique key.\n */\nfunction markOnce (\n  tree,\n  index,\n  key\n) {\n  markStatic(tree, (\"__once__\" + index + (key ? (\"_\" + key) : \"\")), true);\n  return tree\n}\n\nfunction markStatic (\n  tree,\n  key,\n  isOnce\n) {\n  if (Array.isArray(tree)) {\n    for (var i = 0; i < tree.length; i++) {\n      if (tree[i] && typeof tree[i] !== 'string') {\n        markStaticNode(tree[i], (key + \"_\" + i), isOnce);\n      }\n    }\n  } else {\n    markStaticNode(tree, key, isOnce);\n  }\n}\n\nfunction markStaticNode (node, key, isOnce) {\n  node.isStatic = true;\n  node.key = key;\n  node.isOnce = isOnce;\n}\n\n/*  */\n\nfunction bindObjectListeners (data, value) {\n  if (value) {\n    if (!isPlainObject(value)) {\n       true && warn(\n        'v-on without argument expects an Object value',\n        this\n      );\n    } else {\n      var on = data.on = data.on ? extend({}, data.on) : {};\n      for (var key in value) {\n        var existing = on[key];\n        var ours = value[key];\n        on[key] = existing ? [].concat(existing, ours) : ours;\n      }\n    }\n  }\n  return data\n}\n\n/*  */\n\nfunction resolveScopedSlots (\n  fns, // see flow/vnode\n  res,\n  // the following are added in 2.6\n  hasDynamicKeys,\n  contentHashKey\n) {\n  res = res || { $stable: !hasDynamicKeys };\n  for (var i = 0; i < fns.length; i++) {\n    var slot = fns[i];\n    if (Array.isArray(slot)) {\n      resolveScopedSlots(slot, res, hasDynamicKeys);\n    } else if (slot) {\n      // marker for reverse proxying v-slot without scope on this.$slots\n      if (slot.proxy) {\n        slot.fn.proxy = true;\n      }\n      res[slot.key] = slot.fn;\n    }\n  }\n  if (contentHashKey) {\n    (res).$key = contentHashKey;\n  }\n  return res\n}\n\n/*  */\n\nfunction bindDynamicKeys (baseObj, values) {\n  for (var i = 0; i < values.length; i += 2) {\n    var key = values[i];\n    if (typeof key === 'string' && key) {\n      baseObj[values[i]] = values[i + 1];\n    } else if ( true && key !== '' && key !== null) {\n      // null is a speical value for explicitly removing a binding\n      warn(\n        (\"Invalid value for dynamic directive argument (expected string or null): \" + key),\n        this\n      );\n    }\n  }\n  return baseObj\n}\n\n// helper to dynamically append modifier runtime markers to event names.\n// ensure only append when value is already string, otherwise it will be cast\n// to string and cause the type check to miss.\nfunction prependModifier (value, symbol) {\n  return typeof value === 'string' ? symbol + value : value\n}\n\n/*  */\n\nfunction installRenderHelpers (target) {\n  target._o = markOnce;\n  target._n = toNumber;\n  target._s = toString;\n  target._l = renderList;\n  target._t = renderSlot;\n  target._q = looseEqual;\n  target._i = looseIndexOf;\n  target._m = renderStatic;\n  target._f = resolveFilter;\n  target._k = checkKeyCodes;\n  target._b = bindObjectProps;\n  target._v = createTextVNode;\n  target._e = createEmptyVNode;\n  target._u = resolveScopedSlots;\n  target._g = bindObjectListeners;\n  target._d = bindDynamicKeys;\n  target._p = prependModifier;\n}\n\n/*  */\n\nfunction FunctionalRenderContext (\n  data,\n  props,\n  children,\n  parent,\n  Ctor\n) {\n  var this$1 = this;\n\n  var options = Ctor.options;\n  // ensure the createElement function in functional components\n  // gets a unique context - this is necessary for correct named slot check\n  var contextVm;\n  if (hasOwn(parent, '_uid')) {\n    contextVm = Object.create(parent);\n    // $flow-disable-line\n    contextVm._original = parent;\n  } else {\n    // the context vm passed in is a functional context as well.\n    // in this case we want to make sure we are able to get a hold to the\n    // real context instance.\n    contextVm = parent;\n    // $flow-disable-line\n    parent = parent._original;\n  }\n  var isCompiled = isTrue(options._compiled);\n  var needNormalization = !isCompiled;\n\n  this.data = data;\n  this.props = props;\n  this.children = children;\n  this.parent = parent;\n  this.listeners = data.on || emptyObject;\n  this.injections = resolveInject(options.inject, parent);\n  this.slots = function () {\n    if (!this$1.$slots) {\n      normalizeScopedSlots(\n        data.scopedSlots,\n        this$1.$slots = resolveSlots(children, parent)\n      );\n    }\n    return this$1.$slots\n  };\n\n  Object.defineProperty(this, 'scopedSlots', ({\n    enumerable: true,\n    get: function get () {\n      return normalizeScopedSlots(data.scopedSlots, this.slots())\n    }\n  }));\n\n  // support for compiled functional template\n  if (isCompiled) {\n    // exposing $options for renderStatic()\n    this.$options = options;\n    // pre-resolve slots for renderSlot()\n    this.$slots = this.slots();\n    this.$scopedSlots = normalizeScopedSlots(data.scopedSlots, this.$slots);\n  }\n\n  if (options._scopeId) {\n    this._c = function (a, b, c, d) {\n      var vnode = createElement(contextVm, a, b, c, d, needNormalization);\n      if (vnode && !Array.isArray(vnode)) {\n        vnode.fnScopeId = options._scopeId;\n        vnode.fnContext = parent;\n      }\n      return vnode\n    };\n  } else {\n    this._c = function (a, b, c, d) { return createElement(contextVm, a, b, c, d, needNormalization); };\n  }\n}\n\ninstallRenderHelpers(FunctionalRenderContext.prototype);\n\nfunction createFunctionalComponent (\n  Ctor,\n  propsData,\n  data,\n  contextVm,\n  children\n) {\n  var options = Ctor.options;\n  var props = {};\n  var propOptions = options.props;\n  if (isDef(propOptions)) {\n    for (var key in propOptions) {\n      props[key] = validateProp(key, propOptions, propsData || emptyObject);\n    }\n  } else {\n    if (isDef(data.attrs)) { mergeProps(props, data.attrs); }\n    if (isDef(data.props)) { mergeProps(props, data.props); }\n  }\n\n  var renderContext = new FunctionalRenderContext(\n    data,\n    props,\n    children,\n    contextVm,\n    Ctor\n  );\n\n  var vnode = options.render.call(null, renderContext._c, renderContext);\n\n  if (vnode instanceof VNode) {\n    return cloneAndMarkFunctionalResult(vnode, data, renderContext.parent, options, renderContext)\n  } else if (Array.isArray(vnode)) {\n    var vnodes = normalizeChildren(vnode) || [];\n    var res = new Array(vnodes.length);\n    for (var i = 0; i < vnodes.length; i++) {\n      res[i] = cloneAndMarkFunctionalResult(vnodes[i], data, renderContext.parent, options, renderContext);\n    }\n    return res\n  }\n}\n\nfunction cloneAndMarkFunctionalResult (vnode, data, contextVm, options, renderContext) {\n  // #7817 clone node before setting fnContext, otherwise if the node is reused\n  // (e.g. it was from a cached normal slot) the fnContext causes named slots\n  // that should not be matched to match.\n  var clone = cloneVNode(vnode);\n  clone.fnContext = contextVm;\n  clone.fnOptions = options;\n  if (true) {\n    (clone.devtoolsMeta = clone.devtoolsMeta || {}).renderContext = renderContext;\n  }\n  if (data.slot) {\n    (clone.data || (clone.data = {})).slot = data.slot;\n  }\n  return clone\n}\n\nfunction mergeProps (to, from) {\n  for (var key in from) {\n    to[camelize(key)] = from[key];\n  }\n}\n\n/*  */\n\n/*  */\n\n/*  */\n\n/*  */\n\n// inline hooks to be invoked on component VNodes during patch\nvar componentVNodeHooks = {\n  init: function init (vnode, hydrating) {\n    if (\n      vnode.componentInstance &&\n      !vnode.componentInstance._isDestroyed &&\n      vnode.data.keepAlive\n    ) {\n      // kept-alive components, treat as a patch\n      var mountedNode = vnode; // work around flow\n      componentVNodeHooks.prepatch(mountedNode, mountedNode);\n    } else {\n      var child = vnode.componentInstance = createComponentInstanceForVnode(\n        vnode,\n        activeInstance\n      );\n      child.$mount(hydrating ? vnode.elm : undefined, hydrating);\n    }\n  },\n\n  prepatch: function prepatch (oldVnode, vnode) {\n    var options = vnode.componentOptions;\n    var child = vnode.componentInstance = oldVnode.componentInstance;\n    updateChildComponent(\n      child,\n      options.propsData, // updated props\n      options.listeners, // updated listeners\n      vnode, // new parent vnode\n      options.children // new children\n    );\n  },\n\n  insert: function insert (vnode) {\n    var context = vnode.context;\n    var componentInstance = vnode.componentInstance;\n    if (!componentInstance._isMounted) {\n      componentInstance._isMounted = true;\n      callHook(componentInstance, 'mounted');\n    }\n    if (vnode.data.keepAlive) {\n      if (context._isMounted) {\n        // vue-router#1212\n        // During updates, a kept-alive component's child components may\n        // change, so directly walking the tree here may call activated hooks\n        // on incorrect children. Instead we push them into a queue which will\n        // be processed after the whole patch process ended.\n        queueActivatedComponent(componentInstance);\n      } else {\n        activateChildComponent(componentInstance, true /* direct */);\n      }\n    }\n  },\n\n  destroy: function destroy (vnode) {\n    var componentInstance = vnode.componentInstance;\n    if (!componentInstance._isDestroyed) {\n      if (!vnode.data.keepAlive) {\n        componentInstance.$destroy();\n      } else {\n        deactivateChildComponent(componentInstance, true /* direct */);\n      }\n    }\n  }\n};\n\nvar hooksToMerge = Object.keys(componentVNodeHooks);\n\nfunction createComponent (\n  Ctor,\n  data,\n  context,\n  children,\n  tag\n) {\n  if (isUndef(Ctor)) {\n    return\n  }\n\n  var baseCtor = context.$options._base;\n\n  // plain options object: turn it into a constructor\n  if (isObject(Ctor)) {\n    Ctor = baseCtor.extend(Ctor);\n  }\n\n  // if at this stage it's not a constructor or an async component factory,\n  // reject.\n  if (typeof Ctor !== 'function') {\n    if (true) {\n      warn((\"Invalid Component definition: \" + (String(Ctor))), context);\n    }\n    return\n  }\n\n  // async component\n  var asyncFactory;\n  if (isUndef(Ctor.cid)) {\n    asyncFactory = Ctor;\n    Ctor = resolveAsyncComponent(asyncFactory, baseCtor);\n    if (Ctor === undefined) {\n      // return a placeholder node for async component, which is rendered\n      // as a comment node but preserves all the raw information for the node.\n      // the information will be used for async server-rendering and hydration.\n      return createAsyncPlaceholder(\n        asyncFactory,\n        data,\n        context,\n        children,\n        tag\n      )\n    }\n  }\n\n  data = data || {};\n\n  // resolve constructor options in case global mixins are applied after\n  // component constructor creation\n  resolveConstructorOptions(Ctor);\n\n  // transform component v-model data into props & events\n  if (isDef(data.model)) {\n    transformModel(Ctor.options, data);\n  }\n\n  // extract props\n  var propsData = extractPropsFromVNodeData(data, Ctor, tag);\n\n  // functional component\n  if (isTrue(Ctor.options.functional)) {\n    return createFunctionalComponent(Ctor, propsData, data, context, children)\n  }\n\n  // extract listeners, since these needs to be treated as\n  // child component listeners instead of DOM listeners\n  var listeners = data.on;\n  // replace with listeners with .native modifier\n  // so it gets processed during parent component patch.\n  data.on = data.nativeOn;\n\n  if (isTrue(Ctor.options.abstract)) {\n    // abstract components do not keep anything\n    // other than props & listeners & slot\n\n    // work around flow\n    var slot = data.slot;\n    data = {};\n    if (slot) {\n      data.slot = slot;\n    }\n  }\n\n  // install component management hooks onto the placeholder node\n  installComponentHooks(data);\n\n  // return a placeholder vnode\n  var name = Ctor.options.name || tag;\n  var vnode = new VNode(\n    (\"vue-component-\" + (Ctor.cid) + (name ? (\"-\" + name) : '')),\n    data, undefined, undefined, undefined, context,\n    { Ctor: Ctor, propsData: propsData, listeners: listeners, tag: tag, children: children },\n    asyncFactory\n  );\n\n  return vnode\n}\n\nfunction createComponentInstanceForVnode (\n  vnode, // we know it's MountedComponentVNode but flow doesn't\n  parent // activeInstance in lifecycle state\n) {\n  var options = {\n    _isComponent: true,\n    _parentVnode: vnode,\n    parent: parent\n  };\n  // check inline-template render functions\n  var inlineTemplate = vnode.data.inlineTemplate;\n  if (isDef(inlineTemplate)) {\n    options.render = inlineTemplate.render;\n    options.staticRenderFns = inlineTemplate.staticRenderFns;\n  }\n  return new vnode.componentOptions.Ctor(options)\n}\n\nfunction installComponentHooks (data) {\n  var hooks = data.hook || (data.hook = {});\n  for (var i = 0; i < hooksToMerge.length; i++) {\n    var key = hooksToMerge[i];\n    var existing = hooks[key];\n    var toMerge = componentVNodeHooks[key];\n    if (existing !== toMerge && !(existing && existing._merged)) {\n      hooks[key] = existing ? mergeHook$1(toMerge, existing) : toMerge;\n    }\n  }\n}\n\nfunction mergeHook$1 (f1, f2) {\n  var merged = function (a, b) {\n    // flow complains about extra args which is why we use any\n    f1(a, b);\n    f2(a, b);\n  };\n  merged._merged = true;\n  return merged\n}\n\n// transform component v-model info (value and callback) into\n// prop and event handler respectively.\nfunction transformModel (options, data) {\n  var prop = (options.model && options.model.prop) || 'value';\n  var event = (options.model && options.model.event) || 'input'\n  ;(data.attrs || (data.attrs = {}))[prop] = data.model.value;\n  var on = data.on || (data.on = {});\n  var existing = on[event];\n  var callback = data.model.callback;\n  if (isDef(existing)) {\n    if (\n      Array.isArray(existing)\n        ? existing.indexOf(callback) === -1\n        : existing !== callback\n    ) {\n      on[event] = [callback].concat(existing);\n    }\n  } else {\n    on[event] = callback;\n  }\n}\n\n/*  */\n\nvar SIMPLE_NORMALIZE = 1;\nvar ALWAYS_NORMALIZE = 2;\n\n// wrapper function for providing a more flexible interface\n// without getting yelled at by flow\nfunction createElement (\n  context,\n  tag,\n  data,\n  children,\n  normalizationType,\n  alwaysNormalize\n) {\n  if (Array.isArray(data) || isPrimitive(data)) {\n    normalizationType = children;\n    children = data;\n    data = undefined;\n  }\n  if (isTrue(alwaysNormalize)) {\n    normalizationType = ALWAYS_NORMALIZE;\n  }\n  return _createElement(context, tag, data, children, normalizationType)\n}\n\nfunction _createElement (\n  context,\n  tag,\n  data,\n  children,\n  normalizationType\n) {\n  if (isDef(data) && isDef((data).__ob__)) {\n     true && warn(\n      \"Avoid using observed data object as vnode data: \" + (JSON.stringify(data)) + \"\\n\" +\n      'Always create fresh vnode data objects in each render!',\n      context\n    );\n    return createEmptyVNode()\n  }\n  // object syntax in v-bind\n  if (isDef(data) && isDef(data.is)) {\n    tag = data.is;\n  }\n  if (!tag) {\n    // in case of component :is set to falsy value\n    return createEmptyVNode()\n  }\n  // warn against non-primitive key\n  if ( true &&\n    isDef(data) && isDef(data.key) && !isPrimitive(data.key)\n  ) {\n    {\n      warn(\n        'Avoid using non-primitive value as key, ' +\n        'use string/number value instead.',\n        context\n      );\n    }\n  }\n  // support single function children as default scoped slot\n  if (Array.isArray(children) &&\n    typeof children[0] === 'function'\n  ) {\n    data = data || {};\n    data.scopedSlots = { default: children[0] };\n    children.length = 0;\n  }\n  if (normalizationType === ALWAYS_NORMALIZE) {\n    children = normalizeChildren(children);\n  } else if (normalizationType === SIMPLE_NORMALIZE) {\n    children = simpleNormalizeChildren(children);\n  }\n  var vnode, ns;\n  if (typeof tag === 'string') {\n    var Ctor;\n    ns = (context.$vnode && context.$vnode.ns) || config.getTagNamespace(tag);\n    if (config.isReservedTag(tag)) {\n      // platform built-in elements\n      vnode = new VNode(\n        config.parsePlatformTagName(tag), data, children,\n        undefined, undefined, context\n      );\n    } else if ((!data || !data.pre) && isDef(Ctor = resolveAsset(context.$options, 'components', tag))) {\n      // component\n      vnode = createComponent(Ctor, data, context, children, tag);\n    } else {\n      // unknown or unlisted namespaced elements\n      // check at runtime because it may get assigned a namespace when its\n      // parent normalizes children\n      vnode = new VNode(\n        tag, data, children,\n        undefined, undefined, context\n      );\n    }\n  } else {\n    // direct component options / constructor\n    vnode = createComponent(tag, data, context, children);\n  }\n  if (Array.isArray(vnode)) {\n    return vnode\n  } else if (isDef(vnode)) {\n    if (isDef(ns)) { applyNS(vnode, ns); }\n    if (isDef(data)) { registerDeepBindings(data); }\n    return vnode\n  } else {\n    return createEmptyVNode()\n  }\n}\n\nfunction applyNS (vnode, ns, force) {\n  vnode.ns = ns;\n  if (vnode.tag === 'foreignObject') {\n    // use default namespace inside foreignObject\n    ns = undefined;\n    force = true;\n  }\n  if (isDef(vnode.children)) {\n    for (var i = 0, l = vnode.children.length; i < l; i++) {\n      var child = vnode.children[i];\n      if (isDef(child.tag) && (\n        isUndef(child.ns) || (isTrue(force) && child.tag !== 'svg'))) {\n        applyNS(child, ns, force);\n      }\n    }\n  }\n}\n\n// ref #5318\n// necessary to ensure parent re-render when deep bindings like :style and\n// :class are used on slot nodes\nfunction registerDeepBindings (data) {\n  if (isObject(data.style)) {\n    traverse(data.style);\n  }\n  if (isObject(data.class)) {\n    traverse(data.class);\n  }\n}\n\n/*  */\n\nfunction initRender (vm) {\n  vm._vnode = null; // the root of the child tree\n  vm._staticTrees = null; // v-once cached trees\n  var options = vm.$options;\n  var parentVnode = vm.$vnode = options._parentVnode; // the placeholder node in parent tree\n  var renderContext = parentVnode && parentVnode.context;\n  vm.$slots = resolveSlots(options._renderChildren, renderContext);\n  vm.$scopedSlots = emptyObject;\n  // bind the createElement fn to this instance\n  // so that we get proper render context inside it.\n  // args order: tag, data, children, normalizationType, alwaysNormalize\n  // internal version is used by render functions compiled from templates\n  vm._c = function (a, b, c, d) { return createElement(vm, a, b, c, d, false); };\n  // normalization is always applied for the public version, used in\n  // user-written render functions.\n  vm.$createElement = function (a, b, c, d) { return createElement(vm, a, b, c, d, true); };\n\n  // $attrs & $listeners are exposed for easier HOC creation.\n  // they need to be reactive so that HOCs using them are always updated\n  var parentData = parentVnode && parentVnode.data;\n\n  /* istanbul ignore else */\n  if (true) {\n    defineReactive$$1(vm, '$attrs', parentData && parentData.attrs || emptyObject, function () {\n      !isUpdatingChildComponent && warn(\"$attrs is readonly.\", vm);\n    }, true);\n    defineReactive$$1(vm, '$listeners', options._parentListeners || emptyObject, function () {\n      !isUpdatingChildComponent && warn(\"$listeners is readonly.\", vm);\n    }, true);\n  } else {}\n}\n\nvar currentRenderingInstance = null;\n\nfunction renderMixin (Vue) {\n  // install runtime convenience helpers\n  installRenderHelpers(Vue.prototype);\n\n  Vue.prototype.$nextTick = function (fn) {\n    return nextTick(fn, this)\n  };\n\n  Vue.prototype._render = function () {\n    var vm = this;\n    var ref = vm.$options;\n    var render = ref.render;\n    var _parentVnode = ref._parentVnode;\n\n    if (_parentVnode) {\n      vm.$scopedSlots = normalizeScopedSlots(\n        _parentVnode.data.scopedSlots,\n        vm.$slots,\n        vm.$scopedSlots\n      );\n    }\n\n    // set parent vnode. this allows render functions to have access\n    // to the data on the placeholder node.\n    vm.$vnode = _parentVnode;\n    // render self\n    var vnode;\n    try {\n      // There's no need to maintain a stack becaues all render fns are called\n      // separately from one another. Nested component's render fns are called\n      // when parent component is patched.\n      currentRenderingInstance = vm;\n      vnode = render.call(vm._renderProxy, vm.$createElement);\n    } catch (e) {\n      handleError(e, vm, \"render\");\n      // return error render result,\n      // or previous vnode to prevent render error causing blank component\n      /* istanbul ignore else */\n      if ( true && vm.$options.renderError) {\n        try {\n          vnode = vm.$options.renderError.call(vm._renderProxy, vm.$createElement, e);\n        } catch (e) {\n          handleError(e, vm, \"renderError\");\n          vnode = vm._vnode;\n        }\n      } else {\n        vnode = vm._vnode;\n      }\n    } finally {\n      currentRenderingInstance = null;\n    }\n    // if the returned array contains only a single node, allow it\n    if (Array.isArray(vnode) && vnode.length === 1) {\n      vnode = vnode[0];\n    }\n    // return empty vnode in case the render function errored out\n    if (!(vnode instanceof VNode)) {\n      if ( true && Array.isArray(vnode)) {\n        warn(\n          'Multiple root nodes returned from render function. Render function ' +\n          'should return a single root node.',\n          vm\n        );\n      }\n      vnode = createEmptyVNode();\n    }\n    // set parent\n    vnode.parent = _parentVnode;\n    return vnode\n  };\n}\n\n/*  */\n\nfunction ensureCtor (comp, base) {\n  if (\n    comp.__esModule ||\n    (hasSymbol && comp[Symbol.toStringTag] === 'Module')\n  ) {\n    comp = comp.default;\n  }\n  return isObject(comp)\n    ? base.extend(comp)\n    : comp\n}\n\nfunction createAsyncPlaceholder (\n  factory,\n  data,\n  context,\n  children,\n  tag\n) {\n  var node = createEmptyVNode();\n  node.asyncFactory = factory;\n  node.asyncMeta = { data: data, context: context, children: children, tag: tag };\n  return node\n}\n\nfunction resolveAsyncComponent (\n  factory,\n  baseCtor\n) {\n  if (isTrue(factory.error) && isDef(factory.errorComp)) {\n    return factory.errorComp\n  }\n\n  if (isDef(factory.resolved)) {\n    return factory.resolved\n  }\n\n  var owner = currentRenderingInstance;\n  if (owner && isDef(factory.owners) && factory.owners.indexOf(owner) === -1) {\n    // already pending\n    factory.owners.push(owner);\n  }\n\n  if (isTrue(factory.loading) && isDef(factory.loadingComp)) {\n    return factory.loadingComp\n  }\n\n  if (owner && !isDef(factory.owners)) {\n    var owners = factory.owners = [owner];\n    var sync = true;\n    var timerLoading = null;\n    var timerTimeout = null\n\n    ;(owner).$on('hook:destroyed', function () { return remove(owners, owner); });\n\n    var forceRender = function (renderCompleted) {\n      for (var i = 0, l = owners.length; i < l; i++) {\n        (owners[i]).$forceUpdate();\n      }\n\n      if (renderCompleted) {\n        owners.length = 0;\n        if (timerLoading !== null) {\n          clearTimeout(timerLoading);\n          timerLoading = null;\n        }\n        if (timerTimeout !== null) {\n          clearTimeout(timerTimeout);\n          timerTimeout = null;\n        }\n      }\n    };\n\n    var resolve = once(function (res) {\n      // cache resolved\n      factory.resolved = ensureCtor(res, baseCtor);\n      // invoke callbacks only if this is not a synchronous resolve\n      // (async resolves are shimmed as synchronous during SSR)\n      if (!sync) {\n        forceRender(true);\n      } else {\n        owners.length = 0;\n      }\n    });\n\n    var reject = once(function (reason) {\n       true && warn(\n        \"Failed to resolve async component: \" + (String(factory)) +\n        (reason ? (\"\\nReason: \" + reason) : '')\n      );\n      if (isDef(factory.errorComp)) {\n        factory.error = true;\n        forceRender(true);\n      }\n    });\n\n    var res = factory(resolve, reject);\n\n    if (isObject(res)) {\n      if (isPromise(res)) {\n        // () => Promise\n        if (isUndef(factory.resolved)) {\n          res.then(resolve, reject);\n        }\n      } else if (isPromise(res.component)) {\n        res.component.then(resolve, reject);\n\n        if (isDef(res.error)) {\n          factory.errorComp = ensureCtor(res.error, baseCtor);\n        }\n\n        if (isDef(res.loading)) {\n          factory.loadingComp = ensureCtor(res.loading, baseCtor);\n          if (res.delay === 0) {\n            factory.loading = true;\n          } else {\n            timerLoading = setTimeout(function () {\n              timerLoading = null;\n              if (isUndef(factory.resolved) && isUndef(factory.error)) {\n                factory.loading = true;\n                forceRender(false);\n              }\n            }, res.delay || 200);\n          }\n        }\n\n        if (isDef(res.timeout)) {\n          timerTimeout = setTimeout(function () {\n            timerTimeout = null;\n            if (isUndef(factory.resolved)) {\n              reject(\n                 true\n                  ? (\"timeout (\" + (res.timeout) + \"ms)\")\n                  : undefined\n              );\n            }\n          }, res.timeout);\n        }\n      }\n    }\n\n    sync = false;\n    // return in case resolved synchronously\n    return factory.loading\n      ? factory.loadingComp\n      : factory.resolved\n  }\n}\n\n/*  */\n\nfunction isAsyncPlaceholder (node) {\n  return node.isComment && node.asyncFactory\n}\n\n/*  */\n\nfunction getFirstComponentChild (children) {\n  if (Array.isArray(children)) {\n    for (var i = 0; i < children.length; i++) {\n      var c = children[i];\n      if (isDef(c) && (isDef(c.componentOptions) || isAsyncPlaceholder(c))) {\n        return c\n      }\n    }\n  }\n}\n\n/*  */\n\n/*  */\n\nfunction initEvents (vm) {\n  vm._events = Object.create(null);\n  vm._hasHookEvent = false;\n  // init parent attached events\n  var listeners = vm.$options._parentListeners;\n  if (listeners) {\n    updateComponentListeners(vm, listeners);\n  }\n}\n\nvar target;\n\nfunction add (event, fn) {\n  target.$on(event, fn);\n}\n\nfunction remove$1 (event, fn) {\n  target.$off(event, fn);\n}\n\nfunction createOnceHandler (event, fn) {\n  var _target = target;\n  return function onceHandler () {\n    var res = fn.apply(null, arguments);\n    if (res !== null) {\n      _target.$off(event, onceHandler);\n    }\n  }\n}\n\nfunction updateComponentListeners (\n  vm,\n  listeners,\n  oldListeners\n) {\n  target = vm;\n  updateListeners(listeners, oldListeners || {}, add, remove$1, createOnceHandler, vm);\n  target = undefined;\n}\n\nfunction eventsMixin (Vue) {\n  var hookRE = /^hook:/;\n  Vue.prototype.$on = function (event, fn) {\n    var vm = this;\n    if (Array.isArray(event)) {\n      for (var i = 0, l = event.length; i < l; i++) {\n        vm.$on(event[i], fn);\n      }\n    } else {\n      (vm._events[event] || (vm._events[event] = [])).push(fn);\n      // optimize hook:event cost by using a boolean flag marked at registration\n      // instead of a hash lookup\n      if (hookRE.test(event)) {\n        vm._hasHookEvent = true;\n      }\n    }\n    return vm\n  };\n\n  Vue.prototype.$once = function (event, fn) {\n    var vm = this;\n    function on () {\n      vm.$off(event, on);\n      fn.apply(vm, arguments);\n    }\n    on.fn = fn;\n    vm.$on(event, on);\n    return vm\n  };\n\n  Vue.prototype.$off = function (event, fn) {\n    var vm = this;\n    // all\n    if (!arguments.length) {\n      vm._events = Object.create(null);\n      return vm\n    }\n    // array of events\n    if (Array.isArray(event)) {\n      for (var i$1 = 0, l = event.length; i$1 < l; i$1++) {\n        vm.$off(event[i$1], fn);\n      }\n      return vm\n    }\n    // specific event\n    var cbs = vm._events[event];\n    if (!cbs) {\n      return vm\n    }\n    if (!fn) {\n      vm._events[event] = null;\n      return vm\n    }\n    // specific handler\n    var cb;\n    var i = cbs.length;\n    while (i--) {\n      cb = cbs[i];\n      if (cb === fn || cb.fn === fn) {\n        cbs.splice(i, 1);\n        break\n      }\n    }\n    return vm\n  };\n\n  Vue.prototype.$emit = function (event) {\n    var vm = this;\n    if (true) {\n      var lowerCaseEvent = event.toLowerCase();\n      if (lowerCaseEvent !== event && vm._events[lowerCaseEvent]) {\n        tip(\n          \"Event \\\"\" + lowerCaseEvent + \"\\\" is emitted in component \" +\n          (formatComponentName(vm)) + \" but the handler is registered for \\\"\" + event + \"\\\". \" +\n          \"Note that HTML attributes are case-insensitive and you cannot use \" +\n          \"v-on to listen to camelCase events when using in-DOM templates. \" +\n          \"You should probably use \\\"\" + (hyphenate(event)) + \"\\\" instead of \\\"\" + event + \"\\\".\"\n        );\n      }\n    }\n    var cbs = vm._events[event];\n    if (cbs) {\n      cbs = cbs.length > 1 ? toArray(cbs) : cbs;\n      var args = toArray(arguments, 1);\n      var info = \"event handler for \\\"\" + event + \"\\\"\";\n      for (var i = 0, l = cbs.length; i < l; i++) {\n        invokeWithErrorHandling(cbs[i], vm, args, vm, info);\n      }\n    }\n    return vm\n  };\n}\n\n/*  */\n\nvar activeInstance = null;\nvar isUpdatingChildComponent = false;\n\nfunction setActiveInstance(vm) {\n  var prevActiveInstance = activeInstance;\n  activeInstance = vm;\n  return function () {\n    activeInstance = prevActiveInstance;\n  }\n}\n\nfunction initLifecycle (vm) {\n  var options = vm.$options;\n\n  // locate first non-abstract parent\n  var parent = options.parent;\n  if (parent && !options.abstract) {\n    while (parent.$options.abstract && parent.$parent) {\n      parent = parent.$parent;\n    }\n    parent.$children.push(vm);\n  }\n\n  vm.$parent = parent;\n  vm.$root = parent ? parent.$root : vm;\n\n  vm.$children = [];\n  vm.$refs = {};\n\n  vm._watcher = null;\n  vm._inactive = null;\n  vm._directInactive = false;\n  vm._isMounted = false;\n  vm._isDestroyed = false;\n  vm._isBeingDestroyed = false;\n}\n\nfunction lifecycleMixin (Vue) {\n  Vue.prototype._update = function (vnode, hydrating) {\n    var vm = this;\n    var prevEl = vm.$el;\n    var prevVnode = vm._vnode;\n    var restoreActiveInstance = setActiveInstance(vm);\n    vm._vnode = vnode;\n    // Vue.prototype.__patch__ is injected in entry points\n    // based on the rendering backend used.\n    if (!prevVnode) {\n      // initial render\n      vm.$el = vm.__patch__(vm.$el, vnode, hydrating, false /* removeOnly */);\n    } else {\n      // updates\n      vm.$el = vm.__patch__(prevVnode, vnode);\n    }\n    restoreActiveInstance();\n    // update __vue__ reference\n    if (prevEl) {\n      prevEl.__vue__ = null;\n    }\n    if (vm.$el) {\n      vm.$el.__vue__ = vm;\n    }\n    // if parent is an HOC, update its $el as well\n    if (vm.$vnode && vm.$parent && vm.$vnode === vm.$parent._vnode) {\n      vm.$parent.$el = vm.$el;\n    }\n    // updated hook is called by the scheduler to ensure that children are\n    // updated in a parent's updated hook.\n  };\n\n  Vue.prototype.$forceUpdate = function () {\n    var vm = this;\n    if (vm._watcher) {\n      vm._watcher.update();\n    }\n  };\n\n  Vue.prototype.$destroy = function () {\n    var vm = this;\n    if (vm._isBeingDestroyed) {\n      return\n    }\n    callHook(vm, 'beforeDestroy');\n    vm._isBeingDestroyed = true;\n    // remove self from parent\n    var parent = vm.$parent;\n    if (parent && !parent._isBeingDestroyed && !vm.$options.abstract) {\n      remove(parent.$children, vm);\n    }\n    // teardown watchers\n    if (vm._watcher) {\n      vm._watcher.teardown();\n    }\n    var i = vm._watchers.length;\n    while (i--) {\n      vm._watchers[i].teardown();\n    }\n    // remove reference from data ob\n    // frozen object may not have observer.\n    if (vm._data.__ob__) {\n      vm._data.__ob__.vmCount--;\n    }\n    // call the last hook...\n    vm._isDestroyed = true;\n    // invoke destroy hooks on current rendered tree\n    vm.__patch__(vm._vnode, null);\n    // fire destroyed hook\n    callHook(vm, 'destroyed');\n    // turn off all instance listeners.\n    vm.$off();\n    // remove __vue__ reference\n    if (vm.$el) {\n      vm.$el.__vue__ = null;\n    }\n    // release circular reference (#6759)\n    if (vm.$vnode) {\n      vm.$vnode.parent = null;\n    }\n  };\n}\n\nfunction mountComponent (\n  vm,\n  el,\n  hydrating\n) {\n  vm.$el = el;\n  if (!vm.$options.render) {\n    vm.$options.render = createEmptyVNode;\n    if (true) {\n      /* istanbul ignore if */\n      if ((vm.$options.template && vm.$options.template.charAt(0) !== '#') ||\n        vm.$options.el || el) {\n        warn(\n          'You are using the runtime-only build of Vue where the template ' +\n          'compiler is not available. Either pre-compile the templates into ' +\n          'render functions, or use the compiler-included build.',\n          vm\n        );\n      } else {\n        warn(\n          'Failed to mount component: template or render function not defined.',\n          vm\n        );\n      }\n    }\n  }\n  callHook(vm, 'beforeMount');\n\n  var updateComponent;\n  /* istanbul ignore if */\n  if ( true && config.performance && mark) {\n    updateComponent = function () {\n      var name = vm._name;\n      var id = vm._uid;\n      var startTag = \"vue-perf-start:\" + id;\n      var endTag = \"vue-perf-end:\" + id;\n\n      mark(startTag);\n      var vnode = vm._render();\n      mark(endTag);\n      measure((\"vue \" + name + \" render\"), startTag, endTag);\n\n      mark(startTag);\n      vm._update(vnode, hydrating);\n      mark(endTag);\n      measure((\"vue \" + name + \" patch\"), startTag, endTag);\n    };\n  } else {\n    updateComponent = function () {\n      vm._update(vm._render(), hydrating);\n    };\n  }\n\n  // we set this to vm._watcher inside the watcher's constructor\n  // since the watcher's initial patch may call $forceUpdate (e.g. inside child\n  // component's mounted hook), which relies on vm._watcher being already defined\n  new Watcher(vm, updateComponent, noop, {\n    before: function before () {\n      if (vm._isMounted && !vm._isDestroyed) {\n        callHook(vm, 'beforeUpdate');\n      }\n    }\n  }, true /* isRenderWatcher */);\n  hydrating = false;\n\n  // manually mounted instance, call mounted on self\n  // mounted is called for render-created child components in its inserted hook\n  if (vm.$vnode == null) {\n    vm._isMounted = true;\n    callHook(vm, 'mounted');\n  }\n  return vm\n}\n\nfunction updateChildComponent (\n  vm,\n  propsData,\n  listeners,\n  parentVnode,\n  renderChildren\n) {\n  if (true) {\n    isUpdatingChildComponent = true;\n  }\n\n  // determine whether component has slot children\n  // we need to do this before overwriting $options._renderChildren.\n\n  // check if there are dynamic scopedSlots (hand-written or compiled but with\n  // dynamic slot names). Static scoped slots compiled from template has the\n  // \"$stable\" marker.\n  var newScopedSlots = parentVnode.data.scopedSlots;\n  var oldScopedSlots = vm.$scopedSlots;\n  var hasDynamicScopedSlot = !!(\n    (newScopedSlots && !newScopedSlots.$stable) ||\n    (oldScopedSlots !== emptyObject && !oldScopedSlots.$stable) ||\n    (newScopedSlots && vm.$scopedSlots.$key !== newScopedSlots.$key)\n  );\n\n  // Any static slot children from the parent may have changed during parent's\n  // update. Dynamic scoped slots may also have changed. In such cases, a forced\n  // update is necessary to ensure correctness.\n  var needsForceUpdate = !!(\n    renderChildren ||               // has new static slots\n    vm.$options._renderChildren ||  // has old static slots\n    hasDynamicScopedSlot\n  );\n\n  vm.$options._parentVnode = parentVnode;\n  vm.$vnode = parentVnode; // update vm's placeholder node without re-render\n\n  if (vm._vnode) { // update child tree's parent\n    vm._vnode.parent = parentVnode;\n  }\n  vm.$options._renderChildren = renderChildren;\n\n  // update $attrs and $listeners hash\n  // these are also reactive so they may trigger child update if the child\n  // used them during render\n  vm.$attrs = parentVnode.data.attrs || emptyObject;\n  vm.$listeners = listeners || emptyObject;\n\n  // update props\n  if (propsData && vm.$options.props) {\n    toggleObserving(false);\n    var props = vm._props;\n    var propKeys = vm.$options._propKeys || [];\n    for (var i = 0; i < propKeys.length; i++) {\n      var key = propKeys[i];\n      var propOptions = vm.$options.props; // wtf flow?\n      props[key] = validateProp(key, propOptions, propsData, vm);\n    }\n    toggleObserving(true);\n    // keep a copy of raw propsData\n    vm.$options.propsData = propsData;\n  }\n\n  // update listeners\n  listeners = listeners || emptyObject;\n  var oldListeners = vm.$options._parentListeners;\n  vm.$options._parentListeners = listeners;\n  updateComponentListeners(vm, listeners, oldListeners);\n\n  // resolve slots + force update if has children\n  if (needsForceUpdate) {\n    vm.$slots = resolveSlots(renderChildren, parentVnode.context);\n    vm.$forceUpdate();\n  }\n\n  if (true) {\n    isUpdatingChildComponent = false;\n  }\n}\n\nfunction isInInactiveTree (vm) {\n  while (vm && (vm = vm.$parent)) {\n    if (vm._inactive) { return true }\n  }\n  return false\n}\n\nfunction activateChildComponent (vm, direct) {\n  if (direct) {\n    vm._directInactive = false;\n    if (isInInactiveTree(vm)) {\n      return\n    }\n  } else if (vm._directInactive) {\n    return\n  }\n  if (vm._inactive || vm._inactive === null) {\n    vm._inactive = false;\n    for (var i = 0; i < vm.$children.length; i++) {\n      activateChildComponent(vm.$children[i]);\n    }\n    callHook(vm, 'activated');\n  }\n}\n\nfunction deactivateChildComponent (vm, direct) {\n  if (direct) {\n    vm._directInactive = true;\n    if (isInInactiveTree(vm)) {\n      return\n    }\n  }\n  if (!vm._inactive) {\n    vm._inactive = true;\n    for (var i = 0; i < vm.$children.length; i++) {\n      deactivateChildComponent(vm.$children[i]);\n    }\n    callHook(vm, 'deactivated');\n  }\n}\n\nfunction callHook (vm, hook) {\n  // #7573 disable dep collection when invoking lifecycle hooks\n  pushTarget();\n  var handlers = vm.$options[hook];\n  var info = hook + \" hook\";\n  if (handlers) {\n    for (var i = 0, j = handlers.length; i < j; i++) {\n      invokeWithErrorHandling(handlers[i], vm, null, vm, info);\n    }\n  }\n  if (vm._hasHookEvent) {\n    vm.$emit('hook:' + hook);\n  }\n  popTarget();\n}\n\n/*  */\n\nvar MAX_UPDATE_COUNT = 100;\n\nvar queue = [];\nvar activatedChildren = [];\nvar has = {};\nvar circular = {};\nvar waiting = false;\nvar flushing = false;\nvar index = 0;\n\n/**\n * Reset the scheduler's state.\n */\nfunction resetSchedulerState () {\n  index = queue.length = activatedChildren.length = 0;\n  has = {};\n  if (true) {\n    circular = {};\n  }\n  waiting = flushing = false;\n}\n\n// Async edge case #6566 requires saving the timestamp when event listeners are\n// attached. However, calling performance.now() has a perf overhead especially\n// if the page has thousands of event listeners. Instead, we take a timestamp\n// every time the scheduler flushes and use that for all event listeners\n// attached during that flush.\nvar currentFlushTimestamp = 0;\n\n// Async edge case fix requires storing an event listener's attach timestamp.\nvar getNow = Date.now;\n\n// Determine what event timestamp the browser is using. Annoyingly, the\n// timestamp can either be hi-res (relative to page load) or low-res\n// (relative to UNIX epoch), so in order to compare time we have to use the\n// same timestamp type when saving the flush timestamp.\n// All IE versions use low-res event timestamps, and have problematic clock\n// implementations (#9632)\nif (inBrowser && !isIE) {\n  var performance = window.performance;\n  if (\n    performance &&\n    typeof performance.now === 'function' &&\n    getNow() > document.createEvent('Event').timeStamp\n  ) {\n    // if the event timestamp, although evaluated AFTER the Date.now(), is\n    // smaller than it, it means the event is using a hi-res timestamp,\n    // and we need to use the hi-res version for event listener timestamps as\n    // well.\n    getNow = function () { return performance.now(); };\n  }\n}\n\n/**\n * Flush both queues and run the watchers.\n */\nfunction flushSchedulerQueue () {\n  currentFlushTimestamp = getNow();\n  flushing = true;\n  var watcher, id;\n\n  // Sort queue before flush.\n  // This ensures that:\n  // 1. Components are updated from parent to child. (because parent is always\n  //    created before the child)\n  // 2. A component's user watchers are run before its render watcher (because\n  //    user watchers are created before the render watcher)\n  // 3. If a component is destroyed during a parent component's watcher run,\n  //    its watchers can be skipped.\n  queue.sort(function (a, b) { return a.id - b.id; });\n\n  // do not cache length because more watchers might be pushed\n  // as we run existing watchers\n  for (index = 0; index < queue.length; index++) {\n    watcher = queue[index];\n    if (watcher.before) {\n      watcher.before();\n    }\n    id = watcher.id;\n    has[id] = null;\n    watcher.run();\n    // in dev build, check and stop circular updates.\n    if ( true && has[id] != null) {\n      circular[id] = (circular[id] || 0) + 1;\n      if (circular[id] > MAX_UPDATE_COUNT) {\n        warn(\n          'You may have an infinite update loop ' + (\n            watcher.user\n              ? (\"in watcher with expression \\\"\" + (watcher.expression) + \"\\\"\")\n              : \"in a component render function.\"\n          ),\n          watcher.vm\n        );\n        break\n      }\n    }\n  }\n\n  // keep copies of post queues before resetting state\n  var activatedQueue = activatedChildren.slice();\n  var updatedQueue = queue.slice();\n\n  resetSchedulerState();\n\n  // call component updated and activated hooks\n  callActivatedHooks(activatedQueue);\n  callUpdatedHooks(updatedQueue);\n\n  // devtool hook\n  /* istanbul ignore if */\n  if (devtools && config.devtools) {\n    devtools.emit('flush');\n  }\n}\n\nfunction callUpdatedHooks (queue) {\n  var i = queue.length;\n  while (i--) {\n    var watcher = queue[i];\n    var vm = watcher.vm;\n    if (vm._watcher === watcher && vm._isMounted && !vm._isDestroyed) {\n      callHook(vm, 'updated');\n    }\n  }\n}\n\n/**\n * Queue a kept-alive component that was activated during patch.\n * The queue will be processed after the entire tree has been patched.\n */\nfunction queueActivatedComponent (vm) {\n  // setting _inactive to false here so that a render function can\n  // rely on checking whether it's in an inactive tree (e.g. router-view)\n  vm._inactive = false;\n  activatedChildren.push(vm);\n}\n\nfunction callActivatedHooks (queue) {\n  for (var i = 0; i < queue.length; i++) {\n    queue[i]._inactive = true;\n    activateChildComponent(queue[i], true /* true */);\n  }\n}\n\n/**\n * Push a watcher into the watcher queue.\n * Jobs with duplicate IDs will be skipped unless it's\n * pushed when the queue is being flushed.\n */\nfunction queueWatcher (watcher) {\n  var id = watcher.id;\n  if (has[id] == null) {\n    has[id] = true;\n    if (!flushing) {\n      queue.push(watcher);\n    } else {\n      // if already flushing, splice the watcher based on its id\n      // if already past its id, it will be run next immediately.\n      var i = queue.length - 1;\n      while (i > index && queue[i].id > watcher.id) {\n        i--;\n      }\n      queue.splice(i + 1, 0, watcher);\n    }\n    // queue the flush\n    if (!waiting) {\n      waiting = true;\n\n      if ( true && !config.async) {\n        flushSchedulerQueue();\n        return\n      }\n      nextTick(flushSchedulerQueue);\n    }\n  }\n}\n\n/*  */\n\n\n\nvar uid$2 = 0;\n\n/**\n * A watcher parses an expression, collects dependencies,\n * and fires callback when the expression value changes.\n * This is used for both the $watch() api and directives.\n */\nvar Watcher = function Watcher (\n  vm,\n  expOrFn,\n  cb,\n  options,\n  isRenderWatcher\n) {\n  this.vm = vm;\n  if (isRenderWatcher) {\n    vm._watcher = this;\n  }\n  vm._watchers.push(this);\n  // options\n  if (options) {\n    this.deep = !!options.deep;\n    this.user = !!options.user;\n    this.lazy = !!options.lazy;\n    this.sync = !!options.sync;\n    this.before = options.before;\n  } else {\n    this.deep = this.user = this.lazy = this.sync = false;\n  }\n  this.cb = cb;\n  this.id = ++uid$2; // uid for batching\n  this.active = true;\n  this.dirty = this.lazy; // for lazy watchers\n  this.deps = [];\n  this.newDeps = [];\n  this.depIds = new _Set();\n  this.newDepIds = new _Set();\n  this.expression =  true\n    ? expOrFn.toString()\n    : undefined;\n  // parse expression for getter\n  if (typeof expOrFn === 'function') {\n    this.getter = expOrFn;\n  } else {\n    this.getter = parsePath(expOrFn);\n    if (!this.getter) {\n      this.getter = noop;\n       true && warn(\n        \"Failed watching path: \\\"\" + expOrFn + \"\\\" \" +\n        'Watcher only accepts simple dot-delimited paths. ' +\n        'For full control, use a function instead.',\n        vm\n      );\n    }\n  }\n  this.value = this.lazy\n    ? undefined\n    : this.get();\n};\n\n/**\n * Evaluate the getter, and re-collect dependencies.\n */\nWatcher.prototype.get = function get () {\n  pushTarget(this);\n  var value;\n  var vm = this.vm;\n  try {\n    value = this.getter.call(vm, vm);\n  } catch (e) {\n    if (this.user) {\n      handleError(e, vm, (\"getter for watcher \\\"\" + (this.expression) + \"\\\"\"));\n    } else {\n      throw e\n    }\n  } finally {\n    // \"touch\" every property so they are all tracked as\n    // dependencies for deep watching\n    if (this.deep) {\n      traverse(value);\n    }\n    popTarget();\n    this.cleanupDeps();\n  }\n  return value\n};\n\n/**\n * Add a dependency to this directive.\n */\nWatcher.prototype.addDep = function addDep (dep) {\n  var id = dep.id;\n  if (!this.newDepIds.has(id)) {\n    this.newDepIds.add(id);\n    this.newDeps.push(dep);\n    if (!this.depIds.has(id)) {\n      dep.addSub(this);\n    }\n  }\n};\n\n/**\n * Clean up for dependency collection.\n */\nWatcher.prototype.cleanupDeps = function cleanupDeps () {\n  var i = this.deps.length;\n  while (i--) {\n    var dep = this.deps[i];\n    if (!this.newDepIds.has(dep.id)) {\n      dep.removeSub(this);\n    }\n  }\n  var tmp = this.depIds;\n  this.depIds = this.newDepIds;\n  this.newDepIds = tmp;\n  this.newDepIds.clear();\n  tmp = this.deps;\n  this.deps = this.newDeps;\n  this.newDeps = tmp;\n  this.newDeps.length = 0;\n};\n\n/**\n * Subscriber interface.\n * Will be called when a dependency changes.\n */\nWatcher.prototype.update = function update () {\n  /* istanbul ignore else */\n  if (this.lazy) {\n    this.dirty = true;\n  } else if (this.sync) {\n    this.run();\n  } else {\n    queueWatcher(this);\n  }\n};\n\n/**\n * Scheduler job interface.\n * Will be called by the scheduler.\n */\nWatcher.prototype.run = function run () {\n  if (this.active) {\n    var value = this.get();\n    if (\n      value !== this.value ||\n      // Deep watchers and watchers on Object/Arrays should fire even\n      // when the value is the same, because the value may\n      // have mutated.\n      isObject(value) ||\n      this.deep\n    ) {\n      // set new value\n      var oldValue = this.value;\n      this.value = value;\n      if (this.user) {\n        try {\n          this.cb.call(this.vm, value, oldValue);\n        } catch (e) {\n          handleError(e, this.vm, (\"callback for watcher \\\"\" + (this.expression) + \"\\\"\"));\n        }\n      } else {\n        this.cb.call(this.vm, value, oldValue);\n      }\n    }\n  }\n};\n\n/**\n * Evaluate the value of the watcher.\n * This only gets called for lazy watchers.\n */\nWatcher.prototype.evaluate = function evaluate () {\n  this.value = this.get();\n  this.dirty = false;\n};\n\n/**\n * Depend on all deps collected by this watcher.\n */\nWatcher.prototype.depend = function depend () {\n  var i = this.deps.length;\n  while (i--) {\n    this.deps[i].depend();\n  }\n};\n\n/**\n * Remove self from all dependencies' subscriber list.\n */\nWatcher.prototype.teardown = function teardown () {\n  if (this.active) {\n    // remove self from vm's watcher list\n    // this is a somewhat expensive operation so we skip it\n    // if the vm is being destroyed.\n    if (!this.vm._isBeingDestroyed) {\n      remove(this.vm._watchers, this);\n    }\n    var i = this.deps.length;\n    while (i--) {\n      this.deps[i].removeSub(this);\n    }\n    this.active = false;\n  }\n};\n\n/*  */\n\nvar sharedPropertyDefinition = {\n  enumerable: true,\n  configurable: true,\n  get: noop,\n  set: noop\n};\n\nfunction proxy (target, sourceKey, key) {\n  sharedPropertyDefinition.get = function proxyGetter () {\n    return this[sourceKey][key]\n  };\n  sharedPropertyDefinition.set = function proxySetter (val) {\n    this[sourceKey][key] = val;\n  };\n  Object.defineProperty(target, key, sharedPropertyDefinition);\n}\n\nfunction initState (vm) {\n  vm._watchers = [];\n  var opts = vm.$options;\n  if (opts.props) { initProps(vm, opts.props); }\n  if (opts.methods) { initMethods(vm, opts.methods); }\n  if (opts.data) {\n    initData(vm);\n  } else {\n    observe(vm._data = {}, true /* asRootData */);\n  }\n  if (opts.computed) { initComputed(vm, opts.computed); }\n  if (opts.watch && opts.watch !== nativeWatch) {\n    initWatch(vm, opts.watch);\n  }\n}\n\nfunction initProps (vm, propsOptions) {\n  var propsData = vm.$options.propsData || {};\n  var props = vm._props = {};\n  // cache prop keys so that future props updates can iterate using Array\n  // instead of dynamic object key enumeration.\n  var keys = vm.$options._propKeys = [];\n  var isRoot = !vm.$parent;\n  // root instance props should be converted\n  if (!isRoot) {\n    toggleObserving(false);\n  }\n  var loop = function ( key ) {\n    keys.push(key);\n    var value = validateProp(key, propsOptions, propsData, vm);\n    /* istanbul ignore else */\n    if (true) {\n      var hyphenatedKey = hyphenate(key);\n      if (isReservedAttribute(hyphenatedKey) ||\n          config.isReservedAttr(hyphenatedKey)) {\n        warn(\n          (\"\\\"\" + hyphenatedKey + \"\\\" is a reserved attribute and cannot be used as component prop.\"),\n          vm\n        );\n      }\n      defineReactive$$1(props, key, value, function () {\n        if (!isRoot && !isUpdatingChildComponent) {\n          warn(\n            \"Avoid mutating a prop directly since the value will be \" +\n            \"overwritten whenever the parent component re-renders. \" +\n            \"Instead, use a data or computed property based on the prop's \" +\n            \"value. Prop being mutated: \\\"\" + key + \"\\\"\",\n            vm\n          );\n        }\n      });\n    } else {}\n    // static props are already proxied on the component's prototype\n    // during Vue.extend(). We only need to proxy props defined at\n    // instantiation here.\n    if (!(key in vm)) {\n      proxy(vm, \"_props\", key);\n    }\n  };\n\n  for (var key in propsOptions) loop( key );\n  toggleObserving(true);\n}\n\nfunction initData (vm) {\n  var data = vm.$options.data;\n  data = vm._data = typeof data === 'function'\n    ? getData(data, vm)\n    : data || {};\n  if (!isPlainObject(data)) {\n    data = {};\n     true && warn(\n      'data functions should return an object:\\n' +\n      'https://vuejs.org/v2/guide/components.html#data-Must-Be-a-Function',\n      vm\n    );\n  }\n  // proxy data on instance\n  var keys = Object.keys(data);\n  var props = vm.$options.props;\n  var methods = vm.$options.methods;\n  var i = keys.length;\n  while (i--) {\n    var key = keys[i];\n    if (true) {\n      if (methods && hasOwn(methods, key)) {\n        warn(\n          (\"Method \\\"\" + key + \"\\\" has already been defined as a data property.\"),\n          vm\n        );\n      }\n    }\n    if (props && hasOwn(props, key)) {\n       true && warn(\n        \"The data property \\\"\" + key + \"\\\" is already declared as a prop. \" +\n        \"Use prop default value instead.\",\n        vm\n      );\n    } else if (!isReserved(key)) {\n      proxy(vm, \"_data\", key);\n    }\n  }\n  // observe data\n  observe(data, true /* asRootData */);\n}\n\nfunction getData (data, vm) {\n  // #7573 disable dep collection when invoking data getters\n  pushTarget();\n  try {\n    return data.call(vm, vm)\n  } catch (e) {\n    handleError(e, vm, \"data()\");\n    return {}\n  } finally {\n    popTarget();\n  }\n}\n\nvar computedWatcherOptions = { lazy: true };\n\nfunction initComputed (vm, computed) {\n  // $flow-disable-line\n  var watchers = vm._computedWatchers = Object.create(null);\n  // computed properties are just getters during SSR\n  var isSSR = isServerRendering();\n\n  for (var key in computed) {\n    var userDef = computed[key];\n    var getter = typeof userDef === 'function' ? userDef : userDef.get;\n    if ( true && getter == null) {\n      warn(\n        (\"Getter is missing for computed property \\\"\" + key + \"\\\".\"),\n        vm\n      );\n    }\n\n    if (!isSSR) {\n      // create internal watcher for the computed property.\n      watchers[key] = new Watcher(\n        vm,\n        getter || noop,\n        noop,\n        computedWatcherOptions\n      );\n    }\n\n    // component-defined computed properties are already defined on the\n    // component prototype. We only need to define computed properties defined\n    // at instantiation here.\n    if (!(key in vm)) {\n      defineComputed(vm, key, userDef);\n    } else if (true) {\n      if (key in vm.$data) {\n        warn((\"The computed property \\\"\" + key + \"\\\" is already defined in data.\"), vm);\n      } else if (vm.$options.props && key in vm.$options.props) {\n        warn((\"The computed property \\\"\" + key + \"\\\" is already defined as a prop.\"), vm);\n      }\n    }\n  }\n}\n\nfunction defineComputed (\n  target,\n  key,\n  userDef\n) {\n  var shouldCache = !isServerRendering();\n  if (typeof userDef === 'function') {\n    sharedPropertyDefinition.get = shouldCache\n      ? createComputedGetter(key)\n      : createGetterInvoker(userDef);\n    sharedPropertyDefinition.set = noop;\n  } else {\n    sharedPropertyDefinition.get = userDef.get\n      ? shouldCache && userDef.cache !== false\n        ? createComputedGetter(key)\n        : createGetterInvoker(userDef.get)\n      : noop;\n    sharedPropertyDefinition.set = userDef.set || noop;\n  }\n  if ( true &&\n      sharedPropertyDefinition.set === noop) {\n    sharedPropertyDefinition.set = function () {\n      warn(\n        (\"Computed property \\\"\" + key + \"\\\" was assigned to but it has no setter.\"),\n        this\n      );\n    };\n  }\n  Object.defineProperty(target, key, sharedPropertyDefinition);\n}\n\nfunction createComputedGetter (key) {\n  return function computedGetter () {\n    var watcher = this._computedWatchers && this._computedWatchers[key];\n    if (watcher) {\n      if (watcher.dirty) {\n        watcher.evaluate();\n      }\n      if (Dep.target) {\n        watcher.depend();\n      }\n      return watcher.value\n    }\n  }\n}\n\nfunction createGetterInvoker(fn) {\n  return function computedGetter () {\n    return fn.call(this, this)\n  }\n}\n\nfunction initMethods (vm, methods) {\n  var props = vm.$options.props;\n  for (var key in methods) {\n    if (true) {\n      if (typeof methods[key] !== 'function') {\n        warn(\n          \"Method \\\"\" + key + \"\\\" has type \\\"\" + (typeof methods[key]) + \"\\\" in the component definition. \" +\n          \"Did you reference the function correctly?\",\n          vm\n        );\n      }\n      if (props && hasOwn(props, key)) {\n        warn(\n          (\"Method \\\"\" + key + \"\\\" has already been defined as a prop.\"),\n          vm\n        );\n      }\n      if ((key in vm) && isReserved(key)) {\n        warn(\n          \"Method \\\"\" + key + \"\\\" conflicts with an existing Vue instance method. \" +\n          \"Avoid defining component methods that start with _ or $.\"\n        );\n      }\n    }\n    vm[key] = typeof methods[key] !== 'function' ? noop : bind(methods[key], vm);\n  }\n}\n\nfunction initWatch (vm, watch) {\n  for (var key in watch) {\n    var handler = watch[key];\n    if (Array.isArray(handler)) {\n      for (var i = 0; i < handler.length; i++) {\n        createWatcher(vm, key, handler[i]);\n      }\n    } else {\n      createWatcher(vm, key, handler);\n    }\n  }\n}\n\nfunction createWatcher (\n  vm,\n  expOrFn,\n  handler,\n  options\n) {\n  if (isPlainObject(handler)) {\n    options = handler;\n    handler = handler.handler;\n  }\n  if (typeof handler === 'string') {\n    handler = vm[handler];\n  }\n  return vm.$watch(expOrFn, handler, options)\n}\n\nfunction stateMixin (Vue) {\n  // flow somehow has problems with directly declared definition object\n  // when using Object.defineProperty, so we have to procedurally build up\n  // the object here.\n  var dataDef = {};\n  dataDef.get = function () { return this._data };\n  var propsDef = {};\n  propsDef.get = function () { return this._props };\n  if (true) {\n    dataDef.set = function () {\n      warn(\n        'Avoid replacing instance root $data. ' +\n        'Use nested data properties instead.',\n        this\n      );\n    };\n    propsDef.set = function () {\n      warn(\"$props is readonly.\", this);\n    };\n  }\n  Object.defineProperty(Vue.prototype, '$data', dataDef);\n  Object.defineProperty(Vue.prototype, '$props', propsDef);\n\n  Vue.prototype.$set = set;\n  Vue.prototype.$delete = del;\n\n  Vue.prototype.$watch = function (\n    expOrFn,\n    cb,\n    options\n  ) {\n    var vm = this;\n    if (isPlainObject(cb)) {\n      return createWatcher(vm, expOrFn, cb, options)\n    }\n    options = options || {};\n    options.user = true;\n    var watcher = new Watcher(vm, expOrFn, cb, options);\n    if (options.immediate) {\n      try {\n        cb.call(vm, watcher.value);\n      } catch (error) {\n        handleError(error, vm, (\"callback for immediate watcher \\\"\" + (watcher.expression) + \"\\\"\"));\n      }\n    }\n    return function unwatchFn () {\n      watcher.teardown();\n    }\n  };\n}\n\n/*  */\n\nvar uid$3 = 0;\n\nfunction initMixin (Vue) {\n  Vue.prototype._init = function (options) {\n    var vm = this;\n    // a uid\n    vm._uid = uid$3++;\n\n    var startTag, endTag;\n    /* istanbul ignore if */\n    if ( true && config.performance && mark) {\n      startTag = \"vue-perf-start:\" + (vm._uid);\n      endTag = \"vue-perf-end:\" + (vm._uid);\n      mark(startTag);\n    }\n\n    // a flag to avoid this being observed\n    vm._isVue = true;\n    // merge options\n    if (options && options._isComponent) {\n      // optimize internal component instantiation\n      // since dynamic options merging is pretty slow, and none of the\n      // internal component options needs special treatment.\n      initInternalComponent(vm, options);\n    } else {\n      vm.$options = mergeOptions(\n        resolveConstructorOptions(vm.constructor),\n        options || {},\n        vm\n      );\n    }\n    /* istanbul ignore else */\n    if (true) {\n      initProxy(vm);\n    } else {}\n    // expose real self\n    vm._self = vm;\n    initLifecycle(vm);\n    initEvents(vm);\n    initRender(vm);\n    callHook(vm, 'beforeCreate');\n    initInjections(vm); // resolve injections before data/props\n    initState(vm);\n    initProvide(vm); // resolve provide after data/props\n    callHook(vm, 'created');\n\n    /* istanbul ignore if */\n    if ( true && config.performance && mark) {\n      vm._name = formatComponentName(vm, false);\n      mark(endTag);\n      measure((\"vue \" + (vm._name) + \" init\"), startTag, endTag);\n    }\n\n    if (vm.$options.el) {\n      vm.$mount(vm.$options.el);\n    }\n  };\n}\n\nfunction initInternalComponent (vm, options) {\n  var opts = vm.$options = Object.create(vm.constructor.options);\n  // doing this because it's faster than dynamic enumeration.\n  var parentVnode = options._parentVnode;\n  opts.parent = options.parent;\n  opts._parentVnode = parentVnode;\n\n  var vnodeComponentOptions = parentVnode.componentOptions;\n  opts.propsData = vnodeComponentOptions.propsData;\n  opts._parentListeners = vnodeComponentOptions.listeners;\n  opts._renderChildren = vnodeComponentOptions.children;\n  opts._componentTag = vnodeComponentOptions.tag;\n\n  if (options.render) {\n    opts.render = options.render;\n    opts.staticRenderFns = options.staticRenderFns;\n  }\n}\n\nfunction resolveConstructorOptions (Ctor) {\n  var options = Ctor.options;\n  if (Ctor.super) {\n    var superOptions = resolveConstructorOptions(Ctor.super);\n    var cachedSuperOptions = Ctor.superOptions;\n    if (superOptions !== cachedSuperOptions) {\n      // super option changed,\n      // need to resolve new options.\n      Ctor.superOptions = superOptions;\n      // check if there are any late-modified/attached options (#4976)\n      var modifiedOptions = resolveModifiedOptions(Ctor);\n      // update base extend options\n      if (modifiedOptions) {\n        extend(Ctor.extendOptions, modifiedOptions);\n      }\n      options = Ctor.options = mergeOptions(superOptions, Ctor.extendOptions);\n      if (options.name) {\n        options.components[options.name] = Ctor;\n      }\n    }\n  }\n  return options\n}\n\nfunction resolveModifiedOptions (Ctor) {\n  var modified;\n  var latest = Ctor.options;\n  var sealed = Ctor.sealedOptions;\n  for (var key in latest) {\n    if (latest[key] !== sealed[key]) {\n      if (!modified) { modified = {}; }\n      modified[key] = latest[key];\n    }\n  }\n  return modified\n}\n\nfunction Vue (options) {\n  if ( true &&\n    !(this instanceof Vue)\n  ) {\n    warn('Vue is a constructor and should be called with the `new` keyword');\n  }\n  this._init(options);\n}\n\ninitMixin(Vue);\nstateMixin(Vue);\neventsMixin(Vue);\nlifecycleMixin(Vue);\nrenderMixin(Vue);\n\n/*  */\n\nfunction initUse (Vue) {\n  Vue.use = function (plugin) {\n    var installedPlugins = (this._installedPlugins || (this._installedPlugins = []));\n    if (installedPlugins.indexOf(plugin) > -1) {\n      return this\n    }\n\n    // additional parameters\n    var args = toArray(arguments, 1);\n    args.unshift(this);\n    if (typeof plugin.install === 'function') {\n      plugin.install.apply(plugin, args);\n    } else if (typeof plugin === 'function') {\n      plugin.apply(null, args);\n    }\n    installedPlugins.push(plugin);\n    return this\n  };\n}\n\n/*  */\n\nfunction initMixin$1 (Vue) {\n  Vue.mixin = function (mixin) {\n    this.options = mergeOptions(this.options, mixin);\n    return this\n  };\n}\n\n/*  */\n\nfunction initExtend (Vue) {\n  /**\n   * Each instance constructor, including Vue, has a unique\n   * cid. This enables us to create wrapped \"child\n   * constructors\" for prototypal inheritance and cache them.\n   */\n  Vue.cid = 0;\n  var cid = 1;\n\n  /**\n   * Class inheritance\n   */\n  Vue.extend = function (extendOptions) {\n    extendOptions = extendOptions || {};\n    var Super = this;\n    var SuperId = Super.cid;\n    var cachedCtors = extendOptions._Ctor || (extendOptions._Ctor = {});\n    if (cachedCtors[SuperId]) {\n      return cachedCtors[SuperId]\n    }\n\n    var name = extendOptions.name || Super.options.name;\n    if ( true && name) {\n      validateComponentName(name);\n    }\n\n    var Sub = function VueComponent (options) {\n      this._init(options);\n    };\n    Sub.prototype = Object.create(Super.prototype);\n    Sub.prototype.constructor = Sub;\n    Sub.cid = cid++;\n    Sub.options = mergeOptions(\n      Super.options,\n      extendOptions\n    );\n    Sub['super'] = Super;\n\n    // For props and computed properties, we define the proxy getters on\n    // the Vue instances at extension time, on the extended prototype. This\n    // avoids Object.defineProperty calls for each instance created.\n    if (Sub.options.props) {\n      initProps$1(Sub);\n    }\n    if (Sub.options.computed) {\n      initComputed$1(Sub);\n    }\n\n    // allow further extension/mixin/plugin usage\n    Sub.extend = Super.extend;\n    Sub.mixin = Super.mixin;\n    Sub.use = Super.use;\n\n    // create asset registers, so extended classes\n    // can have their private assets too.\n    ASSET_TYPES.forEach(function (type) {\n      Sub[type] = Super[type];\n    });\n    // enable recursive self-lookup\n    if (name) {\n      Sub.options.components[name] = Sub;\n    }\n\n    // keep a reference to the super options at extension time.\n    // later at instantiation we can check if Super's options have\n    // been updated.\n    Sub.superOptions = Super.options;\n    Sub.extendOptions = extendOptions;\n    Sub.sealedOptions = extend({}, Sub.options);\n\n    // cache constructor\n    cachedCtors[SuperId] = Sub;\n    return Sub\n  };\n}\n\nfunction initProps$1 (Comp) {\n  var props = Comp.options.props;\n  for (var key in props) {\n    proxy(Comp.prototype, \"_props\", key);\n  }\n}\n\nfunction initComputed$1 (Comp) {\n  var computed = Comp.options.computed;\n  for (var key in computed) {\n    defineComputed(Comp.prototype, key, computed[key]);\n  }\n}\n\n/*  */\n\nfunction initAssetRegisters (Vue) {\n  /**\n   * Create asset registration methods.\n   */\n  ASSET_TYPES.forEach(function (type) {\n    Vue[type] = function (\n      id,\n      definition\n    ) {\n      if (!definition) {\n        return this.options[type + 's'][id]\n      } else {\n        /* istanbul ignore if */\n        if ( true && type === 'component') {\n          validateComponentName(id);\n        }\n        if (type === 'component' && isPlainObject(definition)) {\n          definition.name = definition.name || id;\n          definition = this.options._base.extend(definition);\n        }\n        if (type === 'directive' && typeof definition === 'function') {\n          definition = { bind: definition, update: definition };\n        }\n        this.options[type + 's'][id] = definition;\n        return definition\n      }\n    };\n  });\n}\n\n/*  */\n\n\n\nfunction getComponentName (opts) {\n  return opts && (opts.Ctor.options.name || opts.tag)\n}\n\nfunction matches (pattern, name) {\n  if (Array.isArray(pattern)) {\n    return pattern.indexOf(name) > -1\n  } else if (typeof pattern === 'string') {\n    return pattern.split(',').indexOf(name) > -1\n  } else if (isRegExp(pattern)) {\n    return pattern.test(name)\n  }\n  /* istanbul ignore next */\n  return false\n}\n\nfunction pruneCache (keepAliveInstance, filter) {\n  var cache = keepAliveInstance.cache;\n  var keys = keepAliveInstance.keys;\n  var _vnode = keepAliveInstance._vnode;\n  for (var key in cache) {\n    var cachedNode = cache[key];\n    if (cachedNode) {\n      var name = getComponentName(cachedNode.componentOptions);\n      if (name && !filter(name)) {\n        pruneCacheEntry(cache, key, keys, _vnode);\n      }\n    }\n  }\n}\n\nfunction pruneCacheEntry (\n  cache,\n  key,\n  keys,\n  current\n) {\n  var cached$$1 = cache[key];\n  if (cached$$1 && (!current || cached$$1.tag !== current.tag)) {\n    cached$$1.componentInstance.$destroy();\n  }\n  cache[key] = null;\n  remove(keys, key);\n}\n\nvar patternTypes = [String, RegExp, Array];\n\nvar KeepAlive = {\n  name: 'keep-alive',\n  abstract: true,\n\n  props: {\n    include: patternTypes,\n    exclude: patternTypes,\n    max: [String, Number]\n  },\n\n  created: function created () {\n    this.cache = Object.create(null);\n    this.keys = [];\n  },\n\n  destroyed: function destroyed () {\n    for (var key in this.cache) {\n      pruneCacheEntry(this.cache, key, this.keys);\n    }\n  },\n\n  mounted: function mounted () {\n    var this$1 = this;\n\n    this.$watch('include', function (val) {\n      pruneCache(this$1, function (name) { return matches(val, name); });\n    });\n    this.$watch('exclude', function (val) {\n      pruneCache(this$1, function (name) { return !matches(val, name); });\n    });\n  },\n\n  render: function render () {\n    var slot = this.$slots.default;\n    var vnode = getFirstComponentChild(slot);\n    var componentOptions = vnode && vnode.componentOptions;\n    if (componentOptions) {\n      // check pattern\n      var name = getComponentName(componentOptions);\n      var ref = this;\n      var include = ref.include;\n      var exclude = ref.exclude;\n      if (\n        // not included\n        (include && (!name || !matches(include, name))) ||\n        // excluded\n        (exclude && name && matches(exclude, name))\n      ) {\n        return vnode\n      }\n\n      var ref$1 = this;\n      var cache = ref$1.cache;\n      var keys = ref$1.keys;\n      var key = vnode.key == null\n        // same constructor may get registered as different local components\n        // so cid alone is not enough (#3269)\n        ? componentOptions.Ctor.cid + (componentOptions.tag ? (\"::\" + (componentOptions.tag)) : '')\n        : vnode.key;\n      if (cache[key]) {\n        vnode.componentInstance = cache[key].componentInstance;\n        // make current key freshest\n        remove(keys, key);\n        keys.push(key);\n      } else {\n        cache[key] = vnode;\n        keys.push(key);\n        // prune oldest entry\n        if (this.max && keys.length > parseInt(this.max)) {\n          pruneCacheEntry(cache, keys[0], keys, this._vnode);\n        }\n      }\n\n      vnode.data.keepAlive = true;\n    }\n    return vnode || (slot && slot[0])\n  }\n};\n\nvar builtInComponents = {\n  KeepAlive: KeepAlive\n};\n\n/*  */\n\nfunction initGlobalAPI (Vue) {\n  // config\n  var configDef = {};\n  configDef.get = function () { return config; };\n  if (true) {\n    configDef.set = function () {\n      warn(\n        'Do not replace the Vue.config object, set individual fields instead.'\n      );\n    };\n  }\n  Object.defineProperty(Vue, 'config', configDef);\n\n  // exposed util methods.\n  // NOTE: these are not considered part of the public API - avoid relying on\n  // them unless you are aware of the risk.\n  Vue.util = {\n    warn: warn,\n    extend: extend,\n    mergeOptions: mergeOptions,\n    defineReactive: defineReactive$$1\n  };\n\n  Vue.set = set;\n  Vue.delete = del;\n  Vue.nextTick = nextTick;\n\n  // 2.6 explicit observable API\n  Vue.observable = function (obj) {\n    observe(obj);\n    return obj\n  };\n\n  Vue.options = Object.create(null);\n  ASSET_TYPES.forEach(function (type) {\n    Vue.options[type + 's'] = Object.create(null);\n  });\n\n  // this is used to identify the \"base\" constructor to extend all plain-object\n  // components with in Weex's multi-instance scenarios.\n  Vue.options._base = Vue;\n\n  extend(Vue.options.components, builtInComponents);\n\n  initUse(Vue);\n  initMixin$1(Vue);\n  initExtend(Vue);\n  initAssetRegisters(Vue);\n}\n\ninitGlobalAPI(Vue);\n\nObject.defineProperty(Vue.prototype, '$isServer', {\n  get: isServerRendering\n});\n\nObject.defineProperty(Vue.prototype, '$ssrContext', {\n  get: function get () {\n    /* istanbul ignore next */\n    return this.$vnode && this.$vnode.ssrContext\n  }\n});\n\n// expose FunctionalRenderContext for ssr runtime helper installation\nObject.defineProperty(Vue, 'FunctionalRenderContext', {\n  value: FunctionalRenderContext\n});\n\nVue.version = '2.6.10';\n\n/*  */\n\n// these are reserved for web because they are directly compiled away\n// during template compilation\nvar isReservedAttr = makeMap('style,class');\n\n// attributes that should be using props for binding\nvar acceptValue = makeMap('input,textarea,option,select,progress');\nvar mustUseProp = function (tag, type, attr) {\n  return (\n    (attr === 'value' && acceptValue(tag)) && type !== 'button' ||\n    (attr === 'selected' && tag === 'option') ||\n    (attr === 'checked' && tag === 'input') ||\n    (attr === 'muted' && tag === 'video')\n  )\n};\n\nvar isEnumeratedAttr = makeMap('contenteditable,draggable,spellcheck');\n\nvar isValidContentEditableValue = makeMap('events,caret,typing,plaintext-only');\n\nvar convertEnumeratedValue = function (key, value) {\n  return isFalsyAttrValue(value) || value === 'false'\n    ? 'false'\n    // allow arbitrary string value for contenteditable\n    : key === 'contenteditable' && isValidContentEditableValue(value)\n      ? value\n      : 'true'\n};\n\nvar isBooleanAttr = makeMap(\n  'allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,' +\n  'default,defaultchecked,defaultmuted,defaultselected,defer,disabled,' +\n  'enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,' +\n  'muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,' +\n  'required,reversed,scoped,seamless,selected,sortable,translate,' +\n  'truespeed,typemustmatch,visible'\n);\n\nvar xlinkNS = 'http://www.w3.org/1999/xlink';\n\nvar isXlink = function (name) {\n  return name.charAt(5) === ':' && name.slice(0, 5) === 'xlink'\n};\n\nvar getXlinkProp = function (name) {\n  return isXlink(name) ? name.slice(6, name.length) : ''\n};\n\nvar isFalsyAttrValue = function (val) {\n  return val == null || val === false\n};\n\n/*  */\n\nfunction genClassForVnode (vnode) {\n  var data = vnode.data;\n  var parentNode = vnode;\n  var childNode = vnode;\n  while (isDef(childNode.componentInstance)) {\n    childNode = childNode.componentInstance._vnode;\n    if (childNode && childNode.data) {\n      data = mergeClassData(childNode.data, data);\n    }\n  }\n  while (isDef(parentNode = parentNode.parent)) {\n    if (parentNode && parentNode.data) {\n      data = mergeClassData(data, parentNode.data);\n    }\n  }\n  return renderClass(data.staticClass, data.class)\n}\n\nfunction mergeClassData (child, parent) {\n  return {\n    staticClass: concat(child.staticClass, parent.staticClass),\n    class: isDef(child.class)\n      ? [child.class, parent.class]\n      : parent.class\n  }\n}\n\nfunction renderClass (\n  staticClass,\n  dynamicClass\n) {\n  if (isDef(staticClass) || isDef(dynamicClass)) {\n    return concat(staticClass, stringifyClass(dynamicClass))\n  }\n  /* istanbul ignore next */\n  return ''\n}\n\nfunction concat (a, b) {\n  return a ? b ? (a + ' ' + b) : a : (b || '')\n}\n\nfunction stringifyClass (value) {\n  if (Array.isArray(value)) {\n    return stringifyArray(value)\n  }\n  if (isObject(value)) {\n    return stringifyObject(value)\n  }\n  if (typeof value === 'string') {\n    return value\n  }\n  /* istanbul ignore next */\n  return ''\n}\n\nfunction stringifyArray (value) {\n  var res = '';\n  var stringified;\n  for (var i = 0, l = value.length; i < l; i++) {\n    if (isDef(stringified = stringifyClass(value[i])) && stringified !== '') {\n      if (res) { res += ' '; }\n      res += stringified;\n    }\n  }\n  return res\n}\n\nfunction stringifyObject (value) {\n  var res = '';\n  for (var key in value) {\n    if (value[key]) {\n      if (res) { res += ' '; }\n      res += key;\n    }\n  }\n  return res\n}\n\n/*  */\n\nvar namespaceMap = {\n  svg: 'http://www.w3.org/2000/svg',\n  math: 'http://www.w3.org/1998/Math/MathML'\n};\n\nvar isHTMLTag = makeMap(\n  'html,body,base,head,link,meta,style,title,' +\n  'address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,' +\n  'div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,' +\n  'a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,' +\n  's,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,' +\n  'embed,object,param,source,canvas,script,noscript,del,ins,' +\n  'caption,col,colgroup,table,thead,tbody,td,th,tr,' +\n  'button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,' +\n  'output,progress,select,textarea,' +\n  'details,dialog,menu,menuitem,summary,' +\n  'content,element,shadow,template,blockquote,iframe,tfoot'\n);\n\n// this map is intentionally selective, only covering SVG elements that may\n// contain child elements.\nvar isSVG = makeMap(\n  'svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,' +\n  'foreignObject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,' +\n  'polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view',\n  true\n);\n\nvar isReservedTag = function (tag) {\n  return isHTMLTag(tag) || isSVG(tag)\n};\n\nfunction getTagNamespace (tag) {\n  if (isSVG(tag)) {\n    return 'svg'\n  }\n  // basic support for MathML\n  // note it doesn't support other MathML elements being component roots\n  if (tag === 'math') {\n    return 'math'\n  }\n}\n\nvar unknownElementCache = Object.create(null);\nfunction isUnknownElement (tag) {\n  /* istanbul ignore if */\n  if (!inBrowser) {\n    return true\n  }\n  if (isReservedTag(tag)) {\n    return false\n  }\n  tag = tag.toLowerCase();\n  /* istanbul ignore if */\n  if (unknownElementCache[tag] != null) {\n    return unknownElementCache[tag]\n  }\n  var el = document.createElement(tag);\n  if (tag.indexOf('-') > -1) {\n    // http://stackoverflow.com/a/28210364/1070244\n    return (unknownElementCache[tag] = (\n      el.constructor === window.HTMLUnknownElement ||\n      el.constructor === window.HTMLElement\n    ))\n  } else {\n    return (unknownElementCache[tag] = /HTMLUnknownElement/.test(el.toString()))\n  }\n}\n\nvar isTextInputType = makeMap('text,number,password,search,email,tel,url');\n\n/*  */\n\n/**\n * Query an element selector if it's not an element already.\n */\nfunction query (el) {\n  if (typeof el === 'string') {\n    var selected = document.querySelector(el);\n    if (!selected) {\n       true && warn(\n        'Cannot find element: ' + el\n      );\n      return document.createElement('div')\n    }\n    return selected\n  } else {\n    return el\n  }\n}\n\n/*  */\n\nfunction createElement$1 (tagName, vnode) {\n  var elm = document.createElement(tagName);\n  if (tagName !== 'select') {\n    return elm\n  }\n  // false or null will remove the attribute but undefined will not\n  if (vnode.data && vnode.data.attrs && vnode.data.attrs.multiple !== undefined) {\n    elm.setAttribute('multiple', 'multiple');\n  }\n  return elm\n}\n\nfunction createElementNS (namespace, tagName) {\n  return document.createElementNS(namespaceMap[namespace], tagName)\n}\n\nfunction createTextNode (text) {\n  return document.createTextNode(text)\n}\n\nfunction createComment (text) {\n  return document.createComment(text)\n}\n\nfunction insertBefore (parentNode, newNode, referenceNode) {\n  parentNode.insertBefore(newNode, referenceNode);\n}\n\nfunction removeChild (node, child) {\n  node.removeChild(child);\n}\n\nfunction appendChild (node, child) {\n  node.appendChild(child);\n}\n\nfunction parentNode (node) {\n  return node.parentNode\n}\n\nfunction nextSibling (node) {\n  return node.nextSibling\n}\n\nfunction tagName (node) {\n  return node.tagName\n}\n\nfunction setTextContent (node, text) {\n  node.textContent = text;\n}\n\nfunction setStyleScope (node, scopeId) {\n  node.setAttribute(scopeId, '');\n}\n\nvar nodeOps = /*#__PURE__*/Object.freeze({\n  createElement: createElement$1,\n  createElementNS: createElementNS,\n  createTextNode: createTextNode,\n  createComment: createComment,\n  insertBefore: insertBefore,\n  removeChild: removeChild,\n  appendChild: appendChild,\n  parentNode: parentNode,\n  nextSibling: nextSibling,\n  tagName: tagName,\n  setTextContent: setTextContent,\n  setStyleScope: setStyleScope\n});\n\n/*  */\n\nvar ref = {\n  create: function create (_, vnode) {\n    registerRef(vnode);\n  },\n  update: function update (oldVnode, vnode) {\n    if (oldVnode.data.ref !== vnode.data.ref) {\n      registerRef(oldVnode, true);\n      registerRef(vnode);\n    }\n  },\n  destroy: function destroy (vnode) {\n    registerRef(vnode, true);\n  }\n};\n\nfunction registerRef (vnode, isRemoval) {\n  var key = vnode.data.ref;\n  if (!isDef(key)) { return }\n\n  var vm = vnode.context;\n  var ref = vnode.componentInstance || vnode.elm;\n  var refs = vm.$refs;\n  if (isRemoval) {\n    if (Array.isArray(refs[key])) {\n      remove(refs[key], ref);\n    } else if (refs[key] === ref) {\n      refs[key] = undefined;\n    }\n  } else {\n    if (vnode.data.refInFor) {\n      if (!Array.isArray(refs[key])) {\n        refs[key] = [ref];\n      } else if (refs[key].indexOf(ref) < 0) {\n        // $flow-disable-line\n        refs[key].push(ref);\n      }\n    } else {\n      refs[key] = ref;\n    }\n  }\n}\n\n/**\n * Virtual DOM patching algorithm based on Snabbdom by\n * Simon Friis Vindum (@paldepind)\n * Licensed under the MIT License\n * https://github.com/paldepind/snabbdom/blob/master/LICENSE\n *\n * modified by Evan You (@yyx990803)\n *\n * Not type-checking this because this file is perf-critical and the cost\n * of making flow understand it is not worth it.\n */\n\nvar emptyNode = new VNode('', {}, []);\n\nvar hooks = ['create', 'activate', 'update', 'remove', 'destroy'];\n\nfunction sameVnode (a, b) {\n  return (\n    a.key === b.key && (\n      (\n        a.tag === b.tag &&\n        a.isComment === b.isComment &&\n        isDef(a.data) === isDef(b.data) &&\n        sameInputType(a, b)\n      ) || (\n        isTrue(a.isAsyncPlaceholder) &&\n        a.asyncFactory === b.asyncFactory &&\n        isUndef(b.asyncFactory.error)\n      )\n    )\n  )\n}\n\nfunction sameInputType (a, b) {\n  if (a.tag !== 'input') { return true }\n  var i;\n  var typeA = isDef(i = a.data) && isDef(i = i.attrs) && i.type;\n  var typeB = isDef(i = b.data) && isDef(i = i.attrs) && i.type;\n  return typeA === typeB || isTextInputType(typeA) && isTextInputType(typeB)\n}\n\nfunction createKeyToOldIdx (children, beginIdx, endIdx) {\n  var i, key;\n  var map = {};\n  for (i = beginIdx; i <= endIdx; ++i) {\n    key = children[i].key;\n    if (isDef(key)) { map[key] = i; }\n  }\n  return map\n}\n\nfunction createPatchFunction (backend) {\n  var i, j;\n  var cbs = {};\n\n  var modules = backend.modules;\n  var nodeOps = backend.nodeOps;\n\n  for (i = 0; i < hooks.length; ++i) {\n    cbs[hooks[i]] = [];\n    for (j = 0; j < modules.length; ++j) {\n      if (isDef(modules[j][hooks[i]])) {\n        cbs[hooks[i]].push(modules[j][hooks[i]]);\n      }\n    }\n  }\n\n  function emptyNodeAt (elm) {\n    return new VNode(nodeOps.tagName(elm).toLowerCase(), {}, [], undefined, elm)\n  }\n\n  function createRmCb (childElm, listeners) {\n    function remove$$1 () {\n      if (--remove$$1.listeners === 0) {\n        removeNode(childElm);\n      }\n    }\n    remove$$1.listeners = listeners;\n    return remove$$1\n  }\n\n  function removeNode (el) {\n    var parent = nodeOps.parentNode(el);\n    // element may have already been removed due to v-html / v-text\n    if (isDef(parent)) {\n      nodeOps.removeChild(parent, el);\n    }\n  }\n\n  function isUnknownElement$$1 (vnode, inVPre) {\n    return (\n      !inVPre &&\n      !vnode.ns &&\n      !(\n        config.ignoredElements.length &&\n        config.ignoredElements.some(function (ignore) {\n          return isRegExp(ignore)\n            ? ignore.test(vnode.tag)\n            : ignore === vnode.tag\n        })\n      ) &&\n      config.isUnknownElement(vnode.tag)\n    )\n  }\n\n  var creatingElmInVPre = 0;\n\n  function createElm (\n    vnode,\n    insertedVnodeQueue,\n    parentElm,\n    refElm,\n    nested,\n    ownerArray,\n    index\n  ) {\n    if (isDef(vnode.elm) && isDef(ownerArray)) {\n      // This vnode was used in a previous render!\n      // now it's used as a new node, overwriting its elm would cause\n      // potential patch errors down the road when it's used as an insertion\n      // reference node. Instead, we clone the node on-demand before creating\n      // associated DOM element for it.\n      vnode = ownerArray[index] = cloneVNode(vnode);\n    }\n\n    vnode.isRootInsert = !nested; // for transition enter check\n    if (createComponent(vnode, insertedVnodeQueue, parentElm, refElm)) {\n      return\n    }\n\n    var data = vnode.data;\n    var children = vnode.children;\n    var tag = vnode.tag;\n    if (isDef(tag)) {\n      if (true) {\n        if (data && data.pre) {\n          creatingElmInVPre++;\n        }\n        if (isUnknownElement$$1(vnode, creatingElmInVPre)) {\n          warn(\n            'Unknown custom element: <' + tag + '> - did you ' +\n            'register the component correctly? For recursive components, ' +\n            'make sure to provide the \"name\" option.',\n            vnode.context\n          );\n        }\n      }\n\n      vnode.elm = vnode.ns\n        ? nodeOps.createElementNS(vnode.ns, tag)\n        : nodeOps.createElement(tag, vnode);\n      setScope(vnode);\n\n      /* istanbul ignore if */\n      {\n        createChildren(vnode, children, insertedVnodeQueue);\n        if (isDef(data)) {\n          invokeCreateHooks(vnode, insertedVnodeQueue);\n        }\n        insert(parentElm, vnode.elm, refElm);\n      }\n\n      if ( true && data && data.pre) {\n        creatingElmInVPre--;\n      }\n    } else if (isTrue(vnode.isComment)) {\n      vnode.elm = nodeOps.createComment(vnode.text);\n      insert(parentElm, vnode.elm, refElm);\n    } else {\n      vnode.elm = nodeOps.createTextNode(vnode.text);\n      insert(parentElm, vnode.elm, refElm);\n    }\n  }\n\n  function createComponent (vnode, insertedVnodeQueue, parentElm, refElm) {\n    var i = vnode.data;\n    if (isDef(i)) {\n      var isReactivated = isDef(vnode.componentInstance) && i.keepAlive;\n      if (isDef(i = i.hook) && isDef(i = i.init)) {\n        i(vnode, false /* hydrating */);\n      }\n      // after calling the init hook, if the vnode is a child component\n      // it should've created a child instance and mounted it. the child\n      // component also has set the placeholder vnode's elm.\n      // in that case we can just return the element and be done.\n      if (isDef(vnode.componentInstance)) {\n        initComponent(vnode, insertedVnodeQueue);\n        insert(parentElm, vnode.elm, refElm);\n        if (isTrue(isReactivated)) {\n          reactivateComponent(vnode, insertedVnodeQueue, parentElm, refElm);\n        }\n        return true\n      }\n    }\n  }\n\n  function initComponent (vnode, insertedVnodeQueue) {\n    if (isDef(vnode.data.pendingInsert)) {\n      insertedVnodeQueue.push.apply(insertedVnodeQueue, vnode.data.pendingInsert);\n      vnode.data.pendingInsert = null;\n    }\n    vnode.elm = vnode.componentInstance.$el;\n    if (isPatchable(vnode)) {\n      invokeCreateHooks(vnode, insertedVnodeQueue);\n      setScope(vnode);\n    } else {\n      // empty component root.\n      // skip all element-related modules except for ref (#3455)\n      registerRef(vnode);\n      // make sure to invoke the insert hook\n      insertedVnodeQueue.push(vnode);\n    }\n  }\n\n  function reactivateComponent (vnode, insertedVnodeQueue, parentElm, refElm) {\n    var i;\n    // hack for #4339: a reactivated component with inner transition\n    // does not trigger because the inner node's created hooks are not called\n    // again. It's not ideal to involve module-specific logic in here but\n    // there doesn't seem to be a better way to do it.\n    var innerNode = vnode;\n    while (innerNode.componentInstance) {\n      innerNode = innerNode.componentInstance._vnode;\n      if (isDef(i = innerNode.data) && isDef(i = i.transition)) {\n        for (i = 0; i < cbs.activate.length; ++i) {\n          cbs.activate[i](emptyNode, innerNode);\n        }\n        insertedVnodeQueue.push(innerNode);\n        break\n      }\n    }\n    // unlike a newly created component,\n    // a reactivated keep-alive component doesn't insert itself\n    insert(parentElm, vnode.elm, refElm);\n  }\n\n  function insert (parent, elm, ref$$1) {\n    if (isDef(parent)) {\n      if (isDef(ref$$1)) {\n        if (nodeOps.parentNode(ref$$1) === parent) {\n          nodeOps.insertBefore(parent, elm, ref$$1);\n        }\n      } else {\n        nodeOps.appendChild(parent, elm);\n      }\n    }\n  }\n\n  function createChildren (vnode, children, insertedVnodeQueue) {\n    if (Array.isArray(children)) {\n      if (true) {\n        checkDuplicateKeys(children);\n      }\n      for (var i = 0; i < children.length; ++i) {\n        createElm(children[i], insertedVnodeQueue, vnode.elm, null, true, children, i);\n      }\n    } else if (isPrimitive(vnode.text)) {\n      nodeOps.appendChild(vnode.elm, nodeOps.createTextNode(String(vnode.text)));\n    }\n  }\n\n  function isPatchable (vnode) {\n    while (vnode.componentInstance) {\n      vnode = vnode.componentInstance._vnode;\n    }\n    return isDef(vnode.tag)\n  }\n\n  function invokeCreateHooks (vnode, insertedVnodeQueue) {\n    for (var i$1 = 0; i$1 < cbs.create.length; ++i$1) {\n      cbs.create[i$1](emptyNode, vnode);\n    }\n    i = vnode.data.hook; // Reuse variable\n    if (isDef(i)) {\n      if (isDef(i.create)) { i.create(emptyNode, vnode); }\n      if (isDef(i.insert)) { insertedVnodeQueue.push(vnode); }\n    }\n  }\n\n  // set scope id attribute for scoped CSS.\n  // this is implemented as a special case to avoid the overhead\n  // of going through the normal attribute patching process.\n  function setScope (vnode) {\n    var i;\n    if (isDef(i = vnode.fnScopeId)) {\n      nodeOps.setStyleScope(vnode.elm, i);\n    } else {\n      var ancestor = vnode;\n      while (ancestor) {\n        if (isDef(i = ancestor.context) && isDef(i = i.$options._scopeId)) {\n          nodeOps.setStyleScope(vnode.elm, i);\n        }\n        ancestor = ancestor.parent;\n      }\n    }\n    // for slot content they should also get the scopeId from the host instance.\n    if (isDef(i = activeInstance) &&\n      i !== vnode.context &&\n      i !== vnode.fnContext &&\n      isDef(i = i.$options._scopeId)\n    ) {\n      nodeOps.setStyleScope(vnode.elm, i);\n    }\n  }\n\n  function addVnodes (parentElm, refElm, vnodes, startIdx, endIdx, insertedVnodeQueue) {\n    for (; startIdx <= endIdx; ++startIdx) {\n      createElm(vnodes[startIdx], insertedVnodeQueue, parentElm, refElm, false, vnodes, startIdx);\n    }\n  }\n\n  function invokeDestroyHook (vnode) {\n    var i, j;\n    var data = vnode.data;\n    if (isDef(data)) {\n      if (isDef(i = data.hook) && isDef(i = i.destroy)) { i(vnode); }\n      for (i = 0; i < cbs.destroy.length; ++i) { cbs.destroy[i](vnode); }\n    }\n    if (isDef(i = vnode.children)) {\n      for (j = 0; j < vnode.children.length; ++j) {\n        invokeDestroyHook(vnode.children[j]);\n      }\n    }\n  }\n\n  function removeVnodes (parentElm, vnodes, startIdx, endIdx) {\n    for (; startIdx <= endIdx; ++startIdx) {\n      var ch = vnodes[startIdx];\n      if (isDef(ch)) {\n        if (isDef(ch.tag)) {\n          removeAndInvokeRemoveHook(ch);\n          invokeDestroyHook(ch);\n        } else { // Text node\n          removeNode(ch.elm);\n        }\n      }\n    }\n  }\n\n  function removeAndInvokeRemoveHook (vnode, rm) {\n    if (isDef(rm) || isDef(vnode.data)) {\n      var i;\n      var listeners = cbs.remove.length + 1;\n      if (isDef(rm)) {\n        // we have a recursively passed down rm callback\n        // increase the listeners count\n        rm.listeners += listeners;\n      } else {\n        // directly removing\n        rm = createRmCb(vnode.elm, listeners);\n      }\n      // recursively invoke hooks on child component root node\n      if (isDef(i = vnode.componentInstance) && isDef(i = i._vnode) && isDef(i.data)) {\n        removeAndInvokeRemoveHook(i, rm);\n      }\n      for (i = 0; i < cbs.remove.length; ++i) {\n        cbs.remove[i](vnode, rm);\n      }\n      if (isDef(i = vnode.data.hook) && isDef(i = i.remove)) {\n        i(vnode, rm);\n      } else {\n        rm();\n      }\n    } else {\n      removeNode(vnode.elm);\n    }\n  }\n\n  function updateChildren (parentElm, oldCh, newCh, insertedVnodeQueue, removeOnly) {\n    var oldStartIdx = 0;\n    var newStartIdx = 0;\n    var oldEndIdx = oldCh.length - 1;\n    var oldStartVnode = oldCh[0];\n    var oldEndVnode = oldCh[oldEndIdx];\n    var newEndIdx = newCh.length - 1;\n    var newStartVnode = newCh[0];\n    var newEndVnode = newCh[newEndIdx];\n    var oldKeyToIdx, idxInOld, vnodeToMove, refElm;\n\n    // removeOnly is a special flag used only by <transition-group>\n    // to ensure removed elements stay in correct relative positions\n    // during leaving transitions\n    var canMove = !removeOnly;\n\n    if (true) {\n      checkDuplicateKeys(newCh);\n    }\n\n    while (oldStartIdx <= oldEndIdx && newStartIdx <= newEndIdx) {\n      if (isUndef(oldStartVnode)) {\n        oldStartVnode = oldCh[++oldStartIdx]; // Vnode has been moved left\n      } else if (isUndef(oldEndVnode)) {\n        oldEndVnode = oldCh[--oldEndIdx];\n      } else if (sameVnode(oldStartVnode, newStartVnode)) {\n        patchVnode(oldStartVnode, newStartVnode, insertedVnodeQueue, newCh, newStartIdx);\n        oldStartVnode = oldCh[++oldStartIdx];\n        newStartVnode = newCh[++newStartIdx];\n      } else if (sameVnode(oldEndVnode, newEndVnode)) {\n        patchVnode(oldEndVnode, newEndVnode, insertedVnodeQueue, newCh, newEndIdx);\n        oldEndVnode = oldCh[--oldEndIdx];\n        newEndVnode = newCh[--newEndIdx];\n      } else if (sameVnode(oldStartVnode, newEndVnode)) { // Vnode moved right\n        patchVnode(oldStartVnode, newEndVnode, insertedVnodeQueue, newCh, newEndIdx);\n        canMove && nodeOps.insertBefore(parentElm, oldStartVnode.elm, nodeOps.nextSibling(oldEndVnode.elm));\n        oldStartVnode = oldCh[++oldStartIdx];\n        newEndVnode = newCh[--newEndIdx];\n      } else if (sameVnode(oldEndVnode, newStartVnode)) { // Vnode moved left\n        patchVnode(oldEndVnode, newStartVnode, insertedVnodeQueue, newCh, newStartIdx);\n        canMove && nodeOps.insertBefore(parentElm, oldEndVnode.elm, oldStartVnode.elm);\n        oldEndVnode = oldCh[--oldEndIdx];\n        newStartVnode = newCh[++newStartIdx];\n      } else {\n        if (isUndef(oldKeyToIdx)) { oldKeyToIdx = createKeyToOldIdx(oldCh, oldStartIdx, oldEndIdx); }\n        idxInOld = isDef(newStartVnode.key)\n          ? oldKeyToIdx[newStartVnode.key]\n          : findIdxInOld(newStartVnode, oldCh, oldStartIdx, oldEndIdx);\n        if (isUndef(idxInOld)) { // New element\n          createElm(newStartVnode, insertedVnodeQueue, parentElm, oldStartVnode.elm, false, newCh, newStartIdx);\n        } else {\n          vnodeToMove = oldCh[idxInOld];\n          if (sameVnode(vnodeToMove, newStartVnode)) {\n            patchVnode(vnodeToMove, newStartVnode, insertedVnodeQueue, newCh, newStartIdx);\n            oldCh[idxInOld] = undefined;\n            canMove && nodeOps.insertBefore(parentElm, vnodeToMove.elm, oldStartVnode.elm);\n          } else {\n            // same key but different element. treat as new element\n            createElm(newStartVnode, insertedVnodeQueue, parentElm, oldStartVnode.elm, false, newCh, newStartIdx);\n          }\n        }\n        newStartVnode = newCh[++newStartIdx];\n      }\n    }\n    if (oldStartIdx > oldEndIdx) {\n      refElm = isUndef(newCh[newEndIdx + 1]) ? null : newCh[newEndIdx + 1].elm;\n      addVnodes(parentElm, refElm, newCh, newStartIdx, newEndIdx, insertedVnodeQueue);\n    } else if (newStartIdx > newEndIdx) {\n      removeVnodes(parentElm, oldCh, oldStartIdx, oldEndIdx);\n    }\n  }\n\n  function checkDuplicateKeys (children) {\n    var seenKeys = {};\n    for (var i = 0; i < children.length; i++) {\n      var vnode = children[i];\n      var key = vnode.key;\n      if (isDef(key)) {\n        if (seenKeys[key]) {\n          warn(\n            (\"Duplicate keys detected: '\" + key + \"'. This may cause an update error.\"),\n            vnode.context\n          );\n        } else {\n          seenKeys[key] = true;\n        }\n      }\n    }\n  }\n\n  function findIdxInOld (node, oldCh, start, end) {\n    for (var i = start; i < end; i++) {\n      var c = oldCh[i];\n      if (isDef(c) && sameVnode(node, c)) { return i }\n    }\n  }\n\n  function patchVnode (\n    oldVnode,\n    vnode,\n    insertedVnodeQueue,\n    ownerArray,\n    index,\n    removeOnly\n  ) {\n    if (oldVnode === vnode) {\n      return\n    }\n\n    if (isDef(vnode.elm) && isDef(ownerArray)) {\n      // clone reused vnode\n      vnode = ownerArray[index] = cloneVNode(vnode);\n    }\n\n    var elm = vnode.elm = oldVnode.elm;\n\n    if (isTrue(oldVnode.isAsyncPlaceholder)) {\n      if (isDef(vnode.asyncFactory.resolved)) {\n        hydrate(oldVnode.elm, vnode, insertedVnodeQueue);\n      } else {\n        vnode.isAsyncPlaceholder = true;\n      }\n      return\n    }\n\n    // reuse element for static trees.\n    // note we only do this if the vnode is cloned -\n    // if the new node is not cloned it means the render functions have been\n    // reset by the hot-reload-api and we need to do a proper re-render.\n    if (isTrue(vnode.isStatic) &&\n      isTrue(oldVnode.isStatic) &&\n      vnode.key === oldVnode.key &&\n      (isTrue(vnode.isCloned) || isTrue(vnode.isOnce))\n    ) {\n      vnode.componentInstance = oldVnode.componentInstance;\n      return\n    }\n\n    var i;\n    var data = vnode.data;\n    if (isDef(data) && isDef(i = data.hook) && isDef(i = i.prepatch)) {\n      i(oldVnode, vnode);\n    }\n\n    var oldCh = oldVnode.children;\n    var ch = vnode.children;\n    if (isDef(data) && isPatchable(vnode)) {\n      for (i = 0; i < cbs.update.length; ++i) { cbs.update[i](oldVnode, vnode); }\n      if (isDef(i = data.hook) && isDef(i = i.update)) { i(oldVnode, vnode); }\n    }\n    if (isUndef(vnode.text)) {\n      if (isDef(oldCh) && isDef(ch)) {\n        if (oldCh !== ch) { updateChildren(elm, oldCh, ch, insertedVnodeQueue, removeOnly); }\n      } else if (isDef(ch)) {\n        if (true) {\n          checkDuplicateKeys(ch);\n        }\n        if (isDef(oldVnode.text)) { nodeOps.setTextContent(elm, ''); }\n        addVnodes(elm, null, ch, 0, ch.length - 1, insertedVnodeQueue);\n      } else if (isDef(oldCh)) {\n        removeVnodes(elm, oldCh, 0, oldCh.length - 1);\n      } else if (isDef(oldVnode.text)) {\n        nodeOps.setTextContent(elm, '');\n      }\n    } else if (oldVnode.text !== vnode.text) {\n      nodeOps.setTextContent(elm, vnode.text);\n    }\n    if (isDef(data)) {\n      if (isDef(i = data.hook) && isDef(i = i.postpatch)) { i(oldVnode, vnode); }\n    }\n  }\n\n  function invokeInsertHook (vnode, queue, initial) {\n    // delay insert hooks for component root nodes, invoke them after the\n    // element is really inserted\n    if (isTrue(initial) && isDef(vnode.parent)) {\n      vnode.parent.data.pendingInsert = queue;\n    } else {\n      for (var i = 0; i < queue.length; ++i) {\n        queue[i].data.hook.insert(queue[i]);\n      }\n    }\n  }\n\n  var hydrationBailed = false;\n  // list of modules that can skip create hook during hydration because they\n  // are already rendered on the client or has no need for initialization\n  // Note: style is excluded because it relies on initial clone for future\n  // deep updates (#7063).\n  var isRenderedModule = makeMap('attrs,class,staticClass,staticStyle,key');\n\n  // Note: this is a browser-only function so we can assume elms are DOM nodes.\n  function hydrate (elm, vnode, insertedVnodeQueue, inVPre) {\n    var i;\n    var tag = vnode.tag;\n    var data = vnode.data;\n    var children = vnode.children;\n    inVPre = inVPre || (data && data.pre);\n    vnode.elm = elm;\n\n    if (isTrue(vnode.isComment) && isDef(vnode.asyncFactory)) {\n      vnode.isAsyncPlaceholder = true;\n      return true\n    }\n    // assert node match\n    if (true) {\n      if (!assertNodeMatch(elm, vnode, inVPre)) {\n        return false\n      }\n    }\n    if (isDef(data)) {\n      if (isDef(i = data.hook) && isDef(i = i.init)) { i(vnode, true /* hydrating */); }\n      if (isDef(i = vnode.componentInstance)) {\n        // child component. it should have hydrated its own tree.\n        initComponent(vnode, insertedVnodeQueue);\n        return true\n      }\n    }\n    if (isDef(tag)) {\n      if (isDef(children)) {\n        // empty element, allow client to pick up and populate children\n        if (!elm.hasChildNodes()) {\n          createChildren(vnode, children, insertedVnodeQueue);\n        } else {\n          // v-html and domProps: innerHTML\n          if (isDef(i = data) && isDef(i = i.domProps) && isDef(i = i.innerHTML)) {\n            if (i !== elm.innerHTML) {\n              /* istanbul ignore if */\n              if ( true &&\n                typeof console !== 'undefined' &&\n                !hydrationBailed\n              ) {\n                hydrationBailed = true;\n                console.warn('Parent: ', elm);\n                console.warn('server innerHTML: ', i);\n                console.warn('client innerHTML: ', elm.innerHTML);\n              }\n              return false\n            }\n          } else {\n            // iterate and compare children lists\n            var childrenMatch = true;\n            var childNode = elm.firstChild;\n            for (var i$1 = 0; i$1 < children.length; i$1++) {\n              if (!childNode || !hydrate(childNode, children[i$1], insertedVnodeQueue, inVPre)) {\n                childrenMatch = false;\n                break\n              }\n              childNode = childNode.nextSibling;\n            }\n            // if childNode is not null, it means the actual childNodes list is\n            // longer than the virtual children list.\n            if (!childrenMatch || childNode) {\n              /* istanbul ignore if */\n              if ( true &&\n                typeof console !== 'undefined' &&\n                !hydrationBailed\n              ) {\n                hydrationBailed = true;\n                console.warn('Parent: ', elm);\n                console.warn('Mismatching childNodes vs. VNodes: ', elm.childNodes, children);\n              }\n              return false\n            }\n          }\n        }\n      }\n      if (isDef(data)) {\n        var fullInvoke = false;\n        for (var key in data) {\n          if (!isRenderedModule(key)) {\n            fullInvoke = true;\n            invokeCreateHooks(vnode, insertedVnodeQueue);\n            break\n          }\n        }\n        if (!fullInvoke && data['class']) {\n          // ensure collecting deps for deep class bindings for future updates\n          traverse(data['class']);\n        }\n      }\n    } else if (elm.data !== vnode.text) {\n      elm.data = vnode.text;\n    }\n    return true\n  }\n\n  function assertNodeMatch (node, vnode, inVPre) {\n    if (isDef(vnode.tag)) {\n      return vnode.tag.indexOf('vue-component') === 0 || (\n        !isUnknownElement$$1(vnode, inVPre) &&\n        vnode.tag.toLowerCase() === (node.tagName && node.tagName.toLowerCase())\n      )\n    } else {\n      return node.nodeType === (vnode.isComment ? 8 : 3)\n    }\n  }\n\n  return function patch (oldVnode, vnode, hydrating, removeOnly) {\n    if (isUndef(vnode)) {\n      if (isDef(oldVnode)) { invokeDestroyHook(oldVnode); }\n      return\n    }\n\n    var isInitialPatch = false;\n    var insertedVnodeQueue = [];\n\n    if (isUndef(oldVnode)) {\n      // empty mount (likely as component), create new root element\n      isInitialPatch = true;\n      createElm(vnode, insertedVnodeQueue);\n    } else {\n      var isRealElement = isDef(oldVnode.nodeType);\n      if (!isRealElement && sameVnode(oldVnode, vnode)) {\n        // patch existing root node\n        patchVnode(oldVnode, vnode, insertedVnodeQueue, null, null, removeOnly);\n      } else {\n        if (isRealElement) {\n          // mounting to a real element\n          // check if this is server-rendered content and if we can perform\n          // a successful hydration.\n          if (oldVnode.nodeType === 1 && oldVnode.hasAttribute(SSR_ATTR)) {\n            oldVnode.removeAttribute(SSR_ATTR);\n            hydrating = true;\n          }\n          if (isTrue(hydrating)) {\n            if (hydrate(oldVnode, vnode, insertedVnodeQueue)) {\n              invokeInsertHook(vnode, insertedVnodeQueue, true);\n              return oldVnode\n            } else if (true) {\n              warn(\n                'The client-side rendered virtual DOM tree is not matching ' +\n                'server-rendered content. This is likely caused by incorrect ' +\n                'HTML markup, for example nesting block-level elements inside ' +\n                '<p>, or missing <tbody>. Bailing hydration and performing ' +\n                'full client-side render.'\n              );\n            }\n          }\n          // either not server-rendered, or hydration failed.\n          // create an empty node and replace it\n          oldVnode = emptyNodeAt(oldVnode);\n        }\n\n        // replacing existing element\n        var oldElm = oldVnode.elm;\n        var parentElm = nodeOps.parentNode(oldElm);\n\n        // create new node\n        createElm(\n          vnode,\n          insertedVnodeQueue,\n          // extremely rare edge case: do not insert if old element is in a\n          // leaving transition. Only happens when combining transition +\n          // keep-alive + HOCs. (#4590)\n          oldElm._leaveCb ? null : parentElm,\n          nodeOps.nextSibling(oldElm)\n        );\n\n        // update parent placeholder node element, recursively\n        if (isDef(vnode.parent)) {\n          var ancestor = vnode.parent;\n          var patchable = isPatchable(vnode);\n          while (ancestor) {\n            for (var i = 0; i < cbs.destroy.length; ++i) {\n              cbs.destroy[i](ancestor);\n            }\n            ancestor.elm = vnode.elm;\n            if (patchable) {\n              for (var i$1 = 0; i$1 < cbs.create.length; ++i$1) {\n                cbs.create[i$1](emptyNode, ancestor);\n              }\n              // #6513\n              // invoke insert hooks that may have been merged by create hooks.\n              // e.g. for directives that uses the \"inserted\" hook.\n              var insert = ancestor.data.hook.insert;\n              if (insert.merged) {\n                // start at index 1 to avoid re-invoking component mounted hook\n                for (var i$2 = 1; i$2 < insert.fns.length; i$2++) {\n                  insert.fns[i$2]();\n                }\n              }\n            } else {\n              registerRef(ancestor);\n            }\n            ancestor = ancestor.parent;\n          }\n        }\n\n        // destroy old node\n        if (isDef(parentElm)) {\n          removeVnodes(parentElm, [oldVnode], 0, 0);\n        } else if (isDef(oldVnode.tag)) {\n          invokeDestroyHook(oldVnode);\n        }\n      }\n    }\n\n    invokeInsertHook(vnode, insertedVnodeQueue, isInitialPatch);\n    return vnode.elm\n  }\n}\n\n/*  */\n\nvar directives = {\n  create: updateDirectives,\n  update: updateDirectives,\n  destroy: function unbindDirectives (vnode) {\n    updateDirectives(vnode, emptyNode);\n  }\n};\n\nfunction updateDirectives (oldVnode, vnode) {\n  if (oldVnode.data.directives || vnode.data.directives) {\n    _update(oldVnode, vnode);\n  }\n}\n\nfunction _update (oldVnode, vnode) {\n  var isCreate = oldVnode === emptyNode;\n  var isDestroy = vnode === emptyNode;\n  var oldDirs = normalizeDirectives$1(oldVnode.data.directives, oldVnode.context);\n  var newDirs = normalizeDirectives$1(vnode.data.directives, vnode.context);\n\n  var dirsWithInsert = [];\n  var dirsWithPostpatch = [];\n\n  var key, oldDir, dir;\n  for (key in newDirs) {\n    oldDir = oldDirs[key];\n    dir = newDirs[key];\n    if (!oldDir) {\n      // new directive, bind\n      callHook$1(dir, 'bind', vnode, oldVnode);\n      if (dir.def && dir.def.inserted) {\n        dirsWithInsert.push(dir);\n      }\n    } else {\n      // existing directive, update\n      dir.oldValue = oldDir.value;\n      dir.oldArg = oldDir.arg;\n      callHook$1(dir, 'update', vnode, oldVnode);\n      if (dir.def && dir.def.componentUpdated) {\n        dirsWithPostpatch.push(dir);\n      }\n    }\n  }\n\n  if (dirsWithInsert.length) {\n    var callInsert = function () {\n      for (var i = 0; i < dirsWithInsert.length; i++) {\n        callHook$1(dirsWithInsert[i], 'inserted', vnode, oldVnode);\n      }\n    };\n    if (isCreate) {\n      mergeVNodeHook(vnode, 'insert', callInsert);\n    } else {\n      callInsert();\n    }\n  }\n\n  if (dirsWithPostpatch.length) {\n    mergeVNodeHook(vnode, 'postpatch', function () {\n      for (var i = 0; i < dirsWithPostpatch.length; i++) {\n        callHook$1(dirsWithPostpatch[i], 'componentUpdated', vnode, oldVnode);\n      }\n    });\n  }\n\n  if (!isCreate) {\n    for (key in oldDirs) {\n      if (!newDirs[key]) {\n        // no longer present, unbind\n        callHook$1(oldDirs[key], 'unbind', oldVnode, oldVnode, isDestroy);\n      }\n    }\n  }\n}\n\nvar emptyModifiers = Object.create(null);\n\nfunction normalizeDirectives$1 (\n  dirs,\n  vm\n) {\n  var res = Object.create(null);\n  if (!dirs) {\n    // $flow-disable-line\n    return res\n  }\n  var i, dir;\n  for (i = 0; i < dirs.length; i++) {\n    dir = dirs[i];\n    if (!dir.modifiers) {\n      // $flow-disable-line\n      dir.modifiers = emptyModifiers;\n    }\n    res[getRawDirName(dir)] = dir;\n    dir.def = resolveAsset(vm.$options, 'directives', dir.name, true);\n  }\n  // $flow-disable-line\n  return res\n}\n\nfunction getRawDirName (dir) {\n  return dir.rawName || ((dir.name) + \".\" + (Object.keys(dir.modifiers || {}).join('.')))\n}\n\nfunction callHook$1 (dir, hook, vnode, oldVnode, isDestroy) {\n  var fn = dir.def && dir.def[hook];\n  if (fn) {\n    try {\n      fn(vnode.elm, dir, vnode, oldVnode, isDestroy);\n    } catch (e) {\n      handleError(e, vnode.context, (\"directive \" + (dir.name) + \" \" + hook + \" hook\"));\n    }\n  }\n}\n\nvar baseModules = [\n  ref,\n  directives\n];\n\n/*  */\n\nfunction updateAttrs (oldVnode, vnode) {\n  var opts = vnode.componentOptions;\n  if (isDef(opts) && opts.Ctor.options.inheritAttrs === false) {\n    return\n  }\n  if (isUndef(oldVnode.data.attrs) && isUndef(vnode.data.attrs)) {\n    return\n  }\n  var key, cur, old;\n  var elm = vnode.elm;\n  var oldAttrs = oldVnode.data.attrs || {};\n  var attrs = vnode.data.attrs || {};\n  // clone observed objects, as the user probably wants to mutate it\n  if (isDef(attrs.__ob__)) {\n    attrs = vnode.data.attrs = extend({}, attrs);\n  }\n\n  for (key in attrs) {\n    cur = attrs[key];\n    old = oldAttrs[key];\n    if (old !== cur) {\n      setAttr(elm, key, cur);\n    }\n  }\n  // #4391: in IE9, setting type can reset value for input[type=radio]\n  // #6666: IE/Edge forces progress value down to 1 before setting a max\n  /* istanbul ignore if */\n  if ((isIE || isEdge) && attrs.value !== oldAttrs.value) {\n    setAttr(elm, 'value', attrs.value);\n  }\n  for (key in oldAttrs) {\n    if (isUndef(attrs[key])) {\n      if (isXlink(key)) {\n        elm.removeAttributeNS(xlinkNS, getXlinkProp(key));\n      } else if (!isEnumeratedAttr(key)) {\n        elm.removeAttribute(key);\n      }\n    }\n  }\n}\n\nfunction setAttr (el, key, value) {\n  if (el.tagName.indexOf('-') > -1) {\n    baseSetAttr(el, key, value);\n  } else if (isBooleanAttr(key)) {\n    // set attribute for blank value\n    // e.g. <option disabled>Select one</option>\n    if (isFalsyAttrValue(value)) {\n      el.removeAttribute(key);\n    } else {\n      // technically allowfullscreen is a boolean attribute for <iframe>,\n      // but Flash expects a value of \"true\" when used on <embed> tag\n      value = key === 'allowfullscreen' && el.tagName === 'EMBED'\n        ? 'true'\n        : key;\n      el.setAttribute(key, value);\n    }\n  } else if (isEnumeratedAttr(key)) {\n    el.setAttribute(key, convertEnumeratedValue(key, value));\n  } else if (isXlink(key)) {\n    if (isFalsyAttrValue(value)) {\n      el.removeAttributeNS(xlinkNS, getXlinkProp(key));\n    } else {\n      el.setAttributeNS(xlinkNS, key, value);\n    }\n  } else {\n    baseSetAttr(el, key, value);\n  }\n}\n\nfunction baseSetAttr (el, key, value) {\n  if (isFalsyAttrValue(value)) {\n    el.removeAttribute(key);\n  } else {\n    // #7138: IE10 & 11 fires input event when setting placeholder on\n    // <textarea>... block the first input event and remove the blocker\n    // immediately.\n    /* istanbul ignore if */\n    if (\n      isIE && !isIE9 &&\n      el.tagName === 'TEXTAREA' &&\n      key === 'placeholder' && value !== '' && !el.__ieph\n    ) {\n      var blocker = function (e) {\n        e.stopImmediatePropagation();\n        el.removeEventListener('input', blocker);\n      };\n      el.addEventListener('input', blocker);\n      // $flow-disable-line\n      el.__ieph = true; /* IE placeholder patched */\n    }\n    el.setAttribute(key, value);\n  }\n}\n\nvar attrs = {\n  create: updateAttrs,\n  update: updateAttrs\n};\n\n/*  */\n\nfunction updateClass (oldVnode, vnode) {\n  var el = vnode.elm;\n  var data = vnode.data;\n  var oldData = oldVnode.data;\n  if (\n    isUndef(data.staticClass) &&\n    isUndef(data.class) && (\n      isUndef(oldData) || (\n        isUndef(oldData.staticClass) &&\n        isUndef(oldData.class)\n      )\n    )\n  ) {\n    return\n  }\n\n  var cls = genClassForVnode(vnode);\n\n  // handle transition classes\n  var transitionClass = el._transitionClasses;\n  if (isDef(transitionClass)) {\n    cls = concat(cls, stringifyClass(transitionClass));\n  }\n\n  // set the class\n  if (cls !== el._prevClass) {\n    el.setAttribute('class', cls);\n    el._prevClass = cls;\n  }\n}\n\nvar klass = {\n  create: updateClass,\n  update: updateClass\n};\n\n/*  */\n\n/*  */\n\n/*  */\n\n/*  */\n\n// in some cases, the event used has to be determined at runtime\n// so we used some reserved tokens during compile.\nvar RANGE_TOKEN = '__r';\nvar CHECKBOX_RADIO_TOKEN = '__c';\n\n/*  */\n\n// normalize v-model event tokens that can only be determined at runtime.\n// it's important to place the event as the first in the array because\n// the whole point is ensuring the v-model callback gets called before\n// user-attached handlers.\nfunction normalizeEvents (on) {\n  /* istanbul ignore if */\n  if (isDef(on[RANGE_TOKEN])) {\n    // IE input[type=range] only supports `change` event\n    var event = isIE ? 'change' : 'input';\n    on[event] = [].concat(on[RANGE_TOKEN], on[event] || []);\n    delete on[RANGE_TOKEN];\n  }\n  // This was originally intended to fix #4521 but no longer necessary\n  // after 2.5. Keeping it for backwards compat with generated code from < 2.4\n  /* istanbul ignore if */\n  if (isDef(on[CHECKBOX_RADIO_TOKEN])) {\n    on.change = [].concat(on[CHECKBOX_RADIO_TOKEN], on.change || []);\n    delete on[CHECKBOX_RADIO_TOKEN];\n  }\n}\n\nvar target$1;\n\nfunction createOnceHandler$1 (event, handler, capture) {\n  var _target = target$1; // save current target element in closure\n  return function onceHandler () {\n    var res = handler.apply(null, arguments);\n    if (res !== null) {\n      remove$2(event, onceHandler, capture, _target);\n    }\n  }\n}\n\n// #9446: Firefox <= 53 (in particular, ESR 52) has incorrect Event.timeStamp\n// implementation and does not fire microtasks in between event propagation, so\n// safe to exclude.\nvar useMicrotaskFix = isUsingMicroTask && !(isFF && Number(isFF[1]) <= 53);\n\nfunction add$1 (\n  name,\n  handler,\n  capture,\n  passive\n) {\n  // async edge case #6566: inner click event triggers patch, event handler\n  // attached to outer element during patch, and triggered again. This\n  // happens because browsers fire microtask ticks between event propagation.\n  // the solution is simple: we save the timestamp when a handler is attached,\n  // and the handler would only fire if the event passed to it was fired\n  // AFTER it was attached.\n  if (useMicrotaskFix) {\n    var attachedTimestamp = currentFlushTimestamp;\n    var original = handler;\n    handler = original._wrapper = function (e) {\n      if (\n        // no bubbling, should always fire.\n        // this is just a safety net in case event.timeStamp is unreliable in\n        // certain weird environments...\n        e.target === e.currentTarget ||\n        // event is fired after handler attachment\n        e.timeStamp >= attachedTimestamp ||\n        // bail for environments that have buggy event.timeStamp implementations\n        // #9462 iOS 9 bug: event.timeStamp is 0 after history.pushState\n        // #9681 QtWebEngine event.timeStamp is negative value\n        e.timeStamp <= 0 ||\n        // #9448 bail if event is fired in another document in a multi-page\n        // electron/nw.js app, since event.timeStamp will be using a different\n        // starting reference\n        e.target.ownerDocument !== document\n      ) {\n        return original.apply(this, arguments)\n      }\n    };\n  }\n  target$1.addEventListener(\n    name,\n    handler,\n    supportsPassive\n      ? { capture: capture, passive: passive }\n      : capture\n  );\n}\n\nfunction remove$2 (\n  name,\n  handler,\n  capture,\n  _target\n) {\n  (_target || target$1).removeEventListener(\n    name,\n    handler._wrapper || handler,\n    capture\n  );\n}\n\nfunction updateDOMListeners (oldVnode, vnode) {\n  if (isUndef(oldVnode.data.on) && isUndef(vnode.data.on)) {\n    return\n  }\n  var on = vnode.data.on || {};\n  var oldOn = oldVnode.data.on || {};\n  target$1 = vnode.elm;\n  normalizeEvents(on);\n  updateListeners(on, oldOn, add$1, remove$2, createOnceHandler$1, vnode.context);\n  target$1 = undefined;\n}\n\nvar events = {\n  create: updateDOMListeners,\n  update: updateDOMListeners\n};\n\n/*  */\n\nvar svgContainer;\n\nfunction updateDOMProps (oldVnode, vnode) {\n  if (isUndef(oldVnode.data.domProps) && isUndef(vnode.data.domProps)) {\n    return\n  }\n  var key, cur;\n  var elm = vnode.elm;\n  var oldProps = oldVnode.data.domProps || {};\n  var props = vnode.data.domProps || {};\n  // clone observed objects, as the user probably wants to mutate it\n  if (isDef(props.__ob__)) {\n    props = vnode.data.domProps = extend({}, props);\n  }\n\n  for (key in oldProps) {\n    if (!(key in props)) {\n      elm[key] = '';\n    }\n  }\n\n  for (key in props) {\n    cur = props[key];\n    // ignore children if the node has textContent or innerHTML,\n    // as these will throw away existing DOM nodes and cause removal errors\n    // on subsequent patches (#3360)\n    if (key === 'textContent' || key === 'innerHTML') {\n      if (vnode.children) { vnode.children.length = 0; }\n      if (cur === oldProps[key]) { continue }\n      // #6601 work around Chrome version <= 55 bug where single textNode\n      // replaced by innerHTML/textContent retains its parentNode property\n      if (elm.childNodes.length === 1) {\n        elm.removeChild(elm.childNodes[0]);\n      }\n    }\n\n    if (key === 'value' && elm.tagName !== 'PROGRESS') {\n      // store value as _value as well since\n      // non-string values will be stringified\n      elm._value = cur;\n      // avoid resetting cursor position when value is the same\n      var strCur = isUndef(cur) ? '' : String(cur);\n      if (shouldUpdateValue(elm, strCur)) {\n        elm.value = strCur;\n      }\n    } else if (key === 'innerHTML' && isSVG(elm.tagName) && isUndef(elm.innerHTML)) {\n      // IE doesn't support innerHTML for SVG elements\n      svgContainer = svgContainer || document.createElement('div');\n      svgContainer.innerHTML = \"<svg>\" + cur + \"</svg>\";\n      var svg = svgContainer.firstChild;\n      while (elm.firstChild) {\n        elm.removeChild(elm.firstChild);\n      }\n      while (svg.firstChild) {\n        elm.appendChild(svg.firstChild);\n      }\n    } else if (\n      // skip the update if old and new VDOM state is the same.\n      // `value` is handled separately because the DOM value may be temporarily\n      // out of sync with VDOM state due to focus, composition and modifiers.\n      // This  #4521 by skipping the unnecesarry `checked` update.\n      cur !== oldProps[key]\n    ) {\n      // some property updates can throw\n      // e.g. `value` on <progress> w/ non-finite value\n      try {\n        elm[key] = cur;\n      } catch (e) {}\n    }\n  }\n}\n\n// check platforms/web/util/attrs.js acceptValue\n\n\nfunction shouldUpdateValue (elm, checkVal) {\n  return (!elm.composing && (\n    elm.tagName === 'OPTION' ||\n    isNotInFocusAndDirty(elm, checkVal) ||\n    isDirtyWithModifiers(elm, checkVal)\n  ))\n}\n\nfunction isNotInFocusAndDirty (elm, checkVal) {\n  // return true when textbox (.number and .trim) loses focus and its value is\n  // not equal to the updated value\n  var notInFocus = true;\n  // #6157\n  // work around IE bug when accessing document.activeElement in an iframe\n  try { notInFocus = document.activeElement !== elm; } catch (e) {}\n  return notInFocus && elm.value !== checkVal\n}\n\nfunction isDirtyWithModifiers (elm, newVal) {\n  var value = elm.value;\n  var modifiers = elm._vModifiers; // injected by v-model runtime\n  if (isDef(modifiers)) {\n    if (modifiers.number) {\n      return toNumber(value) !== toNumber(newVal)\n    }\n    if (modifiers.trim) {\n      return value.trim() !== newVal.trim()\n    }\n  }\n  return value !== newVal\n}\n\nvar domProps = {\n  create: updateDOMProps,\n  update: updateDOMProps\n};\n\n/*  */\n\nvar parseStyleText = cached(function (cssText) {\n  var res = {};\n  var listDelimiter = /;(?![^(]*\\))/g;\n  var propertyDelimiter = /:(.+)/;\n  cssText.split(listDelimiter).forEach(function (item) {\n    if (item) {\n      var tmp = item.split(propertyDelimiter);\n      tmp.length > 1 && (res[tmp[0].trim()] = tmp[1].trim());\n    }\n  });\n  return res\n});\n\n// merge static and dynamic style data on the same vnode\nfunction normalizeStyleData (data) {\n  var style = normalizeStyleBinding(data.style);\n  // static style is pre-processed into an object during compilation\n  // and is always a fresh object, so it's safe to merge into it\n  return data.staticStyle\n    ? extend(data.staticStyle, style)\n    : style\n}\n\n// normalize possible array / string values into Object\nfunction normalizeStyleBinding (bindingStyle) {\n  if (Array.isArray(bindingStyle)) {\n    return toObject(bindingStyle)\n  }\n  if (typeof bindingStyle === 'string') {\n    return parseStyleText(bindingStyle)\n  }\n  return bindingStyle\n}\n\n/**\n * parent component style should be after child's\n * so that parent component's style could override it\n */\nfunction getStyle (vnode, checkChild) {\n  var res = {};\n  var styleData;\n\n  if (checkChild) {\n    var childNode = vnode;\n    while (childNode.componentInstance) {\n      childNode = childNode.componentInstance._vnode;\n      if (\n        childNode && childNode.data &&\n        (styleData = normalizeStyleData(childNode.data))\n      ) {\n        extend(res, styleData);\n      }\n    }\n  }\n\n  if ((styleData = normalizeStyleData(vnode.data))) {\n    extend(res, styleData);\n  }\n\n  var parentNode = vnode;\n  while ((parentNode = parentNode.parent)) {\n    if (parentNode.data && (styleData = normalizeStyleData(parentNode.data))) {\n      extend(res, styleData);\n    }\n  }\n  return res\n}\n\n/*  */\n\nvar cssVarRE = /^--/;\nvar importantRE = /\\s*!important$/;\nvar setProp = function (el, name, val) {\n  /* istanbul ignore if */\n  if (cssVarRE.test(name)) {\n    el.style.setProperty(name, val);\n  } else if (importantRE.test(val)) {\n    el.style.setProperty(hyphenate(name), val.replace(importantRE, ''), 'important');\n  } else {\n    var normalizedName = normalize(name);\n    if (Array.isArray(val)) {\n      // Support values array created by autoprefixer, e.g.\n      // {display: [\"-webkit-box\", \"-ms-flexbox\", \"flex\"]}\n      // Set them one by one, and the browser will only set those it can recognize\n      for (var i = 0, len = val.length; i < len; i++) {\n        el.style[normalizedName] = val[i];\n      }\n    } else {\n      el.style[normalizedName] = val;\n    }\n  }\n};\n\nvar vendorNames = ['Webkit', 'Moz', 'ms'];\n\nvar emptyStyle;\nvar normalize = cached(function (prop) {\n  emptyStyle = emptyStyle || document.createElement('div').style;\n  prop = camelize(prop);\n  if (prop !== 'filter' && (prop in emptyStyle)) {\n    return prop\n  }\n  var capName = prop.charAt(0).toUpperCase() + prop.slice(1);\n  for (var i = 0; i < vendorNames.length; i++) {\n    var name = vendorNames[i] + capName;\n    if (name in emptyStyle) {\n      return name\n    }\n  }\n});\n\nfunction updateStyle (oldVnode, vnode) {\n  var data = vnode.data;\n  var oldData = oldVnode.data;\n\n  if (isUndef(data.staticStyle) && isUndef(data.style) &&\n    isUndef(oldData.staticStyle) && isUndef(oldData.style)\n  ) {\n    return\n  }\n\n  var cur, name;\n  var el = vnode.elm;\n  var oldStaticStyle = oldData.staticStyle;\n  var oldStyleBinding = oldData.normalizedStyle || oldData.style || {};\n\n  // if static style exists, stylebinding already merged into it when doing normalizeStyleData\n  var oldStyle = oldStaticStyle || oldStyleBinding;\n\n  var style = normalizeStyleBinding(vnode.data.style) || {};\n\n  // store normalized style under a different key for next diff\n  // make sure to clone it if it's reactive, since the user likely wants\n  // to mutate it.\n  vnode.data.normalizedStyle = isDef(style.__ob__)\n    ? extend({}, style)\n    : style;\n\n  var newStyle = getStyle(vnode, true);\n\n  for (name in oldStyle) {\n    if (isUndef(newStyle[name])) {\n      setProp(el, name, '');\n    }\n  }\n  for (name in newStyle) {\n    cur = newStyle[name];\n    if (cur !== oldStyle[name]) {\n      // ie9 setting to null has no effect, must use empty string\n      setProp(el, name, cur == null ? '' : cur);\n    }\n  }\n}\n\nvar style = {\n  create: updateStyle,\n  update: updateStyle\n};\n\n/*  */\n\nvar whitespaceRE = /\\s+/;\n\n/**\n * Add class with compatibility for SVG since classList is not supported on\n * SVG elements in IE\n */\nfunction addClass (el, cls) {\n  /* istanbul ignore if */\n  if (!cls || !(cls = cls.trim())) {\n    return\n  }\n\n  /* istanbul ignore else */\n  if (el.classList) {\n    if (cls.indexOf(' ') > -1) {\n      cls.split(whitespaceRE).forEach(function (c) { return el.classList.add(c); });\n    } else {\n      el.classList.add(cls);\n    }\n  } else {\n    var cur = \" \" + (el.getAttribute('class') || '') + \" \";\n    if (cur.indexOf(' ' + cls + ' ') < 0) {\n      el.setAttribute('class', (cur + cls).trim());\n    }\n  }\n}\n\n/**\n * Remove class with compatibility for SVG since classList is not supported on\n * SVG elements in IE\n */\nfunction removeClass (el, cls) {\n  /* istanbul ignore if */\n  if (!cls || !(cls = cls.trim())) {\n    return\n  }\n\n  /* istanbul ignore else */\n  if (el.classList) {\n    if (cls.indexOf(' ') > -1) {\n      cls.split(whitespaceRE).forEach(function (c) { return el.classList.remove(c); });\n    } else {\n      el.classList.remove(cls);\n    }\n    if (!el.classList.length) {\n      el.removeAttribute('class');\n    }\n  } else {\n    var cur = \" \" + (el.getAttribute('class') || '') + \" \";\n    var tar = ' ' + cls + ' ';\n    while (cur.indexOf(tar) >= 0) {\n      cur = cur.replace(tar, ' ');\n    }\n    cur = cur.trim();\n    if (cur) {\n      el.setAttribute('class', cur);\n    } else {\n      el.removeAttribute('class');\n    }\n  }\n}\n\n/*  */\n\nfunction resolveTransition (def$$1) {\n  if (!def$$1) {\n    return\n  }\n  /* istanbul ignore else */\n  if (typeof def$$1 === 'object') {\n    var res = {};\n    if (def$$1.css !== false) {\n      extend(res, autoCssTransition(def$$1.name || 'v'));\n    }\n    extend(res, def$$1);\n    return res\n  } else if (typeof def$$1 === 'string') {\n    return autoCssTransition(def$$1)\n  }\n}\n\nvar autoCssTransition = cached(function (name) {\n  return {\n    enterClass: (name + \"-enter\"),\n    enterToClass: (name + \"-enter-to\"),\n    enterActiveClass: (name + \"-enter-active\"),\n    leaveClass: (name + \"-leave\"),\n    leaveToClass: (name + \"-leave-to\"),\n    leaveActiveClass: (name + \"-leave-active\")\n  }\n});\n\nvar hasTransition = inBrowser && !isIE9;\nvar TRANSITION = 'transition';\nvar ANIMATION = 'animation';\n\n// Transition property/event sniffing\nvar transitionProp = 'transition';\nvar transitionEndEvent = 'transitionend';\nvar animationProp = 'animation';\nvar animationEndEvent = 'animationend';\nif (hasTransition) {\n  /* istanbul ignore if */\n  if (window.ontransitionend === undefined &&\n    window.onwebkittransitionend !== undefined\n  ) {\n    transitionProp = 'WebkitTransition';\n    transitionEndEvent = 'webkitTransitionEnd';\n  }\n  if (window.onanimationend === undefined &&\n    window.onwebkitanimationend !== undefined\n  ) {\n    animationProp = 'WebkitAnimation';\n    animationEndEvent = 'webkitAnimationEnd';\n  }\n}\n\n// binding to window is necessary to make hot reload work in IE in strict mode\nvar raf = inBrowser\n  ? window.requestAnimationFrame\n    ? window.requestAnimationFrame.bind(window)\n    : setTimeout\n  : /* istanbul ignore next */ function (fn) { return fn(); };\n\nfunction nextFrame (fn) {\n  raf(function () {\n    raf(fn);\n  });\n}\n\nfunction addTransitionClass (el, cls) {\n  var transitionClasses = el._transitionClasses || (el._transitionClasses = []);\n  if (transitionClasses.indexOf(cls) < 0) {\n    transitionClasses.push(cls);\n    addClass(el, cls);\n  }\n}\n\nfunction removeTransitionClass (el, cls) {\n  if (el._transitionClasses) {\n    remove(el._transitionClasses, cls);\n  }\n  removeClass(el, cls);\n}\n\nfunction whenTransitionEnds (\n  el,\n  expectedType,\n  cb\n) {\n  var ref = getTransitionInfo(el, expectedType);\n  var type = ref.type;\n  var timeout = ref.timeout;\n  var propCount = ref.propCount;\n  if (!type) { return cb() }\n  var event = type === TRANSITION ? transitionEndEvent : animationEndEvent;\n  var ended = 0;\n  var end = function () {\n    el.removeEventListener(event, onEnd);\n    cb();\n  };\n  var onEnd = function (e) {\n    if (e.target === el) {\n      if (++ended >= propCount) {\n        end();\n      }\n    }\n  };\n  setTimeout(function () {\n    if (ended < propCount) {\n      end();\n    }\n  }, timeout + 1);\n  el.addEventListener(event, onEnd);\n}\n\nvar transformRE = /\\b(transform|all)(,|$)/;\n\nfunction getTransitionInfo (el, expectedType) {\n  var styles = window.getComputedStyle(el);\n  // JSDOM may return undefined for transition properties\n  var transitionDelays = (styles[transitionProp + 'Delay'] || '').split(', ');\n  var transitionDurations = (styles[transitionProp + 'Duration'] || '').split(', ');\n  var transitionTimeout = getTimeout(transitionDelays, transitionDurations);\n  var animationDelays = (styles[animationProp + 'Delay'] || '').split(', ');\n  var animationDurations = (styles[animationProp + 'Duration'] || '').split(', ');\n  var animationTimeout = getTimeout(animationDelays, animationDurations);\n\n  var type;\n  var timeout = 0;\n  var propCount = 0;\n  /* istanbul ignore if */\n  if (expectedType === TRANSITION) {\n    if (transitionTimeout > 0) {\n      type = TRANSITION;\n      timeout = transitionTimeout;\n      propCount = transitionDurations.length;\n    }\n  } else if (expectedType === ANIMATION) {\n    if (animationTimeout > 0) {\n      type = ANIMATION;\n      timeout = animationTimeout;\n      propCount = animationDurations.length;\n    }\n  } else {\n    timeout = Math.max(transitionTimeout, animationTimeout);\n    type = timeout > 0\n      ? transitionTimeout > animationTimeout\n        ? TRANSITION\n        : ANIMATION\n      : null;\n    propCount = type\n      ? type === TRANSITION\n        ? transitionDurations.length\n        : animationDurations.length\n      : 0;\n  }\n  var hasTransform =\n    type === TRANSITION &&\n    transformRE.test(styles[transitionProp + 'Property']);\n  return {\n    type: type,\n    timeout: timeout,\n    propCount: propCount,\n    hasTransform: hasTransform\n  }\n}\n\nfunction getTimeout (delays, durations) {\n  /* istanbul ignore next */\n  while (delays.length < durations.length) {\n    delays = delays.concat(delays);\n  }\n\n  return Math.max.apply(null, durations.map(function (d, i) {\n    return toMs(d) + toMs(delays[i])\n  }))\n}\n\n// Old versions of Chromium (below 61.0.3163.100) formats floating pointer numbers\n// in a locale-dependent way, using a comma instead of a dot.\n// If comma is not replaced with a dot, the input will be rounded down (i.e. acting\n// as a floor function) causing unexpected behaviors\nfunction toMs (s) {\n  return Number(s.slice(0, -1).replace(',', '.')) * 1000\n}\n\n/*  */\n\nfunction enter (vnode, toggleDisplay) {\n  var el = vnode.elm;\n\n  // call leave callback now\n  if (isDef(el._leaveCb)) {\n    el._leaveCb.cancelled = true;\n    el._leaveCb();\n  }\n\n  var data = resolveTransition(vnode.data.transition);\n  if (isUndef(data)) {\n    return\n  }\n\n  /* istanbul ignore if */\n  if (isDef(el._enterCb) || el.nodeType !== 1) {\n    return\n  }\n\n  var css = data.css;\n  var type = data.type;\n  var enterClass = data.enterClass;\n  var enterToClass = data.enterToClass;\n  var enterActiveClass = data.enterActiveClass;\n  var appearClass = data.appearClass;\n  var appearToClass = data.appearToClass;\n  var appearActiveClass = data.appearActiveClass;\n  var beforeEnter = data.beforeEnter;\n  var enter = data.enter;\n  var afterEnter = data.afterEnter;\n  var enterCancelled = data.enterCancelled;\n  var beforeAppear = data.beforeAppear;\n  var appear = data.appear;\n  var afterAppear = data.afterAppear;\n  var appearCancelled = data.appearCancelled;\n  var duration = data.duration;\n\n  // activeInstance will always be the <transition> component managing this\n  // transition. One edge case to check is when the <transition> is placed\n  // as the root node of a child component. In that case we need to check\n  // <transition>'s parent for appear check.\n  var context = activeInstance;\n  var transitionNode = activeInstance.$vnode;\n  while (transitionNode && transitionNode.parent) {\n    context = transitionNode.context;\n    transitionNode = transitionNode.parent;\n  }\n\n  var isAppear = !context._isMounted || !vnode.isRootInsert;\n\n  if (isAppear && !appear && appear !== '') {\n    return\n  }\n\n  var startClass = isAppear && appearClass\n    ? appearClass\n    : enterClass;\n  var activeClass = isAppear && appearActiveClass\n    ? appearActiveClass\n    : enterActiveClass;\n  var toClass = isAppear && appearToClass\n    ? appearToClass\n    : enterToClass;\n\n  var beforeEnterHook = isAppear\n    ? (beforeAppear || beforeEnter)\n    : beforeEnter;\n  var enterHook = isAppear\n    ? (typeof appear === 'function' ? appear : enter)\n    : enter;\n  var afterEnterHook = isAppear\n    ? (afterAppear || afterEnter)\n    : afterEnter;\n  var enterCancelledHook = isAppear\n    ? (appearCancelled || enterCancelled)\n    : enterCancelled;\n\n  var explicitEnterDuration = toNumber(\n    isObject(duration)\n      ? duration.enter\n      : duration\n  );\n\n  if ( true && explicitEnterDuration != null) {\n    checkDuration(explicitEnterDuration, 'enter', vnode);\n  }\n\n  var expectsCSS = css !== false && !isIE9;\n  var userWantsControl = getHookArgumentsLength(enterHook);\n\n  var cb = el._enterCb = once(function () {\n    if (expectsCSS) {\n      removeTransitionClass(el, toClass);\n      removeTransitionClass(el, activeClass);\n    }\n    if (cb.cancelled) {\n      if (expectsCSS) {\n        removeTransitionClass(el, startClass);\n      }\n      enterCancelledHook && enterCancelledHook(el);\n    } else {\n      afterEnterHook && afterEnterHook(el);\n    }\n    el._enterCb = null;\n  });\n\n  if (!vnode.data.show) {\n    // remove pending leave element on enter by injecting an insert hook\n    mergeVNodeHook(vnode, 'insert', function () {\n      var parent = el.parentNode;\n      var pendingNode = parent && parent._pending && parent._pending[vnode.key];\n      if (pendingNode &&\n        pendingNode.tag === vnode.tag &&\n        pendingNode.elm._leaveCb\n      ) {\n        pendingNode.elm._leaveCb();\n      }\n      enterHook && enterHook(el, cb);\n    });\n  }\n\n  // start enter transition\n  beforeEnterHook && beforeEnterHook(el);\n  if (expectsCSS) {\n    addTransitionClass(el, startClass);\n    addTransitionClass(el, activeClass);\n    nextFrame(function () {\n      removeTransitionClass(el, startClass);\n      if (!cb.cancelled) {\n        addTransitionClass(el, toClass);\n        if (!userWantsControl) {\n          if (isValidDuration(explicitEnterDuration)) {\n            setTimeout(cb, explicitEnterDuration);\n          } else {\n            whenTransitionEnds(el, type, cb);\n          }\n        }\n      }\n    });\n  }\n\n  if (vnode.data.show) {\n    toggleDisplay && toggleDisplay();\n    enterHook && enterHook(el, cb);\n  }\n\n  if (!expectsCSS && !userWantsControl) {\n    cb();\n  }\n}\n\nfunction leave (vnode, rm) {\n  var el = vnode.elm;\n\n  // call enter callback now\n  if (isDef(el._enterCb)) {\n    el._enterCb.cancelled = true;\n    el._enterCb();\n  }\n\n  var data = resolveTransition(vnode.data.transition);\n  if (isUndef(data) || el.nodeType !== 1) {\n    return rm()\n  }\n\n  /* istanbul ignore if */\n  if (isDef(el._leaveCb)) {\n    return\n  }\n\n  var css = data.css;\n  var type = data.type;\n  var leaveClass = data.leaveClass;\n  var leaveToClass = data.leaveToClass;\n  var leaveActiveClass = data.leaveActiveClass;\n  var beforeLeave = data.beforeLeave;\n  var leave = data.leave;\n  var afterLeave = data.afterLeave;\n  var leaveCancelled = data.leaveCancelled;\n  var delayLeave = data.delayLeave;\n  var duration = data.duration;\n\n  var expectsCSS = css !== false && !isIE9;\n  var userWantsControl = getHookArgumentsLength(leave);\n\n  var explicitLeaveDuration = toNumber(\n    isObject(duration)\n      ? duration.leave\n      : duration\n  );\n\n  if ( true && isDef(explicitLeaveDuration)) {\n    checkDuration(explicitLeaveDuration, 'leave', vnode);\n  }\n\n  var cb = el._leaveCb = once(function () {\n    if (el.parentNode && el.parentNode._pending) {\n      el.parentNode._pending[vnode.key] = null;\n    }\n    if (expectsCSS) {\n      removeTransitionClass(el, leaveToClass);\n      removeTransitionClass(el, leaveActiveClass);\n    }\n    if (cb.cancelled) {\n      if (expectsCSS) {\n        removeTransitionClass(el, leaveClass);\n      }\n      leaveCancelled && leaveCancelled(el);\n    } else {\n      rm();\n      afterLeave && afterLeave(el);\n    }\n    el._leaveCb = null;\n  });\n\n  if (delayLeave) {\n    delayLeave(performLeave);\n  } else {\n    performLeave();\n  }\n\n  function performLeave () {\n    // the delayed leave may have already been cancelled\n    if (cb.cancelled) {\n      return\n    }\n    // record leaving element\n    if (!vnode.data.show && el.parentNode) {\n      (el.parentNode._pending || (el.parentNode._pending = {}))[(vnode.key)] = vnode;\n    }\n    beforeLeave && beforeLeave(el);\n    if (expectsCSS) {\n      addTransitionClass(el, leaveClass);\n      addTransitionClass(el, leaveActiveClass);\n      nextFrame(function () {\n        removeTransitionClass(el, leaveClass);\n        if (!cb.cancelled) {\n          addTransitionClass(el, leaveToClass);\n          if (!userWantsControl) {\n            if (isValidDuration(explicitLeaveDuration)) {\n              setTimeout(cb, explicitLeaveDuration);\n            } else {\n              whenTransitionEnds(el, type, cb);\n            }\n          }\n        }\n      });\n    }\n    leave && leave(el, cb);\n    if (!expectsCSS && !userWantsControl) {\n      cb();\n    }\n  }\n}\n\n// only used in dev mode\nfunction checkDuration (val, name, vnode) {\n  if (typeof val !== 'number') {\n    warn(\n      \"<transition> explicit \" + name + \" duration is not a valid number - \" +\n      \"got \" + (JSON.stringify(val)) + \".\",\n      vnode.context\n    );\n  } else if (isNaN(val)) {\n    warn(\n      \"<transition> explicit \" + name + \" duration is NaN - \" +\n      'the duration expression might be incorrect.',\n      vnode.context\n    );\n  }\n}\n\nfunction isValidDuration (val) {\n  return typeof val === 'number' && !isNaN(val)\n}\n\n/**\n * Normalize a transition hook's argument length. The hook may be:\n * - a merged hook (invoker) with the original in .fns\n * - a wrapped component method (check ._length)\n * - a plain function (.length)\n */\nfunction getHookArgumentsLength (fn) {\n  if (isUndef(fn)) {\n    return false\n  }\n  var invokerFns = fn.fns;\n  if (isDef(invokerFns)) {\n    // invoker\n    return getHookArgumentsLength(\n      Array.isArray(invokerFns)\n        ? invokerFns[0]\n        : invokerFns\n    )\n  } else {\n    return (fn._length || fn.length) > 1\n  }\n}\n\nfunction _enter (_, vnode) {\n  if (vnode.data.show !== true) {\n    enter(vnode);\n  }\n}\n\nvar transition = inBrowser ? {\n  create: _enter,\n  activate: _enter,\n  remove: function remove$$1 (vnode, rm) {\n    /* istanbul ignore else */\n    if (vnode.data.show !== true) {\n      leave(vnode, rm);\n    } else {\n      rm();\n    }\n  }\n} : {};\n\nvar platformModules = [\n  attrs,\n  klass,\n  events,\n  domProps,\n  style,\n  transition\n];\n\n/*  */\n\n// the directive module should be applied last, after all\n// built-in modules have been applied.\nvar modules = platformModules.concat(baseModules);\n\nvar patch = createPatchFunction({ nodeOps: nodeOps, modules: modules });\n\n/**\n * Not type checking this file because flow doesn't like attaching\n * properties to Elements.\n */\n\n/* istanbul ignore if */\nif (isIE9) {\n  // http://www.matts411.com/post/internet-explorer-9-oninput/\n  document.addEventListener('selectionchange', function () {\n    var el = document.activeElement;\n    if (el && el.vmodel) {\n      trigger(el, 'input');\n    }\n  });\n}\n\nvar directive = {\n  inserted: function inserted (el, binding, vnode, oldVnode) {\n    if (vnode.tag === 'select') {\n      // #6903\n      if (oldVnode.elm && !oldVnode.elm._vOptions) {\n        mergeVNodeHook(vnode, 'postpatch', function () {\n          directive.componentUpdated(el, binding, vnode);\n        });\n      } else {\n        setSelected(el, binding, vnode.context);\n      }\n      el._vOptions = [].map.call(el.options, getValue);\n    } else if (vnode.tag === 'textarea' || isTextInputType(el.type)) {\n      el._vModifiers = binding.modifiers;\n      if (!binding.modifiers.lazy) {\n        el.addEventListener('compositionstart', onCompositionStart);\n        el.addEventListener('compositionend', onCompositionEnd);\n        // Safari < 10.2 & UIWebView doesn't fire compositionend when\n        // switching focus before confirming composition choice\n        // this also fixes the issue where some browsers e.g. iOS Chrome\n        // fires \"change\" instead of \"input\" on autocomplete.\n        el.addEventListener('change', onCompositionEnd);\n        /* istanbul ignore if */\n        if (isIE9) {\n          el.vmodel = true;\n        }\n      }\n    }\n  },\n\n  componentUpdated: function componentUpdated (el, binding, vnode) {\n    if (vnode.tag === 'select') {\n      setSelected(el, binding, vnode.context);\n      // in case the options rendered by v-for have changed,\n      // it's possible that the value is out-of-sync with the rendered options.\n      // detect such cases and filter out values that no longer has a matching\n      // option in the DOM.\n      var prevOptions = el._vOptions;\n      var curOptions = el._vOptions = [].map.call(el.options, getValue);\n      if (curOptions.some(function (o, i) { return !looseEqual(o, prevOptions[i]); })) {\n        // trigger change event if\n        // no matching option found for at least one value\n        var needReset = el.multiple\n          ? binding.value.some(function (v) { return hasNoMatchingOption(v, curOptions); })\n          : binding.value !== binding.oldValue && hasNoMatchingOption(binding.value, curOptions);\n        if (needReset) {\n          trigger(el, 'change');\n        }\n      }\n    }\n  }\n};\n\nfunction setSelected (el, binding, vm) {\n  actuallySetSelected(el, binding, vm);\n  /* istanbul ignore if */\n  if (isIE || isEdge) {\n    setTimeout(function () {\n      actuallySetSelected(el, binding, vm);\n    }, 0);\n  }\n}\n\nfunction actuallySetSelected (el, binding, vm) {\n  var value = binding.value;\n  var isMultiple = el.multiple;\n  if (isMultiple && !Array.isArray(value)) {\n     true && warn(\n      \"<select multiple v-model=\\\"\" + (binding.expression) + \"\\\"> \" +\n      \"expects an Array value for its binding, but got \" + (Object.prototype.toString.call(value).slice(8, -1)),\n      vm\n    );\n    return\n  }\n  var selected, option;\n  for (var i = 0, l = el.options.length; i < l; i++) {\n    option = el.options[i];\n    if (isMultiple) {\n      selected = looseIndexOf(value, getValue(option)) > -1;\n      if (option.selected !== selected) {\n        option.selected = selected;\n      }\n    } else {\n      if (looseEqual(getValue(option), value)) {\n        if (el.selectedIndex !== i) {\n          el.selectedIndex = i;\n        }\n        return\n      }\n    }\n  }\n  if (!isMultiple) {\n    el.selectedIndex = -1;\n  }\n}\n\nfunction hasNoMatchingOption (value, options) {\n  return options.every(function (o) { return !looseEqual(o, value); })\n}\n\nfunction getValue (option) {\n  return '_value' in option\n    ? option._value\n    : option.value\n}\n\nfunction onCompositionStart (e) {\n  e.target.composing = true;\n}\n\nfunction onCompositionEnd (e) {\n  // prevent triggering an input event for no reason\n  if (!e.target.composing) { return }\n  e.target.composing = false;\n  trigger(e.target, 'input');\n}\n\nfunction trigger (el, type) {\n  var e = document.createEvent('HTMLEvents');\n  e.initEvent(type, true, true);\n  el.dispatchEvent(e);\n}\n\n/*  */\n\n// recursively search for possible transition defined inside the component root\nfunction locateNode (vnode) {\n  return vnode.componentInstance && (!vnode.data || !vnode.data.transition)\n    ? locateNode(vnode.componentInstance._vnode)\n    : vnode\n}\n\nvar show = {\n  bind: function bind (el, ref, vnode) {\n    var value = ref.value;\n\n    vnode = locateNode(vnode);\n    var transition$$1 = vnode.data && vnode.data.transition;\n    var originalDisplay = el.__vOriginalDisplay =\n      el.style.display === 'none' ? '' : el.style.display;\n    if (value && transition$$1) {\n      vnode.data.show = true;\n      enter(vnode, function () {\n        el.style.display = originalDisplay;\n      });\n    } else {\n      el.style.display = value ? originalDisplay : 'none';\n    }\n  },\n\n  update: function update (el, ref, vnode) {\n    var value = ref.value;\n    var oldValue = ref.oldValue;\n\n    /* istanbul ignore if */\n    if (!value === !oldValue) { return }\n    vnode = locateNode(vnode);\n    var transition$$1 = vnode.data && vnode.data.transition;\n    if (transition$$1) {\n      vnode.data.show = true;\n      if (value) {\n        enter(vnode, function () {\n          el.style.display = el.__vOriginalDisplay;\n        });\n      } else {\n        leave(vnode, function () {\n          el.style.display = 'none';\n        });\n      }\n    } else {\n      el.style.display = value ? el.__vOriginalDisplay : 'none';\n    }\n  },\n\n  unbind: function unbind (\n    el,\n    binding,\n    vnode,\n    oldVnode,\n    isDestroy\n  ) {\n    if (!isDestroy) {\n      el.style.display = el.__vOriginalDisplay;\n    }\n  }\n};\n\nvar platformDirectives = {\n  model: directive,\n  show: show\n};\n\n/*  */\n\nvar transitionProps = {\n  name: String,\n  appear: Boolean,\n  css: Boolean,\n  mode: String,\n  type: String,\n  enterClass: String,\n  leaveClass: String,\n  enterToClass: String,\n  leaveToClass: String,\n  enterActiveClass: String,\n  leaveActiveClass: String,\n  appearClass: String,\n  appearActiveClass: String,\n  appearToClass: String,\n  duration: [Number, String, Object]\n};\n\n// in case the child is also an abstract component, e.g. <keep-alive>\n// we want to recursively retrieve the real component to be rendered\nfunction getRealChild (vnode) {\n  var compOptions = vnode && vnode.componentOptions;\n  if (compOptions && compOptions.Ctor.options.abstract) {\n    return getRealChild(getFirstComponentChild(compOptions.children))\n  } else {\n    return vnode\n  }\n}\n\nfunction extractTransitionData (comp) {\n  var data = {};\n  var options = comp.$options;\n  // props\n  for (var key in options.propsData) {\n    data[key] = comp[key];\n  }\n  // events.\n  // extract listeners and pass them directly to the transition methods\n  var listeners = options._parentListeners;\n  for (var key$1 in listeners) {\n    data[camelize(key$1)] = listeners[key$1];\n  }\n  return data\n}\n\nfunction placeholder (h, rawChild) {\n  if (/\\d-keep-alive$/.test(rawChild.tag)) {\n    return h('keep-alive', {\n      props: rawChild.componentOptions.propsData\n    })\n  }\n}\n\nfunction hasParentTransition (vnode) {\n  while ((vnode = vnode.parent)) {\n    if (vnode.data.transition) {\n      return true\n    }\n  }\n}\n\nfunction isSameChild (child, oldChild) {\n  return oldChild.key === child.key && oldChild.tag === child.tag\n}\n\nvar isNotTextNode = function (c) { return c.tag || isAsyncPlaceholder(c); };\n\nvar isVShowDirective = function (d) { return d.name === 'show'; };\n\nvar Transition = {\n  name: 'transition',\n  props: transitionProps,\n  abstract: true,\n\n  render: function render (h) {\n    var this$1 = this;\n\n    var children = this.$slots.default;\n    if (!children) {\n      return\n    }\n\n    // filter out text nodes (possible whitespaces)\n    children = children.filter(isNotTextNode);\n    /* istanbul ignore if */\n    if (!children.length) {\n      return\n    }\n\n    // warn multiple elements\n    if ( true && children.length > 1) {\n      warn(\n        '<transition> can only be used on a single element. Use ' +\n        '<transition-group> for lists.',\n        this.$parent\n      );\n    }\n\n    var mode = this.mode;\n\n    // warn invalid mode\n    if ( true &&\n      mode && mode !== 'in-out' && mode !== 'out-in'\n    ) {\n      warn(\n        'invalid <transition> mode: ' + mode,\n        this.$parent\n      );\n    }\n\n    var rawChild = children[0];\n\n    // if this is a component root node and the component's\n    // parent container node also has transition, skip.\n    if (hasParentTransition(this.$vnode)) {\n      return rawChild\n    }\n\n    // apply transition data to child\n    // use getRealChild() to ignore abstract components e.g. keep-alive\n    var child = getRealChild(rawChild);\n    /* istanbul ignore if */\n    if (!child) {\n      return rawChild\n    }\n\n    if (this._leaving) {\n      return placeholder(h, rawChild)\n    }\n\n    // ensure a key that is unique to the vnode type and to this transition\n    // component instance. This key will be used to remove pending leaving nodes\n    // during entering.\n    var id = \"__transition-\" + (this._uid) + \"-\";\n    child.key = child.key == null\n      ? child.isComment\n        ? id + 'comment'\n        : id + child.tag\n      : isPrimitive(child.key)\n        ? (String(child.key).indexOf(id) === 0 ? child.key : id + child.key)\n        : child.key;\n\n    var data = (child.data || (child.data = {})).transition = extractTransitionData(this);\n    var oldRawChild = this._vnode;\n    var oldChild = getRealChild(oldRawChild);\n\n    // mark v-show\n    // so that the transition module can hand over the control to the directive\n    if (child.data.directives && child.data.directives.some(isVShowDirective)) {\n      child.data.show = true;\n    }\n\n    if (\n      oldChild &&\n      oldChild.data &&\n      !isSameChild(child, oldChild) &&\n      !isAsyncPlaceholder(oldChild) &&\n      // #6687 component root is a comment node\n      !(oldChild.componentInstance && oldChild.componentInstance._vnode.isComment)\n    ) {\n      // replace old child transition data with fresh one\n      // important for dynamic transitions!\n      var oldData = oldChild.data.transition = extend({}, data);\n      // handle transition mode\n      if (mode === 'out-in') {\n        // return placeholder node and queue update when leave finishes\n        this._leaving = true;\n        mergeVNodeHook(oldData, 'afterLeave', function () {\n          this$1._leaving = false;\n          this$1.$forceUpdate();\n        });\n        return placeholder(h, rawChild)\n      } else if (mode === 'in-out') {\n        if (isAsyncPlaceholder(child)) {\n          return oldRawChild\n        }\n        var delayedLeave;\n        var performLeave = function () { delayedLeave(); };\n        mergeVNodeHook(data, 'afterEnter', performLeave);\n        mergeVNodeHook(data, 'enterCancelled', performLeave);\n        mergeVNodeHook(oldData, 'delayLeave', function (leave) { delayedLeave = leave; });\n      }\n    }\n\n    return rawChild\n  }\n};\n\n/*  */\n\nvar props = extend({\n  tag: String,\n  moveClass: String\n}, transitionProps);\n\ndelete props.mode;\n\nvar TransitionGroup = {\n  props: props,\n\n  beforeMount: function beforeMount () {\n    var this$1 = this;\n\n    var update = this._update;\n    this._update = function (vnode, hydrating) {\n      var restoreActiveInstance = setActiveInstance(this$1);\n      // force removing pass\n      this$1.__patch__(\n        this$1._vnode,\n        this$1.kept,\n        false, // hydrating\n        true // removeOnly (!important, avoids unnecessary moves)\n      );\n      this$1._vnode = this$1.kept;\n      restoreActiveInstance();\n      update.call(this$1, vnode, hydrating);\n    };\n  },\n\n  render: function render (h) {\n    var tag = this.tag || this.$vnode.data.tag || 'span';\n    var map = Object.create(null);\n    var prevChildren = this.prevChildren = this.children;\n    var rawChildren = this.$slots.default || [];\n    var children = this.children = [];\n    var transitionData = extractTransitionData(this);\n\n    for (var i = 0; i < rawChildren.length; i++) {\n      var c = rawChildren[i];\n      if (c.tag) {\n        if (c.key != null && String(c.key).indexOf('__vlist') !== 0) {\n          children.push(c);\n          map[c.key] = c\n          ;(c.data || (c.data = {})).transition = transitionData;\n        } else if (true) {\n          var opts = c.componentOptions;\n          var name = opts ? (opts.Ctor.options.name || opts.tag || '') : c.tag;\n          warn((\"<transition-group> children must be keyed: <\" + name + \">\"));\n        }\n      }\n    }\n\n    if (prevChildren) {\n      var kept = [];\n      var removed = [];\n      for (var i$1 = 0; i$1 < prevChildren.length; i$1++) {\n        var c$1 = prevChildren[i$1];\n        c$1.data.transition = transitionData;\n        c$1.data.pos = c$1.elm.getBoundingClientRect();\n        if (map[c$1.key]) {\n          kept.push(c$1);\n        } else {\n          removed.push(c$1);\n        }\n      }\n      this.kept = h(tag, null, kept);\n      this.removed = removed;\n    }\n\n    return h(tag, null, children)\n  },\n\n  updated: function updated () {\n    var children = this.prevChildren;\n    var moveClass = this.moveClass || ((this.name || 'v') + '-move');\n    if (!children.length || !this.hasMove(children[0].elm, moveClass)) {\n      return\n    }\n\n    // we divide the work into three loops to avoid mixing DOM reads and writes\n    // in each iteration - which helps prevent layout thrashing.\n    children.forEach(callPendingCbs);\n    children.forEach(recordPosition);\n    children.forEach(applyTranslation);\n\n    // force reflow to put everything in position\n    // assign to this to avoid being removed in tree-shaking\n    // $flow-disable-line\n    this._reflow = document.body.offsetHeight;\n\n    children.forEach(function (c) {\n      if (c.data.moved) {\n        var el = c.elm;\n        var s = el.style;\n        addTransitionClass(el, moveClass);\n        s.transform = s.WebkitTransform = s.transitionDuration = '';\n        el.addEventListener(transitionEndEvent, el._moveCb = function cb (e) {\n          if (e && e.target !== el) {\n            return\n          }\n          if (!e || /transform$/.test(e.propertyName)) {\n            el.removeEventListener(transitionEndEvent, cb);\n            el._moveCb = null;\n            removeTransitionClass(el, moveClass);\n          }\n        });\n      }\n    });\n  },\n\n  methods: {\n    hasMove: function hasMove (el, moveClass) {\n      /* istanbul ignore if */\n      if (!hasTransition) {\n        return false\n      }\n      /* istanbul ignore if */\n      if (this._hasMove) {\n        return this._hasMove\n      }\n      // Detect whether an element with the move class applied has\n      // CSS transitions. Since the element may be inside an entering\n      // transition at this very moment, we make a clone of it and remove\n      // all other transition classes applied to ensure only the move class\n      // is applied.\n      var clone = el.cloneNode();\n      if (el._transitionClasses) {\n        el._transitionClasses.forEach(function (cls) { removeClass(clone, cls); });\n      }\n      addClass(clone, moveClass);\n      clone.style.display = 'none';\n      this.$el.appendChild(clone);\n      var info = getTransitionInfo(clone);\n      this.$el.removeChild(clone);\n      return (this._hasMove = info.hasTransform)\n    }\n  }\n};\n\nfunction callPendingCbs (c) {\n  /* istanbul ignore if */\n  if (c.elm._moveCb) {\n    c.elm._moveCb();\n  }\n  /* istanbul ignore if */\n  if (c.elm._enterCb) {\n    c.elm._enterCb();\n  }\n}\n\nfunction recordPosition (c) {\n  c.data.newPos = c.elm.getBoundingClientRect();\n}\n\nfunction applyTranslation (c) {\n  var oldPos = c.data.pos;\n  var newPos = c.data.newPos;\n  var dx = oldPos.left - newPos.left;\n  var dy = oldPos.top - newPos.top;\n  if (dx || dy) {\n    c.data.moved = true;\n    var s = c.elm.style;\n    s.transform = s.WebkitTransform = \"translate(\" + dx + \"px,\" + dy + \"px)\";\n    s.transitionDuration = '0s';\n  }\n}\n\nvar platformComponents = {\n  Transition: Transition,\n  TransitionGroup: TransitionGroup\n};\n\n/*  */\n\n// install platform specific utils\nVue.config.mustUseProp = mustUseProp;\nVue.config.isReservedTag = isReservedTag;\nVue.config.isReservedAttr = isReservedAttr;\nVue.config.getTagNamespace = getTagNamespace;\nVue.config.isUnknownElement = isUnknownElement;\n\n// install platform runtime directives & components\nextend(Vue.options.directives, platformDirectives);\nextend(Vue.options.components, platformComponents);\n\n// install platform patch function\nVue.prototype.__patch__ = inBrowser ? patch : noop;\n\n// public mount method\nVue.prototype.$mount = function (\n  el,\n  hydrating\n) {\n  el = el && inBrowser ? query(el) : undefined;\n  return mountComponent(this, el, hydrating)\n};\n\n// devtools global hook\n/* istanbul ignore next */\nif (inBrowser) {\n  setTimeout(function () {\n    if (config.devtools) {\n      if (devtools) {\n        devtools.emit('init', Vue);\n      } else if (\n        true\n      ) {\n        console[console.info ? 'info' : 'log'](\n          'Download the Vue Devtools extension for a better development experience:\\n' +\n          'https://github.com/vuejs/vue-devtools'\n        );\n      }\n    }\n    if ( true &&\n      config.productionTip !== false &&\n      typeof console !== 'undefined'\n    ) {\n      console[console.info ? 'info' : 'log'](\n        \"You are running Vue in development mode.\\n\" +\n        \"Make sure to turn on production mode when deploying for production.\\n\" +\n        \"See more tips at https://vuejs.org/guide/deployment.html\"\n      );\n    }\n  }, 0);\n}\n\n/*  */\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (Vue);\n\n\n//# sourceURL=webpack:///./node_modules/vue/dist/vue.runtime.esm.js?");

/***/ }),

/***/ "./node_modules/vuex/dist/vuex.esm.js":
/*!********************************************!*\
  !*** ./node_modules/vuex/dist/vuex.esm.js ***!
  \********************************************/
/*! exports provided: default, Store, install, mapState, mapMutations, mapGetters, mapActions, createNamespacedHelpers */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Store\", function() { return Store; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"install\", function() { return install; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mapState\", function() { return mapState; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mapMutations\", function() { return mapMutations; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mapGetters\", function() { return mapGetters; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mapActions\", function() { return mapActions; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createNamespacedHelpers\", function() { return createNamespacedHelpers; });\n/**\n * vuex v3.1.1\n * (c) 2019 Evan You\n * @license MIT\n */\nfunction applyMixin (Vue) {\n  var version = Number(Vue.version.split('.')[0]);\n\n  if (version >= 2) {\n    Vue.mixin({ beforeCreate: vuexInit });\n  } else {\n    // override init and inject vuex init procedure\n    // for 1.x backwards compatibility.\n    var _init = Vue.prototype._init;\n    Vue.prototype._init = function (options) {\n      if ( options === void 0 ) options = {};\n\n      options.init = options.init\n        ? [vuexInit].concat(options.init)\n        : vuexInit;\n      _init.call(this, options);\n    };\n  }\n\n  /**\n   * Vuex init hook, injected into each instances init hooks list.\n   */\n\n  function vuexInit () {\n    var options = this.$options;\n    // store injection\n    if (options.store) {\n      this.$store = typeof options.store === 'function'\n        ? options.store()\n        : options.store;\n    } else if (options.parent && options.parent.$store) {\n      this.$store = options.parent.$store;\n    }\n  }\n}\n\nvar target = typeof window !== 'undefined'\n  ? window\n  : typeof global !== 'undefined'\n    ? global\n    : {};\nvar devtoolHook = target.__VUE_DEVTOOLS_GLOBAL_HOOK__;\n\nfunction devtoolPlugin (store) {\n  if (!devtoolHook) { return }\n\n  store._devtoolHook = devtoolHook;\n\n  devtoolHook.emit('vuex:init', store);\n\n  devtoolHook.on('vuex:travel-to-state', function (targetState) {\n    store.replaceState(targetState);\n  });\n\n  store.subscribe(function (mutation, state) {\n    devtoolHook.emit('vuex:mutation', mutation, state);\n  });\n}\n\n/**\n * Get the first item that pass the test\n * by second argument function\n *\n * @param {Array} list\n * @param {Function} f\n * @return {*}\n */\n\n/**\n * forEach for object\n */\nfunction forEachValue (obj, fn) {\n  Object.keys(obj).forEach(function (key) { return fn(obj[key], key); });\n}\n\nfunction isObject (obj) {\n  return obj !== null && typeof obj === 'object'\n}\n\nfunction isPromise (val) {\n  return val && typeof val.then === 'function'\n}\n\nfunction assert (condition, msg) {\n  if (!condition) { throw new Error((\"[vuex] \" + msg)) }\n}\n\nfunction partial (fn, arg) {\n  return function () {\n    return fn(arg)\n  }\n}\n\n// Base data struct for store's module, package with some attribute and method\nvar Module = function Module (rawModule, runtime) {\n  this.runtime = runtime;\n  // Store some children item\n  this._children = Object.create(null);\n  // Store the origin module object which passed by programmer\n  this._rawModule = rawModule;\n  var rawState = rawModule.state;\n\n  // Store the origin module's state\n  this.state = (typeof rawState === 'function' ? rawState() : rawState) || {};\n};\n\nvar prototypeAccessors = { namespaced: { configurable: true } };\n\nprototypeAccessors.namespaced.get = function () {\n  return !!this._rawModule.namespaced\n};\n\nModule.prototype.addChild = function addChild (key, module) {\n  this._children[key] = module;\n};\n\nModule.prototype.removeChild = function removeChild (key) {\n  delete this._children[key];\n};\n\nModule.prototype.getChild = function getChild (key) {\n  return this._children[key]\n};\n\nModule.prototype.update = function update (rawModule) {\n  this._rawModule.namespaced = rawModule.namespaced;\n  if (rawModule.actions) {\n    this._rawModule.actions = rawModule.actions;\n  }\n  if (rawModule.mutations) {\n    this._rawModule.mutations = rawModule.mutations;\n  }\n  if (rawModule.getters) {\n    this._rawModule.getters = rawModule.getters;\n  }\n};\n\nModule.prototype.forEachChild = function forEachChild (fn) {\n  forEachValue(this._children, fn);\n};\n\nModule.prototype.forEachGetter = function forEachGetter (fn) {\n  if (this._rawModule.getters) {\n    forEachValue(this._rawModule.getters, fn);\n  }\n};\n\nModule.prototype.forEachAction = function forEachAction (fn) {\n  if (this._rawModule.actions) {\n    forEachValue(this._rawModule.actions, fn);\n  }\n};\n\nModule.prototype.forEachMutation = function forEachMutation (fn) {\n  if (this._rawModule.mutations) {\n    forEachValue(this._rawModule.mutations, fn);\n  }\n};\n\nObject.defineProperties( Module.prototype, prototypeAccessors );\n\nvar ModuleCollection = function ModuleCollection (rawRootModule) {\n  // register root module (Vuex.Store options)\n  this.register([], rawRootModule, false);\n};\n\nModuleCollection.prototype.get = function get (path) {\n  return path.reduce(function (module, key) {\n    return module.getChild(key)\n  }, this.root)\n};\n\nModuleCollection.prototype.getNamespace = function getNamespace (path) {\n  var module = this.root;\n  return path.reduce(function (namespace, key) {\n    module = module.getChild(key);\n    return namespace + (module.namespaced ? key + '/' : '')\n  }, '')\n};\n\nModuleCollection.prototype.update = function update$1 (rawRootModule) {\n  update([], this.root, rawRootModule);\n};\n\nModuleCollection.prototype.register = function register (path, rawModule, runtime) {\n    var this$1 = this;\n    if ( runtime === void 0 ) runtime = true;\n\n  if (true) {\n    assertRawModule(path, rawModule);\n  }\n\n  var newModule = new Module(rawModule, runtime);\n  if (path.length === 0) {\n    this.root = newModule;\n  } else {\n    var parent = this.get(path.slice(0, -1));\n    parent.addChild(path[path.length - 1], newModule);\n  }\n\n  // register nested modules\n  if (rawModule.modules) {\n    forEachValue(rawModule.modules, function (rawChildModule, key) {\n      this$1.register(path.concat(key), rawChildModule, runtime);\n    });\n  }\n};\n\nModuleCollection.prototype.unregister = function unregister (path) {\n  var parent = this.get(path.slice(0, -1));\n  var key = path[path.length - 1];\n  if (!parent.getChild(key).runtime) { return }\n\n  parent.removeChild(key);\n};\n\nfunction update (path, targetModule, newModule) {\n  if (true) {\n    assertRawModule(path, newModule);\n  }\n\n  // update target module\n  targetModule.update(newModule);\n\n  // update nested modules\n  if (newModule.modules) {\n    for (var key in newModule.modules) {\n      if (!targetModule.getChild(key)) {\n        if (true) {\n          console.warn(\n            \"[vuex] trying to add a new module '\" + key + \"' on hot reloading, \" +\n            'manual reload is needed'\n          );\n        }\n        return\n      }\n      update(\n        path.concat(key),\n        targetModule.getChild(key),\n        newModule.modules[key]\n      );\n    }\n  }\n}\n\nvar functionAssert = {\n  assert: function (value) { return typeof value === 'function'; },\n  expected: 'function'\n};\n\nvar objectAssert = {\n  assert: function (value) { return typeof value === 'function' ||\n    (typeof value === 'object' && typeof value.handler === 'function'); },\n  expected: 'function or object with \"handler\" function'\n};\n\nvar assertTypes = {\n  getters: functionAssert,\n  mutations: functionAssert,\n  actions: objectAssert\n};\n\nfunction assertRawModule (path, rawModule) {\n  Object.keys(assertTypes).forEach(function (key) {\n    if (!rawModule[key]) { return }\n\n    var assertOptions = assertTypes[key];\n\n    forEachValue(rawModule[key], function (value, type) {\n      assert(\n        assertOptions.assert(value),\n        makeAssertionMessage(path, key, type, value, assertOptions.expected)\n      );\n    });\n  });\n}\n\nfunction makeAssertionMessage (path, key, type, value, expected) {\n  var buf = key + \" should be \" + expected + \" but \\\"\" + key + \".\" + type + \"\\\"\";\n  if (path.length > 0) {\n    buf += \" in module \\\"\" + (path.join('.')) + \"\\\"\";\n  }\n  buf += \" is \" + (JSON.stringify(value)) + \".\";\n  return buf\n}\n\nvar Vue; // bind on install\n\nvar Store = function Store (options) {\n  var this$1 = this;\n  if ( options === void 0 ) options = {};\n\n  // Auto install if it is not done yet and `window` has `Vue`.\n  // To allow users to avoid auto-installation in some cases,\n  // this code should be placed here. See #731\n  if (!Vue && typeof window !== 'undefined' && window.Vue) {\n    install(window.Vue);\n  }\n\n  if (true) {\n    assert(Vue, \"must call Vue.use(Vuex) before creating a store instance.\");\n    assert(typeof Promise !== 'undefined', \"vuex requires a Promise polyfill in this browser.\");\n    assert(this instanceof Store, \"store must be called with the new operator.\");\n  }\n\n  var plugins = options.plugins; if ( plugins === void 0 ) plugins = [];\n  var strict = options.strict; if ( strict === void 0 ) strict = false;\n\n  // store internal state\n  this._committing = false;\n  this._actions = Object.create(null);\n  this._actionSubscribers = [];\n  this._mutations = Object.create(null);\n  this._wrappedGetters = Object.create(null);\n  this._modules = new ModuleCollection(options);\n  this._modulesNamespaceMap = Object.create(null);\n  this._subscribers = [];\n  this._watcherVM = new Vue();\n\n  // bind commit and dispatch to self\n  var store = this;\n  var ref = this;\n  var dispatch = ref.dispatch;\n  var commit = ref.commit;\n  this.dispatch = function boundDispatch (type, payload) {\n    return dispatch.call(store, type, payload)\n  };\n  this.commit = function boundCommit (type, payload, options) {\n    return commit.call(store, type, payload, options)\n  };\n\n  // strict mode\n  this.strict = strict;\n\n  var state = this._modules.root.state;\n\n  // init root module.\n  // this also recursively registers all sub-modules\n  // and collects all module getters inside this._wrappedGetters\n  installModule(this, state, [], this._modules.root);\n\n  // initialize the store vm, which is responsible for the reactivity\n  // (also registers _wrappedGetters as computed properties)\n  resetStoreVM(this, state);\n\n  // apply plugins\n  plugins.forEach(function (plugin) { return plugin(this$1); });\n\n  var useDevtools = options.devtools !== undefined ? options.devtools : Vue.config.devtools;\n  if (useDevtools) {\n    devtoolPlugin(this);\n  }\n};\n\nvar prototypeAccessors$1 = { state: { configurable: true } };\n\nprototypeAccessors$1.state.get = function () {\n  return this._vm._data.$$state\n};\n\nprototypeAccessors$1.state.set = function (v) {\n  if (true) {\n    assert(false, \"use store.replaceState() to explicit replace store state.\");\n  }\n};\n\nStore.prototype.commit = function commit (_type, _payload, _options) {\n    var this$1 = this;\n\n  // check object-style commit\n  var ref = unifyObjectStyle(_type, _payload, _options);\n    var type = ref.type;\n    var payload = ref.payload;\n    var options = ref.options;\n\n  var mutation = { type: type, payload: payload };\n  var entry = this._mutations[type];\n  if (!entry) {\n    if (true) {\n      console.error((\"[vuex] unknown mutation type: \" + type));\n    }\n    return\n  }\n  this._withCommit(function () {\n    entry.forEach(function commitIterator (handler) {\n      handler(payload);\n    });\n  });\n  this._subscribers.forEach(function (sub) { return sub(mutation, this$1.state); });\n\n  if (\n     true &&\n    options && options.silent\n  ) {\n    console.warn(\n      \"[vuex] mutation type: \" + type + \". Silent option has been removed. \" +\n      'Use the filter functionality in the vue-devtools'\n    );\n  }\n};\n\nStore.prototype.dispatch = function dispatch (_type, _payload) {\n    var this$1 = this;\n\n  // check object-style dispatch\n  var ref = unifyObjectStyle(_type, _payload);\n    var type = ref.type;\n    var payload = ref.payload;\n\n  var action = { type: type, payload: payload };\n  var entry = this._actions[type];\n  if (!entry) {\n    if (true) {\n      console.error((\"[vuex] unknown action type: \" + type));\n    }\n    return\n  }\n\n  try {\n    this._actionSubscribers\n      .filter(function (sub) { return sub.before; })\n      .forEach(function (sub) { return sub.before(action, this$1.state); });\n  } catch (e) {\n    if (true) {\n      console.warn(\"[vuex] error in before action subscribers: \");\n      console.error(e);\n    }\n  }\n\n  var result = entry.length > 1\n    ? Promise.all(entry.map(function (handler) { return handler(payload); }))\n    : entry[0](payload);\n\n  return result.then(function (res) {\n    try {\n      this$1._actionSubscribers\n        .filter(function (sub) { return sub.after; })\n        .forEach(function (sub) { return sub.after(action, this$1.state); });\n    } catch (e) {\n      if (true) {\n        console.warn(\"[vuex] error in after action subscribers: \");\n        console.error(e);\n      }\n    }\n    return res\n  })\n};\n\nStore.prototype.subscribe = function subscribe (fn) {\n  return genericSubscribe(fn, this._subscribers)\n};\n\nStore.prototype.subscribeAction = function subscribeAction (fn) {\n  var subs = typeof fn === 'function' ? { before: fn } : fn;\n  return genericSubscribe(subs, this._actionSubscribers)\n};\n\nStore.prototype.watch = function watch (getter, cb, options) {\n    var this$1 = this;\n\n  if (true) {\n    assert(typeof getter === 'function', \"store.watch only accepts a function.\");\n  }\n  return this._watcherVM.$watch(function () { return getter(this$1.state, this$1.getters); }, cb, options)\n};\n\nStore.prototype.replaceState = function replaceState (state) {\n    var this$1 = this;\n\n  this._withCommit(function () {\n    this$1._vm._data.$$state = state;\n  });\n};\n\nStore.prototype.registerModule = function registerModule (path, rawModule, options) {\n    if ( options === void 0 ) options = {};\n\n  if (typeof path === 'string') { path = [path]; }\n\n  if (true) {\n    assert(Array.isArray(path), \"module path must be a string or an Array.\");\n    assert(path.length > 0, 'cannot register the root module by using registerModule.');\n  }\n\n  this._modules.register(path, rawModule);\n  installModule(this, this.state, path, this._modules.get(path), options.preserveState);\n  // reset store to update getters...\n  resetStoreVM(this, this.state);\n};\n\nStore.prototype.unregisterModule = function unregisterModule (path) {\n    var this$1 = this;\n\n  if (typeof path === 'string') { path = [path]; }\n\n  if (true) {\n    assert(Array.isArray(path), \"module path must be a string or an Array.\");\n  }\n\n  this._modules.unregister(path);\n  this._withCommit(function () {\n    var parentState = getNestedState(this$1.state, path.slice(0, -1));\n    Vue.delete(parentState, path[path.length - 1]);\n  });\n  resetStore(this);\n};\n\nStore.prototype.hotUpdate = function hotUpdate (newOptions) {\n  this._modules.update(newOptions);\n  resetStore(this, true);\n};\n\nStore.prototype._withCommit = function _withCommit (fn) {\n  var committing = this._committing;\n  this._committing = true;\n  fn();\n  this._committing = committing;\n};\n\nObject.defineProperties( Store.prototype, prototypeAccessors$1 );\n\nfunction genericSubscribe (fn, subs) {\n  if (subs.indexOf(fn) < 0) {\n    subs.push(fn);\n  }\n  return function () {\n    var i = subs.indexOf(fn);\n    if (i > -1) {\n      subs.splice(i, 1);\n    }\n  }\n}\n\nfunction resetStore (store, hot) {\n  store._actions = Object.create(null);\n  store._mutations = Object.create(null);\n  store._wrappedGetters = Object.create(null);\n  store._modulesNamespaceMap = Object.create(null);\n  var state = store.state;\n  // init all modules\n  installModule(store, state, [], store._modules.root, true);\n  // reset vm\n  resetStoreVM(store, state, hot);\n}\n\nfunction resetStoreVM (store, state, hot) {\n  var oldVm = store._vm;\n\n  // bind store public getters\n  store.getters = {};\n  var wrappedGetters = store._wrappedGetters;\n  var computed = {};\n  forEachValue(wrappedGetters, function (fn, key) {\n    // use computed to leverage its lazy-caching mechanism\n    // direct inline function use will lead to closure preserving oldVm.\n    // using partial to return function with only arguments preserved in closure enviroment.\n    computed[key] = partial(fn, store);\n    Object.defineProperty(store.getters, key, {\n      get: function () { return store._vm[key]; },\n      enumerable: true // for local getters\n    });\n  });\n\n  // use a Vue instance to store the state tree\n  // suppress warnings just in case the user has added\n  // some funky global mixins\n  var silent = Vue.config.silent;\n  Vue.config.silent = true;\n  store._vm = new Vue({\n    data: {\n      $$state: state\n    },\n    computed: computed\n  });\n  Vue.config.silent = silent;\n\n  // enable strict mode for new vm\n  if (store.strict) {\n    enableStrictMode(store);\n  }\n\n  if (oldVm) {\n    if (hot) {\n      // dispatch changes in all subscribed watchers\n      // to force getter re-evaluation for hot reloading.\n      store._withCommit(function () {\n        oldVm._data.$$state = null;\n      });\n    }\n    Vue.nextTick(function () { return oldVm.$destroy(); });\n  }\n}\n\nfunction installModule (store, rootState, path, module, hot) {\n  var isRoot = !path.length;\n  var namespace = store._modules.getNamespace(path);\n\n  // register in namespace map\n  if (module.namespaced) {\n    store._modulesNamespaceMap[namespace] = module;\n  }\n\n  // set state\n  if (!isRoot && !hot) {\n    var parentState = getNestedState(rootState, path.slice(0, -1));\n    var moduleName = path[path.length - 1];\n    store._withCommit(function () {\n      Vue.set(parentState, moduleName, module.state);\n    });\n  }\n\n  var local = module.context = makeLocalContext(store, namespace, path);\n\n  module.forEachMutation(function (mutation, key) {\n    var namespacedType = namespace + key;\n    registerMutation(store, namespacedType, mutation, local);\n  });\n\n  module.forEachAction(function (action, key) {\n    var type = action.root ? key : namespace + key;\n    var handler = action.handler || action;\n    registerAction(store, type, handler, local);\n  });\n\n  module.forEachGetter(function (getter, key) {\n    var namespacedType = namespace + key;\n    registerGetter(store, namespacedType, getter, local);\n  });\n\n  module.forEachChild(function (child, key) {\n    installModule(store, rootState, path.concat(key), child, hot);\n  });\n}\n\n/**\n * make localized dispatch, commit, getters and state\n * if there is no namespace, just use root ones\n */\nfunction makeLocalContext (store, namespace, path) {\n  var noNamespace = namespace === '';\n\n  var local = {\n    dispatch: noNamespace ? store.dispatch : function (_type, _payload, _options) {\n      var args = unifyObjectStyle(_type, _payload, _options);\n      var payload = args.payload;\n      var options = args.options;\n      var type = args.type;\n\n      if (!options || !options.root) {\n        type = namespace + type;\n        if ( true && !store._actions[type]) {\n          console.error((\"[vuex] unknown local action type: \" + (args.type) + \", global type: \" + type));\n          return\n        }\n      }\n\n      return store.dispatch(type, payload)\n    },\n\n    commit: noNamespace ? store.commit : function (_type, _payload, _options) {\n      var args = unifyObjectStyle(_type, _payload, _options);\n      var payload = args.payload;\n      var options = args.options;\n      var type = args.type;\n\n      if (!options || !options.root) {\n        type = namespace + type;\n        if ( true && !store._mutations[type]) {\n          console.error((\"[vuex] unknown local mutation type: \" + (args.type) + \", global type: \" + type));\n          return\n        }\n      }\n\n      store.commit(type, payload, options);\n    }\n  };\n\n  // getters and state object must be gotten lazily\n  // because they will be changed by vm update\n  Object.defineProperties(local, {\n    getters: {\n      get: noNamespace\n        ? function () { return store.getters; }\n        : function () { return makeLocalGetters(store, namespace); }\n    },\n    state: {\n      get: function () { return getNestedState(store.state, path); }\n    }\n  });\n\n  return local\n}\n\nfunction makeLocalGetters (store, namespace) {\n  var gettersProxy = {};\n\n  var splitPos = namespace.length;\n  Object.keys(store.getters).forEach(function (type) {\n    // skip if the target getter is not match this namespace\n    if (type.slice(0, splitPos) !== namespace) { return }\n\n    // extract local getter type\n    var localType = type.slice(splitPos);\n\n    // Add a port to the getters proxy.\n    // Define as getter property because\n    // we do not want to evaluate the getters in this time.\n    Object.defineProperty(gettersProxy, localType, {\n      get: function () { return store.getters[type]; },\n      enumerable: true\n    });\n  });\n\n  return gettersProxy\n}\n\nfunction registerMutation (store, type, handler, local) {\n  var entry = store._mutations[type] || (store._mutations[type] = []);\n  entry.push(function wrappedMutationHandler (payload) {\n    handler.call(store, local.state, payload);\n  });\n}\n\nfunction registerAction (store, type, handler, local) {\n  var entry = store._actions[type] || (store._actions[type] = []);\n  entry.push(function wrappedActionHandler (payload, cb) {\n    var res = handler.call(store, {\n      dispatch: local.dispatch,\n      commit: local.commit,\n      getters: local.getters,\n      state: local.state,\n      rootGetters: store.getters,\n      rootState: store.state\n    }, payload, cb);\n    if (!isPromise(res)) {\n      res = Promise.resolve(res);\n    }\n    if (store._devtoolHook) {\n      return res.catch(function (err) {\n        store._devtoolHook.emit('vuex:error', err);\n        throw err\n      })\n    } else {\n      return res\n    }\n  });\n}\n\nfunction registerGetter (store, type, rawGetter, local) {\n  if (store._wrappedGetters[type]) {\n    if (true) {\n      console.error((\"[vuex] duplicate getter key: \" + type));\n    }\n    return\n  }\n  store._wrappedGetters[type] = function wrappedGetter (store) {\n    return rawGetter(\n      local.state, // local state\n      local.getters, // local getters\n      store.state, // root state\n      store.getters // root getters\n    )\n  };\n}\n\nfunction enableStrictMode (store) {\n  store._vm.$watch(function () { return this._data.$$state }, function () {\n    if (true) {\n      assert(store._committing, \"do not mutate vuex store state outside mutation handlers.\");\n    }\n  }, { deep: true, sync: true });\n}\n\nfunction getNestedState (state, path) {\n  return path.length\n    ? path.reduce(function (state, key) { return state[key]; }, state)\n    : state\n}\n\nfunction unifyObjectStyle (type, payload, options) {\n  if (isObject(type) && type.type) {\n    options = payload;\n    payload = type;\n    type = type.type;\n  }\n\n  if (true) {\n    assert(typeof type === 'string', (\"expects string as the type, but found \" + (typeof type) + \".\"));\n  }\n\n  return { type: type, payload: payload, options: options }\n}\n\nfunction install (_Vue) {\n  if (Vue && _Vue === Vue) {\n    if (true) {\n      console.error(\n        '[vuex] already installed. Vue.use(Vuex) should be called only once.'\n      );\n    }\n    return\n  }\n  Vue = _Vue;\n  applyMixin(Vue);\n}\n\n/**\n * Reduce the code which written in Vue.js for getting the state.\n * @param {String} [namespace] - Module's namespace\n * @param {Object|Array} states # Object's item can be a function which accept state and getters for param, you can do something for state and getters in it.\n * @param {Object}\n */\nvar mapState = normalizeNamespace(function (namespace, states) {\n  var res = {};\n  normalizeMap(states).forEach(function (ref) {\n    var key = ref.key;\n    var val = ref.val;\n\n    res[key] = function mappedState () {\n      var state = this.$store.state;\n      var getters = this.$store.getters;\n      if (namespace) {\n        var module = getModuleByNamespace(this.$store, 'mapState', namespace);\n        if (!module) {\n          return\n        }\n        state = module.context.state;\n        getters = module.context.getters;\n      }\n      return typeof val === 'function'\n        ? val.call(this, state, getters)\n        : state[val]\n    };\n    // mark vuex getter for devtools\n    res[key].vuex = true;\n  });\n  return res\n});\n\n/**\n * Reduce the code which written in Vue.js for committing the mutation\n * @param {String} [namespace] - Module's namespace\n * @param {Object|Array} mutations # Object's item can be a function which accept `commit` function as the first param, it can accept anthor params. You can commit mutation and do any other things in this function. specially, You need to pass anthor params from the mapped function.\n * @return {Object}\n */\nvar mapMutations = normalizeNamespace(function (namespace, mutations) {\n  var res = {};\n  normalizeMap(mutations).forEach(function (ref) {\n    var key = ref.key;\n    var val = ref.val;\n\n    res[key] = function mappedMutation () {\n      var args = [], len = arguments.length;\n      while ( len-- ) args[ len ] = arguments[ len ];\n\n      // Get the commit method from store\n      var commit = this.$store.commit;\n      if (namespace) {\n        var module = getModuleByNamespace(this.$store, 'mapMutations', namespace);\n        if (!module) {\n          return\n        }\n        commit = module.context.commit;\n      }\n      return typeof val === 'function'\n        ? val.apply(this, [commit].concat(args))\n        : commit.apply(this.$store, [val].concat(args))\n    };\n  });\n  return res\n});\n\n/**\n * Reduce the code which written in Vue.js for getting the getters\n * @param {String} [namespace] - Module's namespace\n * @param {Object|Array} getters\n * @return {Object}\n */\nvar mapGetters = normalizeNamespace(function (namespace, getters) {\n  var res = {};\n  normalizeMap(getters).forEach(function (ref) {\n    var key = ref.key;\n    var val = ref.val;\n\n    // The namespace has been mutated by normalizeNamespace\n    val = namespace + val;\n    res[key] = function mappedGetter () {\n      if (namespace && !getModuleByNamespace(this.$store, 'mapGetters', namespace)) {\n        return\n      }\n      if ( true && !(val in this.$store.getters)) {\n        console.error((\"[vuex] unknown getter: \" + val));\n        return\n      }\n      return this.$store.getters[val]\n    };\n    // mark vuex getter for devtools\n    res[key].vuex = true;\n  });\n  return res\n});\n\n/**\n * Reduce the code which written in Vue.js for dispatch the action\n * @param {String} [namespace] - Module's namespace\n * @param {Object|Array} actions # Object's item can be a function which accept `dispatch` function as the first param, it can accept anthor params. You can dispatch action and do any other things in this function. specially, You need to pass anthor params from the mapped function.\n * @return {Object}\n */\nvar mapActions = normalizeNamespace(function (namespace, actions) {\n  var res = {};\n  normalizeMap(actions).forEach(function (ref) {\n    var key = ref.key;\n    var val = ref.val;\n\n    res[key] = function mappedAction () {\n      var args = [], len = arguments.length;\n      while ( len-- ) args[ len ] = arguments[ len ];\n\n      // get dispatch function from store\n      var dispatch = this.$store.dispatch;\n      if (namespace) {\n        var module = getModuleByNamespace(this.$store, 'mapActions', namespace);\n        if (!module) {\n          return\n        }\n        dispatch = module.context.dispatch;\n      }\n      return typeof val === 'function'\n        ? val.apply(this, [dispatch].concat(args))\n        : dispatch.apply(this.$store, [val].concat(args))\n    };\n  });\n  return res\n});\n\n/**\n * Rebinding namespace param for mapXXX function in special scoped, and return them by simple object\n * @param {String} namespace\n * @return {Object}\n */\nvar createNamespacedHelpers = function (namespace) { return ({\n  mapState: mapState.bind(null, namespace),\n  mapGetters: mapGetters.bind(null, namespace),\n  mapMutations: mapMutations.bind(null, namespace),\n  mapActions: mapActions.bind(null, namespace)\n}); };\n\n/**\n * Normalize the map\n * normalizeMap([1, 2, 3]) => [ { key: 1, val: 1 }, { key: 2, val: 2 }, { key: 3, val: 3 } ]\n * normalizeMap({a: 1, b: 2, c: 3}) => [ { key: 'a', val: 1 }, { key: 'b', val: 2 }, { key: 'c', val: 3 } ]\n * @param {Array|Object} map\n * @return {Object}\n */\nfunction normalizeMap (map) {\n  return Array.isArray(map)\n    ? map.map(function (key) { return ({ key: key, val: key }); })\n    : Object.keys(map).map(function (key) { return ({ key: key, val: map[key] }); })\n}\n\n/**\n * Return a function expect two param contains namespace and map. it will normalize the namespace and then the param's function will handle the new namespace and the map.\n * @param {Function} fn\n * @return {Function}\n */\nfunction normalizeNamespace (fn) {\n  return function (namespace, map) {\n    if (typeof namespace !== 'string') {\n      map = namespace;\n      namespace = '';\n    } else if (namespace.charAt(namespace.length - 1) !== '/') {\n      namespace += '/';\n    }\n    return fn(namespace, map)\n  }\n}\n\n/**\n * Search a special module from store by namespace. if module not exist, print error message.\n * @param {Object} store\n * @param {String} helper\n * @param {String} namespace\n * @return {Object}\n */\nfunction getModuleByNamespace (store, helper, namespace) {\n  var module = store._modulesNamespaceMap[namespace];\n  if ( true && !module) {\n    console.error((\"[vuex] module namespace not found in \" + helper + \"(): \" + namespace));\n  }\n  return module\n}\n\nvar index_esm = {\n  Store: Store,\n  install: install,\n  version: '3.1.1',\n  mapState: mapState,\n  mapMutations: mapMutations,\n  mapGetters: mapGetters,\n  mapActions: mapActions,\n  createNamespacedHelpers: createNamespacedHelpers\n};\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (index_esm);\n\n\n\n//# sourceURL=webpack:///./node_modules/vuex/dist/vuex.esm.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/module.js":
/*!***********************************!*\
  !*** (webpack)/buildin/module.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = function(module) {\n\tif (!module.webpackPolyfill) {\n\t\tmodule.deprecate = function() {};\n\t\tmodule.paths = [];\n\t\t// module.parent = undefined by default\n\t\tif (!module.children) module.children = [];\n\t\tObject.defineProperty(module, \"loaded\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.l;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"id\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.i;\n\t\t\t}\n\t\t});\n\t\tmodule.webpackPolyfill = 1;\n\t}\n\treturn module;\n};\n\n\n//# sourceURL=webpack:///(webpack)/buildin/module.js?");

/***/ }),

/***/ "./node_modules/wrappy/wrappy.js":
/*!***************************************!*\
  !*** ./node_modules/wrappy/wrappy.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/wrappy/wrappy.js?");

/***/ }),

/***/ "./node_modules/yaku/lib/_.js":
/*!************************************!*\
  !*** ./node_modules/yaku/lib/_.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var Promise = __webpack_require__(/*! ./yaku */ \"./node_modules/yaku/lib/yaku.js\");\n\nmodule.exports = {\n\n    extendPrototype: function (src, target) {\n        for (var k in target) {\n            src.prototype[k] = target[k];\n        }\n        return src;\n    },\n\n    isFunction: function (obj) {\n        return typeof obj === \"function\";\n    },\n\n    isNumber: function (obj) {\n        return typeof obj === \"number\";\n    },\n\n    Promise: Promise,\n\n    slice: [].slice\n\n};\n\n\n//# sourceURL=webpack:///./node_modules/yaku/lib/_.js?");

/***/ }),

/***/ "./node_modules/yaku/lib/promisify.js":
/*!********************************************!*\
  !*** ./node_modules/yaku/lib/promisify.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var _ = __webpack_require__(/*! ./_ */ \"./node_modules/yaku/lib/_.js\");\nvar isFn = _.isFunction;\n\nmodule.exports = function (fn, self) {\n    return function (a, b, c, d, e) {\n        var len = arguments.length\n        , args, promise, resolve, reject;\n\n        promise = new _.Promise(function (r, rj) {\n            resolve = r;\n            reject = rj;\n        });\n\n        function cb (err, val) {\n            err == null ? resolve(val) : reject(err);\n        }\n\n        // For the sake of performance.\n        switch (len) {\n        case 0: fn.call(self, cb); break;\n        case 1: isFn(a) ? fn.call(self, a) : fn.call(self, a, cb); break;\n        case 2: isFn(b) ? fn.call(self, a, b) : fn.call(self, a, b, cb); break;\n        case 3: isFn(c) ? fn.call(self, a, b, c) : fn.call(self, a, b, c, cb); break;\n        case 4: isFn(d) ? fn.call(self, a, b, c, d) : fn.call(self, a, b, c, d, cb); break;\n        case 5: isFn(e) ? fn.call(self, a, b, c, d, e) : fn.call(self, a, b, c, d, e, cb); break;\n        default:\n            args = new Array(len);\n\n            for (var i = 0; i < len; i++) {\n                args[i] = arguments[i];\n            }\n\n            if (isFn(args[len - 1])) {\n                return fn.apply(self, args);\n            }\n\n            args[i] = cb;\n            fn.apply(self, args);\n        }\n\n        return promise;\n    };\n};\n\n\n//# sourceURL=webpack:///./node_modules/yaku/lib/promisify.js?");

/***/ }),

/***/ "./node_modules/yaku/lib/yaku.js":
/*!***************************************!*\
  !*** ./node_modules/yaku/lib/yaku.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/*\n Yaku v0.16.7\n (c) 2015 Yad Smood. http://ysmood.org\n License MIT\n*/\n(function () {\n    \"use strict\";\n\n    var $undefined\n    , $null = null\n    , root = typeof window === \"object\" ? window : global\n    , isLongStackTrace = false\n    , process = root.process\n    , Arr = Array\n    , Err = Error\n\n    , $rejected = 0\n    , $resolved = 1\n    , $pending = 2\n\n    , $Symbol = \"Symbol\"\n    , $iterator = \"iterator\"\n    , $species = \"species\"\n    , $speciesKey = $Symbol + \"(\" + $species + \")\"\n    , $return = \"return\"\n\n    , $unhandled = \"_uh\"\n    , $promiseTrace = \"_pt\"\n    , $settlerTrace = \"_st\"\n\n    , $invalidThis = \"Invalid this\"\n    , $invalidArgument = \"Invalid argument\"\n    , $fromPrevious = \"\\nFrom previous \"\n    , $promiseCircularChain = \"Chaining cycle detected for promise\"\n    , $unhandledRejectionMsg = \"Uncaught (in promise)\"\n    , $rejectionHandled = \"rejectionHandled\"\n    , $unhandledRejection = \"unhandledRejection\"\n\n    , $tryCatchFn\n    , $tryCatchThis\n    , $tryErr = { e: $null }\n    , $noop = function () {}\n    , $cleanStackReg = /^.+\\/node_modules\\/yaku\\/.+\\n?/mg\n    ;\n\n    /**\n     * This class follows the [Promises/A+](https://promisesaplus.com) and\n     * [ES6](http://people.mozilla.org/~jorendorff/es6-draft.html#sec-promise-objects) spec\n     * with some extra helpers.\n     * @param  {Function} executor Function object with two arguments resolve, reject.\n     * The first argument fulfills the promise, the second argument rejects it.\n     * We can call these functions, once our operation is completed.\n     */\n    var Yaku = module.exports = function Promise (executor) {\n        var self = this,\n            err;\n\n        // \"this._s\" is the internal state of: pending, resolved or rejected\n        // \"this._v\" is the internal value\n\n        if (!isObject(self) || self._s !== $undefined)\n            throw genTypeError($invalidThis);\n\n        self._s = $pending;\n\n        if (isLongStackTrace) self[$promiseTrace] = genTraceInfo();\n\n        if (executor !== $noop) {\n            if (!isFunction(executor))\n                throw genTypeError($invalidArgument);\n\n            err = genTryCatcher(executor)(\n                genSettler(self, $resolved),\n                genSettler(self, $rejected)\n            );\n\n            if (err === $tryErr)\n                settlePromise(self, $rejected, err.e);\n        }\n    };\n\n    Yaku[\"default\"] = Yaku;\n\n    extendPrototype(Yaku, {\n        /**\n         * Appends fulfillment and rejection handlers to the promise,\n         * and returns a new promise resolving to the return value of the called handler.\n         * @param  {Function} onFulfilled Optional. Called when the Promise is resolved.\n         * @param  {Function} onRejected  Optional. Called when the Promise is rejected.\n         * @return {Yaku} It will return a new Yaku which will resolve or reject after\n         * @example\n         * the current Promise.\n         * ```js\n         * var Promise = require('yaku');\n         * var p = Promise.resolve(10);\n         *\n         * p.then((v) => {\n         *     console.log(v);\n         * });\n         * ```\n         */\n        then: function then (onFulfilled, onRejected) {\n            if (this._s === undefined) throw genTypeError();\n\n            return addHandler(\n                this,\n                newCapablePromise(Yaku.speciesConstructor(this, Yaku)),\n                onFulfilled,\n                onRejected\n            );\n        },\n\n        /**\n         * The `catch()` method returns a Promise and deals with rejected cases only.\n         * It behaves the same as calling `Promise.prototype.then(undefined, onRejected)`.\n         * @param  {Function} onRejected A Function called when the Promise is rejected.\n         * This function has one argument, the rejection reason.\n         * @return {Yaku} A Promise that deals with rejected cases only.\n         * @example\n         * ```js\n         * var Promise = require('yaku');\n         * var p = Promise.reject(new Error(\"ERR\"));\n         *\n         * p['catch']((v) => {\n         *     console.log(v);\n         * });\n         * ```\n         */\n        \"catch\": function (onRejected) {\n            return this.then($undefined, onRejected);\n        },\n\n        // The number of current promises that attach to this Yaku instance.\n        _pCount: 0,\n\n        // The parent Yaku.\n        _pre: $null,\n\n        // A unique type flag, it helps different versions of Yaku know each other.\n        _Yaku: 1\n    });\n\n    /**\n     * The `Promise.resolve(value)` method returns a Promise object that is resolved with the given value.\n     * If the value is a thenable (i.e. has a then method), the returned promise will \"follow\" that thenable,\n     * adopting its eventual state; otherwise the returned promise will be fulfilled with the value.\n     * @param  {Any} value Argument to be resolved by this Promise.\n     * Can also be a Promise or a thenable to resolve.\n     * @return {Yaku}\n     * @example\n     * ```js\n     * var Promise = require('yaku');\n     * var p = Promise.resolve(10);\n     * ```\n     */\n    Yaku.resolve = function resolve (val) {\n        return isYaku(val) ? val : settleWithX(newCapablePromise(this), val);\n    };\n\n    /**\n     * The `Promise.reject(reason)` method returns a Promise object that is rejected with the given reason.\n     * @param  {Any} reason Reason why this Promise rejected.\n     * @return {Yaku}\n     * @example\n     * ```js\n     * var Promise = require('yaku');\n     * var p = Promise.reject(new Error(\"ERR\"));\n     * ```\n     */\n    Yaku.reject = function reject (reason) {\n        return settlePromise(newCapablePromise(this), $rejected, reason);\n    };\n\n    /**\n     * The `Promise.race(iterable)` method returns a promise that resolves or rejects\n     * as soon as one of the promises in the iterable resolves or rejects,\n     * with the value or reason from that promise.\n     * @param  {iterable} iterable An iterable object, such as an Array.\n     * @return {Yaku} The race function returns a Promise that is settled\n     * the same way as the first passed promise to settle.\n     * It resolves or rejects, whichever happens first.\n     * @example\n     * ```js\n     * var Promise = require('yaku');\n     * Promise.race([\n     *     123,\n     *     Promise.resolve(0)\n     * ])\n     * .then((value) => {\n     *     console.log(value); // => 123\n     * });\n     * ```\n     */\n    Yaku.race = function race (iterable) {\n        var self = this\n        , p = newCapablePromise(self)\n\n        , resolve = function (val) {\n            settlePromise(p, $resolved, val);\n        }\n\n        , reject = function (val) {\n            settlePromise(p, $rejected, val);\n        }\n\n        , ret = genTryCatcher(each)(iterable, function (v) {\n            self.resolve(v).then(resolve, reject);\n        });\n\n        if (ret === $tryErr) return self.reject(ret.e);\n\n        return p;\n    };\n\n    /**\n     * The `Promise.all(iterable)` method returns a promise that resolves when\n     * all of the promises in the iterable argument have resolved.\n     *\n     * The result is passed as an array of values from all the promises.\n     * If something passed in the iterable array is not a promise,\n     * it's converted to one by Promise.resolve. If any of the passed in promises rejects,\n     * the all Promise immediately rejects with the value of the promise that rejected,\n     * discarding all the other promises whether or not they have resolved.\n     * @param  {iterable} iterable An iterable object, such as an Array.\n     * @return {Yaku}\n     * @example\n     * ```js\n     * var Promise = require('yaku');\n     * Promise.all([\n     *     123,\n     *     Promise.resolve(0)\n     * ])\n     * .then((values) => {\n     *     console.log(values); // => [123, 0]\n     * });\n     * ```\n     * @example\n     * Use with iterable.\n     * ```js\n     * var Promise = require('yaku');\n     * Promise.all((function * () {\n     *     yield 10;\n     *     yield new Promise(function (r) { setTimeout(r, 1000, \"OK\") });\n     * })())\n     * .then((values) => {\n     *     console.log(values); // => [123, 0]\n     * });\n     * ```\n     */\n    Yaku.all = function all (iterable) {\n        var self = this\n        , p1 = newCapablePromise(self)\n        , res = []\n        , ret\n        ;\n\n        function reject (reason) {\n            settlePromise(p1, $rejected, reason);\n        }\n\n        ret = genTryCatcher(each)(iterable, function (item, i) {\n            self.resolve(item).then(function (value) {\n                res[i] = value;\n                if (!--ret) settlePromise(p1, $resolved, res);\n            }, reject);\n        });\n\n        if (ret === $tryErr) return self.reject(ret.e);\n\n        if (!ret) settlePromise(p1, $resolved, []);\n\n        return p1;\n    };\n\n    /**\n     * The ES6 Symbol object that Yaku should use, by default it will use the\n     * global one.\n     * @type {Object}\n     * @example\n     * ```js\n     * var core = require(\"core-js/library\");\n     * var Promise = require(\"yaku\");\n     * Promise.Symbol = core.Symbol;\n     * ```\n     */\n    Yaku.Symbol = root[$Symbol] || {};\n\n    // To support browsers that don't support `Object.defineProperty`.\n    genTryCatcher(function () {\n        Object.defineProperty(Yaku, getSpecies(), {\n            get: function () { return this; }\n        });\n    })();\n\n    /**\n     * Use this api to custom the species behavior.\n     * https://tc39.github.io/ecma262/#sec-speciesconstructor\n     * @param {Any} O The current this object.\n     * @param {Function} defaultConstructor\n     */\n    Yaku.speciesConstructor = function (O, D) {\n        var C = O.constructor;\n\n        return C ? (C[getSpecies()] || D) : D;\n    };\n\n    /**\n     * Catch all possibly unhandled rejections. If you want to use specific\n     * format to display the error stack, overwrite it.\n     * If it is set, auto `console.error` unhandled rejection will be disabled.\n     * @param {Any} reason The rejection reason.\n     * @param {Yaku} p The promise that was rejected.\n     * @example\n     * ```js\n     * var Promise = require('yaku');\n     * Promise.onUnhandledRejection = (reason) => {\n     *     console.error(reason);\n     * };\n     *\n     * // The console will log an unhandled rejection error message.\n     * Promise.reject('my reason');\n     *\n     * // The below won't log the unhandled rejection error message.\n     * Promise.reject('v').catch(() => {});\n     * ```\n     */\n    Yaku.unhandledRejection = function (reason, p) {\n        try {\n            root.console.error(\n                $unhandledRejectionMsg,\n                isLongStackTrace ? p.longStack : genStackInfo(reason, p)\n            );\n        } catch (e) {} // eslint-disable-line\n    };\n\n    /**\n     * Emitted whenever a Promise was rejected and an error handler was\n     * attached to it (for example with `.catch()`) later than after an event loop turn.\n     * @param {Any} reason The rejection reason.\n     * @param {Yaku} p The promise that was rejected.\n     */\n    Yaku.rejectionHandled = $noop;\n\n    /**\n     * It is used to enable the long stack trace.\n     * Once it is enabled, it can't be reverted.\n     * While it is very helpful in development and testing environments,\n     * it is not recommended to use it in production. It will slow down\n     * application and eat up memory.\n     * It will add an extra property `longStack` to the Error object.\n     * @example\n     * ```js\n     * var Promise = require('yaku');\n     * Promise.enableLongStackTrace();\n     * Promise.reject(new Error(\"err\")).catch((err) => {\n     *     console.log(err.longStack);\n     * });\n     * ```\n     */\n    Yaku.enableLongStackTrace = function () {\n        isLongStackTrace = true;\n    };\n\n    /**\n     * Only Node has `process.nextTick` function. For browser there are\n     * so many ways to polyfill it. Yaku won't do it for you, instead you\n     * can choose what you prefer. For example, this project\n     * [setImmediate](https://github.com/YuzuJS/setImmediate).\n     * By default, Yaku will use `process.nextTick` on Node, `setTimeout` on browser.\n     * @type {Function}\n     * @example\n     * ```js\n     * var Promise = require('yaku');\n     * Promise.nextTick = fn => window.setImmediate(fn);\n     * ```\n     * @example\n     * You can even use sync resolution if you really know what you are doing.\n     * ```js\n     * var Promise = require('yaku');\n     * Promise.nextTick = fn => fn();\n     * ```\n     */\n    Yaku.nextTick = process ?\n        process.nextTick :\n        function (fn) { setTimeout(fn); };\n\n    // ********************** Private **********************\n\n    Yaku._Yaku = 1;\n\n    /**\n     * All static variable name will begin with `$`. Such as `$rejected`.\n     * @private\n     */\n\n    // ******************************* Utils ********************************\n\n    function getSpecies () {\n        return Yaku[$Symbol][$species] || $speciesKey;\n    }\n\n    function extendPrototype (src, target) {\n        for (var k in target) {\n            src.prototype[k] = target[k];\n        }\n        return src;\n    }\n\n    function isObject (obj) {\n        return obj && typeof obj === \"object\";\n    }\n\n    function isFunction (obj) {\n        return typeof obj === \"function\";\n    }\n\n    function isInstanceOf (a, b) {\n        return a instanceof b;\n    }\n\n    function isError (obj) {\n        return isInstanceOf(obj, Err);\n    }\n\n    function ensureType (obj, fn, msg) {\n        if (!fn(obj)) throw genTypeError(msg);\n    }\n\n    /**\n     * Wrap a function into a try-catch.\n     * @private\n     * @return {Any | $tryErr}\n     */\n    function tryCatcher () {\n        try {\n            return $tryCatchFn.apply($tryCatchThis, arguments);\n        } catch (e) {\n            $tryErr.e = e;\n            return $tryErr;\n        }\n    }\n\n    /**\n     * Generate a try-catch wrapped function.\n     * @private\n     * @param  {Function} fn\n     * @return {Function}\n     */\n    function genTryCatcher (fn, self) {\n        $tryCatchFn = fn;\n        $tryCatchThis = self;\n        return tryCatcher;\n    }\n\n    /**\n     * Generate a scheduler.\n     * @private\n     * @param  {Integer}  initQueueSize\n     * @param  {Function} fn `(Yaku, Value) ->` The schedule handler.\n     * @return {Function} `(Yaku, Value) ->` The scheduler.\n     */\n    function genScheduler (initQueueSize, fn) {\n        /**\n         * All async promise will be scheduled in\n         * here, so that they can be execute on the next tick.\n         * @private\n         */\n        var fnQueue = Arr(initQueueSize)\n        , fnQueueLen = 0;\n\n        /**\n         * Run all queued functions.\n         * @private\n         */\n        function flush () {\n            var i = 0;\n            while (i < fnQueueLen) {\n                fn(fnQueue[i], fnQueue[i + 1]);\n                fnQueue[i++] = $undefined;\n                fnQueue[i++] = $undefined;\n            }\n\n            fnQueueLen = 0;\n            if (fnQueue.length > initQueueSize) fnQueue.length = initQueueSize;\n        }\n\n        return function (v, arg) {\n            fnQueue[fnQueueLen++] = v;\n            fnQueue[fnQueueLen++] = arg;\n\n            if (fnQueueLen === 2) Yaku.nextTick(flush);\n        };\n    }\n\n    /**\n     * Generate a iterator\n     * @param  {Any} obj\n     * @private\n     * @return {Object || TypeError}\n     */\n    function each (iterable, fn) {\n        var len\n        , i = 0\n        , iter\n        , item\n        , ret\n        ;\n\n        if (!iterable) throw genTypeError($invalidArgument);\n\n        var gen = iterable[Yaku[$Symbol][$iterator]];\n        if (isFunction(gen))\n            iter = gen.call(iterable);\n        else if (isFunction(iterable.next)) {\n            iter = iterable;\n        }\n        else if (isInstanceOf(iterable, Arr)) {\n            len = iterable.length;\n            while (i < len) {\n                fn(iterable[i], i++);\n            }\n            return i;\n        } else\n            throw genTypeError($invalidArgument);\n\n        while (!(item = iter.next()).done) {\n            ret = genTryCatcher(fn)(item.value, i++);\n            if (ret === $tryErr) {\n                isFunction(iter[$return]) && iter[$return]();\n                throw ret.e;\n            }\n        }\n\n        return i;\n    }\n\n    /**\n     * Generate type error object.\n     * @private\n     * @param  {String} msg\n     * @return {TypeError}\n     */\n    function genTypeError (msg) {\n        return new TypeError(msg);\n    }\n\n    function genTraceInfo (noTitle) {\n        return (noTitle ? \"\" : $fromPrevious) + new Err().stack;\n    }\n\n\n    // *************************** Promise Helpers ****************************\n\n    /**\n     * Resolve the value returned by onFulfilled or onRejected.\n     * @private\n     * @param {Yaku} p1\n     * @param {Yaku} p2\n     */\n    var scheduleHandler = genScheduler(999, function (p1, p2) {\n        var x, handler;\n\n        // 2.2.2\n        // 2.2.3\n        handler = p1._s ? p2._onFulfilled : p2._onRejected;\n\n        // 2.2.7.3\n        // 2.2.7.4\n        if (handler === $undefined) {\n            settlePromise(p2, p1._s, p1._v);\n            return;\n        }\n\n        // 2.2.7.1\n        x = genTryCatcher(callHanler)(handler, p1._v);\n        if (x === $tryErr) {\n            // 2.2.7.2\n            settlePromise(p2, $rejected, x.e);\n            return;\n        }\n\n        settleWithX(p2, x);\n    });\n\n    var scheduleUnhandledRejection = genScheduler(9, function (p) {\n        if (!hashOnRejected(p)) {\n            p[$unhandled] = 1;\n            emitEvent($unhandledRejection, p);\n        }\n    });\n\n    function emitEvent (name, p) {\n        var browserEventName = \"on\" + name.toLowerCase()\n            , browserHandler = root[browserEventName];\n\n        if (process && process.listeners(name).length)\n            name === $unhandledRejection ?\n                process.emit(name, p._v, p) : process.emit(name, p);\n        else if (browserHandler)\n            browserHandler({ reason: p._v, promise: p });\n        else\n            Yaku[name](p._v, p);\n    }\n\n    function isYaku (val) { return val && val._Yaku; }\n\n    function newCapablePromise (Constructor) {\n        if (isYaku(Constructor)) return new Constructor($noop);\n\n        var p, r, j;\n        p = new Constructor(function (resolve, reject) {\n            if (p) throw genTypeError();\n\n            r = resolve;\n            j = reject;\n        });\n\n        ensureType(r, isFunction);\n        ensureType(j, isFunction);\n\n        return p;\n    }\n\n    /**\n     * It will produce a settlePromise function to user.\n     * Such as the resolve and reject in this `new Yaku (resolve, reject) ->`.\n     * @private\n     * @param  {Yaku} self\n     * @param  {Integer} state The value is one of `$pending`, `$resolved` or `$rejected`.\n     * @return {Function} `(value) -> undefined` A resolve or reject function.\n     */\n    function genSettler (self, state) {\n        return function (value) {\n            if (isLongStackTrace)\n                self[$settlerTrace] = genTraceInfo(true);\n\n            if (state === $resolved)\n                settleWithX(self, value);\n            else\n                settlePromise(self, state, value);\n        };\n    }\n\n    /**\n     * Link the promise1 to the promise2.\n     * @private\n     * @param {Yaku} p1\n     * @param {Yaku} p2\n     * @param {Function} onFulfilled\n     * @param {Function} onRejected\n     */\n    function addHandler (p1, p2, onFulfilled, onRejected) {\n        // 2.2.1\n        if (isFunction(onFulfilled))\n            p2._onFulfilled = onFulfilled;\n        if (isFunction(onRejected)) {\n            if (p1[$unhandled]) emitEvent($rejectionHandled, p1);\n\n            p2._onRejected = onRejected;\n        }\n\n        if (isLongStackTrace) p2._pre = p1;\n        p1[p1._pCount++] = p2;\n\n        // 2.2.6\n        if (p1._s !== $pending)\n            scheduleHandler(p1, p2);\n\n        // 2.2.7\n        return p2;\n    }\n\n    // iterate tree\n    function hashOnRejected (node) {\n        // A node shouldn't be checked twice.\n        if (node._umark)\n            return true;\n        else\n            node._umark = true;\n\n        var i = 0\n        , len = node._pCount\n        , child;\n\n        while (i < len) {\n            child = node[i++];\n            if (child._onRejected || hashOnRejected(child)) return true;\n        }\n    }\n\n    function genStackInfo (reason, p) {\n        var stackInfo = [];\n\n        function push (trace) {\n            return stackInfo.push(trace.replace(/^\\s+|\\s+$/g, \"\"));\n        }\n\n        if (isLongStackTrace) {\n            if (p[$settlerTrace])\n                push(p[$settlerTrace]);\n\n            // Hope you guys could understand how the back trace works.\n            // We only have to iterate through the tree from the bottom to root.\n            (function iter (node) {\n                if (node && $promiseTrace in node) {\n                    iter(node._next);\n                    push(node[$promiseTrace] + \"\");\n                    iter(node._pre);\n                }\n            })(p);\n        }\n\n        return (reason && reason.stack ? reason.stack : reason) +\n            (\"\\n\" + stackInfo.join(\"\\n\")).replace($cleanStackReg, \"\");\n    }\n\n    function callHanler (handler, value) {\n        // 2.2.5\n        return handler(value);\n    }\n\n    /**\n     * Resolve or reject a promise.\n     * @private\n     * @param  {Yaku} p\n     * @param  {Integer} state\n     * @param  {Any} value\n     */\n    function settlePromise (p, state, value) {\n        var i = 0\n        , len = p._pCount;\n\n        // 2.1.2\n        // 2.1.3\n        if (p._s === $pending) {\n            // 2.1.1.1\n            p._s = state;\n            p._v = value;\n\n            if (state === $rejected) {\n                if (isLongStackTrace && isError(value)) {\n                    value.longStack = genStackInfo(value, p);\n                }\n\n                scheduleUnhandledRejection(p);\n            }\n\n            // 2.2.4\n            while (i < len) {\n                scheduleHandler(p, p[i++]);\n            }\n        }\n\n        return p;\n    }\n\n    /**\n     * Resolve or reject promise with value x. The x can also be a thenable.\n     * @private\n     * @param {Yaku} p\n     * @param {Any | Thenable} x A normal value or a thenable.\n     */\n    function settleWithX (p, x) {\n        // 2.3.1\n        if (x === p && x) {\n            settlePromise(p, $rejected, genTypeError($promiseCircularChain));\n            return p;\n        }\n\n        // 2.3.2\n        // 2.3.3\n        if (x !== $null && (isFunction(x) || isObject(x))) {\n            // 2.3.2.1\n            var xthen = genTryCatcher(getThen)(x);\n\n            if (xthen === $tryErr) {\n                // 2.3.3.2\n                settlePromise(p, $rejected, xthen.e);\n                return p;\n            }\n\n            if (isFunction(xthen)) {\n                if (isLongStackTrace && isYaku(x))\n                    p._next = x;\n\n                // Fix https://bugs.chromium.org/p/v8/issues/detail?id=4162\n                if (isYaku(x))\n                    settleXthen(p, x, xthen);\n                else\n                    Yaku.nextTick(function () {\n                        settleXthen(p, x, xthen);\n                    });\n            } else\n                // 2.3.3.4\n                settlePromise(p, $resolved, x);\n        } else\n            // 2.3.4\n            settlePromise(p, $resolved, x);\n\n        return p;\n    }\n\n    /**\n     * Try to get a promise's then method.\n     * @private\n     * @param  {Thenable} x\n     * @return {Function}\n     */\n    function getThen (x) { return x.then; }\n\n    /**\n     * Resolve then with its promise.\n     * @private\n     * @param  {Yaku} p\n     * @param  {Thenable} x\n     * @param  {Function} xthen\n     */\n    function settleXthen (p, x, xthen) {\n        // 2.3.3.3\n        var err = genTryCatcher(xthen, x)(function (y) {\n            // 2.3.3.3.3\n            // 2.3.3.3.1\n            x && (x = $null, settleWithX(p, y));\n        }, function (r) {\n            // 2.3.3.3.3\n            // 2.3.3.3.2\n            x && (x = $null, settlePromise(p, $rejected, r));\n        });\n\n        // 2.3.3.3.4.1\n        if (err === $tryErr && x) {\n            // 2.3.3.3.4.2\n            settlePromise(p, $rejected, err.e);\n            x = $null;\n        }\n    }\n\n})();\n\n\n//# sourceURL=webpack:///./node_modules/yaku/lib/yaku.js?");

/***/ }),

/***/ "./node_modules/zip-local/libs/ZipExport.js":
/*!**************************************************!*\
  !*** ./node_modules/zip-local/libs/ZipExport.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar async = __webpack_require__(/*! async */ \"./node_modules/async/lib/async.js\");\nvar ZippedFS = __webpack_require__(/*! ./ZippedFS.js */ \"./node_modules/zip-local/libs/ZippedFS.js\");\n\n/*****************************************************************************************\n******************************** PRIVATE HELPER FUNCTIONS ********************************\n*****************************************************************************************/\n\n/*\n * extracts an unzipped file to the disk asynchrnously\n * @param _path {String}: extraction path\n * @param jszip {JSZip}: the jszip object containg the unzipped file\n * @param callback {Function}: the function to be called when extracting is done\n */\nfunction extract_to(_path, jszip, callback) {\n\n    var extraction_path = _path === null ? \"./\" : path.normalize(_path);\n    if(extraction_path[extraction_path.length - 1] !== path.sep) {\n        extraction_path += path.sep;\n    }\n\n    // make sure that the extraction path points to a existing directory\n    fs.stat(extraction_path, function (err, stats) {\n\n        if (err) {\n            callback(err);\n            return;\n        }\n\n        if (!stats.isDirectory()) {\n            callback(new Error(extraction_path + \" is not a directory\"));\n            return;\n        }\n\n        // sort out the unzipped file to directories and files\n        var dirs = [];\n        var files = [];\n        for (var name in jszip.files) {\n\n            var entry = jszip.files[name];\n\n            if (entry.dir)\n                dirs.push(name);\n            else\n                files.push(name);\n        }\n\n        // sort the directories ascendingy by level\n        dirs.sort(function (a, b) {\n            function dir_sep_count(dir) { return (dir.match(/\\//g) || []).length; }\n\n            return dir_sep_count(a) - dir_sep_count(b);\n        });\n\n\n        // create the directories\n        async.eachSeries(dirs, function (dir, end_iteration) {\n\n            //check first if the directory exists\n            fs.stat(extraction_path + dir, function(err, stats) {\n                if((err && err.code === \"ENOENT\") || !stats.isDirectory()) {\n                    // create the directory if it doesn't exist\n                    fs.mkdir(extraction_path + dir, function (err) {\n                        // end of this iteration\n                        if(err) {\n                            end_iteration(err);\n                            return;\n                        }\n                        end_iteration();\n                    });\n                }\n                else if(err && err.code !== \"ENOENT\") {\n                    end_iteration(err);\n                    return;\n                }\n                else {\n                    end_iteration();\n                }\n            });\n\n        }, function (err) {\n\n            if (err) {\n                callback(err);\n                return;\n            }\n\n            // write the files\n            async.each(files, function (file, end_iteration) {\n\n                var data = jszip.file(file).asNodeBuffer();\n\n                fs.writeFile(extraction_path + file, data, function (err) {\n\n                    if (err) {\n                        end_iteration(err);\n                        return;\n                    }\n\n                    // end of this iteration\n                    end_iteration();\n\n                });\n            }, function (err) {\n\n                if(err) {\n                    callback(err);\n                    return;\n                }\n\n                // invoke the callback\n                callback(null);\n            });\n        });\n    });\n}\n\n/*\n * extracts an unzipped file to the disk synchrnously\n * @param _path {String}: extraction path\n * @param jszip {JSZip}: the jszip object containg the unzipped file\n */\nfunction extract_to_sync(_path, jszip) {\n\n    var extraction_path = _path === null ? \"./\" : path.normalize(_path);\n    if(extraction_path[extraction_path.length - 1] !== path.sep) {\n        extraction_path += path.sep;\n    }\n\n    // make sure that the extraction path points to a existing directory\n    var stats;\n    try { stats = fs.statSync(extraction_path); }\n    catch (err) { throw new Error(extraction_path + \" doesn't exist\"); }\n    if (!stats.isDirectory())\n        throw new Error(extraction_path + \" is not a directory\");\n\n    // sort out the unzipped file to directories and files\n    var dirs = [];\n    var files = [];\n    for (var name in jszip.files) {\n\n        var entry = jszip.files[name];\n\n        if (entry.dir)\n            dirs.push(name);\n        else\n            files.push(name);\n    }\n\n    // sort the directories ascendingy by level\n    dirs.sort(function (a, b) {\n        function dir_sep_count(dir) { return (dir.match(/\\//g) || []).length; }\n\n        return dir_sep_count(a) - dir_sep_count(b);\n    });\n\n\n    // create the directories\n    dirs.forEach(function (dir) {\n        try {\n            var stats = fs.statSync(extraction_path + dir);\n            if(!stats.isDirectory()) {\n                throw new Error(\"!dir\");\n            }\n        }\n        catch(err) {\n            if(err.code === \"ENOENT\" || err.message === \"!dir\") {\n                fs.mkdirSync(extraction_path + dir);\n            }\n            else {\n                throw err;\n            }\n        }\n    });\n\n    // write the files\n    files.forEach(function (file) {\n\n        var data = jszip.file(file).asNodeBuffer();\n\n        fs.writeFileSync(extraction_path + file, data);\n    });\n\n}\n\n\n/*****************************************************************************************\n********************************** MODULE PUBLIC APIS ************************************\n***** THE MODULE CONTAINS THE APIS THAT DEAL WITH EXPORTING AFTER ZIPPING IS COMPLETE ****\n*****************************************************************************************/\n\n/*\n * constructs a ZipExport object out of a JSZip object\n * @param jszip {JSZip}: the JSZip object\n * @param unzipped {Boolean}: a flag to indicate if the source jszip was from an unzipped file\n * @param async {Boolean}: a flag to indicate whether the zipping was asynchrnously\n */\nfunction ZipExport(jszip, unzipped, async) {\n\n    // hold the JSZip for exporting\n    this.content = jszip;\n\n    // determines if the exported will be compressed\n    this.compressed = false;\n\n    // determines if the source is an unzipped file\n    this.src_unzipped = unzipped ? true : false;\n\n    // determines if the exported file will be written asynchronously\n    this.save_async = async ? true : false;\n}\n\n/*\n * returns the associated JSZip object for low level operations\n * @returns {JSZip}: the associated JSZip object\n */\nZipExport.prototype.lowLevel = function () {\n\n    return this.content;\n}\n\n/*\n * sets the object so that the exported format will be compressed\n */\nZipExport.prototype.compress = function () {\n\n    if(!this.src_unzipped)\n        this.compressed = true;\n\n    return this;\n}\n\n/*\n * returns the zipped/unzipped file representation in memory\n * @return {Buffer|ZippedFS}: Buffer for a zipped file, a ZippedFS object for unzipped\n */\nZipExport.prototype.memory = function() {\n\n    if (!this.src_unzipped) {\n\n        // generate the zipped buffer\n        var buff = this.content.generate({\n            type: \"nodebuffer\",\n            compression: this.compressed ? \"DEFLATE\" : undefined\n        });\n\n        return new Buffer(buff);\n    }\n    else {\n\n        // return a ZippedFS object of the unzipped file\n        return new ZippedFS(this.content);\n    }\n}\n\n/*\n * writes the zipped/unzipped file to disk\n * @param _path {String}: path to the output file\n * @param _callback {Function}: the function to be called when the save is done (only in async zipping)\n */\nZipExport.prototype.save = function (_path, _callback) {\n\n    var callback = _callback || function () { };\n\n    if (!this.src_unzipped) {\n        // generate the zipped buffer\n        var buff = this.content.generate({\n            type: \"nodebuffer\",\n            compression: this.compressed ? \"DEFLATE\" : undefined\n        });\n\n        var normalized_path = path.normalize(_path);\n\n        // write the new file\n        if (!this.save_async) {\n\n            fs.writeFileSync(normalized_path, buff);\n\n        }\n        else\n            fs.writeFile(normalized_path, buff, function (err) {\n\n                if (err) {\n                    callback(err);\n                    return;\n                }\n\n                //invoke the callback\n                callback(null);\n\n            });\n    }\n    else {\n\n        // extract the unzipped file to given directory\n        if (!this.save_async)\n            extract_to_sync(_path ? _path : null, this.content);\n        else\n            extract_to(_path ? _path : null, this.content, callback);\n    }\n}\n\n\nmodule.exports = ZipExport;\n\n\n//# sourceURL=webpack:///./node_modules/zip-local/libs/ZipExport.js?");

/***/ }),

/***/ "./node_modules/zip-local/libs/ZippedFS.js":
/*!*************************************************!*\
  !*** ./node_modules/zip-local/libs/ZippedFS.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/*****************************************************************************************\n***** THE MODULE CONTAINS THE APIS THAT DEAL WITH READING FILES FROM AN UNZIPPED FILE ****\n*****************************************************************************************/\n\n/*\n * constructs a ZippedFS object out of a unzipped JSZip object\n * @param jszip {JSZip}: the JSZip object\n */\nfunction ZippedFS(jszip) {\n\n    // holds the content of the unzipped file\n    this.unzipped_file = jszip;\n    \n    // holds a list of the files in the unzipped file\n    this.files_list = [];\n\n    // populate the files list\n    for (var name in this.unzipped_file.files) {\n        \n        var entry = this.unzipped_file.files[name];\n        if (!entry.dir)\n            this.files_list.push(name);\n    }\n}\n\n/*\n * returns the list of the files in the unzipped file\n * @return {Array}: a list of file paths in the unzipped file\n */\nZippedFS.prototype.contents = function () {\n    return this.files_list;\n}\n\n/*\n * reads a file in the unzipped file by its path\n * @param _path {String}: the path of the file inside the unzipped file\n * @param type {String}: the return type of the file, either buffer or text\n * @return {Buffer|String}: a buffer that contains the file or the file as text\n */\nZippedFS.prototype.read = function (_path, type) {\n\n    if (this.files_list.indexOf(_path) !== -1) {\n        \n        if (type === 'buffer')\n            return this.unzipped_file.file(_path).asNodeBuffer();\n        else if (type === 'text')\n            return this.unzipped_file.file(_path).asText();\n        else\n            throw new Error(\"Unrecognized type\");\n    }\n    else\n        throw new Error(_path + \" doesn't exist within the unzipped file\");\n}\n\n\nmodule.exports = ZippedFS; \n\n \n\n//# sourceURL=webpack:///./node_modules/zip-local/libs/ZippedFS.js?");

/***/ }),

/***/ "./node_modules/zip-local/main.js":
/*!****************************************!*\
  !*** ./node_modules/zip-local/main.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar JSZip = __webpack_require__(/*! jszip */ \"./node_modules/jszip/lib/index.js\");\nvar Q = __webpack_require__(/*! q */ \"./node_modules/q/q.js\");\nvar async = __webpack_require__(/*! async */ \"./node_modules/async/lib/async.js\")\nvar ZipExport = __webpack_require__(/*! ./libs/ZipExport.js */ \"./node_modules/zip-local/libs/ZipExport.js\");\nvar ZippedFS = __webpack_require__(/*! ./libs/ZippedFS.js */ \"./node_modules/zip-local/libs/ZippedFS.js\");\n\n/*\n * factory method to create jszip objects where 'createFolders'\n * option is the default behavior everywhere\n */\n JSZip.make = function(data, options) {\n\n     // augments the options object with a 'createFolders' option\n     function augment(_opts) {\n         var opts = _opts || {};\n         opts.createFolders = opts.createFolders || true;\n         return opts;\n     }\n\n     var instance = new JSZip(data, augment(options));\n\n     var originals = {};\n     originals.load = instance.load;\n     originals.file = instance.file;\n\n     instance.load = function(data, options) {\n         return originals.load.call(instance, data, augment(options));\n     };\n\n     instance.file = function(name, data, options) {\n         if(!data) {\n             return originals.file.call(instance, name);\n         }\n\n         return originals.file.call(instance, name, data, augment(options));\n     };\n\n     return instance;\n };\n\n/*****************************************************************************************\n******************************** PRIVATE HELPER FUNCTIONS ********************************\n*****************************************************************************************/\n\n/*\n * recursively and asynchronously vistis the directory and all subdirectories and zips all files it finds\n * @param dir {String}: the path to the subdirectory\n * @param zipped_dir {JSZip}: the JSZip object with the new directory as root\n */\nfunction zip_dir(dir, zipped_dir) {\n\n    var deferred = Q.defer();\n\n    fs.readdir(dir, function (err, entries) {\n\n        if (err) {\n            deferred.reject(err);\n            return;\n        }\n\n        var entries_paths = entries.map(function (entry) {\n            return path.normalize(dir + path.sep + entry);\n        });\n\n        async.map(entries_paths, fs.stat, function (err, stats) {\n\n            if(err) {\n                deferred.reject(err);\n                return;\n            }\n\n            var entries_count = entries_paths.length;\n\n            // construct a an array of objects each contain an with-parent entry and its type\n            var typed_entries = Array(entries_count);\n            for (var i = 0; i < entries_count; i++) {\n\n                typed_entries[i] = {\n                    path: entries_paths[i],\n                    type: stats[i].isDirectory() ? 'dir' : 'file'\n                }\n            }\n\n            async.each(typed_entries, function (entry, callback) {\n\n                var parsed_entry_path = path.parse(entry.path);\n\n                if (entry.type === 'dir') {\n\n                    var new_zipped_dir = zipped_dir.folder(parsed_entry_path.base);\n\n                    // recursively zip the newly found dir\n                    Q.fcall(zip_dir, entry.path, new_zipped_dir).then(function () {\n                        //the end of this iteration\n                        callback();\n                    })\n                    .catch(function(error) {\n                        callback(error);\n                    }).done();\n                }\n                else {\n\n                    fs.readFile(entry.path, function (err, data) {\n\n                        if (err) {\n                            callback(err);\n                            return;\n                        }\n\n                        //zip the file within the current subdir\n                        zipped_dir.file(parsed_entry_path.base, data);\n\n                        // the end of this iteration\n                        callback();\n                    });\n                }\n\n            }, function (err) {\n\n                // here all iterations are over\n                if (err)\n                    deferred.reject(err);\n                else\n                    // resolve the deferred and fullfil the promise\n                    deferred.resolve();\n            });\n        });\n    });\n\n    return deferred.promise;\n}\n\n/*\n * recursively and synchronously visits the directory and all subdirectories and zips all files it finds\n * @param dir {String}: the path to the subdirectory\n * @param zipped_dir {JSZip}: the JSZip object with the new directory as root\n */\nfunction zip_dir_sync(dir, zipped_dir) {\n\n    var entries = fs.readdirSync(dir);\n    var entries_count = entries.length;\n\n    for(var i = 0; i < entries_count; i++) {\n        var entry = entries[i];\n        var entry_normalized_path = path.normalize(dir + path.sep + entry);\n        var entry_stats = fs.statSync(entry_normalized_path);\n\n        if(entry_stats.isDirectory()) {\n\n            var new_zipped_dir = zipped_dir.folder(entry);\n\n            // recursively zip the newly found dir\n            zip_dir_sync(entry_normalized_path, new_zipped_dir);\n        }\n        else {\n\n            var file = fs.readFileSync(entry_normalized_path);\n\n            // zip the file within current subdir\n            zipped_dir.file(entry, file);\n        }\n    }\n}\n\n\n/*****************************************************************************************\n********************************** MODULE PUBLIC APIS ************************************\n*****************************************************************************************/\n\n\nvar ZipLocal = {};  //the module container\n\nZipLocal.sync = {} // container for the synchronous version of the the api\n\n/*\n * zips a given file/directory asynchronously\n * @param entity {String || Buffer || ZippedFS}: the path to file/directory to zip, the buffer containing the file or a ZippedFS object of an unzipped file\n * @param _callback {Function}: the function to be called when the zipping is done\n * @param _shiftedCallback {Function}: the callback shifted to last argument if entity is a Buffer (optional)\n */\nZipLocal.zip = function (entity, _callback, _shiftedCallback) {\n\n    var zipped_obj = JSZip.make();\n\n    if (typeof entity === \"string\") {\n\n        // the entity is a path pointing to a file or a directory\n\n        // the callback is not shifted\n        var callback = _callback || function () { };\n\n        var normalized_path = path.normalize(entity);\n\n        fs.stat(normalized_path, function (err, stats) {\n\n            if (err) {\n                callback(err);\n                return;\n            }\n\n            if (stats.isDirectory()) {\n\n                // start zipping the directory\n                Q.fcall(zip_dir, normalized_path, zipped_obj).then(function () {\n\n                    // invoke the callback\n                    callback(null, new ZipExport(zipped_obj, false, true));\n                })\n                .catch(function(error) {\n                    callback(error);\n                }).done();\n            }\n            else {\n\n                var parsed_path = path.parse(normalized_path);\n                fs.readFile(normalized_path, function (err, file) {\n\n                    if (err) {\n                        callback(err);\n                        return;\n                    }\n\n                    zipped_obj.file(parsed_path.base, file);\n\n                    // invoke the callback\n                    callback(null, new ZipExport(zipped_obj, false, true));\n\n                });\n            }\n        });\n    }\n    else if (entity instanceof Buffer) {\n\n        // the entity is a buffer containing a file\n\n        // the _callback argument is now the name of the file in buffer\n        // the callback is shifted to _shiftedCallback argument\n        var name = _callback;\n        var callback = _shiftedCallback || function () { };\n\n        zipped_obj.file(name, entity);\n\n        // invoke the callback\n        callback(null, new ZipExport(zipped_obj, false, true));\n    }\n\n    else if (entity instanceof ZippedFS) {\n\n        // the entity is a ZippedFS from an unzipped file\n        var callback = _callback || function () { };\n\n        //invoke the callback\n        callback(null, new ZipExport(entity.unzipped_file, false, true));\n    }\n    else {\n        callback(new Error(\"Unsupported type: data is neither a path or a Buffer\"));\n    }\n}\n\n/*\n * unzips a given zip file asynchronously\n * @param file {String || Buffer}: the path to the zip file or the buffer containing it\n * @param _callback {Function}: the function to be called when the unzipping is done\n */\nZipLocal.unzip = function (file, _callback) {\n\n    var callback = _callback || function () { };\n    var zipped_obj = JSZip.make();\n\n    if (typeof file === \"string\") {\n\n        // file is a path that points to a zip file\n\n        var normalized_path = path.normalize(file);\n\n        fs.readFile(normalized_path, function (err, data) {\n\n            if(err) {\n                callback(err);\n                return;\n            }\n\n            zipped_obj.load(data);\n\n            //invoke the callback\n            callback(null, new ZipExport(zipped_obj, true, true))\n\n        });\n    }\n    else if (file instanceof Buffer) {\n\n        // file is a Buffer that contains the data\n\n        zipped_obj.load(file);\n\n        //invoke the callback\n        callback(null, new ZipExport(zipped_obj, true, true))\n    }\n    else {\n        callback(new Error(\"Unsupported type: data is neither a path or a Buffer\"));\n    }\n\n}\n\n/*\n * zips a given file/directory synchronously\n * @param entity {String || Buffer || ZippedFS}: the path to the file/directory to zip, a buffer containing a file or a ZippedFS object of an unzipped file\n * @param buffer_name {String}: the name of the file if entity is buffer (optional)\n * @return {ZipExport}: the ZipExport object that contains exporting interfaces\n */\nZipLocal.sync.zip = function(entity, buffer_name) {\n\n    var zipped_obj = JSZip.make();\n\n    if (typeof entity === \"string\") {\n\n        // the entity is a path pointing to a file or a directory\n\n        var normalized_path = path.normalize(entity);\n        var stats = fs.statSync(normalized_path);\n\n        if (stats.isDirectory()) {\n\n            // start zipping the directory\n            zip_dir_sync(normalized_path, zipped_obj);\n\n            return new ZipExport(zipped_obj);\n        }\n        else {\n\n            var parsed_path = path.parse(normalized_path);\n            var file = fs.readFileSync(normalized_path);\n\n            zipped_obj.file(parsed_path.base, file);\n\n        }\n    }\n    else if (entity instanceof Buffer) {\n\n        // the entity is a buffer containing a file\n\n        zipped_obj.file(buffer_name, entity);\n    }\n    else if (entity instanceof ZippedFS) {\n\n        // the entity is a ZippedFS from an unzipped file\n\n        //change the zipped_obj\n        zipped_obj = entity.unzipped_file;\n    }\n    else {\n        throw new Error(\"Unsupported type: data is neither a path or a Buffer\");\n    }\n\n    return new ZipExport(zipped_obj);\n}\n\n/*\n * unzips a given zip file synchrnously\n * @param file {String || Buffer}: the path to the zip file or the buffer containing it\n * @return {ZipExport}: the ZipExport object that contains exporting interfaces\n */\nZipLocal.sync.unzip = function (file) {\n\n    var zipped_obj = JSZip.make();\n\n    if (typeof file === \"string\") {\n\n        // file is a path that points to a zip file\n\n        var normalized_path = path.normalize(file);\n\n        var data = fs.readFileSync(normalized_path);\n\n        zipped_obj.load(data);\n    }\n    else if (file instanceof Buffer) {\n\n        // file is a Buffer that contains the data\n\n        zipped_obj.load(file);\n    }\n    else {\n        throw new Error(\"Unsupported type: data is neither a path or a Buffer\");\n    }\n\n    return new ZipExport(zipped_obj, true, false);\n};\n\n\nmodule.exports = ZipLocal;\n\n\n//# sourceURL=webpack:///./node_modules/zip-local/main.js?");

/***/ }),

/***/ "./src/background.js":
/*!***************************!*\
  !*** ./src/background.js ***!
  \***************************/
/*! no exports provided */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! electron */ \"electron\");\n/* harmony import */ var electron__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(electron__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var vue_cli_plugin_electron_builder_lib__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! vue-cli-plugin-electron-builder/lib */ \"./node_modules/vue-cli-plugin-electron-builder/lib/index.js\");\n/* harmony import */ var _start__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./start */ \"./src/start.js\");\n\n\n\nconst ipc = __webpack_require__(/*! electron */ \"electron\").ipcMain\nconst path = __webpack_require__(/*! path */ \"path\")\n\n\nconst isDevelopment = \"development\" !== 'production'\n// Keep a global reference of the window object, if you don't, the window will\n// be closed automatically when the JavaScript object is garbage collected.\nlet win\n// Scheme must be registered before the app is ready\nelectron__WEBPACK_IMPORTED_MODULE_0__[\"protocol\"].registerSchemesAsPrivileged([{ scheme: 'app', privileges: { secure: true, standard: true } }])\nipc.on('deploy', (sys, item) => {\n  Object(_start__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(item)  //\n})\nfunction createWindow() {\n  // Create the browser window.\n  win = new electron__WEBPACK_IMPORTED_MODULE_0__[\"BrowserWindow\"]({\n    width: 900, height: 600, webPreferences: {\n      nodeIntegration: true\n    }\n  })\n\n  if (true) {\n    // Load the url of the dev server if in development mode\n    win.loadURL(\"http://localhost:8080/\")\n    if (!process.env.IS_TEST) win.webContents.openDevTools()\n  } else {}\n\n  win.on('closed', () => {\n    win = null\n  })\n}\n\n// Quit when all windows are closed.\nelectron__WEBPACK_IMPORTED_MODULE_0__[\"app\"].on('window-all-closed', () => {\n  // On macOS it is common for applications and their menu bar\n  // to stay active until the user quits explicitly with Cmd + Q\n  if (process.platform !== 'darwin') {\n    electron__WEBPACK_IMPORTED_MODULE_0__[\"app\"].quit()\n  }\n})\n\nelectron__WEBPACK_IMPORTED_MODULE_0__[\"app\"].on('activate', () => {\n  // On macOS it's common to re-create a window in the app when the\n  // dock icon is clicked and there are no other windows open.\n  if (win === null) {\n    createWindow()\n  }\n})\n\n// This method will be called when Electron has finished\n// initialization and is ready to create browser windows.\n// Some APIs can only be used after this event occurs.\nelectron__WEBPACK_IMPORTED_MODULE_0__[\"app\"].on('ready', async () => {\n  if (isDevelopment && !process.env.IS_TEST) {\n    // Install Vue Devtools\n    // Devtools extensions are broken in Electron 6.0.0 and greater\n    // See https://github.com/nklayman/vue-cli-plugin-electron-builder/issues/378 for more info\n    // Electron will not launch with Devtools extensions installed on Windows 10 with dark mode\n    // If you are not using Windows 10 dark mode, you may uncomment these lines\n    // In addition, if the linked issue is closed, you can upgrade electron and uncomment these lines\n    // try {\n    //   await installVueDevtools()\n    // } catch (e) {\n    //   console.error('Vue Devtools failed to install:', e.toString())\n    // }\n\n  }\n  createWindow()\n})\n\n// Exit cleanly on request from parent process in development mode.\nif (isDevelopment) {\n  if (process.platform === 'win32') {\n    process.on('message', data => {\n      if (data === 'graceful-exit') {\n        electron__WEBPACK_IMPORTED_MODULE_0__[\"app\"].quit()\n      }\n    })\n  } else {\n    process.on('SIGTERM', () => {\n      electron__WEBPACK_IMPORTED_MODULE_0__[\"app\"].quit()\n    })\n  }\n}\n\n\n//# sourceURL=webpack:///./src/background.js?");

/***/ }),

/***/ "./src/start.js":
/*!**********************!*\
  !*** ./src/start.js ***!
  \**********************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _store__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./store */ \"./src/store.js\");\n\r\nvar start = async (item) => {\r\n    const fs = __webpack_require__(/*! fs */ \"fs\")\r\n    const path = __webpack_require__(/*! path */ \"path\")\r\n    const zipper = __webpack_require__(/*! zip-local */ \"./node_modules/zip-local/main.js\")\r\n    const shell = __webpack_require__(/*! shelljs */ \"./node_modules/shelljs/shell.js\")\r\n    const node_ssh = __webpack_require__(/*! node-ssh */ \"./node_modules/node-ssh/lib/index.js\")\r\n    let SSH = new node_ssh()\r\n    shell.config.execPath = path.join('C:', 'Program Files', 'nodejs', 'node.exe')\r\n    const config = {\r\n        SERVER_PATH: item.location, // ssh\r\n        SSH_USER: item.ssh, // ssh \r\n        SSH_KEY: item.password, // ssh  \r\n        PATH: item.addressServer, // \r\n        distDir: path.resolve(item.addressLocal), // \r\n        distZipPath: path.resolve(item.addressLocal, 'dist.zip') // ,\r\n    }\r\n    // loggs\r\n    // \r\n    const compileDist = async () => {\r\n        //  \r\n        _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", '')\r\n        shell.cd(path.resolve(config.distDir, '../'))\r\n        _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", '')\r\n        _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", path.resolve(config.distDir, '../'))\r\n        _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", '')\r\n        shell.exec(`npm run build`)\r\n        _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", '')\r\n    }\r\n    // ********* dist  *********\r\n    const zipDist = async () => {\r\n        try {\r\n            if (fs.existsSync(config.distZipPath)) {\r\n                _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", 'dist.zip, ')\r\n                fs.unlinkSync(config.distZipPath)\r\n            } else {\r\n                _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", 'zip')\r\n            }\r\n            await zipper.sync.zip(config.distDir).compress().save(config.distZipPath);\r\n            _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", '')\r\n        } catch (error) {\r\n            _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", error)\r\n            _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", 'dist')\r\n        }\r\n    }\r\n    // ********* ssh *********\r\n    const connectSSh = async () => {\r\n        _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", ` ${config.SERVER_PATH}`)\r\n        try {\r\n            await SSH.connect({\r\n                host: config.SERVER_PATH,\r\n                username: config.SSH_USER,\r\n                password: config.SSH_KEY\r\n            })\r\n            _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", 'SSH ')\r\n        } catch (error) {\r\n            _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", 'SSH ');\r\n        }\r\n    }\r\n    // *********  *********\r\n    const runCommond = async (commond) => {\r\n        const result = await SSH.exec(commond, [], { cwd: config.PATH })\r\n        _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", result)\r\n    }\r\n    const commonds = [`ls`, `rm -rf *`]\r\n    // *********  *********\r\n    const runBeforeCommand = async () => {\r\n        for (let i = 0; i < commonds.length; i++) {\r\n            await runCommond(commonds[i])\r\n        }\r\n    }\r\n    // ********* ssh  *********\r\n    const uploadZipBySSH = async () => {\r\n        // ssh\r\n        await connectSSh()\r\n        // \r\n        await runBeforeCommand()\r\n        // \r\n        // let spinner = ora('').start()\r\n        try {\r\n            await SSH.putFile(config.distZipPath, config.PATH + '/dist.zip')\r\n            _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", \", \")\r\n            await runCommond('unzip ./dist.zip')\r\n            await runCommond('rm  ./dist.zip')\r\n        } catch (error) {\r\n            _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", '')\r\n        }\r\n    }\r\n    // *********  *********\r\n    const runTask = async () => {\r\n        await compileDist()\r\n        await zipDist()\r\n        await uploadZipBySSH()\r\n        _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", '!')\r\n        // defaultLog('')\r\n        await fs.unlinkSync(config.distZipPath)\r\n        _store__WEBPACK_IMPORTED_MODULE_0__[\"default\"].commit(\"setPrompt\", '!')\r\n        SSH.dispose()\r\n        // exit process\r\n        // process.exit(1)\r\n    }\r\n    runTask()\r\n}\r\n/* harmony default export */ __webpack_exports__[\"default\"] = (start);\n\n//# sourceURL=webpack:///./src/start.js?");

/***/ }),

/***/ "./src/store.js":
/*!**********************!*\
  !*** ./src/store.js ***!
  \**********************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var vue__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! vue */ \"./node_modules/vue/dist/vue.runtime.esm.js\");\n/* harmony import */ var vuex__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! vuex */ \"./node_modules/vuex/dist/vuex.esm.js\");\n\n\n\nvue__WEBPACK_IMPORTED_MODULE_0__[\"default\"].use(vuex__WEBPACK_IMPORTED_MODULE_1__[\"default\"])\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (new vuex__WEBPACK_IMPORTED_MODULE_1__[\"default\"].Store({\n  state: {\n    Prompt: []\n  },\n  mutations: {\n    setPrompt(state, text) {\n      state.Prompt.push(text)\n    },\n    delPrompt(state) {\n      state.Prompt = []\n    },\n  },\n  actions: {\n\n  }\n}));\n\n\n//# sourceURL=webpack:///./src/store.js?");

/***/ }),

/***/ 0:
/*!*********************************!*\
  !*** multi ./src/background.js ***!
  \*********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = __webpack_require__(/*! f:\\CODE\\deploy-electron\\electron\\src\\background.js */\"./src/background.js\");\n\n\n//# sourceURL=webpack:///multi_./src/background.js?");

/***/ }),

/***/ "assert":
/*!*************************!*\
  !*** external "assert" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"assert\");\n\n//# sourceURL=webpack:///external_%22assert%22?");

/***/ }),

/***/ "buffer":
/*!*************************!*\
  !*** external "buffer" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"buffer\");\n\n//# sourceURL=webpack:///external_%22buffer%22?");

/***/ }),

/***/ "child_process":
/*!********************************!*\
  !*** external "child_process" ***!
  \********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"child_process\");\n\n//# sourceURL=webpack:///external_%22child_process%22?");

/***/ }),

/***/ "constants":
/*!****************************!*\
  !*** external "constants" ***!
  \****************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"constants\");\n\n//# sourceURL=webpack:///external_%22constants%22?");

/***/ }),

/***/ "crypto":
/*!*************************!*\
  !*** external "crypto" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"crypto\");\n\n//# sourceURL=webpack:///external_%22crypto%22?");

/***/ }),

/***/ "dns":
/*!**********************!*\
  !*** external "dns" ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"dns\");\n\n//# sourceURL=webpack:///external_%22dns%22?");

/***/ }),

/***/ "electron":
/*!***************************!*\
  !*** external "electron" ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"electron\");\n\n//# sourceURL=webpack:///external_%22electron%22?");

/***/ }),

/***/ "events":
/*!*************************!*\
  !*** external "events" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"events\");\n\n//# sourceURL=webpack:///external_%22events%22?");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"fs\");\n\n//# sourceURL=webpack:///external_%22fs%22?");

/***/ }),

/***/ "http":
/*!***********************!*\
  !*** external "http" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"http\");\n\n//# sourceURL=webpack:///external_%22http%22?");

/***/ }),

/***/ "https":
/*!************************!*\
  !*** external "https" ***!
  \************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"https\");\n\n//# sourceURL=webpack:///external_%22https%22?");

/***/ }),

/***/ "net":
/*!**********************!*\
  !*** external "net" ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"net\");\n\n//# sourceURL=webpack:///external_%22net%22?");

/***/ }),

/***/ "os":
/*!*********************!*\
  !*** external "os" ***!
  \*********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"os\");\n\n//# sourceURL=webpack:///external_%22os%22?");

/***/ }),

/***/ "path":
/*!***********************!*\
  !*** external "path" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"path\");\n\n//# sourceURL=webpack:///external_%22path%22?");

/***/ }),

/***/ "stream":
/*!*************************!*\
  !*** external "stream" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"stream\");\n\n//# sourceURL=webpack:///external_%22stream%22?");

/***/ }),

/***/ "url":
/*!**********************!*\
  !*** external "url" ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"url\");\n\n//# sourceURL=webpack:///external_%22url%22?");

/***/ }),

/***/ "util":
/*!***********************!*\
  !*** external "util" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"util\");\n\n//# sourceURL=webpack:///external_%22util%22?");

/***/ }),

/***/ "zlib":
/*!***********************!*\
  !*** external "zlib" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"zlib\");\n\n//# sourceURL=webpack:///external_%22zlib%22?");

/***/ })

/******/ });